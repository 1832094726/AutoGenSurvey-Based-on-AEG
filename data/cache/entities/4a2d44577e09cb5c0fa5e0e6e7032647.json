{
  "entities": [
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_LatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Latent Left-Linking Model (L3M)",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF",
          "F1"
        ],
        "architecture": {
          "components": [
            "Pairwise Scorer",
            "Left-Linking Model"
          ],
          "connections": [
            "Mention-Pair Granularity",
            "Best-Left-Link Inference"
          ],
          "mechanisms": [
            "Efficient Inference",
            "Knowledge-Based Constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Pairwise Weight Vector",
            "Temperature Parameter"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Score",
          "Feature Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ConstrainedLatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Constrained Latent Left-Linking Model (CL3M)",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF",
          "F1"
        ],
        "architecture": {
          "components": [
            "Pairwise Scorer",
            "Left-Linking Model",
            "Constraint Injection"
          ],
          "connections": [
            "Mention-Pair Granularity",
            "Best-Left-Link Inference"
          ],
          "mechanisms": [
            "Efficient Inference",
            "Domain-Specific Constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Pairwise Weight Vector",
            "Temperature Parameter"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Score",
          "Feature Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ProbabilisticLatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Probabilistic Latent Left-Linking Model (PL3M)",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF",
          "F1"
        ],
        "architecture": {
          "components": [
            "Pairwise Scorer",
            "Probabilistic Left-Linking Model"
          ],
          "connections": [
            "Mention-Pair Granularity",
            "Best-Left-Link Inference"
          ],
          "mechanisms": [
            "Efficient Inference",
            "Probability Distribution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Likelihood-Based Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Pairwise Weight Vector",
            "Temperature Parameter"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Score",
          "Feature Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE_2004",
        "entity_type": "Dataset",
        "name": "ACE 2004",
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Ontonotes_2012",
        "entity_type": "Dataset",
        "name": "Ontonotes-5.0",
        "year": 2012,
        "creators": [
          "Pradhan et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_Coreference",
        "entity_type": "Metric",
        "name": "MUC",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "metric_entity": {
        "metric_id": "BCUB_Coreference",
        "entity_type": "Metric",
        "name": "BCUB",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "metric_entity": {
        "metric_id": "CEAF_EntityBased",
        "entity_type": "Metric",
        "name": "Entity-based CEAF",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Average",
        "entity_type": "Metric",
        "name": "Average F1",
        "category": "Coreference Evaluation",
        "formula": "Average of MUC, BCUB, and CEAF F1 scores"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_BestLeftLink",
        "entity_type": "Algorithm",
        "name": "Best-Left-Link",
        "year": 2013,
        "authors": [
          "Ng and Cardie",
          "Bengtson and Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE_2004",
          "Ontonotes_2012"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_EntityBased",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Pairwise Scoring",
            "Transitive Closure"
          ],
          "connections": [
            "Mention Pair Scoring",
            "Clustering"
          ],
          "mechanisms": [
            "Left-Linking Strategy"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Binary Training Data Generation"
          ],
          "parameter_tuning": [
            "Threshold Tuning"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2009_SpanningTree",
        "entity_type": "Algorithm",
        "name": "Spanning Tree",
        "year": 2009,
        "authors": [
          "Yu and Joachims"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE_2004",
          "Ontonotes_2012"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_EntityBased",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Latent Spanning Forest"
          ],
          "connections": [
            "Mention Pair Scoring",
            "Clustering"
          ],
          "mechanisms": [
            "Latent Structure"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Prediction"
          ],
          "parameter_tuning": [
            "Loss-Based Margin"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Finley2005_SupervisedClustering",
        "entity_type": "Algorithm",
        "name": "Supervised Clustering",
        "year": 2005,
        "authors": [
          "Finley and Joachims"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE_2004",
          "Ontonotes_2012"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_EntityBased",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Support Vector Machines"
          ],
          "connections": [
            "Mention Pair Scoring",
            "Clustering"
          ],
          "mechanisms": [
            "Correlational Clustering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Prediction"
          ],
          "parameter_tuning": [
            "Loss-Based Margin"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL_SharedTask_2011",
        "entity_type": "Dataset",
        "name": "CoNLL Shared Task 2011",
        "year": 2011,
        "creators": [
          "Pradhan et al."
        ],
        "domain": "Natural Language Processing",
        "description": "Shared task for coreference resolution"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL_SharedTask_2012",
        "entity_type": "Dataset",
        "name": "CoNLL Shared Task 2012",
        "year": 2012,
        "creators": [
          "Pradhan et al."
        ],
        "domain": "Natural Language Processing",
        "description": "Shared task for coreference resolution"
      }
    },
    {
      "metric_entity": {
        "metric_id": "RandIndex_Loss",
        "entity_type": "Metric",
        "name": "Rand Index Loss",
        "year": 1971,
        "authors": [
          "Rand"
        ],
        "category": "Clustering Evaluation",
        "description": "Measures the similarity between two data clusterings"
      }
    },
    {
      "metric_entity": {
        "metric_id": "B3_Score",
        "entity_type": "Metric",
        "name": "B3 Score",
        "year": 1998,
        "authors": [
          "Bagga and Baldwin"
        ],
        "category": "Coreference Evaluation",
        "description": "Measures the quality of coreference resolution"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_MaxMarginApproach",
        "entity_type": "Algorithm",
        "name": "Max-Margin Approach",
        "year": 2013,
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE_2004",
          "Ontonotes_2012"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_EntityBased",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Pairwise Scorer",
            "Latent Left-Linking Model"
          ],
          "connections": [
            "Pairwise Scorer -> Latent Left-Linking Model"
          ],
          "mechanisms": [
            "Max-Margin Optimization",
            "Loss Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "Concave Convex Procedure"
          ],
          "parameter_tuning": [
            "Regularization Parameter λ",
            "Threshold t"
          ]
        },
        "feature_processing": [
          "Pairwise Features Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ConstraintAugmentedScoring",
        "entity_type": "Algorithm",
        "name": "Constraint-Augmented Scoring Function",
        "year": 2013,
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE_2004",
          "Ontonotes_2012"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_EntityBased",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Latent Left-Linking Model",
            "Domain-Specific Constraints"
          ],
          "connections": [
            "Latent Left-Linking Model -> Domain-Specific Constraints"
          ],
          "mechanisms": [
            "Constraint Injection",
            "Weighted Sum of Constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Constraint Scores ρ"
          ]
        },
        "feature_processing": [
          "Pairwise Features Extraction",
          "Constraint Features"
        ]
      }
    },
    {
      "constraint_entity": {
        "constraint_id": "SameSpan_Constraint",
        "entity_type": "Constraint",
        "name": "SameSpan",
        "description": "Two mentions must be linked if they share the same surface text span and the number of words in the text span is larger than a threshold.",
        "year": 2013,
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ]
      }
    },
    {
      "constraint_entity": {
        "constraint_id": "SameDetNom_Constraint",
        "entity_type": "Constraint",
        "name": "SameDetNom",
        "description": "Two mentions must be linked if both mentions start with a determiner and the WordNet-based similarity score between the mention head words is above a threshold.",
        "year": 2013,
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ]
      }
    },
    {
      "constraint_entity": {
        "constraint_id": "SameProperName_Constraint",
        "entity_type": "Constraint",
        "name": "SameProperName",
        "description": "Two mentions must be linked if they are both proper names and the similarity score measured by a named entity-based similarity metric is higher than a threshold.",
        "year": 2013,
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ]
      }
    },
    {
      "constraint_entity": {
        "constraint_id": "ModifierMismatch_Constraint",
        "entity_type": "Constraint",
        "name": "ModifierMismatch",
        "description": "Prevents two mentions from being linked if the head modifiers conflict.",
        "year": 2013,
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ]
      }
    },
    {
      "constraint_entity": {
        "constraint_id": "PropertyMismatch_Constraint",
        "entity_type": "Constraint",
        "name": "PropertyMismatch",
        "description": "Prevents two mentions from being linked if their properties conflict.",
        "year": 2013,
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "PairwiseCompatibilityScore",
        "entity_type": "Metric",
        "name": "Pairwise Compatibility Score",
        "description": "Score indicating the compatibility of a pair of mentions",
        "category": "Coreference Resolution",
        "formula": "w · φ(j, i)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "LeftLinkProbability",
        "entity_type": "Metric",
        "name": "Left-Link Probability",
        "description": "Probability that mention i links to mention j",
        "category": "Coreference Resolution",
        "formula": "P r[j ← i; d, w] = e^(1/γ * (w · φ(i,j))) / Z_i(w, γ)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ClusterJoinProbability",
        "entity_type": "Metric",
        "name": "Cluster Join Probability",
        "description": "Probability that mention i joins an existing cluster c",
        "category": "Coreference Resolution",
        "formula": "P r[c ⊙ i; d, w] = Σ_{j∈c,0≤j<i} P r[j ← i; d, w]"
      }
    },
    {
      "metric_entity": {
        "metric_id": "KroneckerDeltaFunction",
        "entity_type": "Metric",
        "name": "Kronecker Delta Function",
        "description": "Function that puts probability 1 on the max-scoring mention and 0 elsewhere",
        "category": "Coreference Resolution",
        "formula": "δ(i, j) = 1 if i and j are not coreferent, 0 otherwise"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fernandes2012_LatentStructurePerceptron",
        "entity_type": "Algorithm",
        "name": "Latent Structure Perceptron",
        "year": 2012,
        "authors": [
          "E. R. Fernandes",
          "C. N. dos Santos",
          "R. L. Milidiu"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "Ontonotes-5.0",
          "ACE 2004"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Feature Induction",
            "Perceptron"
          ],
          "connections": [
            "Latent Structure"
          ],
          "mechanisms": [
            "Feature Induction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Induction Parameters"
          ]
        },
        "feature_processing": [
          "Feature Induction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Ontonotes_5.0_GoldMentions",
        "entity_type": "Dataset",
        "name": "Ontonotes-5.0 Gold Mentions",
        "description": "Gold mentions from Ontonotes-5.0 dataset",
        "domain": "Natural Language Processing",
        "year": 2012,
        "creators": [
          "Pradhan et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE_2004_GoldMentions",
        "entity_type": "Dataset",
        "name": "ACE 2004 Gold Mentions",
        "description": "Gold mentions from ACE 2004 dataset",
        "domain": "Natural Language Processing",
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_NamedEntities",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 Score for Named Entities",
        "category": "Coreference Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ENT_C",
        "entity_type": "Metric",
        "name": "ENT-C",
        "description": "Evaluation on clusters that contain at least one proper name mention",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined"
      }
    },
    {
      "metric_entity": {
        "metric_id": "PER_C",
        "entity_type": "Metric",
        "name": "PER-C",
        "description": "Evaluation on clusters that contain at least one 'Person' entity",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ORG_C",
        "entity_type": "Metric",
        "name": "ORG-C",
        "description": "Evaluation on clusters that contain at least one 'Organization' entity",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_NeuralNetworkDependencyParser",
        "entity_type": "Algorithm",
        "name": "Neural Network Dependency Parser",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English Penn Treebank",
          "Chinese Penn Treebank"
        ],
        "metrics": [
          "Unlabeled Attachment Score (UAS)",
          "Labeled Attachment Score (LAS)"
        ],
        "architecture": {
          "components": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Arc Label Embeddings",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Input Layer -> Hidden Layer",
            "Hidden Layer -> Softmax Layer"
          ],
          "mechanisms": [
            "Cube Activation Function",
            "Pre-trained Word Embeddings Initialization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Averaged Perceptron",
            "Mini-batched AdaGrad",
            "Dropout"
          ],
          "parameter_tuning": [
            "Embedding Size",
            "Hidden Layer Size",
            "Regularization Parameter",
            "Initial Learning Rate"
          ]
        },
        "feature_processing": [
          "Dense Features",
          "Pre-computed Matrix Multiplications"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "English_Penn_Treebank_2014",
        "entity_type": "Dataset",
        "name": "English Penn Treebank",
        "description": "A dataset for parsing English sentences.",
        "domain": "Natural Language Processing",
        "size": 39832,
        "year": 2014,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Chinese_Penn_Treebank_2014",
        "entity_type": "Dataset",
        "name": "Chinese Penn Treebank",
        "description": "A dataset for parsing Chinese sentences.",
        "domain": "Natural Language Processing",
        "size": 16091,
        "year": 2014,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Unlabeled_Attachment_Score_Parsing",
        "entity_type": "Metric",
        "name": "Unlabeled Attachment Score (UAS)",
        "description": "Measures the proportion of correctly attached words without considering labels.",
        "category": "Parsing Evaluation",
        "formula": "Number of correct attachments / Total number of attachments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Labeled_Attachment_Score_Parsing",
        "entity_type": "Metric",
        "name": "Labeled Attachment Score (LAS)",
        "description": "Measures the proportion of correctly attached words with correct labels.",
        "category": "Parsing Evaluation",
        "formula": "Number of correct labeled attachments / Total number of attachments"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_ArcStandardSystem",
        "entity_type": "Algorithm",
        "name": "Arc-Standard System",
        "year": 2014,
        "authors": [
          "Nivre, J."
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Stack",
            "Buffer",
            "Set of Dependency Arcs"
          ],
          "connections": [
            "LEFT-ARC",
            "RIGHT-ARC",
            "SHIFT"
          ],
          "mechanisms": [
            "Configuration Transition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Greedy Parsing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Feasible_Transitions_Count_Parsing",
        "entity_type": "Metric",
        "name": "Feasible Transitions Count",
        "description": "Number of feasible transitions in the parsing process",
        "category": "Parsing Evaluation",
        "formula": "Count of valid transitions in the parsing sequence"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_NeuralNetworkBasedParser",
        "entity_type": "Algorithm",
        "name": "Neural Network Based Parser",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Arc Label Embeddings"
          ],
          "mechanisms": [
            "Cube Activation Function",
            "Pre-trained Word Embeddings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Shortest Stack Oracle",
            "Cross-Entropy Loss",
            "L2 Regularization"
          ],
          "parameter_tuning": [
            "AdaGrad",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Dense Features",
          "Pre-computed Matrix Multiplications"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Cross_Entropy_Loss_Optimization",
        "entity_type": "Metric",
        "name": "Cross-Entropy Loss",
        "description": "A measure of the difference between the predicted probability distribution and the actual distribution.",
        "category": "Optimization",
        "formula": "-∑ log(pti)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "L2_Regularization_Parsing",
        "entity_type": "Metric",
        "name": "L2 Regularization",
        "description": "A technique to prevent overfitting by penalizing large weights.",
        "category": "Regularization",
        "formula": "λ/2 * ||θ||^2"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL_Dependencies_2014",
        "entity_type": "Dataset",
        "name": "CoNLL Syntactic Dependencies",
        "description": "A dataset for syntactic dependencies derived from the Penn Treebank.",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Johansson, R.",
          "Nugues, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Stanford_Basic_Dependencies_2014",
        "entity_type": "Dataset",
        "name": "Stanford Basic Dependencies",
        "description": "A dataset for basic dependencies derived from the Penn Treebank.",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "de Marneffe, M.-C.",
          "MacCartney, B.",
          "Manning, C. D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_CubeActivationFunction",
        "entity_type": "Algorithm",
        "name": "Cube Activation Function",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Hidden Layer"
          ],
          "connections": [
            "Input Layer"
          ],
          "mechanisms": [
            "Non-linear Mapping"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Modeling Product Terms"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_PreTrainedWordEmbeddings",
        "entity_type": "Algorithm",
        "name": "Pre-trained Word Embeddings",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Word Embeddings"
          ],
          "connections": [],
          "mechanisms": [
            "Semantic Similarity"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Initialization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_GreedyArcEagerParser",
        "entity_type": "Algorithm",
        "name": "Greedy Arc-Eager Parser",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Stack",
            "Buffer",
            "Transition System"
          ],
          "connections": [
            "LEFT-ARC",
            "RIGHT-ARC",
            "SHIFT"
          ],
          "mechanisms": [
            "Feature Templates",
            "Structured Averaged Perceptron"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Early-update Strategy"
          ],
          "parameter_tuning": [
            "Hyperparameters Tuning"
          ]
        },
        "feature_processing": [
          "Indicator Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_GreedyArcStandardParser",
        "entity_type": "Algorithm",
        "name": "Greedy Arc-Standard Parser",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Stack",
            "Buffer",
            "Transition System"
          ],
          "connections": [
            "LEFT-ARC",
            "RIGHT-ARC",
            "SHIFT"
          ],
          "mechanisms": [
            "Feature Templates",
            "Structured Averaged Perceptron"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Early-update Strategy"
          ],
          "parameter_tuning": [
            "Hyperparameters Tuning"
          ]
        },
        "feature_processing": [
          "Indicator Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "MaltParser_2014",
        "entity_type": "Algorithm",
        "name": "MaltParser",
        "year": 2014,
        "authors": [
          "Joakim Nivre",
          "Johan Hall",
          "Jens Nilsson"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Stack",
            "Buffer",
            "Transition System"
          ],
          "connections": [
            "LEFT-ARC",
            "RIGHT-ARC",
            "SHIFT"
          ],
          "mechanisms": [
            "Feature Templates",
            "Liblinear Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stackproj",
            "Nivreeager"
          ],
          "parameter_tuning": [
            "Hyperparameters Tuning"
          ]
        },
        "feature_processing": [
          "Indicator Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "MSTParser_2014",
        "entity_type": "Algorithm",
        "name": "MSTParser",
        "year": 2014,
        "authors": [
          "Ryan McDonald",
          "Fernando Pereira"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Graph-Based Parser"
          ],
          "connections": [
            "First-Order Graph"
          ],
          "mechanisms": [
            "Default Options"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Default Options"
          ],
          "parameter_tuning": [
            "Hyperparameters Tuning"
          ]
        },
        "feature_processing": [
          "Indicator Features"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Speed_SentencesPerSecond_Parsing",
        "entity_type": "Metric",
        "name": "Speed (sent/s)",
        "description": "Parsing speed measured in sentences per second",
        "category": "Parsing Efficiency",
        "formula": "Number of sentences parsed / Time taken (seconds)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mayberry1999_ShiftReduceConstituencyParser",
        "entity_type": "Algorithm",
        "name": "Shift Reduce Constituency Parser",
        "year": 1999,
        "authors": [
          "Mayberry III, M.",
          "Miikkulainen, R."
        ],
        "task": "Constituency Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Neural Network",
            "One-hot Word Representations"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Henderson2004_SynchronyNetworkParser",
        "entity_type": "Algorithm",
        "name": "Synchrony Network Parser",
        "year": 2004,
        "authors": [
          "Henderson, J."
        ],
        "task": "Constituency Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Neural Network"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Titov2007_IncrementalSigmoidBeliefNetworks",
        "entity_type": "Algorithm",
        "name": "Incremental Sigmoid Belief Networks",
        "year": 2007,
        "authors": [
          "Titov, I.",
          "Henderson, J."
        ],
        "task": "Constituency Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Belief Networks"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Garg2011_TemporalRestrictedBoltzmannMachine",
        "entity_type": "Algorithm",
        "name": "Temporal Restricted Boltzmann Machine",
        "year": 2011,
        "authors": [
          "Garg, N.",
          "Henderson, J."
        ],
        "task": "Dependency Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Restricted Boltzmann Machine"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_CompositionalVectorGrammars",
        "entity_type": "Algorithm",
        "name": "Compositional Vector Grammars",
        "year": 2013,
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C.D.",
          "Ng, A.Y."
        ],
        "task": "Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Vector Grammars"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Stenetorp2013_RecursiveNeuralNetworks",
        "entity_type": "Algorithm",
        "name": "Recursive Neural Networks",
        "year": 2013,
        "authors": [
          "Stenetorp, P."
        ],
        "task": "Dependency Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Neural Networks"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Titov2007_GenerativeLatentVariableModel",
        "entity_type": "Algorithm",
        "name": "Generative Latent Variable Model",
        "year": 2007,
        "authors": [
          "Titov, I.",
          "Henderson, J."
        ],
        "task": "Dependency Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Latent Variable Model"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_MultiPassSieve",
        "entity_type": "Algorithm",
        "name": "Multi-Pass Sieve",
        "title": "A Multi-Pass Sieve for Coreference Resolution",
        "year": 2010,
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV2",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC",
          "B3"
        ],
        "architecture": {
          "components": [
            "Pass 1- Exact Match",
            "Pass 2- Precise Constructs",
            "Pass 3- Strict Head Matching",
            "Pass 4- Variants of Strict Head",
            "Pass 5- Variants of Strict Head",
            "Pass 6- Relaxed Head Matching",
            "Pass 7- Pronouns"
          ],
          "connections": [
            "Each pass builds on the previous pass's entity cluster output"
          ],
          "mechanisms": [
            "Attribute sharing",
            "Mention selection",
            "Search Pruning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised",
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic information",
          "Attribute sharing",
          "Cluster information"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-ROTH-DEV2_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-ROTH-DEV2",
        "description": "Development split of Bengston and Roth(2008) from the 2004 Automatic Content Extraction (ACE) evaluation",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": 2004,
        "creators": [
          "Bengston and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-CULOTTA-TEST_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-CULOTTA-TEST",
        "description": "Partition of ACE 2004 corpus reserved for testing by several previous works",
        "domain": "Natural Language Processing",
        "size": 107,
        "year": 2004,
        "creators": [
          "Culotta et al.",
          "Bengston and Roth",
          "Haghighi and Klein"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-NWIRE_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-NWIRE",
        "description": "Newswire subset of the ACE 2004 corpus",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": 2004,
        "creators": [
          "Poon and Domingos",
          "Haghighi and Klein"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MUC6-TEST_1995",
        "entity_type": "Dataset",
        "name": "MUC6-TEST",
        "description": "Test corpus from the sixth Message Understanding Conference (MUC-6) evaluation",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": 1995,
        "creators": [
          "Vilain et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_F1",
        "entity_type": "Metric",
        "name": "Pairwise F1",
        "description": "Computed over mention pairs in the same entity cluster",
        "category": "Coreference Resolution",
        "formula": "2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_Scoring",
        "entity_type": "Metric",
        "name": "MUC",
        "description": "Measures how many predicted clusters need to be merged to cover the gold clusters",
        "category": "Coreference Resolution",
        "formula": "Not specified"
      }
    },
    {
      "metric_entity": {
        "metric_id": "B3_Scoring",
        "entity_type": "Metric",
        "name": "B3",
        "description": "Uses the intersection between predicted and gold clusters for a given mention to mark correct mentions and the sizes of the predicted and gold clusters as denominators for precision and recall",
        "category": "Coreference Resolution",
        "formula": "Not specified"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004_2004",
        "entity_type": "Dataset",
        "name": "ACE2004",
        "description": "Automatic Content Extraction 2004 corpus used for coreference resolution.",
        "domain": "Natural Language Processing",
        "year": 2004,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MUC6_1995",
        "entity_type": "Dataset",
        "name": "MUC6",
        "description": "Message Understanding Conference 6 test corpus used for coreference resolution.",
        "domain": "Natural Language Processing",
        "year": 1995,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_Precision",
        "entity_type": "Metric",
        "name": "Pairwise Precision",
        "description": "Precision computed over mention pairs in the same entity cluster.",
        "category": "Coreference Resolution Evaluation",
        "formula": "Number of correctly linked mention pairs / Total number of linked mention pairs"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_Recall",
        "entity_type": "Metric",
        "name": "Pairwise Recall",
        "description": "Recall computed over mention pairs in the same entity cluster.",
        "category": "Coreference Resolution Evaluation",
        "formula": "Number of correctly linked mention pairs / Total number of gold mention pairs"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_Pass1ExactMatch",
        "entity_type": "Algorithm",
        "name": "Pass 1 - Exact Match",
        "year": 2010,
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Exact Extent Match"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Exact Extent Match"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_Pass2PreciseConstructs",
        "entity_type": "Algorithm",
        "name": "Pass 2 - Precise Constructs",
        "year": 2010,
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Appositive",
            "Predicate Nominative",
            "Role Appositive",
            "Relative Pronoun",
            "Acronym",
            "Demonym"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Appositive",
          "Predicate Nominative",
          "Role Appositive",
          "Relative Pronoun",
          "Acronym",
          "Demonym"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_Pass3StrictHeadMatching",
        "entity_type": "Algorithm",
        "name": "Pass 3 - Strict Head Matching",
        "year": 2010,
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Cluster Head Match",
            "Word Inclusion",
            "Compatible Modifiers Only",
            "Not i-within-i"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Cluster Head Match",
          "Word Inclusion",
          "Compatible Modifiers Only",
          "Not i-within-i"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_Pass4VariantsOfStrictHead",
        "entity_type": "Algorithm",
        "name": "Pass 4 - Variants of Strict Head",
        "year": 2010,
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Cluster Head Match",
            "Word Inclusion",
            "Not i-within-i"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Cluster Head Match",
          "Word Inclusion",
          "Not i-within-i"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_Pass5VariantsOfStrictHead",
        "entity_type": "Algorithm",
        "name": "Pass 5 - Variants of Strict Head",
        "year": 2010,
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Cluster Head Match",
            "Compatible Modifiers Only",
            "Not i-within-i"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Cluster Head Match",
          "Compatible Modifiers Only",
          "Not i-within-i"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_Pass6RelaxedHeadMatching",
        "entity_type": "Algorithm",
        "name": "Pass 6 - Relaxed Head Matching",
        "year": 2010,
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Cluster Head Match",
            "Word Inclusion",
            "Not i-within-i"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Cluster Head Match",
          "Word Inclusion",
          "Not i-within-i"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_Pass7Pronouns",
        "entity_type": "Algorithm",
        "name": "Pass 7 - Pronouns",
        "year": 2010,
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Number Agreement",
            "Gender Agreement",
            "Person Agreement",
            "Animacy Agreement",
            "NER Label Agreement"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Agreement",
          "Gender Agreement",
          "Person Agreement",
          "Animacy Agreement",
          "NER Label Agreement"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_SinglePassVariant",
        "entity_type": "Algorithm",
        "name": "Single-Pass Variant",
        "year": 2010,
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "MUC_Scoring",
          "B3_Scoring",
          "Pairwise_F1"
        ],
        "architecture": {
          "components": [
            "Feature Extraction",
            "Coreference Model"
          ],
          "connections": [
            "Feature Input -> Coreference Model"
          ],
          "mechanisms": [
            "Single-Pass Decision Making"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score",
        "entity_type": "Metric",
        "name": "F1 Score",
        "category": "Classification Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_SemanticComponent",
        "entity_type": "Algorithm",
        "name": "Semantic Component",
        "year": 2009,
        "authors": [
          "Haghighi, A.",
          "Klein, D."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Semantic Head Matching",
            "Transductive Learning"
          ],
          "connections": [
            "Syntactic Patterns",
            "Wikipedia Articles"
          ],
          "mechanisms": [
            "Bootstrapping",
            "Syntactic Patterns"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Transductive Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Semantic Head Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengston2008_SupervisedModel",
        "entity_type": "Algorithm",
        "name": "Supervised Model",
        "year": 2008,
        "authors": [
          "Bengston, E.",
          "Roth, D."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-CULOTTA-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Feature-rich Models"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Finkel2008_SupervisedModel",
        "entity_type": "Algorithm",
        "name": "Supervised Model",
        "year": 2008,
        "authors": [
          "Finkel, J.",
          "Manning, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-NWIRE"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Feature-rich Models"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
        "entity_type": "Algorithm",
        "name": "Structured Self-attentive Sentence Embedding",
        "title": "A Structured Self-attentive Sentence Embedding",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Sentence Representation",
        "dataset": [
          "Age dataset",
          "Yelp dataset",
          "SNLI dataset"
        ],
        "metrics": [
          "Classification Accuracy"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Self-attention Mechanism",
            "Fully Connected Layer",
            "Softmax Layer"
          ],
          "connections": [
            "LSTM hidden states to Attention Mechanism",
            "Attention Mechanism to Embedding Matrix",
            "Embedding Matrix to Fully Connected Layer"
          ],
          "mechanisms": [
            "Self-attention",
            "Penalization Term"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size",
            "Dropout",
            "L2 Regularization"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Tokenization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Age_dataset_2017",
        "entity_type": "Dataset",
        "name": "Age dataset",
        "description": "Twitter tweets in English, Spanish, and Dutch with age and gender labels",
        "domain": "Social Media",
        "size": 76485,
        "year": 2017,
        "creators": [
          "IBM Watson"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Yelp_dataset_2017",
        "entity_type": "Dataset",
        "name": "Yelp dataset",
        "description": "2.7M Yelp reviews with star ratings",
        "domain": "Sentiment Analysis",
        "size": 500000,
        "year": 2017,
        "creators": [
          "Yelp"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SNLI_dataset_2015",
        "entity_type": "Dataset",
        "name": "SNLI dataset",
        "description": "570k human-written English sentence pairs manually labeled for entailment, contradiction, and neutral",
        "domain": "Textual Entailment",
        "size": 570000,
        "year": 2015,
        "creators": [
          "Bowman et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Classification",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Classification accuracy",
        "category": "Classification Evaluation",
        "formula": "Correct classifications / Total classifications"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_BidirectionalLSTM",
        "entity_type": "Algorithm",
        "name": "Bidirectional LSTM",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Sentence Embedding",
        "dataset": [
          "Age dataset",
          "Yelp dataset",
          "SNLI dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "LSTM cells",
            "Forward LSTM",
            "Backward LSTM"
          ],
          "connections": [
            "Concatenation of forward and backward LSTM outputs"
          ],
          "mechanisms": [
            "Bidirectional processing of sequences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Batch size",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_SelfAttentionMechanism",
        "entity_type": "Algorithm",
        "name": "Self-Attention Mechanism",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Sentence Embedding",
        "dataset": [
          "Age dataset",
          "Yelp dataset",
          "SNLI dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Weight matrices",
            "Softmax function",
            "Dot product"
          ],
          "connections": [
            "Attention weights applied to LSTM hidden states"
          ],
          "mechanisms": [
            "Multiple attention heads",
            "Penalization term for diversity"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Batch size",
            "Penalization coefficient"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_PenalizationTerm",
        "entity_type": "Algorithm",
        "name": "Penalization Term",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Sentence Embedding",
        "dataset": [
          "Age dataset",
          "Yelp dataset",
          "SNLI dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Frobenius norm",
            "Identity matrix"
          ],
          "connections": [
            "Dot product of annotation matrix and its transpose"
          ],
          "mechanisms": [
            "Encouraging diversity in attention weights"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Penalization coefficient"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_PrunedMLP",
        "entity_type": "Algorithm",
        "name": "Pruned MLP",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Sentence Embedding",
        "dataset": [
          "Age dataset",
          "Yelp dataset",
          "SNLI dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Hidden layers",
            "Weight pruning"
          ],
          "connections": [
            "Structured connections reflecting matrix embedding"
          ],
          "mechanisms": [
            "Reducing parameters in fully connected layer"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Number of hidden units",
            "Pruning parameters"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_GatedEncoder",
        "entity_type": "Algorithm",
        "name": "Gated Encoder",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Textual Entailment",
        "dataset": [
          "SNLI dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Factor matrices",
            "Multiplicative interactions"
          ],
          "connections": [
            "Three-way multiplicative interaction"
          ],
          "mechanisms": [
            "Encoding semantic relations between sentences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Learning rate"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bowman2016_300DLSTMEncoders",
        "entity_type": "Algorithm",
        "name": "300D LSTM encoders",
        "year": 2016,
        "authors": [
          "Bowman, S.R.",
          "Gauthier, J.",
          "Rastogi, A.",
          "Gupta, R.",
          "Manning, C.D.",
          "Potts, C."
        ],
        "task": "Textual Entailment",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "LSTM"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liu2016b_600DBiLSTMEncoders",
        "entity_type": "Algorithm",
        "name": "600D(300+300) BiLSTM encoders",
        "year": 2016,
        "authors": [
          "Liu, Y.",
          "Sun, C.",
          "Lin, L.",
          "Wang, X."
        ],
        "task": "Textual Entailment",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM"
          ],
          "connections": [
            "Bidirectional"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mou2015a_300DTreeBasedCNNEncoders",
        "entity_type": "Algorithm",
        "name": "300D Tree-based CNN encoders",
        "year": 2015,
        "authors": [
          "Mou, L.",
          "Men, R.",
          "Li, G.",
          "Xu, Y.",
          "Zhang, L.",
          "Yan, R.",
          "Jin, Z."
        ],
        "task": "Textual Entailment",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "CNN",
            "Tree-based"
          ],
          "connections": [
            "Convolutional"
          ],
          "mechanisms": [
            "Hierarchical"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bowman2016_300DSPINNPIEncoders",
        "entity_type": "Algorithm",
        "name": "300D SPINN-PI encoders",
        "year": 2016,
        "authors": [
          "Bowman, S.R.",
          "Gauthier, J.",
          "Rastogi, A.",
          "Gupta, R.",
          "Manning, C.D.",
          "Potts, C."
        ],
        "task": "Textual Entailment",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "SPINN-PI"
          ],
          "connections": [
            "Recursive"
          ],
          "mechanisms": [
            "Tree-based"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Munkhdalai2016a_300DNTISLSTMLSTMEncoders",
        "entity_type": "Algorithm",
        "name": "300D NTI-SLSTM-LSTM encoders",
        "year": 2016,
        "authors": [
          "Munkhdalai, T.",
          "Yu, H."
        ],
        "task": "Textual Entailment",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "NTI-SLSTM",
            "LSTM"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Vendrov2015_1024DGRUEncodersWithSkipThoughtsPreTraining",
        "entity_type": "Algorithm",
        "name": "1024D GRU encoders with SkipThoughts pre-training",
        "year": 2015,
        "authors": [
          "Vendrov, I.",
          "Kiros, R.",
          "Fidler, S.",
          "Urtasun, R."
        ],
        "task": "Textual Entailment",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "GRU"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised",
            "Pre-trained"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Munkhdalai2016b_300DNSEEncoders",
        "entity_type": "Algorithm",
        "name": "300D NSE encoders",
        "year": 2016,
        "authors": [
          "Munkhdalai, T.",
          "Yu, H."
        ],
        "task": "Textual Entailment",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "NSE"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ling2015_AttentionBasedWordEmbedding",
        "entity_type": "Algorithm",
        "name": "Attention-Based Word Embedding",
        "year": 2015,
        "authors": [
          "Ling, W.",
          "Chu-Cheng, L.",
          "Tsvetkov, Y.",
          "Amir, S."
        ],
        "task": "Word Representation",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Attention Mechanism",
            "Word Embedding"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liu2016a_SentenceLevelAttention",
        "entity_type": "Algorithm",
        "name": "Sentence-Level Attention",
        "year": 2016,
        "authors": [
          "Liu, Y.",
          "Sun, C.",
          "Lin, L.",
          "Wang, X."
        ],
        "task": "Sentence Representation",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Attention Mechanism",
            "LSTM"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Li2016_SelfAttentionForQA",
        "entity_type": "Algorithm",
        "name": "Self-Attention for Question Answering",
        "year": 2016,
        "authors": [
          "Li, P.",
          "Li, W.",
          "He, Z.",
          "Wang, X.",
          "Cao, Y.",
          "Zhou, J.",
          "Xu, W."
        ],
        "task": "Question Answering",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Self-Attention Mechanism",
            "Factoid QA Model"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cheng2016_LSTMN",
        "entity_type": "Algorithm",
        "name": "LSTMN",
        "year": 2016,
        "authors": [
          "Cheng, J.",
          "Dong, L.",
          "Lapata, M."
        ],
        "task": "Sentence Representation",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "LSTM",
            "Intra-Sentence Attention"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Parikh2016_DecomposableAttentionModel",
        "entity_type": "Algorithm",
        "name": "Decomposable Attention Model",
        "year": 2016,
        "authors": [
          "Parikh, A.P.",
          "Tackstrom, O.",
          "Das, D.",
          "Uszkoreit, J."
        ],
        "task": "Natural Language Inference",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Attention Mechanism"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_MultiplicativeInteractions",
        "entity_type": "Algorithm",
        "name": "Multiplicative Interactions",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Textual Entailment",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Matrix Embedding",
            "Gated Encoder"
          ],
          "connections": [
            "Three-way Multiplicative Interaction"
          ],
          "mechanisms": [
            "Factor Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Shared Parameters",
            "Independent Processing"
          ],
          "parameter_tuning": [
            "Weight Matrices"
          ]
        },
        "feature_processing": [
          "Batched Dot Product"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_TagBasedMWP",
        "entity_type": "Algorithm",
        "name": "Tag-based statistical MWP solver",
        "title": "A Tag-based English Math Word Problem Solver with Understanding, Reasoning and Explanation",
        "year": 2016,
        "authors": [
          "Chao-Chun Liang",
          "Kuang-Yi Hsu",
          "Chien-Tsung Huang",
          "Chung-Min Li",
          "Shen-Yu Miao",
          "Keh-Yih Su"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "MA1",
          "MA2",
          "IXL"
        ],
        "metrics": [
          "Accuracy",
          "Cross-validation accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "LA -> STC -> LFC -> IE -> EG"
          ],
          "mechanisms": [
            "Tag-based annotation",
            "Logic inference",
            "First-order logic predicates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning",
            "Rule-based logic inference"
          ],
          "parameter_tuning": [
            "SVM classifier with linear kernel"
          ]
        },
        "feature_processing": [
          "Dependency parsing",
          "Co-reference resolution",
          "POS tagging",
          "Named entity recognition"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MA1_2014",
        "entity_type": "Dataset",
        "name": "MA1",
        "description": "Simple math word problems on addition and subtraction for third, fourth, and fifth graders",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MA2_2014",
        "entity_type": "Dataset",
        "name": "MA2",
        "description": "Math word problems with more irrelevant information",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IXL_2014",
        "entity_type": "Dataset",
        "name": "IXL",
        "description": "Math word problems with more information gaps",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "CrossValidationAccuracy",
        "entity_type": "Metric",
        "name": "Cross-validation accuracy",
        "description": "Accuracy measured using cross-validation",
        "category": "Classification evaluation",
        "formula": "Average accuracy over multiple folds"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_LanguageAnalyzer",
        "entity_type": "Algorithm",
        "name": "Language Analyzer (LA)",
        "year": 2016,
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "Stanford CoreNLP suite"
          ],
          "connections": [
            "Tokenization",
            "Sentence Splitting",
            "POS Tagging",
            "Lemmatization",
            "Named Entity Recognition",
            "Parsing",
            "Co-reference Resolution"
          ],
          "mechanisms": [
            "Syntactic Tree Generation",
            "Dependency Relation Extraction",
            "Co-reference Chain Annotation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based Annotation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Tokenization",
          "POS Tagging",
          "Dependency Parsing",
          "Co-reference Resolution"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_SolutionTypeClassifier",
        "entity_type": "Algorithm",
        "name": "Solution Type Classifier (STC)",
        "year": 2016,
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "Mathematical Operation Classification",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "SVM Classifier with Linear Kernel"
          ],
          "connections": [
            "Verb Category Features",
            "Keyword Indicators",
            "Pattern Matching Indicators"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Kernel Function Selection"
          ]
        },
        "feature_processing": [
          "Verb Category Feature Extraction",
          "Keyword Detection",
          "Pattern Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_LogicFormConverter",
        "entity_type": "Algorithm",
        "name": "Logic Form Converter (LFC)",
        "year": 2016,
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "Logical Representation Conversion",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "First-Order Logic Predicate Generator"
          ],
          "connections": [
            "Deterministic Mapping Rules",
            "Dependency Structure Parsing"
          ],
          "mechanisms": [
            "Predicate Generation",
            "Logical Form Transformation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dependency Parsing",
          "Predicate Generation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_InferenceEngine",
        "entity_type": "Algorithm",
        "name": "Inference Engine (IE)",
        "year": 2016,
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "Logical Inference",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "Inference Rules",
            "Mathematical Operation Utilities"
          ],
          "connections": [
            "Fact Selection",
            "Mathematical Operations"
          ],
          "mechanisms": [
            "Inference",
            "Fact Derivation",
            "Mathematical Computation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Fact Selection",
          "Mathematical Operation Execution"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_ExplanationGenerator",
        "entity_type": "Algorithm",
        "name": "Explanation Generator (EG)",
        "year": 2016,
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "Explanation Generation",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "Reasoning Chain Interpreter",
            "Template-Based Explanation Generator"
          ],
          "connections": [
            "Reasoning Chain Parsing",
            "Template Application"
          ],
          "mechanisms": [
            "Explanation Text Generation",
            "Reasoning Chain Interpretation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Reasoning Chain Parsing",
          "Template Application"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_ARIS",
        "entity_type": "Algorithm",
        "name": "ARIS",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": 2014,
        "authors": [
          "Hosseini, M.J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "Entity Attribute Changer"
          ],
          "connections": [
            "Schema-based Entity Attribute Modification"
          ],
          "mechanisms": [
            "Rule-based System"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based Schema Matching"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Verb Categorization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_KAZB",
        "entity_type": "Algorithm",
        "name": "KAZB",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "Equation Template Alignment"
          ],
          "connections": [
            "Text-to-Equation Mapping"
          ],
          "mechanisms": [
            "Statistical Approach"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pre-extracted Equation Templates"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Text Alignment"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_TagBasedFramework",
        "entity_type": "Algorithm",
        "name": "Tag-based Statistical Framework",
        "year": 2016,
        "authors": [
          "Chao-Chun Liang",
          "Kuang-Yi Hsu",
          "Chien-Tsung Huang",
          "Chung-Min Li",
          "Shen-Yu Miao",
          "Keh-Yih Su"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "MA1",
          "MA2",
          "IXL"
        ],
        "metrics": [
          "Accuracy",
          "Cross Validation Accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "LA -> STC -> LFC -> IE -> EG"
          ],
          "mechanisms": [
            "Tag-based annotation",
            "Logic inference",
            "Syntactic and semantic tagging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "SVM with linear kernel"
          ]
        },
        "feature_processing": [
          "Dependency parsing",
          "Co-reference resolution",
          "POS tagging",
          "Named entity recognition"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
        "entity_type": "Algorithm",
        "name": "Easy-First Non-Directional Dependency Parsing",
        "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing",
        "year": 2010,
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "WSJ Treebank",
          "CoNLL 2007 English test set"
        ],
        "metrics": [
          "Accuracy",
          "Root",
          "Complete"
        ],
        "architecture": {
          "components": [
            "ATTACHLEFT",
            "ATTACHRIGHT"
          ],
          "connections": [
            "Dependency edges"
          ],
          "mechanisms": [
            "Non-directional parsing",
            "Best-first parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured perceptron"
          ],
          "parameter_tuning": [
            "Feature representation",
            "Weight vector updates"
          ]
        },
        "feature_processing": [
          "POS tagging",
          "Feature templates"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WSJ_Treebank_2010",
        "entity_type": "Dataset",
        "name": "WSJ Treebank",
        "description": "Wall Street Journal Treebank",
        "domain": "Natural Language Processing",
        "size": "Sections 2-21 for training, Section 22 for development, Section 23 for testing",
        "year": 2010,
        "creators": [
          "Penn2Malt conversion program"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL_2007_English_test_set_2010",
        "entity_type": "Dataset",
        "name": "CoNLL 2007 English test set",
        "description": "English dataset from the CoNLL 2007 shared task",
        "domain": "Natural Language Processing",
        "size": "Smaller in size, created using a different conversion procedure",
        "year": 2010,
        "creators": [
          "CoNLL 2007 shared task organizers"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Root_Prediction",
        "entity_type": "Metric",
        "name": "Root",
        "description": "Percentage of sentences in which the ROOT attachment is correct",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correct ROOT attachments / Total sentences"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Complete_Correct_Parses",
        "entity_type": "Metric",
        "name": "Complete",
        "description": "Percentage of sentences in which all tokens were assigned their correct parent",
        "category": "Dependency Parsing Evaluation",
        "formula": "Sentences with all correct token assignments / Total sentences"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_NonDirectionalParsing",
        "entity_type": "Algorithm",
        "name": "Non-directional Parsing",
        "year": 2010,
        "authors": [
          "Goldberg, Yoav",
          "Elhadad, Michael"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "ATTACHLEFT",
            "ATTACHRIGHT"
          ],
          "connections": [
            "pi, pi+1"
          ],
          "mechanisms": [
            "score(ACTION(i))",
            "edgeFor(best)",
            "pending"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "weight vector w~",
            "feature representation φ"
          ]
        },
        "feature_processing": [
          "Binary valued features",
          "POS tags",
          "Head word forms",
          "Left-most and right-most child POS tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_StructuredPerceptronTraining",
        "entity_type": "Algorithm",
        "name": "Structured Perceptron Training",
        "year": 2010,
        "authors": [
          "Goldberg, Yoav",
          "Elhadad, Michael"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "argmax",
            "score(act(i))",
            "edgeFor(act(i))"
          ],
          "connections": [
            "choice",
            "good",
            "w~"
          ],
          "mechanisms": [
            "isValid(action, Gold, Arcs)",
            "parameter updates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "weight vector w~",
            "feature representation φ"
          ]
        },
        "feature_processing": [
          "Binary valued features",
          "POS tags",
          "Head word forms",
          "Left-most and right-most child POS tags"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Penn2Malt_Conversion_Program_2010",
        "entity_type": "Dataset",
        "name": "Penn2Malt Conversion Program",
        "year": 2010,
        "creators": [
          "Yamada, H.",
          "Matsumoto, Y."
        ],
        "domain": "Natural Language Processing",
        "description": "Program used to convert constituency trees to dependency structures"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Unlabeled_Accuracy",
        "entity_type": "Metric",
        "name": "Unlabeled Accuracy",
        "description": "Percentage of tokens which got assigned their correct parent",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly assigned tokens / Total tokens"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_FeatureRepresentation",
        "entity_type": "Algorithm",
        "name": "Feature Representation",
        "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing",
        "year": 2010,
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Unlabeled_Accuracy",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Structural Features",
            "Unigram Features",
            "Bigram Features",
            "PP-Attachment Features"
          ],
          "connections": [
            "Action Features",
            "Sentence Context",
            "Partial Structures"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Score Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron Training"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Binary Valued Features",
          "POS Tagging",
          "Head Word Form",
          "Left-Most and Right-Most Child POS Tags"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Surface_Distance_Syntactic_Structure",
        "entity_type": "Metric",
        "name": "Surface Distance",
        "description": "Distance between structure heads in terms of syntactic structure",
        "category": "Syntactic Evaluation",
        "formula": "Δpipj"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Structure_Length",
        "entity_type": "Metric",
        "name": "Structure Length",
        "description": "Length of the structures",
        "category": "Syntactic Evaluation",
        "formula": "lenp"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Word_Form",
        "entity_type": "Metric",
        "name": "Word Form",
        "description": "Head word form of a partial structure",
        "category": "Lexical Evaluation",
        "formula": "wp"
      }
    },
    {
      "metric_entity": {
        "metric_id": "POS_Tag",
        "entity_type": "Metric",
        "name": "POS Tag",
        "description": "POS tag of the head word",
        "category": "Syntactic Evaluation",
        "formula": "tp"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Left_Most_Child_POS_Tag",
        "entity_type": "Metric",
        "name": "Left-Most Child POS Tag",
        "description": "POS tag of the left-most child of a partial structure",
        "category": "Syntactic Evaluation",
        "formula": "lcp"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Right_Most_Child_POS_Tag",
        "entity_type": "Metric",
        "name": "Right-Most Child POS Tag",
        "description": "POS tag of the right-most child of a partial structure",
        "category": "Syntactic Evaluation",
        "formula": "rcp"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_OptimizedFeatureExtraction",
        "entity_type": "Algorithm",
        "name": "Optimized Feature Extraction",
        "year": 2010,
        "authors": [
          "Goldberg, Y.",
          "Elhadad, M."
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Unlabeled_Accuracy",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Heap",
            "Feature Extraction Module"
          ],
          "connections": [
            "Heap for argmax computation",
            "Feature extraction for each action/location pair"
          ],
          "mechanisms": [
            "Reuse of extracted features",
            "Heap-based optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron Training"
          ],
          "parameter_tuning": [
            "Window size for feature extraction"
          ]
        },
        "feature_processing": [
          "Local context features",
          "Syntactic structure features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_HeapBasedArgmax",
        "entity_type": "Algorithm",
        "name": "Heap-Based Argmax Computation",
        "year": 2010,
        "authors": [
          "Goldberg, Y.",
          "Elhadad, M."
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Unlabeled_Accuracy",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Heap Data Structure"
          ],
          "connections": [
            "Heap for argmax computation"
          ],
          "mechanisms": [
            "Efficient argmax computation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron Training"
          ],
          "parameter_tuning": [
            "Heap size"
          ]
        },
        "feature_processing": [
          "Feature scores"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_TransitionBasedParsing",
        "entity_type": "Algorithm",
        "name": "Transition-based Parsing",
        "year": 2010,
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Shift-reduce framework",
            "Left-to-right processing"
          ],
          "connections": [
            "Word-by-word traversal",
            "Local decision-making"
          ],
          "mechanisms": [
            "Feature extraction from left context",
            "Limited lookahead"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Feature engineering"
          ]
        },
        "feature_processing": [
          "POS tagging",
          "Syntactic structure analysis"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_GraphBasedParsing",
        "entity_type": "Algorithm",
        "name": "Graph-based Parsing",
        "year": 2010,
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Global optimization",
            "Exhaustive search"
          ],
          "connections": [
            "Edge scoring",
            "Tree construction"
          ],
          "mechanisms": [
            "First-order models",
            "Higher-order models"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Feature selection",
            "Model complexity control"
          ]
        },
        "feature_processing": [
          "Edge-based features",
          "Tree-based features"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Unlabeled_Dependency_Accuracy",
        "entity_type": "Metric",
        "name": "Unlabeled Dependency Accuracy",
        "description": "Percentage of tokens assigned their correct parent without considering labels",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly assigned tokens / Total tokens"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Root_Attachment_Accuracy",
        "entity_type": "Metric",
        "name": "Root Attachment Accuracy",
        "description": "Percentage of sentences with correct ROOT attachment",
        "category": "Dependency Parsing Evaluation",
        "formula": "Sentences with correct ROOT attachment / Total sentences"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Penn_Treebank_2010",
        "entity_type": "Dataset",
        "name": "Penn Treebank",
        "description": "A large annotated corpus of English text",
        "domain": "Natural Language Processing",
        "size": "Various sections",
        "year": 2010,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL_2006_Shared_Task",
        "entity_type": "Dataset",
        "name": "CoNLL 2006 Shared Task",
        "description": "Multilingual dependency parsing dataset",
        "domain": "Natural Language Processing",
        "size": "Various languages",
        "year": 2006,
        "creators": [
          "CoNLL organizers"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Earley1970_EfficientParsingAlgorithm",
        "entity_type": "Algorithm",
        "name": "Efficient Context-Free Parsing Algorithm",
        "title": "An Efficient Context-Free Parsing Algorithm",
        "year": 1970,
        "authors": [
          "Jay Earley"
        ],
        "task": "Parsing context-free grammars",
        "dataset": [],
        "metrics": [
          "Time complexity",
          "Space complexity"
        ],
        "architecture": {
          "components": [
            "Predictor",
            "Completer",
            "Scanner"
          ],
          "connections": [
            "State transitions",
            "Look-ahead"
          ],
          "mechanisms": [
            "State sets",
            "Derivation trees"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Look-ahead strings",
          "State sets"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "TimeComplexity_Parsing",
        "entity_type": "Metric",
        "name": "Time complexity",
        "description": "Time required to parse a string",
        "category": "Algorithm performance",
        "formula": "O(n^3) for general context-free grammars, O(n^2) for unambiguous grammars, O(n) for bounded state grammars"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpaceComplexity_Parsing",
        "entity_type": "Metric",
        "name": "Space complexity",
        "description": "Memory required to parse a string",
        "category": "Algorithm performance",
        "formula": "O(n^2)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Knuth1965_LRkAlgorithm",
        "entity_type": "Algorithm",
        "name": "LR(k) Algorithm",
        "year": 1965,
        "authors": [
          "Knuth, D.E."
        ],
        "task": "Parsing",
        "dataset": [],
        "metrics": [
          "TimeComplexity_Parsing",
          "SpaceComplexity_Parsing"
        ],
        "architecture": {
          "components": [
            "Predictor",
            "Scanner",
            "Completer"
          ],
          "connections": [
            "State transitions",
            "Look-ahead"
          ],
          "mechanisms": [
            "Stack-based parsing"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cocke1966_CockeAlgorithm",
        "entity_type": "Algorithm",
        "name": "Cocke's Algorithm",
        "year": 1966,
        "authors": [
          "Cocke, J."
        ],
        "task": "Parsing",
        "dataset": [],
        "metrics": [
          "TimeComplexity_Parsing",
          "SpaceComplexity_Parsing"
        ],
        "architecture": {
          "components": [
            "Parsing table",
            "Dynamic programming"
          ],
          "connections": [
            "State transitions"
          ],
          "mechanisms": [
            "Normal form requirement"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Younger1967_RecognitionAlgorithm",
        "entity_type": "Algorithm",
        "name": "Younger's Recognition Algorithm",
        "year": 1967,
        "authors": [
          "Younger, D.H."
        ],
        "task": "Parsing",
        "dataset": [],
        "metrics": [
          "TimeComplexity_Parsing",
          "SpaceComplexity_Parsing"
        ],
        "architecture": {
          "components": [
            "Parsing table",
            "Dynamic programming"
          ],
          "connections": [
            "State transitions"
          ],
          "mechanisms": [
            "Turing machine implementation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kasami1969_SyntaxAnalysisProcedure",
        "entity_type": "Algorithm",
        "name": "Kasami's Syntax Analysis Procedure",
        "year": 1969,
        "authors": [
          "Kasami, T.",
          "Torii, K."
        ],
        "task": "Parsing",
        "dataset": [],
        "metrics": [
          "TimeComplexity_Parsing",
          "SpaceComplexity_Parsing"
        ],
        "architecture": {
          "components": [
            "Parsing table",
            "Dynamic programming"
          ],
          "connections": [
            "State transitions"
          ],
          "mechanisms": [
            "Unambiguous context-free grammars"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "TimeComplexity_Parsing_n2",
        "entity_type": "Metric",
        "name": "Time Complexity (n^2)",
        "description": "Time complexity for parsing unambiguous grammars",
        "category": "Parsing performance",
        "formula": "O(n^2)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "TimeComplexity_Parsing_n3",
        "entity_type": "Metric",
        "name": "Time Complexity (n^3)",
        "description": "Time complexity for parsing general context-free grammars",
        "category": "Parsing performance",
        "formula": "O(n^3)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpaceComplexity_Parsing_n2",
        "entity_type": "Metric",
        "name": "Space Complexity (n^2)",
        "description": "Space complexity for parsing context-free grammars",
        "category": "Parsing performance",
        "formula": "O(n^2)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpaceComplexity_Parsing_n3",
        "entity_type": "Metric",
        "name": "Space Complexity (n^3)",
        "description": "Space complexity for storing parse trees",
        "category": "Parsing performance",
        "formula": "O(n^3)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Earley1970_TopDownParser",
        "entity_type": "Algorithm",
        "name": "Top-Down Parser",
        "year": 1970,
        "authors": [
          "Earley, J."
        ],
        "task": "Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Predictor",
            "Scanner",
            "Completer"
          ],
          "connections": [
            "State transitions",
            "Look-ahead"
          ],
          "mechanisms": [
            "State sets",
            "Derivation trees"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Look-ahead strings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Earley1970_BottomUpParser",
        "entity_type": "Algorithm",
        "name": "Bottom-Up Parser",
        "year": 1970,
        "authors": [
          "Earley, J."
        ],
        "task": "Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Shift",
            "Reduce"
          ],
          "connections": [
            "Stack operations"
          ],
          "mechanisms": [
            "Parsing tables"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Earley1970_SelectiveTopDownParser",
        "entity_type": "Algorithm",
        "name": "Selective Top-Down Parser",
        "year": 1970,
        "authors": [
          "Earley, J."
        ],
        "task": "Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Selective Predictor",
            "Scanner",
            "Completer"
          ],
          "connections": [
            "State transitions",
            "Look-ahead"
          ],
          "mechanisms": [
            "State sets",
            "Derivation trees"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Look-ahead strings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Earley1970_SelectiveBottomUpParser",
        "entity_type": "Algorithm",
        "name": "Selective Bottom-Up Parser",
        "year": 1970,
        "authors": [
          "Earley, J."
        ],
        "task": "Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Selective Shift",
            "Reduce"
          ],
          "connections": [
            "Stack operations"
          ],
          "mechanisms": [
            "Parsing tables"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "PrimitiveOperations_Parsing",
        "entity_type": "Metric",
        "name": "Primitive Operations",
        "description": "Number of primitive operations performed during parsing",
        "category": "Parsing Evaluation",
        "formula": "Count of operations such as adding a state to a state set"
      }
    },
    {
      "metric_entity": {
        "metric_id": "TimeBound_Parsing",
        "entity_type": "Metric",
        "name": "Time Bound",
        "description": "Upper bound on the time complexity of the parsing algorithm",
        "category": "Parsing Evaluation",
        "formula": "Time complexity in terms of input string length n"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpaceBound_Parsing",
        "entity_type": "Metric",
        "name": "Space Bound",
        "description": "Upper bound on the space complexity of the parsing algorithm",
        "category": "Parsing Evaluation",
        "formula": "Space complexity in terms of input string length n"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "GrammarExamples_1970",
        "entity_type": "Dataset",
        "name": "Grammar Examples",
        "description": "Examples of context-free grammars used for testing parsing algorithms",
        "domain": "Formal Language Theory",
        "size": "Not specified",
        "year": 1970,
        "creators": [
          "Earley, J."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Earley1970_EfficientParsingAlgorithm_KleeneStarExtension",
        "entity_type": "Algorithm",
        "name": "Efficient Context-Free Parsing Algorithm with Kleene Star Extension",
        "year": 1970,
        "authors": [
          "Jay Earley"
        ],
        "task": "Parsing context-free grammars",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Predictor",
            "Completer",
            "Scanner"
          ],
          "connections": [
            "State transitions",
            "Look-ahead handling"
          ],
          "mechanisms": [
            "Kleene star notation support"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Kleene star notation handling"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "PrimitiveOperations_Count",
        "entity_type": "Metric",
        "name": "Primitive Operations Count",
        "description": "Number of primitive operations performed by the algorithm",
        "category": "Algorithm performance",
        "formula": "Count of state additions or attempts to add states"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Griffiths1965_TopDownParser",
        "entity_type": "Algorithm",
        "name": "Top-Down Parser",
        "year": 1965,
        "authors": [
          "Griffiths, T.",
          "Petrick, S."
        ],
        "task": "Parsing",
        "dataset": [
          "Propositional Calculus Grammar",
          "GRE Grammar",
          "NSE Grammar"
        ],
        "metrics": [
          "Primitive Operations Count"
        ],
        "architecture": {
          "components": [
            "Backtracking"
          ],
          "connections": [
            "Recursive Descent"
          ],
          "mechanisms": [
            "Predictive Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backtracking"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "None"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Griffiths1965_BottomUpParser",
        "entity_type": "Algorithm",
        "name": "Bottom-Up Parser",
        "year": 1965,
        "authors": [
          "Griffiths, T.",
          "Petrick, S."
        ],
        "task": "Parsing",
        "dataset": [
          "Propositional Calculus Grammar",
          "GRE Grammar",
          "NSE Grammar"
        ],
        "metrics": [
          "Primitive Operations Count"
        ],
        "architecture": {
          "components": [
            "Shift-Reduce"
          ],
          "connections": [
            "LR Parsing"
          ],
          "mechanisms": [
            "Deterministic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Shift-Reduce"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "None"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Griffiths1965_SelectiveTopDownParser",
        "entity_type": "Algorithm",
        "name": "Selective Top-Down Parser",
        "year": 1965,
        "authors": [
          "Griffiths, T.",
          "Petrick, S."
        ],
        "task": "Parsing",
        "dataset": [
          "Propositional Calculus Grammar",
          "GRE Grammar",
          "NSE Grammar"
        ],
        "metrics": [
          "Primitive Operations Count"
        ],
        "architecture": {
          "components": [
            "Selective Backtracking"
          ],
          "connections": [
            "Selective Recursive Descent"
          ],
          "mechanisms": [
            "Selective Predictive Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Selective Backtracking"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "None"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Griffiths1965_SelectiveBottomUpParser",
        "entity_type": "Algorithm",
        "name": "Selective Bottom-Up Parser",
        "year": 1965,
        "authors": [
          "Griffiths, T.",
          "Petrick, S."
        ],
        "task": "Parsing",
        "dataset": [
          "Propositional Calculus Grammar",
          "GRE Grammar",
          "NSE Grammar"
        ],
        "metrics": [
          "Primitive Operations Count"
        ],
        "architecture": {
          "components": [
            "Selective Shift-Reduce"
          ],
          "connections": [
            "Selective LR Parsing"
          ],
          "mechanisms": [
            "Selective Deterministic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Selective Shift-Reduce"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "None"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PropositionalCalculusGrammar_1970",
        "entity_type": "Dataset",
        "name": "Propositional Calculus Grammar",
        "year": 1970,
        "creators": [
          "Griffiths, T.",
          "Petrick, S."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "GREGrammar_1970",
        "entity_type": "Dataset",
        "name": "GRE Grammar",
        "year": 1970,
        "creators": [
          "Griffiths, T.",
          "Petrick, S."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NSEGrammar_1970",
        "entity_type": "Dataset",
        "name": "NSE Grammar",
        "year": 1970,
        "creators": [
          "Griffiths, T.",
          "Petrick, S."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "PrimitiveOperationsCount_Parsing",
        "entity_type": "Metric",
        "name": "Primitive Operations Count",
        "description": "Number of primitive operations performed by the parsing algorithm",
        "category": "Parsing Evaluation",
        "formula": "Count of state additions or attempts to add states"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2015_GeoTutor",
        "entity_type": "Algorithm",
        "name": "GeoTutor",
        "title": "Automatic Synthesis of Geometry Problems for an Intelligent Tutoring System",
        "year": 2015,
        "authors": [
          "Chris Alvin",
          "Sumit Gulwani",
          "Rupak Majumdar",
          "Supratik Mukhopadhyay"
        ],
        "task": "Euclidean Geometry Problem Synthesis",
        "dataset": [
          "High School Geometry Problems"
        ],
        "metrics": [
          "Proof Width",
          "Proof Length",
          "Deductive Steps"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Pebbling Algorithm",
            "Problem Synthesis"
          ],
          "connections": [
            "Forward Edges",
            "Back-Edges"
          ],
          "mechanisms": [
            "Traversal Algorithm",
            "Coarse Problem Homomorphism",
            "Goal Analogous Problems"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Breadth-First Pebbling",
            "Coordinate-Based Computation"
          ],
          "parameter_tuning": [
            "User Query Restrictions"
          ]
        },
        "feature_processing": [
          "Invariant Characteristics Extraction",
          "Student Knowledge Base Integration"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "HighSchoolGeometryProblems_2015",
        "entity_type": "Dataset",
        "name": "High School Geometry Problems",
        "description": "A corpus of high school geometry problems from standard geometry textbooks",
        "domain": "Education",
        "size": 155,
        "year": 2015,
        "creators": [
          "Chris Alvin",
          "Sumit Gulwani",
          "Rupak Majumdar",
          "Supratik Mukhopadhyay"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ProofWidth_Classification",
        "entity_type": "Metric",
        "name": "Proof Width",
        "description": "The width of the problem hypergraph",
        "category": "Classification Assessment",
        "formula": "Width of the hypergraph"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ProofLength_Classification",
        "entity_type": "Metric",
        "name": "Proof Length",
        "description": "The diameter of the problem hypergraph",
        "category": "Classification Assessment",
        "formula": "Diameter of the hypergraph"
      }
    },
    {
      "metric_entity": {
        "metric_id": "DeductiveSteps_Classification",
        "entity_type": "Metric",
        "name": "Deductive Steps",
        "description": "The number of hyperedges in the problem hypergraph",
        "category": "Classification Assessment",
        "formula": "Number of hyperedges"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2015_HypergraphTraversal",
        "entity_type": "Algorithm",
        "name": "Hypergraph Traversal",
        "year": 2015,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "Problem Synthesis",
        "dataset": [
          "HighSchoolGeometryProblems_2015"
        ],
        "metrics": [
          "ProofWidth_Classification",
          "ProofLength_Classification",
          "DeductiveSteps_Classification"
        ],
        "architecture": {
          "components": [
            "Nodes",
            "Hyperedges"
          ],
          "connections": [
            "Forward Edges",
            "Back-Edges"
          ],
          "mechanisms": [
            "Pebbling Technique",
            "Breadth-First Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Exploration of Hypergraph"
          ],
          "parameter_tuning": [
            "User Query Restrictions"
          ]
        },
        "feature_processing": [
          "Coordinate-Based Computation",
          "Assumption Filtering"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "StandardMathTextbooks_2006",
        "entity_type": "Dataset",
        "name": "Standard Math Textbooks",
        "description": "Collection of standard mathematics textbooks for grades IX and X",
        "domain": "Education",
        "size": 110,
        "year": 2006,
        "creators": [
          "Sinclair, D.",
          "Dikshit, et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "GoalAnalogousPartitions_Classification",
        "entity_type": "Metric",
        "name": "Goal Analogous Partitions",
        "description": "Number of partitions based on goal analogous problems",
        "category": "Classification",
        "formula": "Number of unique goal analogous problem sets"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2015_PebblingAlgorithm",
        "entity_type": "Algorithm",
        "name": "Pebbling Algorithm",
        "year": 2015,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "Problem Synthesis",
        "dataset": [
          "HighSchoolGeometryProblems_2015"
        ],
        "metrics": [
          "ProofWidth_Classification",
          "ProofLength_Classification",
          "DeductiveSteps_Classification"
        ],
        "architecture": {
          "components": [
            "Forward Edges",
            "Back-Edges"
          ],
          "connections": [
            "Hypergraph Traversal",
            "Breadth-First Search"
          ],
          "mechanisms": [
            "Deduction",
            "Axiom Application"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Breadth-First Pebbling"
          ],
          "parameter_tuning": [
            "User Query Restrictions"
          ]
        },
        "feature_processing": [
          "Coordinate-Based Computation",
          "Assumption Filtering"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IndianMathTextbooks_2006",
        "entity_type": "Dataset",
        "name": "Indian Math Textbooks",
        "year": 2006,
        "creators": [
          "Sinclair, D.",
          "Dikshit, et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "USMathTextbooks_2006",
        "entity_type": "Dataset",
        "name": "US Math Textbooks",
        "year": 2006,
        "creators": [
          "Boyd, et al.",
          "Larson, et al.",
          "Jurgensen, Brown, and Jurgensen"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "StrictlyInterestingProblems_Classification",
        "entity_type": "Metric",
        "name": "Strictly Interesting Problems",
        "category": "Problem Classification",
        "formula": "Problems that require at least one of the assumptions and cannot be derived from algebraic manipulation"
      }
    },
    {
      "metric_entity": {
        "metric_id": "CoarseProblemHomomorphism_Classification",
        "entity_type": "Metric",
        "name": "Coarse Problem Homomorphism",
        "category": "Problem Analogy",
        "formula": "Mapping between problem hypergraphs preserving node types and edge structures"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2015_CoordinateBasedComputation",
        "entity_type": "Algorithm",
        "name": "Coordinate-Based Computation",
        "year": 2015,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "Euclidean Geometry Problem Synthesis",
        "dataset": [
          "HighSchoolGeometryProblems_2015"
        ],
        "metrics": [
          "ProofWidth_Classification",
          "ProofLength_Classification",
          "DeductiveSteps_Classification"
        ],
        "architecture": {
          "components": [
            "Coordinate Calculation",
            "Figure Strengthening"
          ],
          "connections": [
            "Input Figure -> Coordinate Calculation -> Figure Strengthening"
          ],
          "mechanisms": [
            "Midpoint Detection",
            "Triangle Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Coordinate Processing",
          "Geometric Property Extraction"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "AveGoalAnalogousPartitions_Classification",
        "entity_type": "Metric",
        "name": "Average Goal Analogous Partitions",
        "category": "Classification",
        "formula": "Average number of partitions based on goal analogous problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ahmed2013_NaturalDeductionProblemGenerator",
        "entity_type": "Algorithm",
        "name": "Natural Deduction Problem Generator",
        "year": 2013,
        "authors": [
          "Ahmed, U. Z.",
          "Gulwani, S.",
          "Karkare, A."
        ],
        "task": "Natural Deduction Problem Generation",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Andersen2013_TraceBasedFramework",
        "entity_type": "Algorithm",
        "name": "Trace-Based Framework",
        "year": 2013,
        "authors": [
          "Andersen, E.",
          "Gulwani, S.",
          "Popovic, Z."
        ],
        "task": "Analyzing and Synthesizing Educational Progressions",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sadigh2012_AutomatedExerciseGeneration",
        "entity_type": "Algorithm",
        "name": "Automated Exercise Generation",
        "year": 2012,
        "authors": [
          "Sadigh, D.",
          "Seshia, S. A.",
          "Gupta, M."
        ],
        "task": "Exercise Generation for Embedded Systems",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Singh2012_AlgebraProblemGenerator",
        "entity_type": "Algorithm",
        "name": "Algebra Problem Generator",
        "year": 2012,
        "authors": [
          "Singh, R.",
          "Gulwani, S.",
          "Rajamani, S. K."
        ],
        "task": "Algebra Problem Generation",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Gulwani2011_GeometryConstructionsSynthesizer",
        "entity_type": "Algorithm",
        "name": "Geometry Constructions Synthesizer",
        "year": 2011,
        "authors": [
          "Gulwani, S.",
          "Korthikanti, V. A.",
          "Tiwari, A."
        ],
        "task": "Geometry Construction Synthesis",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shi2015_SigmaDolphin",
        "entity_type": "Algorithm",
        "name": "SigmaDolphin",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": 2015,
        "authors": [
          "Shuming Shi",
          "Yuehui Wang",
          "Chin-Yew Lin",
          "Xiaojiang Liu",
          "Yong Rui"
        ],
        "task": "自动求解数学文字题",
        "dataset": [
          "Algebra.com_2015",
          "YahooAnswers.com_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "CFG Parser",
            "Reasoning Module",
            "Semantic Representation Language DOL"
          ],
          "connections": [
            "NL Text -> DOL Trees -> Math Expressions"
          ],
          "mechanisms": [
            "Context-Free Grammar Parsing",
            "Semantic Interpretation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CFG Rules Creation",
            "Semantic Parsing"
          ],
          "parameter_tuning": [
            "Type Compatibility Checking"
          ]
        },
        "feature_processing": [
          "Natural Language Processing",
          "Mathematical Expression Derivation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Algebra.com_2015",
        "entity_type": "Dataset",
        "name": "Algebra.com",
        "description": "一个用户发布数学问题并获得导师帮助的网站",
        "domain": "数学教育",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Various Contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "YahooAnswers.com_2015",
        "entity_type": "Dataset",
        "name": "Yahoo Answers",
        "description": "一个用户提问并获得答案的问答平台",
        "domain": "数学教育",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Various Contributors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Classification",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "精确率",
        "category": "分类评估",
        "formula": "正确分类样本数 / 总分类样本数"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Classification",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "召回率",
        "category": "分类评估",
        "formula": "正确分类样本数 / 总实际正样本数"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Classification",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1分数",
        "category": "分类评估",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bobrow1964_STUDENT",
        "entity_type": "Algorithm",
        "name": "STUDENT",
        "year": 1964,
        "authors": [
          "Bobrow, D.G."
        ],
        "task": "Solving algebraic word problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Transformation patterns",
            "Kernel sentences"
          ],
          "connections": [],
          "mechanisms": [
            "Pattern matching",
            "Verb categorization"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Charniak1968_CARPS",
        "entity_type": "Algorithm",
        "name": "CARPS",
        "year": 1968,
        "authors": [
          "Charniak, E."
        ],
        "task": "Solving English rate problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Tree structure"
          ],
          "connections": [],
          "mechanisms": [
            "Information gathering"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liguda2012_AugmentedSemanticNetworks",
        "entity_type": "Algorithm",
        "name": "Augmented Semantic Networks",
        "year": 2012,
        "authors": [
          "Liguda, C.",
          "Pfeiffer, T."
        ],
        "task": "Modeling math word problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Semantic networks"
          ],
          "connections": [],
          "mechanisms": [
            "Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_VerbCategorization",
        "entity_type": "Algorithm",
        "name": "Verb Categorization",
        "year": 2014,
        "authors": [
          "Hosseini, M.J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Verb categories"
          ],
          "connections": [],
          "mechanisms": [
            "Learning"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_EquationSystem",
        "entity_type": "Algorithm",
        "name": "Equation System",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Solving algebra word problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Equation templates"
          ],
          "connections": [],
          "mechanisms": [
            "Mapping to templates"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Freebase_2015",
        "entity_type": "Dataset",
        "name": "Freebase",
        "year": 2015,
        "creators": [],
        "domain": "General Knowledge",
        "size": null
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shi2015_CFGParser",
        "entity_type": "Algorithm",
        "name": "CFG Parser",
        "year": 2015,
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Algebra.com_2015",
          "YahooAnswers.com_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "CFG Grammar Rules",
            "Top-down Parser",
            "Earley Algorithm"
          ],
          "connections": [
            "Parsing NL Text to DOL Trees"
          ],
          "mechanisms": [
            "Context-Free Grammar",
            "Dynamic Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Semi-automatic Creation of Grammar Rules"
          ],
          "parameter_tuning": [
            "Type Compatibility Checking"
          ]
        },
        "feature_processing": [
          "Lexical String Handling",
          "Entity Variable Assignment"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shi2015_ReasoningModule",
        "entity_type": "Algorithm",
        "name": "Reasoning Module",
        "year": 2015,
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Algebra.com_2015",
          "YahooAnswers.com_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "Math Expression Derivation",
            "Equation System Solver"
          ],
          "connections": [
            "Deriving Math Expressions from DOL Trees"
          ],
          "mechanisms": [
            "Semantic Interpretation of DOL Nodes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Construction of Semantic Interpretations"
          ],
          "parameter_tuning": [
            "Handling Empty Parsing Results"
          ]
        },
        "feature_processing": [
          "Variable ID Assignment",
          "Lazy Variable ID Assignment"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "LinearT2_2015",
        "entity_type": "Dataset",
        "name": "LinearT2",
        "year": 2015,
        "creators": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "domain": "Math Word Problem Solving",
        "description": "Subset of problems with linear equations and at least two problems for each equation template"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "LinearT6_2015",
        "entity_type": "Dataset",
        "name": "LinearT6",
        "year": 2015,
        "creators": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "domain": "Math Word Problem Solving",
        "description": "Subset of problems with linear equations and at least six problems for each equation template"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Coverage_Classification",
        "entity_type": "Metric",
        "name": "Coverage",
        "category": "Classification Evaluation",
        "formula": "Number of Correct Answers / Total Number of Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "BasicSim_2015",
        "entity_type": "Algorithm",
        "name": "BasicSim",
        "year": 2015,
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "自动求解数学文字题",
        "dataset": [
          "LinearT2_2015",
          "LinearT6_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "相似性计算",
            "最相似问题应用"
          ],
          "connections": [
            "测试问题与训练集问题的相似性计算"
          ],
          "mechanisms": [
            "基于相似性的方程应用"
          ]
        },
        "methodology": {
          "training_strategy": [
            "基于训练集的问题相似性计算"
          ],
          "parameter_tuning": [
            "相似性阈值"
          ]
        },
        "feature_processing": [
          "问题相似性特征提取"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "TestSetAll_2015",
        "entity_type": "Dataset",
        "name": "Test Set All",
        "year": 2015,
        "creators": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "domain": "数学文字题求解",
        "size": 1504,
        "description": "包含1504个数学文字题的测试集"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DevSet_2015",
        "entity_type": "Dataset",
        "name": "Development Set",
        "year": 2015,
        "creators": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "domain": "数学文字题求解",
        "size": 374,
        "description": "包含374个数学文字题的开发集"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shi2015_SemanticParsingAndReasoning",
        "entity_type": "Algorithm",
        "name": "Semantic Parsing and Reasoning",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": 2015,
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.-Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "Solving Math Word Problems",
        "dataset": [
          "Algebra.com_2015",
          "YahooAnswers.com_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "Meaning Representation Language (DOL)",
            "CFG Parser",
            "Reasoning Module"
          ],
          "connections": [
            "NL Text -> DOL Trees -> Math Expressions"
          ],
          "mechanisms": [
            "Semantic Parsing",
            "Reasoning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CFG Grammar Rules",
            "Semantic Interpretation"
          ],
          "parameter_tuning": [
            "Type Compatibility Checking",
            "Score Calculation"
          ]
        },
        "feature_processing": [
          "Context-Free Grammar Parsing",
          "Entity Variable Assignment"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NumberWordProblems_2015",
        "entity_type": "Dataset",
        "name": "Number Word Problems",
        "description": "A collection of math word problems focusing on number-related problems",
        "domain": "Mathematics",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.-Y.",
          "Liu, X.",
          "Rui, Y."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_Aristo",
        "entity_type": "Algorithm",
        "name": "Aristo",
        "title": "Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY Regents Science Exam"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "IR Solver",
            "PMI Solver",
            "SVM Solver",
            "RULE Solver",
            "ILP Solver"
          ],
          "connections": [
            "Logistic Regression Combiner"
          ],
          "mechanisms": [
            "Information Retrieval",
            "Pointwise Mutual Information",
            "Support Vector Machine",
            "Rule-based Reasoning",
            "Integer Linear Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Ensemble Learning"
          ],
          "parameter_tuning": [
            "Logistic Regression Calibration"
          ]
        },
        "feature_processing": [
          "TF-IDF Scoring",
          "Lexical Chunk Matching",
          "Syntactic Pattern Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NY_Regents_Science_Exam_2016",
        "entity_type": "Dataset",
        "name": "NY Regents Science Exam",
        "description": "Standardized science exam questions for 4th grade students",
        "domain": "Elementary Education",
        "size": 237,
        "year": 2016,
        "creators": [
          "New York State Education Department"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_IRSolver",
        "entity_type": "Algorithm",
        "name": "Information Retrieval Solver",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Lucene Search Engine"
          ],
          "connections": [
            "Query to Search Engine",
            "Search Engine to Retrieved Sentences"
          ],
          "mechanisms": [
            "Text Matching",
            "Relevance Scoring"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Stopword Filtering",
          "Non-stopword Overlap"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_PMISolver",
        "entity_type": "Algorithm",
        "name": "Pointwise Mutual Information Solver",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "PMI Calculation Module"
          ],
          "connections": [
            "Question to PMI Calculation",
            "Answer Options to PMI Calculation"
          ],
          "mechanisms": [
            "Association Strength Measurement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "Window Size for Co-occurrence"
          ]
        },
        "feature_processing": [
          "Unigram Extraction",
          "Bigram Extraction",
          "Trigram Extraction",
          "Skip-Bigram Extraction",
          "Stopword Filtering"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_SVMSolver",
        "entity_type": "Algorithm",
        "name": "Support Vector Machine Solver",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Word Embedding Module",
            "SVM Ranker"
          ],
          "connections": [
            "Question to Word Embedding",
            "Answer Options to Word Embedding",
            "Embeddings to SVM Ranker"
          ],
          "mechanisms": [
            "Cosine Similarity Calculation",
            "Pairwise Cosine Similarity Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Kernel Parameters"
          ]
        },
        "feature_processing": [
          "Word Embedding Generation",
          "Vector Summation",
          "Vector Normalization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_RULESolver",
        "entity_type": "Algorithm",
        "name": "RULE Solver",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Rule Extraction Module",
            "Reasoning Module"
          ],
          "connections": [
            "Text to Rule Extraction",
            "Rules to Reasoning",
            "Question to Reasoning"
          ],
          "mechanisms": [
            "Implication Extraction",
            "Logical Reasoning",
            "Lexical Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Automatic Rule Extraction"
          ],
          "parameter_tuning": [
            "Rule Confidence Threshold"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Implication Pattern Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_ILPSolver",
        "entity_type": "Algorithm",
        "name": "Integer Linear Programming Solver",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Knowledge Table Module",
            "ILP Model"
          ],
          "connections": [
            "Tables to ILP Model",
            "Question to ILP Model",
            "Answer Options to ILP Model"
          ],
          "mechanisms": [
            "Proof Graph Construction",
            "Global Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "Similarity Measure Threshold",
            "Structural Constraints"
          ]
        },
        "feature_processing": [
          "Table Construction",
          "Relation Extraction",
          "TF-IDF Scoring"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Elementary_Science_Corpus_2016",
        "entity_type": "Dataset",
        "name": "Elementary Science Corpus",
        "description": "Corpus of 80k sentences about elementary science",
        "domain": "Elementary Education",
        "size": 80000,
        "year": 2016,
        "creators": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Web_Corpus_2016",
        "entity_type": "Dataset",
        "name": "Web Corpus",
        "description": "Corpus of 5 × 10^10 tokens extracted from Web pages",
        "domain": "General Web Content",
        "size": 50000000000,
        "year": 2016,
        "creators": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Score_Percentage",
        "entity_type": "Metric",
        "name": "Score Percentage",
        "description": "Percentage of correctly answered questions",
        "category": "Question Answering Evaluation",
        "formula": "Number of Correct Answers / Total Number of Questions * 100%"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Khot2015_Praline",
        "entity_type": "Algorithm",
        "name": "Praline",
        "year": 2015,
        "authors": [
          "Khot, T.",
          "Balasubramanian, N.",
          "Gribkoff, E.",
          "Sabharwal, A.",
          "Clark, P.",
          "Etzioni, O."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "Markov Logic Networks (MLNs)"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Parameter tuning for MLNs"
          ],
          "parameter_tuning": [
            "Optimal parameter values"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Score_Percentage_Regression",
        "entity_type": "Metric",
        "name": "Score Percentage",
        "description": "Percentage of correctly answered questions",
        "category": "Question Answering Evaluation",
        "formula": "Number of correct answers / Total number of questions * 100%"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_PMITaskFailureAnalysis",
        "entity_type": "Algorithm",
        "name": "PMI Task Failure Analysis",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "PMI Solver"
          ],
          "connections": [
            "Question-Answer Co-occurrence"
          ],
          "mechanisms": [
            "Co-occurrence Frequency"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Word Co-occurrence Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_RULETaskFailureAnalysis",
        "entity_type": "Algorithm",
        "name": "RULE Task Failure Analysis",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "RULE Solver"
          ],
          "connections": [
            "Rule Application"
          ],
          "mechanisms": [
            "Implication Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Analysis",
          "Implication Rule Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_ILPTaskStrengthAnalysis",
        "entity_type": "Algorithm",
        "name": "ILP Task Strength Analysis",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "ILP Solver"
          ],
          "connections": [
            "Table Joining"
          ],
          "mechanisms": [
            "Propositional Logic"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Table Construction",
          "Propositional Logic Encoding"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Score_Percentage_Comparison",
        "entity_type": "Metric",
        "name": "Score Percentage for Comparison Questions",
        "description": "Percentage of correctly answered comparison questions",
        "category": "Question Type Specific Evaluation",
        "formula": "Correctly answered comparison questions / Total comparison questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Score_Percentage_Arithmetic",
        "entity_type": "Metric",
        "name": "Score Percentage for Arithmetic Reasoning",
        "description": "Percentage of correctly answered arithmetic reasoning questions",
        "category": "Question Type Specific Evaluation",
        "formula": "Correctly answered arithmetic reasoning questions / Total arithmetic reasoning questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Score_Percentage_ComplexInference",
        "entity_type": "Metric",
        "name": "Score Percentage for Complex Inference",
        "description": "Percentage of correctly answered complex inference questions",
        "category": "Question Type Specific Evaluation",
        "formula": "Correctly answered complex inference questions / Total complex inference questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Score_Percentage_Structured",
        "entity_type": "Metric",
        "name": "Score Percentage for Structured Questions",
        "description": "Percentage of correctly answered structured questions",
        "category": "Question Type Specific Evaluation",
        "formula": "Correctly answered structured questions / Total structured questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Score_Percentage_Story",
        "entity_type": "Metric",
        "name": "Score Percentage for Story Questions",
        "description": "Percentage of correctly answered story questions",
        "category": "Question Type Specific Evaluation",
        "formula": "Correctly answered story questions / Total story questions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_MultipleRepresentationSystem",
        "entity_type": "Algorithm",
        "name": "Multiple Representation System",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P.",
          "Khashabi, D."
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "IR Solver",
            "PMI Solver",
            "SVM Solver",
            "RULE Solver",
            "ILP Solver"
          ],
          "connections": [
            "Logistic Regression Combiner"
          ],
          "mechanisms": [
            "Information Retrieval",
            "Statistical Reasoning",
            "Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Ensemble Learning"
          ],
          "parameter_tuning": [
            "Logistic Regression Calibration"
          ]
        },
        "feature_processing": [
          "Text Parsing",
          "Corpus Statistics",
          "Rule Extraction",
          "Table Building"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Score_Percentage_Ensemble",
        "entity_type": "Metric",
        "name": "Score Percentage",
        "description": "Percentage of correctly answered questions",
        "category": "Question Answering Evaluation",
        "formula": "Correct Answers / Total Questions * 100%"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_NeuralEquationClassifier",
        "entity_type": "Algorithm",
        "name": "Neural Equation Classifier",
        "year": 2018,
        "authors": [
          "Benjamin Robaidek",
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi"
        ],
        "task": "Solving Algebra Word Problems",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "softmax"
          ],
          "connections": [
            "word problem text -> BiLSTM -> softmax -> equation template"
          ],
          "mechanisms": [
            "cross entropy loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "end-to-end training"
          ],
          "parameter_tuning": [
            "learning parameters θ",
            "weights W"
          ]
        },
        "feature_processing": [
          "abstracting specific numbers from word problem text"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DRAW_2016",
        "entity_type": "Dataset",
        "name": "DRAW",
        "year": 2016,
        "creators": [
          "Shyam Upadhyay",
          "Ming-Wei Chang"
        ],
        "domain": "Algebra Word Problems",
        "size": 1000,
        "description": "A challenging and diverse algebra word problem set"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MAWPS_2016",
        "entity_type": "Dataset",
        "name": "MAWPS",
        "year": 2016,
        "creators": [
          "Rik Koncel-Kedziorski",
          "Subhro Roy",
          "Aida Amini",
          "Nate Kushman",
          "Hannaneh Hajishirzi"
        ],
        "domain": "Algebra Word Problems",
        "size": 2373,
        "description": "A math word problem repository"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Math23K_2017",
        "entity_type": "Dataset",
        "name": "Math23K",
        "year": 2017,
        "creators": [
          "Yan Wang",
          "Xiaojiang Liu",
          "Shuming Shi"
        ],
        "domain": "Algebra Word Problems",
        "size": 23164,
        "description": "A large dataset of Chinese algebra word problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_EquationTemplate",
        "entity_type": "Algorithm",
        "name": "Equation Template",
        "year": 2018,
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "Equation Template Generator"
          ],
          "connections": [
            "Word Problem Text -> Equation Template"
          ],
          "mechanisms": [
            "Number Abstraction",
            "Template Population"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross Entropy Loss"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden State Size"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Text Normalization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_Seq2SeqModel",
        "entity_type": "Algorithm",
        "name": "Seq2Seq Model",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H.T."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Attention Mechanism"
          ],
          "connections": [
            "Bidirectional LSTM",
            "Convolutional Neural Network"
          ],
          "mechanisms": [
            "Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training",
            "Cross entropy loss"
          ],
          "parameter_tuning": [
            "Hidden state dimension",
            "Embedding dimension",
            "Dropout rate"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Number abstraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_StructuredSelfAttention",
        "entity_type": "Algorithm",
        "name": "Structured Self-Attention",
        "year": 2017,
        "authors": [
          "Lin, Z.",
          "Feng, M.",
          "dos Santos, C.N.",
          "Yu, M.",
          "Xiang, B.",
          "Zhou, B.",
          "Bengio, Y."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM Encoder",
            "Multi-hop Attention"
          ],
          "connections": [
            "Bidirectional LSTM"
          ],
          "mechanisms": [
            "Self-Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training",
            "Cross entropy loss"
          ],
          "parameter_tuning": [
            "Attention hops",
            "Redundancy reduction"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KoncelKedziorski2016_RetrievalModel",
        "entity_type": "Algorithm",
        "name": "Retrieval Model",
        "year": 2016,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Roy, S.",
          "Amini, A.",
          "Kushman, N.",
          "Hajishirzi, H."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Similarity Metric"
          ],
          "connections": [
            "Jaccard Distance",
            "Cosine Similarity"
          ],
          "mechanisms": [
            "Nearest Neighbor"
          ]
        },
        "methodology": {
          "training_strategy": [
            "No training required"
          ],
          "parameter_tuning": [
            "Similarity threshold"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_GloVe",
        "entity_type": "Algorithm",
        "name": "GloVe",
        "year": 2014,
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C."
        ],
        "task": "Word Embedding",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "None"
        ],
        "architecture": {
          "components": [
            "Global Vectors"
          ],
          "connections": [
            "Word co-occurrence matrix"
          ],
          "mechanisms": [
            "Matrix factorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised learning"
          ],
          "parameter_tuning": [
            "Vector dimension"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Peters2018_ELMo",
        "entity_type": "Algorithm",
        "name": "ELMo",
        "year": 2018,
        "authors": [
          "Peters, M.E.",
          "Neumann, M.",
          "Iyyer, M.",
          "Gardner, M.",
          "Clark, C.",
          "Lee, K.",
          "Zettlemoyer, L."
        ],
        "task": "Word Embedding",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "None"
        ],
        "architecture": {
          "components": [
            "Character embeddings",
            "Bidirectional LSTM"
          ],
          "connections": [
            "Character-level CNN"
          ],
          "mechanisms": [
            "Contextualized word representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised learning"
          ],
          "parameter_tuning": [
            "Layer weights"
          ]
        },
        "feature_processing": [
          "Character embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_BiLSTMClassifier",
        "entity_type": "Algorithm",
        "name": "BiLSTM Classifier",
        "year": 2018,
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Softmax Layer"
          ],
          "connections": [
            "Word Embedding -> Bidirectional LSTM -> Softmax"
          ],
          "mechanisms": [
            "Cross Entropy Loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Hidden state size",
            "Dropout rate"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_Seq2SeqModel",
        "entity_type": "Algorithm",
        "name": "Seq2Seq Model",
        "year": 2018,
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder (LSTM/CNN)",
            "Decoder (LSTM/CNN)",
            "Attention Mechanism"
          ],
          "connections": [
            "Word Embedding -> Encoder -> Attention -> Decoder"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Sequence Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Teacher forcing"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Hidden state size",
            "Dropout rate",
            "Kernel width"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "OracleAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Oracle Accuracy",
        "description": "The maximum possible accuracy if all test equation templates appear in the training data.",
        "category": "Classification Evaluation",
        "formula": "Number of test equation templates appearing in training data / Total number of test equation templates"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_SemanticLimitations",
        "entity_type": "Algorithm",
        "name": "Semantic Limitations",
        "year": 2018,
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Word Problem Text",
            "Equation Templates"
          ],
          "connections": [
            "Mapping Text to Templates"
          ],
          "mechanisms": [
            "Semantic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross Entropy Loss"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Template Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_WorldKnowledge",
        "entity_type": "Algorithm",
        "name": "World Knowledge",
        "year": 2018,
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Word Problem Text",
            "Equation Templates"
          ],
          "connections": [
            "Mapping Text to Templates"
          ],
          "mechanisms": [
            "External Knowledge Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross Entropy Loss"
          ]
        },
        "feature_processing": [
          "Contextual Information",
          "Geographical Directions"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorRate_SemanticLimitations",
        "entity_type": "Metric",
        "name": "Error Rate (Semantic Limitations)",
        "description": "Percentage of errors due to incomplete semantic understanding",
        "category": "Error Analysis",
        "formula": "Number of Semantic Errors / Total Number of Errors"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorRate_WorldKnowledge",
        "entity_type": "Metric",
        "name": "Error Rate (World Knowledge)",
        "description": "Percentage of errors due to lack of world knowledge",
        "category": "Error Analysis",
        "formula": "Number of World Knowledge Errors / Total Number of Errors"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_RNNBasedSeq2SeqModel",
        "entity_type": "Algorithm",
        "name": "RNN-based Seq2Seq Model",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "GRU",
            "LSTM"
          ],
          "connections": [
            "Encoder-Decoder"
          ],
          "mechanisms": [
            "Number Mapping",
            "Significant Number Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mini-batch",
            "Dropout"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Epochs"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_HybridModel",
        "entity_type": "Algorithm",
        "name": "Hybrid Model",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "RNN-based Seq2Seq Model",
            "Retrieval Model"
          ],
          "connections": [
            "Threshold-based Selection"
          ],
          "mechanisms": [
            "Similarity-based Retrieval",
            "Seq2Seq Generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mini-batch",
            "Dropout"
          ],
          "parameter_tuning": [
            "Threshold",
            "Learning Rate",
            "Epochs"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_SignificantNumberIdentification",
        "entity_type": "Algorithm",
        "name": "Significant Number Identification",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "LSTM"
          ],
          "connections": [
            "Binary Classification"
          ],
          "mechanisms": [
            "Context Window"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mini-batch"
          ],
          "parameter_tuning": [
            "Nodes",
            "Window Size"
          ]
        },
        "feature_processing": [
          "Context Window"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Alg514_2014",
        "entity_type": "Dataset",
        "name": "Alg514",
        "description": "A dataset of linear algebra problems",
        "domain": "Natural Language Processing",
        "size": 514,
        "year": 2014,
        "creators": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Charniak1968_CalculusWordProblems",
        "entity_type": "Algorithm",
        "name": "Calculus Word Problems",
        "year": 1968,
        "authors": [
          "Charniak, E."
        ],
        "task": "Calculus Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Pattern Matching"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KoncelKedziorski2015_EquationTrees",
        "entity_type": "Algorithm",
        "name": "Equation Trees",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "Algebraic Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Equation Generation",
            "Scoring"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_EquationTemplateSystem",
        "entity_type": "Algorithm",
        "name": "Equation Template System",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Equation Templates"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_MaxMarginObjective",
        "entity_type": "Algorithm",
        "name": "Max-Margin Objective",
        "year": 2015,
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Max-Margin Objective"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_MultiStepArithmetic",
        "entity_type": "Algorithm",
        "name": "Multi-Step Arithmetic",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Vieira, T.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Multi-Step Reasoning"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_FormulaLearning",
        "entity_type": "Algorithm",
        "name": "Formula Learning",
        "year": 2016,
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "Simple Arithmetic Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Formula Usage"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin1878_2015",
        "entity_type": "Dataset",
        "name": "Dolphin1878",
        "year": 2015,
        "creators": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.-Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "domain": "Math Word Problem Solving",
        "size": 1878,
        "description": "Number word problems"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DRAW1K_2017",
        "entity_type": "Dataset",
        "name": "DRAW-1K",
        "year": 2017,
        "creators": [
          "Shyam, U.",
          "Ming-Wei, C."
        ],
        "domain": "Math Word Problem Solving",
        "size": 1000,
        "description": "Algebra, linear, one-VAR problems"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin18K_2016",
        "entity_type": "Dataset",
        "name": "Dolphin18K",
        "year": 2016,
        "creators": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.-Y.",
          "Yin, J.",
          "Ma, W.-Y."
        ],
        "domain": "Math Word Problem Solving",
        "size": 18000,
        "description": "Large and diverse math word problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_NumberMapping",
        "entity_type": "Algorithm",
        "name": "Number Mapping",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "数学文字问题求解",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "映射模块",
            "变量替换"
          ],
          "connections": [
            "问题文本到方程模板的转换"
          ],
          "mechanisms": [
            "数字替换规则"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习"
          ],
          "parameter_tuning": [
            "无"
          ]
        },
        "feature_processing": [
          "数字提取",
          "变量替换"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_EquationTemplate",
        "entity_type": "Algorithm",
        "name": "Equation Template",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "数学文字问题求解",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "方程模板生成器"
          ],
          "connections": [
            "问题文本到方程模板的转换"
          ],
          "mechanisms": [
            "方程模板匹配"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习"
          ],
          "parameter_tuning": [
            "无"
          ]
        },
        "feature_processing": [
          "方程模板生成"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_RetrievalModel",
        "entity_type": "Algorithm",
        "name": "Retrieval Model",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "TF-IDF Vectorizer",
            "Jaccard Similarity"
          ],
          "connections": [
            "Vector Comparison"
          ],
          "mechanisms": [
            "Lexical Similarity Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Similarity-Based Retrieval"
          ],
          "parameter_tuning": [
            "Threshold Setting"
          ]
        },
        "feature_processing": [
          "TF-IDF Scoring"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Retrieval",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Precision measures the proportion of true positive results among the retrieved instances.",
        "category": "Retrieval Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Retrieval",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Recall measures the proportion of true positive results among all relevant instances.",
        "category": "Retrieval Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "JaccardSimilarity",
        "entity_type": "Metric",
        "name": "Jaccard Similarity",
        "description": "Jaccard Similarity measures the similarity between two sets.",
        "category": "Set Similarity",
        "formula": "|A ∩ B| / |A ∪ B|"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_GRU",
        "entity_type": "Algorithm",
        "name": "GRU",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Gated Recurrent Units"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Update gate",
            "Reset gate",
            "Hidden state"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Standard dropout"
          ],
          "parameter_tuning": [
            "Dropout probability 0.5"
          ]
        },
        "feature_processing": [
          "Number mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_LSTM",
        "entity_type": "Algorithm",
        "name": "LSTM",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Long Short-Term Memory"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Input gate",
            "Forget gate",
            "Output gate",
            "Hidden state"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Standard dropout"
          ],
          "parameter_tuning": [
            "Dropout probability 0.5"
          ]
        },
        "feature_processing": [
          "Number mapping"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Seq2Seq",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Precision of the Seq2Seq model",
        "category": "Classification",
        "formula": "True positives / (True positives + False positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Seq2Seq",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Recall of the Seq2Seq model",
        "category": "Classification",
        "formula": "True positives / (True positives + False negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1Score_Seq2Seq",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 Score of the Seq2Seq model",
        "category": "Classification",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_G-ALIGNER",
        "entity_type": "Algorithm",
        "name": "G-ALIGNER",
        "title": "Diagram Understanding in Geometry Questions",
        "year": 2014,
        "authors": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "Geometry Questions Dataset_2014"
        ],
        "metrics": [
          "F1 Score_Identifying Primitives",
          "F1 Score_Aligning Visual Elements"
        ],
        "architecture": {
          "components": [
            "Primitive Detection",
            "Textual Mention Extraction",
            "Alignment Constraint Function"
          ],
          "connections": [
            "Visual Coherence Function",
            "Coverage Function"
          ],
          "mechanisms": [
            "Submodular Optimization",
            "Greedy Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Optimization",
            "Initialization of Primitives",
            "Corner Detection"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Hough Transform",
          "Gaussian Blur",
          "Binarization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geometry Questions Dataset_2014",
        "entity_type": "Dataset",
        "name": "Geometry Questions Dataset",
        "description": "A dataset of geometry questions including textual descriptions and diagrams",
        "domain": "Geometry",
        "size": 100,
        "year": 2014,
        "creators": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1 Score_Identifying Primitives",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Identifying Primitives",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1 Score_Aligning Visual Elements",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Aligning Visual Elements",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_HoughTransform",
        "entity_type": "Algorithm",
        "name": "Hough Transform",
        "year": 2014,
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "Primitive Detection",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Line Detection",
            "Circle Detection"
          ],
          "connections": [
            "Parametric Representation",
            "Post-processing for Endpoints"
          ],
          "mechanisms": [
            "Thresholding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Threshold for Line Detection",
            "Threshold for Circle Detection",
            "Non-maximum Suppression Parameters"
          ]
        },
        "feature_processing": [
          "Gaussian Blur",
          "Binarization"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Identifying Primitives",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Precision for identifying primitives",
        "category": "Primitive Detection Evaluation",
        "formula": "Number of Correctly Identified Primitives / Total Number of Identified Primitives"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Identifying Primitives",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Recall for identifying primitives",
        "category": "Primitive Detection Evaluation",
        "formula": "Number of Correctly Identified Primitives / Number of Primitives in Ground Truth"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Aligning Textual Mentions",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for aligning textual mentions with visual elements",
        "category": "Alignment Evaluation",
        "formula": "Number of Correct Alignments / Total Number of Alignments"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_OptimizationProcedure",
        "entity_type": "Algorithm",
        "name": "Optimization Procedure",
        "year": 2014,
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall",
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Coverage Function",
            "Visual Coherence Function",
            "Alignment Constraint Function"
          ],
          "connections": [
            "Maximizing Agreement Between Textual and Visual Data"
          ],
          "mechanisms": [
            "Submodular Optimization",
            "Greedy Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Greedy Method"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Primitive Extraction",
          "Corner Detection",
          "Textual Mention Initialization"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Coverage_Function_DiagramUnderstanding",
        "entity_type": "Metric",
        "name": "Coverage Function",
        "description": "Measures the proportion of important pixels in the diagram explained by the identified primitives.",
        "category": "Diagram Understanding Evaluation",
        "formula": "Number of covered pixels / Total number of non-white pixels"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Visual_Coherence_Function_DiagramUnderstanding",
        "entity_type": "Metric",
        "name": "Visual Coherence Function",
        "description": "Measures the visual coherence of the identified primitives by comparing detected corners and primitives.",
        "category": "Diagram Understanding Evaluation",
        "formula": "Number of matched corners / Total number of detected corners"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Alignment_Constraint_Function_DiagramUnderstanding",
        "entity_type": "Metric",
        "name": "Alignment Constraint Function",
        "description": "Models the alignment between textual mentions and visual elements.",
        "category": "Diagram Understanding Evaluation",
        "formula": "(Number of aligned textual mentions / Total number of textual mentions) - Redundancy"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "HighSchoolPlaneGeometryQuestions_2014",
        "entity_type": "Dataset",
        "name": "High School Plane Geometry Questions",
        "description": "A dataset of high school plane geometry questions with textual descriptions and accompanying diagrams.",
        "domain": "Geometry",
        "size": 100,
        "year": 2014,
        "creators": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_GreedyMethod",
        "entity_type": "Algorithm",
        "name": "Greedy Method",
        "year": 2014,
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Primitive Identification",
            "Alignment with Textual Mentions"
          ],
          "connections": [
            "Coverage Function",
            "Visual Coherence Function",
            "Alignment Constraint Function"
          ],
          "mechanisms": [
            "Submodular Optimization",
            "Greedy Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Optimization"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Hough Transform for Initial Primitives",
          "Corner Detection"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Identifying_Primatives",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall for identifying primitives.",
        "category": "Diagram Understanding Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Aligning_Visual_Elements",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall for aligning visual elements with textual mentions.",
        "category": "Diagram Understanding Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Identifying_Primatives",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Number of correctly identified primitives divided by total number of identified primitives.",
        "category": "Diagram Understanding Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Identifying_Primatives",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Number of correctly identified primitives divided by the number of primitives in ground truth.",
        "category": "Diagram Understanding Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Aligning_Textual_Mentions",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correctly aligned textual mentions with visual elements.",
        "category": "Diagram Understanding Evaluation",
        "formula": "Correct Alignments / Total Alignments"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_HarrisCornerDetector",
        "entity_type": "Algorithm",
        "name": "Harris Corner Detector",
        "year": 2014,
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "Corner Detection",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Corner Detection"
          ],
          "connections": [
            "Visual Coherence Function"
          ],
          "mechanisms": [
            "Feature Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Initialization"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Corner Scoring"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_SubmodularOptimization",
        "entity_type": "Algorithm",
        "name": "Submodular Optimization",
        "year": 2014,
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall",
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Coverage Function",
            "Visual Coherence Function",
            "Alignment Constraint Function"
          ],
          "connections": [
            "Maximizing Agreement Between Textual and Visual Data"
          ],
          "mechanisms": [
            "Submodular Objective Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Greedy Method"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Primitive Extraction",
          "Corner Detection",
          "Textual Mention Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "HighSchoolGeometryQuestions_2014",
        "entity_type": "Dataset",
        "name": "High School Geometry Questions",
        "description": "Dataset of high school plane geometry questions with textual descriptions and diagrams.",
        "domain": "Geometry",
        "size": 100,
        "year": 2014,
        "creators": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Alignment_Accuracy",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Alignment Accuracy",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Alignment_Accuracy",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Ratio of correctly identified alignments to total identified alignments",
        "category": "Alignment Accuracy",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Alignment_Accuracy",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Ratio of correctly identified alignments to total actual alignments",
        "category": "Alignment Accuracy",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Alignment_Accuracy",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correct alignments out of total alignments",
        "category": "Alignment Accuracy",
        "formula": "Correct Alignments / Total Alignments"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_PrimitiveExtraction",
        "entity_type": "Algorithm",
        "name": "Primitive Extraction",
        "year": 2014,
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Line Segments",
            "Circle Segments",
            "Arcs"
          ],
          "connections": [
            "Combining Primitives into Visual Elements"
          ],
          "mechanisms": [
            "Hough Transform",
            "Post-processing for Endpoint Determination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Over-generation of Primitives"
          ],
          "parameter_tuning": [
            "Low Threshold for Over-generation"
          ]
        },
        "feature_processing": [
          "Noise Removal",
          "Binarization",
          "Continuous Binary Point Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_CornerDetection",
        "entity_type": "Algorithm",
        "name": "Corner Detection",
        "year": 2014,
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Corners"
          ],
          "connections": [
            "Matching Corners to Primitives"
          ],
          "mechanisms": [
            "Harris Corner Detector"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Encouraging Visual Coherence"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Scoring Corners Based on Proximity to Primitives"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_TextualMentionExtraction",
        "entity_type": "Algorithm",
        "name": "Textual Mention Extraction",
        "year": 2014,
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Textual Mentions"
          ],
          "connections": [
            "Aligning Textual Mentions to Visual Elements"
          ],
          "mechanisms": [
            "Keyword Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Extracting Mentions from Textual Descriptions"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Keyword Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Watanabe1991_IntegrationFramework",
        "entity_type": "Algorithm",
        "name": "Integration Framework",
        "title": "Diagram Understanding Using Integration of Layout Information and Textual Information",
        "year": 1991,
        "authors": [
          "Yasuhiko Watanabe",
          "Makoto Nagao"
        ],
        "task": "Diagram Understanding",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Layout Information",
            "Natural Language Information"
          ],
          "connections": [
            "Connection",
            "Adjacency"
          ],
          "mechanisms": [
            "Semantic Interpretation",
            "Clue Expressions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Observation and Experiments"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Pattern/Layout Information",
          "Natural Language Information"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PBF_Diagrams_1991",
        "entity_type": "Dataset",
        "name": "PBF Diagrams",
        "description": "Diagrams from Pictorial Book of Flora (PBF) in Japanese",
        "domain": "Botanical Illustrations",
        "size": 31,
        "year": 1991,
        "creators": [
          "Yasuhiko Watanabe",
          "Makoto Nagao"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SemanticAnalysis_SuccessRate",
        "entity_type": "Metric",
        "name": "Success Rate",
        "description": "Rate of successful semantic analysis",
        "category": "Semantic Analysis Evaluation",
        "formula": "Number of successful interpretations / Total number of interpretations"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Watanabe1991_SemanticInterpretationFramework",
        "entity_type": "Algorithm",
        "name": "Semantic Interpretation Framework",
        "year": 1991,
        "authors": [
          "Yasuhiko Watanabe",
          "Makoto Nagao"
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "PBF Diagrams"
        ],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Layout Information",
            "Natural Language Information"
          ],
          "connections": [
            "Integration of Layout and Natural Language Information"
          ],
          "mechanisms": [
            "Symbol Connection",
            "Spatial Relationship Similarity",
            "Expression Patterns"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Annotation of Diagram Elements"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Japanese Morphological Analysis",
          "Pattern Matching"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SuccessRate_DiagramUnderstanding",
        "entity_type": "Metric",
        "name": "Success Rate",
        "description": "Proportion of correctly interpreted diagram elements.",
        "category": "Diagram Understanding Evaluation",
        "formula": "Number of Correctly Interpreted Elements / Total Number of Elements"
      }
    },
    {
      "metric_entity": {
        "metric_id": "FailureRate_DiagramUnderstanding",
        "entity_type": "Metric",
        "name": "Failure Rate",
        "description": "Proportion of incorrectly interpreted diagram elements.",
        "category": "Diagram Understanding Evaluation",
        "formula": "Number of Incorrectly Interpreted Elements / Total Number of Elements"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Watanabe1991_LayoutAndNaturalLanguageIntegration",
        "entity_type": "Algorithm",
        "name": "Layout and Natural Language Integration Framework",
        "year": 1991,
        "authors": [
          "Watanabe, Y.",
          "Nagao, M."
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "PBF Diagrams"
        ],
        "metrics": [
          "Success Rate",
          "Failure Rate"
        ],
        "architecture": {
          "components": [
            "Layout Information",
            "Natural Language Information"
          ],
          "connections": [
            "Symbol Connection",
            "Spatial Adjacency"
          ],
          "mechanisms": [
            "Semantic Interpretation Rules",
            "Clue Expressions Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pattern Matching",
            "Japanese Morphological Analysis"
          ],
          "parameter_tuning": [
            "Expression Patterns Matching",
            "Spatial Relationship Detection"
          ]
        },
        "feature_processing": [
          "ID Number Assignment",
          "Element Correspondence Description"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Watanabe1991_RuleBasedSemanticAnalysis",
        "entity_type": "Algorithm",
        "name": "Rule-Based Semantic Analysis",
        "year": 1991,
        "authors": [
          "Watanabe, Y.",
          "Nagao, M."
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "PBF Diagrams"
        ],
        "metrics": [
          "Success Rate",
          "Failure Rate"
        ],
        "architecture": {
          "components": [
            "Rule 1",
            "Rule 2",
            "Rule 3",
            "Rule 4",
            "Rule 5",
            "Rule 6",
            "Rule 7"
          ],
          "connections": [
            "Layout Information",
            "Natural Language Information"
          ],
          "mechanisms": [
            "Symbol Connection",
            "Spatial Relationship",
            "Expression Patterns"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Annotation"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Japanese Morphological Analysis",
          "Pattern Matching"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SuccessRate_SemanticAnalysis",
        "entity_type": "Metric",
        "name": "Success Rate",
        "description": "The proportion of correctly interpreted elements in the diagrams.",
        "category": "Diagram Understanding Evaluation",
        "formula": "Number of correct interpretations / Total number of elements"
      }
    },
    {
      "metric_entity": {
        "metric_id": "FailureRate_SemanticAnalysis",
        "entity_type": "Metric",
        "name": "Failure Rate",
        "description": "The proportion of incorrectly interpreted elements in the diagrams.",
        "category": "Diagram Understanding Evaluation",
        "formula": "Number of incorrect interpretations / Total number of elements"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_DimensionallyGuidedSynthesis",
        "entity_type": "Algorithm",
        "name": "Dimensionally Guided Synthesis",
        "title": "Dimensionally Guided Synthesis of Mathematical Word Problems",
        "year": 2016,
        "authors": [
          "Ke Wang",
          "Zhendong Su"
        ],
        "task": "Mathematical Word Problem Generation",
        "dataset": [],
        "metrics": [
          "authenticity",
          "diversity",
          "configurability"
        ],
        "architecture": {
          "components": [
            "equation generator",
            "narrative generator"
          ],
          "connections": [
            "equation generation -> narrative generation"
          ],
          "mechanisms": [
            "dimensional consistency",
            "binary expression tree",
            "sub-story generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "random equation synthesis",
            "variable unrolling"
          ],
          "parameter_tuning": [
            "dimensional units assignment",
            "arithmetic operation complexity"
          ]
        },
        "feature_processing": [
          "dimensional units handling",
          "keyword assignment",
          "numerical value generation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Authenticity_TextbookSimilarity",
        "entity_type": "Metric",
        "name": "Authenticity",
        "description": "Statistical indistinguishability from actual textbook problems",
        "category": "Problem Similarity",
        "formula": "Paired t-test and Chi-square test of independence"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorRate_Comparison",
        "entity_type": "Metric",
        "name": "Error Rate",
        "description": "Comparison of error rates between generated and textbook problems",
        "category": "Problem Difficulty",
        "formula": "Two one-sided test for equivalence"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Performance_Efficiency",
        "entity_type": "Metric",
        "name": "Performance",
        "description": "Time taken to synthesize problems",
        "category": "Generation Efficiency",
        "formula": "Boxplot analysis of synthesis time"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_EquationGenerator",
        "entity_type": "Algorithm",
        "name": "Equation Generator",
        "year": 2016,
        "authors": [
          "Wang, K.",
          "Su, Z."
        ],
        "task": "Mathematical Word Problem Generation",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Seed Equation Synthesis",
            "Variable Unrolling"
          ],
          "connections": [
            "Semantic Instantiation",
            "Operational Rules"
          ],
          "mechanisms": [
            "Dimensional Unit Assignment",
            "Binary Expression Tree"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Equation Generation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dimensional Unit Handling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_NarrativeGenerator",
        "entity_type": "Algorithm",
        "name": "Narrative Generator",
        "year": 2016,
        "authors": [
          "Wang, K.",
          "Su, Z."
        ],
        "task": "Mathematical Word Problem Generation",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Binary Expression Tree",
            "Keyword Assignment",
            "Sub-story Generation"
          ],
          "connections": [
            "Atomic Expression Trees",
            "Postorder Traversal"
          ],
          "mechanisms": [
            "Verbal Templates",
            "Sub-story Concatenation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Recursive Story Construction"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dimensional Unit Integration",
          "Keyword Selection"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "StatisticalIndistinguishability_Authenticity",
        "entity_type": "Metric",
        "name": "Statistical Indistinguishability",
        "description": "Measure of whether generated problems are statistically indistinguishable from textbook problems",
        "category": "Authenticity Assessment",
        "formula": "Paired t-test and Chi-square test of independence"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorMargin_Similarity",
        "entity_type": "Metric",
        "name": "Error Margin",
        "description": "Threshold error margin for comparing error rates between problem sets",
        "category": "Problem Set Similarity",
        "formula": "Two one-sided test for equivalence"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SingaporeMathCurriculum_2009",
        "entity_type": "Dataset",
        "name": "Singapore Math Curriculum",
        "description": "Collection of mathematical word problems used in Singapore schools",
        "domain": "Education",
        "size": 24,
        "year": 2009,
        "creators": [
          "Frank Schaffer Publications"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_SMTSolver",
        "entity_type": "Algorithm",
        "name": "SMT Solver",
        "title": "Dimensionally Guided Synthesis of Mathematical Word Problems",
        "year": 2016,
        "authors": [
          "Ke Wang",
          "Zhendong Su"
        ],
        "task": "Mathematical Word Problem Generation",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Solver"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DimensionalUnits_2016",
        "entity_type": "Dataset",
        "name": "Dimensional Units",
        "description": "A set of dimensional units used for generating mathematical word problems.",
        "domain": "Mathematics Education",
        "size": 43,
        "year": 2016,
        "creators": [
          "Ke Wang",
          "Zhendong Su"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "PairedTTest_Similarity",
        "entity_type": "Metric",
        "name": "Paired T-Test",
        "description": "Statistical test used to compare the means of two related groups.",
        "category": "Statistical Significance",
        "formula": "t = (mean1 - mean2) / sqrt((std1^2 + std2^2) / n)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ChiSquaredTest_Independence",
        "entity_type": "Metric",
        "name": "Chi-Squared Test of Independence",
        "description": "Statistical test used to determine if there is a significant association between two categorical variables.",
        "category": "Statistical Significance",
        "formula": "χ² = Σ((O - E)^2 / E)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "StoufferTest_GroupLevel",
        "entity_type": "Metric",
        "name": "Stouffer Test",
        "description": "Statistical method used to combine the results of multiple independent tests into a single test statistic.",
        "category": "Statistical Significance",
        "formula": "Z = Σ(Zi / sqrt(k))"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Singley2002_AutomaticItemGeneration",
        "entity_type": "Algorithm",
        "name": "Automatic Item Generation",
        "year": 2002,
        "authors": [
          "Singley, M. K.",
          "Bennett, R. E."
        ],
        "task": "Mathematical Word Problem Generation",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {
          "training_strategy": [
            "Template-based natural language generation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deane2003_FrameSemanticsBasedGeneration",
        "entity_type": "Algorithm",
        "name": "Frame Semantics Based Generation",
        "year": 2003,
        "authors": [
          "Deane, P.",
          "Sheehan, K."
        ],
        "task": "Mathematical Word Problem Generation",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {
          "training_strategy": [
            "Frame Semantics"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Polozov2015_PersonalizedWordProblemGeneration",
        "entity_type": "Algorithm",
        "name": "Personalized Word Problem Generation",
        "year": 2015,
        "authors": [
          "Polozov, O.",
          "O'Rourke, E.",
          "Smith, A. M.",
          "Zettlemoyer, L.",
          "Gulwani, S.",
          "Popovic, Z."
        ],
        "task": "Mathematical Word Problem Generation",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {
          "training_strategy": [
            "Engaging story lines"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liguda2012_ModelingWordProblems",
        "entity_type": "Algorithm",
        "name": "Modeling Word Problems",
        "year": 2012,
        "authors": [
          "Liguda, C.",
          "Pfeiffer, T."
        ],
        "task": "Mathematical Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {
          "training_strategy": [
            "Augmented Semantic Networks"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_VerbCategorizationSolver",
        "entity_type": "Algorithm",
        "name": "Verb Categorization Solver",
        "year": 2014,
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {
          "training_strategy": [
            "Verb categorization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_AutomaticAlgebraSolver",
        "entity_type": "Algorithm",
        "name": "Automatic Algebra Solver",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {},
        "methodology": {
          "training_strategy": [
            "Learning from equations or final answers"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_MWPSynthesisApproach",
        "entity_type": "Algorithm",
        "name": "MWPSynthesis Approach",
        "year": 2016,
        "authors": [
          "Wang, K.",
          "Su, Z."
        ],
        "task": "Mathematical Word Problem Synthesis",
        "dataset": [
          "Singapore Math Curriculum 2009"
        ],
        "metrics": [
          "Authenticity",
          "Error Rate",
          "Statistical Indistinguishability"
        ],
        "architecture": {
          "components": [
            "Equation Generator",
            "Narrative Generator"
          ],
          "connections": [
            "Equation to Story Conversion"
          ],
          "mechanisms": [
            "Dimensional Units",
            "Binary Expression Trees"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Equation Generation",
            "Dimensional Unit Assignment"
          ],
          "parameter_tuning": [
            "Arithmetic Operation Complexity",
            "Distraction Elements"
          ]
        },
        "feature_processing": [
          "Dimensional Unit Handling",
          "Natural Language Story Generation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_SkipGram",
        "entity_type": "Algorithm",
        "name": "Skip-gram",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "News Articles"
        ],
        "metrics": [
          "Accuracy",
          "Training Speed"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Output Layer"
          ],
          "connections": [
            "Input to Hidden",
            "Hidden to Output"
          ],
          "mechanisms": [
            "Negative Sampling",
            "Hierarchical Softmax"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of Frequent Words",
            "Negative Sampling",
            "Hierarchical Softmax"
          ],
          "parameter_tuning": [
            "Dimensionality",
            "Context Size",
            "Subsampling Rate"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_HierarchicalSoftmax",
        "entity_type": "Algorithm",
        "name": "Hierarchical Softmax",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "News Articles"
        ],
        "metrics": [
          "Accuracy",
          "Training Speed"
        ],
        "architecture": {
          "components": [
            "Binary Tree",
            "Output Nodes"
          ],
          "connections": [
            "Root to Leaf"
          ],
          "mechanisms": [
            "Binary Tree Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of Frequent Words"
          ],
          "parameter_tuning": [
            "Tree Structure"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_NegativeSampling",
        "entity_type": "Algorithm",
        "name": "Negative Sampling",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "News Articles"
        ],
        "metrics": [
          "Accuracy",
          "Training Speed"
        ],
        "architecture": {
          "components": [
            "Noise Distribution",
            "Logistic Regression"
          ],
          "connections": [
            "Target Word to Noise Samples"
          ],
          "mechanisms": [
            "Logistic Regression"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of Frequent Words"
          ],
          "parameter_tuning": [
            "Number of Negative Samples"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NewsArticles_2013",
        "entity_type": "Dataset",
        "name": "News Articles",
        "description": "A large dataset consisting of various news articles",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": 2013,
        "creators": [
          "Google Inc."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_AnalogicalReasoning",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy on the analogical reasoning task",
        "category": "Analogical Reasoning",
        "formula": "Correct predictions / Total predictions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "TrainingSpeed",
        "entity_type": "Metric",
        "name": "Training Speed",
        "description": "Speed of training the model",
        "category": "Training Efficiency",
        "formula": "Time taken to train the model"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_Subsampling",
        "entity_type": "Algorithm",
        "name": "Subsampling of Frequent Words",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Word Representation Learning",
        "dataset": [
          "NewsArticles_2013"
        ],
        "metrics": [
          "TrainingSpeed",
          "Accuracy_AnalogicalReasoning"
        ],
        "architecture": {
          "components": [
            "Skip-gram model"
          ],
          "connections": [
            "Input word -> Context words"
          ],
          "mechanisms": [
            "Probability-based word discarding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Discard frequent words with probability"
          ],
          "parameter_tuning": [
            "Threshold t"
          ]
        },
        "feature_processing": [
          "Word frequency filtering"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "TotalAccuracy_AnalogicalReasoning",
        "entity_type": "Metric",
        "name": "Total Accuracy",
        "description": "Overall accuracy on analogical reasoning task",
        "category": "Analogical Reasoning Evaluation",
        "formula": "Average of syntactic and semantic accuracy"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SyntacticAccuracy_AnalogicalReasoning",
        "entity_type": "Metric",
        "name": "Syntactic Accuracy",
        "description": "Accuracy on syntactic analogical reasoning task",
        "category": "Analogical Reasoning Evaluation",
        "formula": "Correct syntactic analogies / Total syntactic analogies"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SemanticAccuracy_AnalogicalReasoning",
        "entity_type": "Metric",
        "name": "Semantic Accuracy",
        "description": "Accuracy on semantic analogical reasoning task",
        "category": "Analogical Reasoning Evaluation",
        "formula": "Correct semantic analogies / Total semantic analogies"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PhraseAnalogyDataset_2013",
        "entity_type": "Dataset",
        "name": "Phrase Analogy Dataset",
        "description": "Dataset for evaluating phrase-based analogical reasoning",
        "domain": "Natural Language Processing",
        "size": 3218,
        "year": 2013,
        "creators": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_SkipGramWithSubsampling",
        "entity_type": "Algorithm",
        "name": "Skip-gram with Subsampling",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Word Representation Learning",
        "dataset": [
          "NewsArticles_2013"
        ],
        "metrics": [
          "Accuracy_AnalogicalReasoning",
          "TrainingSpeed",
          "TotalAccuracy_AnalogicalReasoning",
          "SyntacticAccuracy_AnalogicalReasoning",
          "SemanticAccuracy_AnalogicalReasoning"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Output Layer"
          ],
          "connections": [
            "Input to Hidden",
            "Hidden to Output"
          ],
          "mechanisms": [
            "Subsampling of Frequent Words"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of Frequent Words"
          ],
          "parameter_tuning": [
            "Threshold for Subsampling"
          ]
        },
        "feature_processing": [
          "Subsampling of Frequent Words"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_PhraseAnalogy",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy on the phrase analogy task",
        "category": "Phrase Analogy Evaluation",
        "formula": "Number of correct answers / Total number of questions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_PhraseSkipGram",
        "entity_type": "Algorithm",
        "name": "Phrase Skip-gram",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Learning vector representations for phrases",
        "dataset": [
          "NewsArticles_2013"
        ],
        "metrics": [
          "Accuracy_PhraseAnalogy"
        ],
        "architecture": {
          "components": [
            "Skip-gram model",
            "Phrase identification"
          ],
          "connections": [
            "Word vectors",
            "Phrase vectors"
          ],
          "mechanisms": [
            "Data-driven phrase formation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of frequent words"
          ],
          "parameter_tuning": [
            "Dimensionality",
            "Context size",
            "Threshold for phrase formation"
          ]
        },
        "feature_processing": [
          "Phrase formation based on unigram and bigram counts"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_AdditiveCompositionality",
        "entity_type": "Algorithm",
        "name": "Additive Compositionality",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Analogical Reasoning",
        "dataset": [
          "Phrase Analogy Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Word Vectors",
            "Element-wise Addition"
          ],
          "connections": [
            "Vector Summation"
          ],
          "mechanisms": [
            "Linear Structure"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Skip-gram Model"
          ],
          "parameter_tuning": [
            "Vector Dimensionality"
          ]
        },
        "feature_processing": [
          "Vector Representation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_AdditiveCompositionality",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of the model in performing analogical reasoning using vector addition",
        "category": "Analogical Reasoning",
        "formula": "Number of correct analogies / Total number of analogies"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_DEDUCOM",
        "entity_type": "Algorithm",
        "name": "DEDUCOM",
        "title": "Experiments with a Deductive Question-Answering Program",
        "year": 1965,
        "authors": [
          "James R. Slagle"
        ],
        "task": "Deductive Question-Answering",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Fact Interpreter",
            "Question Reducer",
            "Search Procedure"
          ],
          "connections": [
            "Fact Interpreter -> Question Reducer",
            "Question Reducer -> Search Procedure"
          ],
          "mechanisms": [
            "Depth-First Search",
            "Logical Deduction in Predicate Calculus"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Providing facts to the system"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Logical deduction rules",
          "Fact representation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Answer_Variety_Question_Answering",
        "entity_type": "Metric",
        "name": "Variety of Answerable Questions",
        "description": "The range of different types of questions that can be answered by the system",
        "category": "Question Answering Evaluation",
        "formula": "Number of different types of questions answered correctly"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Speed_of_Answering_Questions",
        "entity_type": "Metric",
        "name": "Speed of Answering Questions",
        "description": "Time taken by the system to answer a question",
        "category": "Performance Evaluation",
        "formula": "Time taken to provide an answer"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_AdviceTaker",
        "entity_type": "Algorithm",
        "name": "Advice Taker",
        "year": 1965,
        "authors": [
          "McCarthy, J."
        ],
        "task": "Deductive reasoning and question answering",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Fact representation",
            "Inference rules"
          ],
          "connections": [
            "Logical deduction",
            "Predicate calculus"
          ],
          "mechanisms": [
            "Heuristic programming",
            "Educated guessing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based inference"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Logical transformations"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_SIRProgram",
        "entity_type": "Algorithm",
        "name": "SIR Program",
        "year": 1965,
        "authors": [
          "Raphael, B."
        ],
        "task": "Question answering",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Fact representation",
            "Inference rules"
          ],
          "connections": [
            "Logical deduction",
            "Predicate calculus"
          ],
          "mechanisms": [
            "Heuristic programming",
            "Educated guessing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based inference"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Logical transformations"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_LISPInterpreterExtension",
        "entity_type": "Algorithm",
        "name": "LISP Interpreter Extension",
        "year": 1965,
        "authors": [
          "Slagle, J.R."
        ],
        "task": "Deductive Question-Answering",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "LISP Interpreter",
            "Fact Processing Module",
            "Question Reduction Module"
          ],
          "connections": [
            "Fact Processing -> Question Reduction -> Answer Generation"
          ],
          "mechanisms": [
            "Recursive Question Reduction",
            "Fact Lookup"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Fact Representation",
          "Logical Deduction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_QuestionReduction",
        "entity_type": "Algorithm",
        "name": "Question Reduction",
        "year": 1965,
        "authors": [
          "Slagle, J.R."
        ],
        "task": "Deductive Question-Answering",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Original Question",
            "Simpler Question",
            "Directly Answerable Question"
          ],
          "connections": [
            "Reduction Process"
          ],
          "mechanisms": [
            "Deduction Rules"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_DepthFirstSearch",
        "entity_type": "Algorithm",
        "name": "Depth-First Search",
        "year": 1965,
        "authors": [
          "Slagle, J.R."
        ],
        "task": "Search Procedure",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Nodes",
            "Branches"
          ],
          "connections": [
            "Traversal Order"
          ],
          "mechanisms": [
            "Backtracking"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Answer_Correctness",
        "entity_type": "Metric",
        "name": "Answer Correctness",
        "description": "Whether the answer provided by DEDUCOM is correct.",
        "category": "Question-Answering Evaluation",
        "formula": "Number of Correct Answers / Total Number of Questions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_Valueans",
        "entity_type": "Algorithm",
        "name": "Valueans",
        "year": 1965,
        "authors": [
          "Slagle, J.R."
        ],
        "task": "Question Answering",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Valueans Function"
          ],
          "connections": [
            "Valueans to Answer Generation"
          ],
          "mechanisms": [
            "Logical Deduction"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Correctness_AnswerGeneration",
        "entity_type": "Metric",
        "name": "Correctness",
        "description": "衡量答案生成的正确性",
        "category": "Answer Generation Evaluation",
        "formula": "正确答案数/总答案数"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2016_ImplicitQuantityRelationExtractor",
        "entity_type": "Algorithm",
        "name": "Implicit Quantity Relation Extractor",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": 2016,
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": "Extracting implicit quantity relations in arithmetic word problems",
        "dataset": [
          "Elementary school arithmetic application problem_2011",
          "Suzhou Education Publishing House_dataset"
        ],
        "metrics": [
          "Classification Accuracy"
        ],
        "architecture": {
          "components": [
            "Chinese phrase parse",
            "SVM classification",
            "Instantiation method of required general implicit quantity relations"
          ],
          "connections": [
            "Chinese phrase parse -> SVM classification -> Instantiation method"
          ],
          "mechanisms": [
            "Semantic models",
            "Sequence alignment",
            "Equation construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SVM with slack variable",
            "Bag of words feature extraction"
          ],
          "parameter_tuning": [
            "C (weight number for slack variable)"
          ]
        },
        "feature_processing": [
          "Bag of words",
          "Chinese phrase parse",
          "Normalization of common units"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Elementary_school_arithmetic_application_problem_2011",
        "entity_type": "Dataset",
        "name": "Elementary school arithmetic application problem",
        "description": "Arithmetic word problems from People's Education Press, 2011",
        "domain": "Education",
        "size": 627,
        "year": 2011,
        "creators": [
          "People's Education Press"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Suzhou_Education_Publishing_House_dataset",
        "entity_type": "Dataset",
        "name": "Suzhou Education Publishing House dataset",
        "description": "Training dataset containing different types of arithmetic word problems",
        "domain": "Education",
        "size": 283,
        "year": 2016,
        "creators": [
          "Suzhou Education Publishing House"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Classification_Accuracy",
        "entity_type": "Metric",
        "name": "Classification Accuracy",
        "description": "Accuracy of SVM classification for arithmetic word problems",
        "category": "Classification evaluation",
        "formula": "Number of correctly classified samples / Total number of samples"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2016_SVMClassification",
        "entity_type": "Algorithm",
        "name": "SVM Classification",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": 2016,
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": "Arithmetic Word Problem Classification",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy"
        ],
        "architecture": {
          "components": [
            "SVM Classifier",
            "Slack Variable"
          ],
          "connections": [
            "Input Features -> SVM Classifier -> Output Classification"
          ],
          "mechanisms": [
            "Kernel Function",
            "Max Margin Hyperplane"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-validation",
            "Grid Search"
          ],
          "parameter_tuning": [
            "C (Regularization Parameter)",
            "Kernel Type"
          ]
        },
        "feature_processing": [
          "Bag of Words",
          "Part-of-Speech Tagging"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Targeting_classification_dataset_2011",
        "entity_type": "Dataset",
        "name": "Targeting Classification Dataset",
        "description": "Arithmetic word problems for classification",
        "domain": "Education",
        "size": 627,
        "year": 2011,
        "creators": [
          "People's Education Press"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Classification_Error_Rate",
        "entity_type": "Metric",
        "name": "Classification Error Rate",
        "description": "Rate of incorrect classifications",
        "category": "Classification Evaluation",
        "formula": "Incorrect Classifications / Total Classifications"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2016_ChinesePhraseParse",
        "entity_type": "Algorithm",
        "name": "Chinese Phrase Parse",
        "year": 2016,
        "authors": [
          "Yu, X.",
          "Jian, P.",
          "Wang, M.",
          "Wu, S."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy"
        ],
        "architecture": {
          "components": [
            "ICTCLAS"
          ],
          "connections": [
            "Input Text -> ICTCLAS -> Annotated Text"
          ],
          "mechanisms": [
            "Part-of-Speech Tagging",
            "Phrase Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Preprocessing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Part-of-Speech Tagging",
          "Phrase Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2016_SemanticModelInstantiation",
        "entity_type": "Algorithm",
        "name": "Semantic Model Instantiation",
        "year": 2016,
        "authors": [
          "Yu, X.",
          "Jian, P.",
          "Wang, M.",
          "Wu, S."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy"
        ],
        "architecture": {
          "components": [
            "Semantic Models",
            "Equation Construction"
          ],
          "connections": [
            "Parsed Text -> Semantic Models -> Equations"
          ],
          "mechanisms": [
            "Mapping Variables",
            "Constructing Equations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Post-processing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Variable Allocation",
          "Equation Formation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2016_NormalizedCommonUnits",
        "entity_type": "Algorithm",
        "name": "Normalized Common Units",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": 2016,
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": "Normalization of units in arithmetic word problems",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy"
        ],
        "architecture": {
          "components": [
            "Unit normalization module"
          ],
          "connections": [
            "Preprocessing step before Chinese phrase parse"
          ],
          "mechanisms": [
            "Unit conversion rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based normalization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Unit unification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2016_SVMAlgorithm",
        "entity_type": "Algorithm",
        "name": "SVM Algorithm",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": 2016,
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy",
          "Classification_Error_Rate"
        ],
        "architecture": {
          "components": [
            "Kernel Function",
            "Slack Variable"
          ],
          "connections": [
            "Hyperplane Calculation",
            "Margin Maximization"
          ],
          "mechanisms": [
            "Support Vector Identification",
            "Classification Boundary"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-validation",
            "Grid Search"
          ],
          "parameter_tuning": [
            "C (Regularization Parameter)",
            "Gamma"
          ]
        },
        "feature_processing": [
          "Bag of Words",
          "TF-IDF"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_FrameBasedCalculus",
        "entity_type": "Algorithm",
        "name": "Frame-Based Calculus",
        "title": "Frame-Based Calculus of solving Arithmetic Multi-Step Addition and Subtraction word problems",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "Solving multi-step addition and subtraction word problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "MSWPAS-NP",
            "MSWPAS-CP"
          ],
          "connections": [
            "Natural language processing",
            "Frame-based calculus"
          ],
          "mechanisms": [
            "Means-end Analysis",
            "Production rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Problem representation",
            "Planning",
            "Trying to solve and assessment"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Comprehending the natural language of problems",
          "Constructing problem frames"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_MeansEndAnalysis",
        "entity_type": "Algorithm",
        "name": "Means-end Analysis",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Present Object",
            "Desired Object",
            "Operator"
          ],
          "connections": [
            "Find Difference",
            "Apply Operator",
            "Transform Object"
          ],
          "mechanisms": [
            "Planning",
            "Sub-goal Generation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ChineseElementarySchoolTextbooks_2010",
        "entity_type": "Dataset",
        "name": "Chinese Elementary School Textbooks",
        "description": "Word problems gathered from four publishers in Chinese (one book from People’s Education Press, one book from Beijing Normal University Press, and two books from DONGBEI Normal University Press)",
        "domain": "Mathematics Education",
        "size": "Not specified",
        "year": 2010,
        "creators": [
          "Various Publishers"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Correctness_Solving",
        "entity_type": "Metric",
        "name": "Correctness",
        "description": "Whether the system correctly solves multi-step addition and subtraction word problems",
        "category": "Problem Solving Evaluation",
        "formula": "Number of Correctly Solved Problems / Total Number of Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_MSMPAS_CP",
        "entity_type": "Algorithm",
        "name": "MSWPAS-CP",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "Solving multi-step addition and subtraction word problems",
        "dataset": [
          "ChineseElementarySchoolTextbooks_2010"
        ],
        "metrics": [
          "Correctness_Solving"
        ],
        "architecture": {
          "components": [
            "Goal Stack",
            "Fact Base",
            "Frame Identification Module",
            "Working Memory",
            "Rule Base",
            "Executive Controlling Module"
          ],
          "connections": [
            "Goal Stack -> Executive Controlling Module",
            "Fact Base <-> Working Memory",
            "Frame Identification Module -> Working Memory",
            "Rule Base -> Working Memory"
          ],
          "mechanisms": [
            "Means-end Analysis",
            "Frame-based Calculus"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Problem Representation",
            "Planning",
            "Trying to Solve and Assessment"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Natural Language Processing",
          "Semantic Frame Construction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_ProductionRules",
        "entity_type": "Algorithm",
        "name": "Production Rules",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "Solving Multi-Step Addition and Subtraction Word Problems",
        "dataset": [
          "ChineseElementarySchoolTextbooks_2010"
        ],
        "metrics": [
          "Correctness_Solving"
        ],
        "architecture": {
          "components": [
            "Rule Base",
            "Fact Base",
            "Working Memory",
            "Goal Stack",
            "Frame Identification Module",
            "Executive Controlling Module"
          ],
          "connections": [
            "Rule Base -> Fact Base",
            "Fact Base -> Working Memory",
            "Goal Stack -> Working Memory",
            "Frame Identification Module -> Working Memory",
            "Executive Controlling Module -> All Modules"
          ],
          "mechanisms": [
            "Means-end Analysis",
            "Frame-based Calculus"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Means-end Analysis"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Frame-based Representation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ChineseTextbooks_2010",
        "entity_type": "Dataset",
        "name": "Chinese Textbooks",
        "year": 2010,
        "creators": [
          "People’s Education Press",
          "Beijing Normal University Press",
          "DONGBEI Normal University Press"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_FrameIdentificationModule",
        "entity_type": "Algorithm",
        "name": "Frame Identification Module",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "Identifying and selecting frames from fact base",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Object slot",
            "Specification slot",
            "Time slot",
            "Role slot"
          ],
          "connections": [
            "Identifies related frames based on slot values"
          ],
          "mechanisms": [
            "Slot value matching"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Identifies related propositions"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_WorkingMemory",
        "entity_type": "Algorithm",
        "name": "Working Memory",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "Simulating short-term memory",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Current goal",
            "Assignment frames",
            "Relation frame"
          ],
          "connections": [
            "Stores and updates current goal and related frames"
          ],
          "mechanisms": [
            "Reset when goal changes"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_RuleBase",
        "entity_type": "Algorithm",
        "name": "Rule Base",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "Storing domain knowledge",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Production rules"
          ],
          "connections": [
            "Matches rules to current goal"
          ],
          "mechanisms": [
            "Expands when solving more problems"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_ExecutiveControllingModule",
        "entity_type": "Algorithm",
        "name": "Executive Controlling Module",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "Coordinating system modules",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Goal stack",
            "Fact base",
            "Frame identification",
            "Working memory",
            "Rule base"
          ],
          "connections": [
            "Controls interaction between modules"
          ],
          "mechanisms": [
            "Determines current goal and triggers rule base"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "deMarneffe2006_TypedDependencyParser",
        "entity_type": "Algorithm",
        "name": "Typed Dependency Parser",
        "title": "Generating Typed Dependency Parses from Phrase Structure Parses",
        "year": 2006,
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "Penn Treebank",
          "Brown Corpus"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Dependency Extraction Rules",
            "Dependency Typing Rules"
          ],
          "connections": [
            "Phrase Structure Trees -> Dependency Graphs"
          ],
          "mechanisms": [
            "Collapsing Dependencies",
            "Semantic Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Treebank-trained Statistical Parsers"
          ],
          "parameter_tuning": [
            "Rule-based Pattern Matching"
          ]
        },
        "feature_processing": [
          "Semantic Head Retrieval",
          "Collapsing Prepositions and Conjunctions"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreebank_1999",
        "entity_type": "Dataset",
        "name": "Penn Treebank",
        "description": "A large annotated corpus of English text",
        "domain": "Natural Language Processing",
        "size": "Over 4.5 million words",
        "year": 1999,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "BrownCorpus_1964",
        "entity_type": "Dataset",
        "name": "Brown Corpus",
        "description": "A standard corpus of present-day edited American English",
        "domain": "Natural Language Processing",
        "size": "1 million words",
        "year": 1964,
        "creators": [
          "Henry Kučera",
          "W. Nelson Francis"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "DependencyAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Dependency Accuracy",
        "description": "Accuracy of dependency relations in a sentence",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly identified dependencies / Total dependencies"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collins1999_HeadDrivenStatisticalModels",
        "entity_type": "Algorithm",
        "name": "Head-Driven Statistical Models",
        "year": 1999,
        "authors": [
          "Michael Collins"
        ],
        "task": "Natural Language Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parsing",
            "Statistical Models"
          ],
          "connections": [
            "Dependency Extraction Rules"
          ],
          "mechanisms": [
            "Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Maximum Likelihood Estimation"
          ]
        },
        "feature_processing": [
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Klein2003_AccurateUnlexicalizedParsing",
        "entity_type": "Algorithm",
        "name": "Accurate Unlexicalized Parsing",
        "year": 2003,
        "authors": [
          "Dan Klein",
          "Christopher D. Manning"
        ],
        "task": "Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parsing",
            "Statistical Models"
          ],
          "connections": [
            "Dependency Extraction Rules"
          ],
          "mechanisms": [
            "Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Maximum Likelihood Estimation"
          ]
        },
        "feature_processing": [
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin1998_MINIPAR",
        "entity_type": "Algorithm",
        "name": "MINIPAR",
        "year": 1998,
        "authors": [
          "Dekang Lin"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Dependency Parsing"
          ],
          "connections": [
            "Dependency Extraction Rules"
          ],
          "mechanisms": [
            "Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Rule-Based"
          ]
        },
        "feature_processing": [
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sleator1993_LinkParser",
        "entity_type": "Algorithm",
        "name": "Link Parser",
        "year": 1993,
        "authors": [
          "Daniel D. Sleator",
          "Davy Temperley"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Dependency Parsing"
          ],
          "connections": [
            "Dependency Extraction Rules"
          ],
          "mechanisms": [
            "Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Rule-Based"
          ]
        },
        "feature_processing": [
          "Syntactic Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AlpinoDependencyTreebank_2002",
        "entity_type": "Dataset",
        "name": "Alpino Dependency Treebank",
        "year": 2002,
        "creators": [
          "Leonoor van der Beek",
          "Gosse Bouma",
          "Robert Malouf",
          "Gertjan van Noord"
        ],
        "domain": "Computational Linguistics",
        "description": "Dutch dependency treebank"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DanishDependencyTreebank_2003",
        "entity_type": "Dataset",
        "name": "Danish Dependency Treebank",
        "year": 2003,
        "creators": [
          "Matthias T. Kromann"
        ],
        "domain": "Computational Linguistics",
        "description": "Danish dependency treebank"
      }
    },
    {
      "metric_entity": {
        "metric_id": "DependencyStructureAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Dependency Structure Accuracy",
        "category": "Dependency Parsing Evaluation",
        "description": "Accuracy of dependency structure"
      }
    },
    {
      "metric_entity": {
        "metric_id": "DependencyTypeAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Dependency Type Accuracy",
        "category": "Dependency Parsing Evaluation",
        "description": "Accuracy of dependency type"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "deMarneffe2006_PASCALRecognizingTextualEntailment",
        "entity_type": "Algorithm",
        "name": "PASCAL Recognizing Textual Entailment",
        "year": 2006,
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": "Textual Entailment Recognition",
        "dataset": [
          "Brown Corpus"
        ],
        "metrics": [
          "DependencyAccuracy_Classification",
          "DependencyTypeAccuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Typed Dependency Trees",
            "Quasi-Logical Representation",
            "Alignment Module",
            "Learning Module"
          ],
          "connections": [
            "Dependency Trees -> Quasi-Logical Representation",
            "Quasi-Logical Representation -> Alignment Module",
            "Alignment Module -> Learning Module"
          ],
          "mechanisms": [
            "Predicate-Argument Structure Encoding",
            "Event Structure Representation",
            "Structure Alignment",
            "Feature Generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "Predicate-Argument Structure Features",
          "Dependency Relation Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WSJSection_PennTreebank_1999",
        "entity_type": "Dataset",
        "name": "Wall Street Journal Section of Penn Treebank",
        "description": "A section of the Penn Treebank containing news articles from the Wall Street Journal.",
        "domain": "Natural Language Processing",
        "size": "Varies",
        "year": 1999,
        "creators": [
          "Klein, Dan",
          "Manning, Christopher D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "PerDependencyAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Per-Dependency Accuracy",
        "description": "Accuracy of each dependency relation in the dependency parse.",
        "category": "Dependency Parsing Evaluation",
        "formula": "Number of Correct Dependencies / Total Number of Dependencies"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Klein2003_StanfordParser",
        "entity_type": "Algorithm",
        "name": "Stanford Parser",
        "year": 2003,
        "authors": [
          "Klein, Dan",
          "Manning, Christopher D."
        ],
        "task": "Phrase Structure Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Per-Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Typed Dependency Extractor"
          ],
          "connections": [
            "Phrase Structure Trees -> Typed Dependencies"
          ],
          "mechanisms": [
            "Rule-based Dependency Extraction",
            "Collapsing Prepositions and Conjunctions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Statistical Parsing"
          ],
          "parameter_tuning": [
            "Collins Head Rules",
            "Semantic Head Retrieval"
          ]
        },
        "feature_processing": [
          "Phrase Structure Trees",
          "Head Identification"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Carroll1999_GrevalTestSuite",
        "entity_type": "Dataset",
        "name": "Greval Test Suite",
        "year": 1999,
        "authors": [
          "Carroll, John",
          "Minnen, Guido",
          "Briscoe, Ted"
        ],
        "domain": "Natural Language Processing",
        "description": "A test suite for evaluating parser performance"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "deMarneffe2006_TypedDependencyExtraction",
        "entity_type": "Algorithm",
        "name": "Typed Dependency Extraction",
        "year": 2006,
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "Penn Treebank",
          "Brown Corpus"
        ],
        "metrics": [
          "Dependency Accuracy",
          "Per-Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Dependency Extractor",
            "Dependency Typer"
          ],
          "connections": [
            "Phrase Structure Trees -> Dependency Extraction -> Dependency Typing"
          ],
          "mechanisms": [
            "Rule-based extraction",
            "Pattern matching on phrase structure trees"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Training on Penn Treebank"
          ],
          "parameter_tuning": [
            "Collins head rules",
            "Semantic head identification"
          ]
        },
        "feature_processing": [
          "Handling of prepositions and conjunctions",
          "Processing of conjunct dependencies"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Gelernter1959_GeometryMachine",
        "entity_type": "Algorithm",
        "name": "Geometry Machine",
        "year": 1959,
        "authors": [
          "Gelernter"
        ],
        "task": "Geometry Theorem Proving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Heuristic Knowledge",
            "Backward Chaining Search Strategy"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Backward Chaining"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Diagram Analysis"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "CeruttiDavis1969_FORMAC",
        "entity_type": "Algorithm",
        "name": "FORMAC",
        "year": 1969,
        "authors": [
          "Cerutti",
          "Davis"
        ],
        "task": "Elementary Analytic Geometry Theorem Proving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Symbolic Manipulation",
            "Descartes' Method"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Coordinate Assignment"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hilbert1899_AxiomaticGeometry",
        "entity_type": "Algorithm",
        "name": "Axiomatic Geometry",
        "year": 1899,
        "authors": [
          "Hilbert, D."
        ],
        "task": "Geometry Theorem Proving",
        "methodology": {
          "training_strategy": [
            "Formalization of axioms"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "No geometric intuition required"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Tarski1926_EuclideanGeometryAxioms",
        "entity_type": "Algorithm",
        "name": "Euclidean Geometry Axioms",
        "year": 1926,
        "authors": [
          "Tarski, A."
        ],
        "task": "Geometry Theorem Proving",
        "methodology": {
          "training_strategy": [
            "Primitive relations: betweenness and equidistance"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Points only"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Poincare1902_MechanicalRules",
        "entity_type": "Algorithm",
        "name": "Mechanical Rules",
        "year": 1902,
        "authors": [
          "Poincare, H."
        ],
        "task": "Geometry Theorem Proving",
        "methodology": {
          "training_strategy": [
            "Purely mechanical rules"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Axioms application without understanding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koedinger1990_SearchStrategies",
        "entity_type": "Algorithm",
        "name": "Search Strategies",
        "year": 1990,
        "authors": [
          "Koedinger, K.R."
        ],
        "task": "Geometry Theorem Proving",
        "methodology": {
          "training_strategy": [
            "Sophisticated search strategies"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Heuristic knowledge"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Descartes_Method",
        "entity_type": "Algorithm",
        "name": "Descartes' Method",
        "year": null,
        "authors": [
          "Descartes, R."
        ],
        "task": "Analytic Geometry Theorem Proving",
        "methodology": {
          "training_strategy": [
            "Assigning coordinates to points"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Algebraic approach"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1999_GeoRep",
        "entity_type": "Algorithm",
        "name": "GeoRep",
        "title": "GeoRep: A Flexible Tool for Spatial Representation of Line Drawings",
        "year": 1999,
        "authors": [
          "Ronald W. Ferguson",
          "Kenneth D. Forbus"
        ],
        "task": "Spatial Representation and Reasoning",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Low-Level Relational Describer (LLRD)",
            "High-Level Relational Describer (HLRD)"
          ],
          "connections": [
            "LLRD to HLRD"
          ],
          "mechanisms": [
            "Visual Operations Library",
            "Reference Frame Relations",
            "Proximity Detection",
            "Grouping Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning",
            "Domain-specific rules"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Primitive shape detection",
          "Proximity-based relation detection",
          "Interval relations",
          "Polygon and polyline detection",
          "Boundary description"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1994_MAGI",
        "entity_type": "Algorithm",
        "name": "MAGI",
        "title": "MAGI: Analogy-based encoding using symmetry and regularity",
        "year": 1994,
        "authors": [
          "Ronald W. Ferguson"
        ],
        "task": "Symmetry Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Symmetry Detection Engine"
          ],
          "connections": [
            "GeoRep to Symmetry Detection"
          ],
          "mechanisms": [
            "Symmetry and Repetition Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Shape and orientation analysis"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1995_JUXTA",
        "entity_type": "Algorithm",
        "name": "JUXTA",
        "title": "Understanding illustrations of physical laws by integrating differences in visual and textual representations",
        "year": 1995,
        "authors": [
          "Ronald W. Ferguson",
          "Kenneth D. Forbus"
        ],
        "task": "Diagram Understanding",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Visual Level",
            "Physical Level",
            "Process Level"
          ],
          "connections": [
            "GeoRep to JUXTA"
          ],
          "mechanisms": [
            "Representation Levels",
            "Contextual Analysis"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Visual and physical relation detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Forbus1980_MD_PV",
        "entity_type": "Algorithm",
        "name": "MD/PV Model",
        "title": "Spatial and qualitative aspects of reasoning about motion",
        "year": 1980,
        "authors": [
          "Kenneth D. Forbus"
        ],
        "task": "Spatial Reasoning",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Metric Diagram",
            "Place Vocabulary"
          ],
          "connections": [
            "MD to PV"
          ],
          "mechanisms": [
            "Query-based Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Spatial relation extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ullman1984_UniversalVisualRoutines",
        "entity_type": "Algorithm",
        "name": "Universal Visual Routines",
        "year": 1984,
        "authors": [
          "Ullman, S."
        ],
        "task": "Spatial Reasoning",
        "architecture": {
          "components": [
            "Low-level vision routines",
            "Intermediate-level vision routines"
          ],
          "mechanisms": [
            "Automatic detection of visual relations",
            "Domain-independent processing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None (not a learning algorithm)"
          ],
          "parameter_tuning": [
            "None (not a learning algorithm)"
          ]
        },
        "feature_processing": [
          "Detection of primitive visual elements",
          "Computation of visual relations"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Allen1983_IntervalRelations",
        "entity_type": "Algorithm",
        "name": "Interval Relations",
        "year": 1983,
        "authors": [
          "Allen, J. F."
        ],
        "task": "Temporal and Spatial Reasoning",
        "architecture": {
          "components": [
            "Temporal intervals",
            "Spatial intervals"
          ],
          "mechanisms": [
            "Representation of temporal and spatial intervals",
            "Calculation of interval relations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None (not a learning algorithm)"
          ],
          "parameter_tuning": [
            "None (not a learning algorithm)"
          ]
        },
        "feature_processing": [
          "Temporal and spatial interval detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Forbus1993_LTRE",
        "entity_type": "Algorithm",
        "name": "LTRE",
        "year": 1993,
        "authors": [
          "Forbus, K. D.",
          "de Kleer, J."
        ],
        "task": "Rule-based Reasoning",
        "architecture": {
          "components": [
            "Logic-based Truth Maintenance System",
            "Rule Engine"
          ],
          "mechanisms": [
            "Application of rules",
            "Maintenance of truth values"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None (not a learning algorithm)"
          ],
          "parameter_tuning": [
            "None (not a learning algorithm)"
          ]
        },
        "feature_processing": [
          "Logical rule application"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1999_SymmetryDetectionModel",
        "entity_type": "Algorithm",
        "name": "Symmetry Detection Model",
        "year": 1999,
        "authors": [
          "Ferguson, R. W."
        ],
        "task": "Symmetry Detection",
        "dataset": [
          "Polygon Figures"
        ],
        "metrics": [
          "Symmetry Judgment Accuracy"
        ],
        "architecture": {
          "components": [
            "GeoRep",
            "MAGI"
          ],
          "connections": [
            "GeoRep generates low-level relational description -> MAGI judges symmetry"
          ],
          "mechanisms": [
            "Detecting qualitative visual structure"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Detecting concavities and convexities in polygon boundaries"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PolygonFigures_1996",
        "entity_type": "Dataset",
        "name": "Polygon Figures",
        "description": "Set of randomly generated polygons used for symmetry detection experiments",
        "domain": "Psychological Experiments",
        "size": 240,
        "year": 1996,
        "creators": [
          "Ferguson, R. W.",
          "Aminoff, A.",
          "Gentner, D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SymmetryJudgmentAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Symmetry Judgment Accuracy",
        "description": "Accuracy of judging whether a polygon is symmetric",
        "category": "Classification Evaluation",
        "formula": "Number of correctly identified symmetric/asymmetric polygons / Total number of polygons"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1999_JUXTA",
        "entity_type": "Algorithm",
        "name": "JUXTA",
        "year": 1999,
        "authors": [
          "Ferguson, R. W."
        ],
        "task": "Critiquing Simplified Diagrams of Physical Phenomena",
        "dataset": [
          "Simplified Diagrams"
        ],
        "metrics": [
          "Relevance of Visual Differences"
        ],
        "architecture": {
          "components": [
            "GeoRep",
            "HLRD Rules"
          ],
          "connections": [
            "GeoRep generates visual, physical, and process levels -> HLRD rules interpret and critique"
          ],
          "mechanisms": [
            "Detecting physical and process differences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Detecting aligned differences in diagrams"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SimplifiedDiagrams_PhysicalPhenomena",
        "entity_type": "Dataset",
        "name": "Simplified Diagrams of Physical Phenomena",
        "description": "Set of simplified diagrams used to critique physical phenomena",
        "domain": "Physics Education",
        "size": "Not specified",
        "year": 1999,
        "creators": [
          "Ferguson, R. W."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "RelevanceOfVisualDifferences_Critique",
        "entity_type": "Metric",
        "name": "Relevance of Visual Differences",
        "description": "Measure of how visual differences affect the understanding of physical objects or processes",
        "category": "Critique Evaluation",
        "formula": "Not specified"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1999_COADiagramInterpreter",
        "entity_type": "Algorithm",
        "name": "COA Diagram Interpreter",
        "year": 1999,
        "authors": [
          "Ferguson, R. W.",
          "Forbus, K. D."
        ],
        "task": "Spatial Reasoning about Course of Action Diagrams",
        "dataset": [
          "COA Diagrams"
        ],
        "metrics": [
          "Recognition Accuracy"
        ],
        "architecture": {
          "components": [
            "GeoRep",
            "HLRD Rules"
          ],
          "connections": [
            "GeoRep generates description of units, areas, and tasks -> HLRD rules interpret"
          ],
          "mechanisms": [
            "Recognizing line-drawn symbols"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Handling ambiguous shapes based on context"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "COADiagrams_Military",
        "entity_type": "Dataset",
        "name": "COA Diagrams",
        "description": "Set of Course of Action diagrams used by the military for tasks such as troop movement planning",
        "domain": "Military Planning",
        "size": "Not specified",
        "year": 1999,
        "creators": [
          "Ferguson, R. W.",
          "Forbus, K. D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "RecognitionAccuracy_Recognition",
        "entity_type": "Metric",
        "name": "Recognition Accuracy",
        "description": "Accuracy of recognizing symbols in COA diagrams",
        "category": "Recognition Evaluation",
        "formula": "Number of correctly recognized symbols / Total number of symbols"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1999_LowLevelRelationalDescriber",
        "entity_type": "Algorithm",
        "name": "Low-Level Relational Describer (LLRD)",
        "year": 1999,
        "authors": [
          "Ferguson, R. W.",
          "Forbus, K. D."
        ],
        "task": "Spatial Representation",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "proximity detection",
            "visual operations",
            "orientation detection",
            "parallel line detection",
            "connectivity detection",
            "polygon and polyline detection",
            "boundary description",
            "interval relations"
          ],
          "connections": [
            "proximity-based relations",
            "visual operation pipeline"
          ],
          "mechanisms": [
            "universal visual routines",
            "pre-attentive grouping factors"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "proximity calculation",
          "visual element grouping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1999_HighLevelRelationalDescriber",
        "entity_type": "Algorithm",
        "name": "High-Level Relational Describer (HLRD)",
        "year": 1999,
        "authors": [
          "Ferguson, R. W.",
          "Forbus, K. D."
        ],
        "task": "Place Vocabulary Construction",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "rule engine",
            "LTRE",
            "truth maintenance system",
            "visual operation library"
          ],
          "connections": [
            "domain-dependent rules",
            "visual relation extension"
          ],
          "mechanisms": [
            "representational links",
            "context-based symbol recognition"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "domain-specific rules",
          "proximate object delimitation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ProximityAccuracy_VisualRelation",
        "entity_type": "Metric",
        "name": "Proximity Accuracy",
        "description": "Accuracy of detecting proximate visual elements",
        "category": "Spatial Relation Detection",
        "formula": "Correctly identified proximate elements / Total proximate element pairs"
      }
    },
    {
      "metric_entity": {
        "metric_id": "IntervalRelationAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Interval Relation Accuracy",
        "description": "Accuracy of detecting interval relations between parallel line segments",
        "category": "Classification",
        "formula": "Correctly classified interval relations / Total interval relations"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MilitaryCOADiagrams_1999",
        "entity_type": "Dataset",
        "name": "Military Course of Action (COA) Diagrams",
        "description": "Diagrams used by the military for tasks such as troop movement planning",
        "domain": "Military Planning",
        "size": null,
        "year": 1999,
        "creators": [
          "DARPA",
          "Northwestern University"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kosslyn1994_DiagramEffectiveness",
        "entity_type": "Algorithm",
        "name": "Diagram Effectiveness",
        "year": 1994,
        "authors": [
          "Kosslyn, S. M."
        ],
        "task": "Understanding Diagrams",
        "metrics": [
          "Effectiveness",
          "Clarity"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Clarity_VisualRelation",
        "entity_type": "Metric",
        "name": "Clarity",
        "description": "衡量图表是否清晰传达信息",
        "category": "视觉关系评估"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Effectiveness_VisualRelation",
        "entity_type": "Metric",
        "name": "Effectiveness",
        "description": "衡量图表传达信息的有效性",
        "category": "视觉关系评估"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Tufte1990_EnvisioningInformation",
        "entity_type": "Dataset",
        "name": "Envisioning Information",
        "description": "关于信息可视化的书籍",
        "domain": "信息可视化",
        "year": 1990,
        "creators": [
          "Tufte, E. R."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Wikipedia_2010",
        "entity_type": "Dataset",
        "name": "Wikipedia 2010",
        "description": "A 2010 Wikipedia dump with 1 billion tokens",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": 2010,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Wikipedia_2014",
        "entity_type": "Dataset",
        "name": "Wikipedia 2014",
        "description": "A 2014 Wikipedia dump with 1.6 billion tokens",
        "domain": "Natural Language Processing",
        "size": 1600000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Gigaword_5",
        "entity_type": "Dataset",
        "name": "Gigaword 5",
        "description": "A dataset with 4.3 billion tokens",
        "domain": "Natural Language Processing",
        "size": 4300000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Common_Crawl",
        "entity_type": "Dataset",
        "name": "Common Crawl",
        "description": "A dataset with 42 billion tokens of web data",
        "domain": "Natural Language Processing",
        "size": 42000000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Analogy",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy on the word analogy task",
        "category": "Word Analogy Task",
        "formula": "Correct answers / Total questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Spearman_Rank_Correlation_Similarity",
        "entity_type": "Metric",
        "name": "Spearman's Rank Correlation",
        "description": "Rank correlation between word similarity scores and human judgments",
        "category": "Word Similarity Task",
        "formula": "ρ = 1 - (6 * Σd^2) / (n * (n^2 - 1))"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deerwester1990_LSA",
        "entity_type": "Algorithm",
        "name": "Latent Semantic Analysis (LSA)",
        "year": 1990,
        "authors": [
          "Deerwester, S.",
          "Dumais, S. T.",
          "Furnas, G. W.",
          "Landauer, T. K.",
          "Harshman, R."
        ],
        "task": "Information Retrieval",
        "dataset": [
          "Term-Document Matrices"
        ],
        "metrics": [
          "Similarity Measures"
        ],
        "architecture": {
          "components": [
            "Matrix Factorization"
          ],
          "connections": [
            "Low-Rank Approximation"
          ],
          "mechanisms": [
            "Decomposition of Large Matrices"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Global Matrix Factorization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Statistical Information Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lund1996_HAL",
        "entity_type": "Algorithm",
        "name": "Hyperspace Analogue to Language (HAL)",
        "year": 1996,
        "authors": [
          "Lund, K.",
          "Burgess, C."
        ],
        "task": "Word Representation",
        "dataset": [
          "Term-Term Matrices"
        ],
        "metrics": [
          "Co-occurrence Counts"
        ],
        "architecture": {
          "components": [
            "Matrix of Term-Term Co-occurrences"
          ],
          "connections": [
            "Word-Word Relationships"
          ],
          "mechanisms": [
            "Contextual Co-occurrence"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Global Matrix Factorization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Rohde2006_COALS",
        "entity_type": "Algorithm",
        "name": "COALS Method",
        "year": 2006,
        "authors": [
          "Rohde, D. L. T.",
          "Gonnerman, L. M.",
          "Plaut, D. C."
        ],
        "task": "Word Representation",
        "dataset": [
          "Co-occurrence Matrices"
        ],
        "metrics": [
          "Entropy-Based Normalization",
          "Correlation-Based Normalization"
        ],
        "architecture": {
          "components": [
            "Transformed Co-occurrence Matrix"
          ],
          "connections": [
            "Normalized Co-occurrence Counts"
          ],
          "mechanisms": [
            "Compression of Raw Counts"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Normalization Techniques"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Statistical Information Compression"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lebret2014_HPCA",
        "entity_type": "Algorithm",
        "name": "Hellinger PCA (HPCA)",
        "year": 2014,
        "authors": [
          "Lebret, R.",
          "Collobert, R."
        ],
        "task": "Word Representation",
        "dataset": [
          "Co-occurrence Matrices"
        ],
        "metrics": [
          "Square Root Transformation"
        ],
        "architecture": {
          "components": [
            "Principal Component Analysis"
          ],
          "connections": [
            "Hellinger Distance"
          ],
          "mechanisms": [
            "Dimensionality Reduction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Matrix Factorization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Statistical Information Transformation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengio2003_NeuralLM",
        "entity_type": "Algorithm",
        "name": "Neural Probabilistic Language Model",
        "year": 2003,
        "authors": [
          "Bengio, Y.",
          "Ducharme, R.",
          "Vincent, P.",
          "Janvin, C."
        ],
        "task": "Language Modeling",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Log Probability"
        ],
        "architecture": {
          "components": [
            "Simple Neural Network Architecture"
          ],
          "connections": [
            "Word Vector Representations"
          ],
          "mechanisms": [
            "Language Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Training"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collobert2008_UnifiedArchitecture",
        "entity_type": "Algorithm",
        "name": "Unified Architecture for NLP",
        "year": 2008,
        "authors": [
          "Collobert, R.",
          "Weston, J."
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Performance on Various Tasks"
        ],
        "architecture": {
          "components": [
            "Deep Neural Networks"
          ],
          "connections": [
            "Multitask Learning"
          ],
          "mechanisms": [
            "Unified Framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collobert2011_NLPFromScratch",
        "entity_type": "Algorithm",
        "name": "Natural Language Processing (Almost) from Scratch",
        "year": 2011,
        "authors": [
          "Collobert, R.",
          "Weston, J.",
          "Bottou, L.",
          "Karlen, M.",
          "Kavukcuoglu, K.",
          "Kuksa, P."
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Performance on Various Tasks"
        ],
        "architecture": {
          "components": [
            "Deep Neural Networks"
          ],
          "connections": [
            "Multitask Learning"
          ],
          "mechanisms": [
            "Unified Framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_CBOW",
        "entity_type": "Algorithm",
        "name": "Continuous Bag-of-Words (CBOW) Model",
        "year": 2013,
        "authors": [
          "Mikolov, T.",
          "Chen, K.",
          "Corrado, G.",
          "Dean, J."
        ],
        "task": "Word Representation",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Log Probability"
        ],
        "architecture": {
          "components": [
            "Single-Layer Architecture"
          ],
          "connections": [
            "Inner Product Between Word Vectors"
          ],
          "mechanisms": [
            "Prediction of Target Words"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Training"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mnih2013_vLBL",
        "entity_type": "Algorithm",
        "name": "Vector Log-Bilinear Model (vLBL)",
        "year": 2013,
        "authors": [
          "Mnih, A.",
          "Kavukcuoglu, K."
        ],
        "task": "Word Representation",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Log Probability"
        ],
        "architecture": {
          "components": [
            "Single-Layer Architecture"
          ],
          "connections": [
            "Inner Product Between Word Vectors"
          ],
          "mechanisms": [
            "Prediction of Context Words"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Training"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Levy2014_PPMI",
        "entity_type": "Algorithm",
        "name": "Positive Pointwise Mutual Information (PPMI)",
        "year": 2014,
        "authors": [
          "Levy, O.",
          "Goldberg, Y.",
          "Ramat-Gan, I."
        ],
        "task": "Word Representation",
        "dataset": [
          "Co-occurrence Matrices"
        ],
        "metrics": [
          "Pointwise Mutual Information"
        ],
        "architecture": {
          "components": [
            "Co-occurrence Matrix Transformation"
          ],
          "connections": [
            "Normalized Co-occurrence Counts"
          ],
          "mechanisms": [
            "Information-Theoretic Transformation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Matrix Transformation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Statistical Information Transformation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_WeightedLeastSquaresRegression",
        "entity_type": "Algorithm",
        "name": "Weighted Least Squares Regression",
        "year": 2014,
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C.D."
        ],
        "task": "Word Representation Learning",
        "dataset": [
          "Wikipedia_2010",
          "Wikipedia_2014",
          "Gigaword_5",
          "Common_Crawl"
        ],
        "metrics": [
          "Accuracy_Analogy",
          "Spearman_Rank_Correlation_Similarity"
        ],
        "architecture": {
          "components": [
            "Weighting Function",
            "Logarithmic Transformation"
          ],
          "connections": [
            "Co-occurrence Matrix",
            "Vector Differences"
          ],
          "mechanisms": [
            "Global Statistics Utilization",
            "Efficient Statistical Information Leveraging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "xmax=100",
            "α=3/4"
          ]
        },
        "feature_processing": [
          "Co-occurrence Counts",
          "Context Window"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL2003_NER",
        "entity_type": "Dataset",
        "name": "CoNLL-2003",
        "description": "Named Entity Recognition benchmark dataset",
        "domain": "Natural Language Processing",
        "size": "Not specified",
        "year": 2003,
        "creators": [
          "Tjong Kim Sang, E.F.",
          "De Meulder, F."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_NER",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Named Entity Recognition",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "CrossEntropy_Error",
        "entity_type": "Metric",
        "name": "Cross Entropy Error",
        "description": "Measure of the difference between two probability distributions",
        "category": "Classification",
        "formula": "-sum(p_i * log(q_i))"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WordSim353_2001",
        "entity_type": "Dataset",
        "name": "WordSim-353",
        "description": "Word similarity dataset",
        "domain": "Natural Language Processing",
        "year": 2001,
        "creators": [
          "Finkelstein, L.",
          "Gabrilovich, E.",
          "Matias, Y.",
          "Rivlin, E.",
          "Solan, Z.",
          "Wolfman, G.",
          "Ruppin, E."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MC_1991",
        "entity_type": "Dataset",
        "name": "MC",
        "description": "Miller and Charles word similarity dataset",
        "domain": "Natural Language Processing",
        "year": 1991,
        "creators": [
          "Miller, G.A.",
          "Charles, W.G."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "RG_1965",
        "entity_type": "Dataset",
        "name": "RG",
        "description": "Rubenstein and Goodenough word similarity dataset",
        "domain": "Natural Language Processing",
        "year": 1965,
        "creators": [
          "Rubenstein, H.",
          "Goodenough, J.B."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SCWS_2012",
        "entity_type": "Dataset",
        "name": "SCWS",
        "description": "Sentences Containing Word Similarities",
        "domain": "Natural Language Processing",
        "year": 2012,
        "creators": [
          "Huang, E.H.",
          "Socher, R.",
          "Manning, C.D.",
          "Ng, A.Y."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "RW_2013",
        "entity_type": "Dataset",
        "name": "RW",
        "description": "Rare Words dataset",
        "domain": "Natural Language Processing",
        "year": 2013,
        "creators": [
          "Luong, M.T.",
          "Socher, R.",
          "Manning, C.D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_SymmetricContextWindow",
        "entity_type": "Algorithm",
        "name": "Symmetric Context Window",
        "year": 2014,
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C.D."
        ],
        "task": "Word Representation",
        "dataset": [
          "Wikipedia_2014",
          "Gigaword_5"
        ],
        "metrics": [
          "Accuracy_Analogy"
        ],
        "architecture": {
          "components": [
            "Word Vectors",
            "Context Vectors"
          ],
          "connections": [
            "Dot Product"
          ],
          "mechanisms": [
            "Weighted Least Squares Regression"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Symmetric Context Window"
          ],
          "parameter_tuning": [
            "Vector Dimension",
            "Context Window Size"
          ]
        },
        "feature_processing": [
          "Co-occurrence Counts"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_AsymmetricContextWindow",
        "entity_type": "Algorithm",
        "name": "Asymmetric Context Window",
        "year": 2014,
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C.D."
        ],
        "task": "Word Representation",
        "dataset": [
          "Wikipedia_2014",
          "Gigaword_5"
        ],
        "metrics": [
          "Accuracy_Analogy"
        ],
        "architecture": {
          "components": [
            "Word Vectors",
            "Context Vectors"
          ],
          "connections": [
            "Dot Product"
          ],
          "mechanisms": [
            "Weighted Least Squares Regression"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Asymmetric Context Window"
          ],
          "parameter_tuning": [
            "Vector Dimension",
            "Context Window Size"
          ]
        },
        "feature_processing": [
          "Co-occurrence Counts"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TemplateBasedStatisticalLearning",
        "entity_type": "Algorithm",
        "name": "KAZB",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "自动求解数学文字题",
        "dataset": [
          "Alg514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "模板匹配",
            "句子推理"
          ],
          "connections": [
            "问题句子到模板映射"
          ],
          "mechanisms": [
            "统计学习"
          ]
        },
        "methodology": {
          "training_strategy": [
            "跨句子推理"
          ],
          "parameter_tuning": [
            "模板定义"
          ]
        },
        "feature_processing": [
          "问题句子建模"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_ImprovedTemplateBasedStatisticalLearning",
        "entity_type": "Algorithm",
        "name": "ZDC",
        "year": 2015,
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "自动求解数学文字题",
        "dataset": [
          "Alg514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "改进的模板匹配",
            "句子推理"
          ],
          "connections": [
            "问题句子到模板映射"
          ],
          "mechanisms": [
            "统计学习"
          ]
        },
        "methodology": {
          "training_strategy": [
            "减少名词短语与变量的对齐建模"
          ],
          "parameter_tuning": [
            "模板定义"
          ]
        },
        "feature_processing": [
          "问题句子建模"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_SimpleSimilarityBasedMethod",
        "entity_type": "Algorithm",
        "name": "SIM",
        "year": 2016,
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.Y.",
          "Yin, J.",
          "Ma, W.Y."
        ],
        "task": "自动求解数学文字题",
        "dataset": [
          "Alg514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "词汇相似性计算",
            "模板选择",
            "模板槽填充"
          ],
          "connections": [
            "问题句子到模板映射"
          ],
          "mechanisms": [
            "基于相似性的方法"
          ]
        },
        "methodology": {
          "training_strategy": [
            "加权Jaccard相似性计算"
          ],
          "parameter_tuning": [
            "TF-IDF分数向量"
          ]
        },
        "feature_processing": [
          "问题句子建模"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DRAW_2015",
        "entity_type": "Dataset",
        "name": "DRAW",
        "year": 2015,
        "authors": [
          "Upadhyay, S.",
          "Chang, M.W."
        ],
        "domain": "代数文字题",
        "size": 1000,
        "description": "包含1000个代数文字题，每个问题标注有线性方程"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SingleEQ_2015",
        "entity_type": "Dataset",
        "name": "SingleEQ",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "domain": "单一线性方程问题",
        "size": 508,
        "description": "包含508个问题，每个对应一个单一线性方程"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_VerbCategoryLearning",
        "entity_type": "Algorithm",
        "name": "Verb Category Learning",
        "year": 2014,
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Verb Categorization",
            "Learning Model"
          ],
          "connections": [
            "Verb Categories -> Equation Templates"
          ],
          "mechanisms": [
            "Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Verb Category Parameters"
          ]
        },
        "feature_processing": [
          "Verb Category Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KoncelKedziorski2015_SingleLinearEquationSolver",
        "entity_type": "Algorithm",
        "name": "Single Linear Equation Solver",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "SingleEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Equation Parser",
            "Solver"
          ],
          "connections": [
            "Text -> Equation -> Solution"
          ],
          "mechanisms": [
            "Parsing Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Parsing"
          ],
          "parameter_tuning": [
            "Parsing Rules"
          ]
        },
        "feature_processing": [
          "Textual Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_GeneralArithmeticWordProblemSolver",
        "entity_type": "Algorithm",
        "name": "General Arithmetic Word Problem Solver",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Parsing",
            "Reasoning Engine"
          ],
          "connections": [
            "Text -> Semantic Representation -> Solution"
          ],
          "mechanisms": [
            "Semantic Parsing Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Parsing"
          ],
          "parameter_tuning": [
            "Parsing Rules"
          ]
        },
        "feature_processing": [
          "Textual Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Verb395_2014",
        "entity_type": "Dataset",
        "name": "Verb395",
        "description": "Collection of addition/subtraction problems",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "YahooAnswers_MathPosts_2016",
        "entity_type": "Dataset",
        "name": "Yahoo! Answers Math Posts",
        "description": "Mathematics category posts from Yahoo! Answers, containing raw problem text and answer text.",
        "domain": "Mathematical Problem Solving",
        "size": 1000000,
        "year": 2016,
        "creators": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_AnswerExtractionRankingSVM",
        "entity_type": "Algorithm",
        "name": "Answer Extraction Ranking SVM",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": 2016,
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "Automatic Answer Extraction",
        "dataset": [
          "YahooAnswers_MathPosts_2016"
        ],
        "metrics": [
          "Precision_AnswerExtraction",
          "Recall_AnswerExtraction"
        ],
        "architecture": {
          "components": [
            "Ranking SVM"
          ],
          "connections": [
            "Feature extraction from answer text",
            "Conditional probability calculation"
          ],
          "mechanisms": [
            "Maximizing margin between correct and incorrect instances"
          ]
        },
        "methodology": {
          "training_strategy": [
            "5-fold cross-validation"
          ],
          "parameter_tuning": [
            "Parameter vector ν"
          ]
        },
        "feature_processing": [
          "Local context features",
          "Global features",
          "Number value features",
          "Number set features",
          "Dimension features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_EquationExtractionAlgorithm",
        "entity_type": "Algorithm",
        "name": "Equation Extraction Algorithm",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": 2016,
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "Automatic Equation Annotation",
        "dataset": [
          "YahooAnswers_MathPosts_2016"
        ],
        "metrics": [
          "Precision_EquationExtraction",
          "Recall_EquationExtraction"
        ],
        "architecture": {
          "components": [
            "Candidate extraction",
            "Solution voting"
          ],
          "connections": [
            "Regular expression matching",
            "Equation system construction",
            "Solution verification"
          ],
          "mechanisms": [
            "Reducing duplicate equations",
            "Selecting equation system with maximum degree"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not explicitly mentioned"
          ],
          "parameter_tuning": [
            "Not explicitly mentioned"
          ]
        },
        "feature_processing": [
          "Regular expression matching",
          "Solution verification"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_AnswerExtraction",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Proportion of correctly extracted answers among all extracted answers.",
        "category": "Answer Extraction Evaluation",
        "formula": "True positives / (True positives + False positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_AnswerExtraction",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Proportion of correctly extracted answers among all actual answers.",
        "category": "Answer Extraction Evaluation",
        "formula": "True positives / (True positives + False negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_EquationExtraction",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Proportion of correctly extracted equation systems among all extracted equation systems.",
        "category": "Equation Extraction Evaluation",
        "formula": "True positives / (True positives + False positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_EquationExtraction",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Proportion of correctly extracted equation systems among all actual equation systems.",
        "category": "Equation Extraction Evaluation",
        "formula": "True positives / (True positives + False negatives)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shi2015_NumberWordProblemSolver",
        "entity_type": "Algorithm",
        "name": "Number Word Problem Solver",
        "year": 2015,
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.-Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "自动解决数学文字问题",
        "dataset": [
          "Dolphin1878_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "语义解析模块",
            "推理模块"
          ],
          "connections": [
            "输入问题 -> 语义解析 -> 推理 -> 输出答案"
          ],
          "mechanisms": [
            "模式匹配",
            "动词分类"
          ]
        },
        "methodology": {
          "training_strategy": [
            "监督学习"
          ],
          "parameter_tuning": [
            "超参数调整"
          ]
        },
        "feature_processing": [
          "句子结构化",
          "方程推导"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Small01_2016",
        "entity_type": "Dataset",
        "name": "Small.01",
        "description": "从All.Linear中选择对应于Alg514中的28个模板的问题",
        "domain": "数学文字问题",
        "size": 2021,
        "year": 2016,
        "creators": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.-Y.",
          "Yin, J.",
          "Ma, W."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Small02_2016",
        "entity_type": "Dataset",
        "name": "Small.02",
        "description": "从Small.01中随机移除问题，使得每个模板包含与Alg514相似数量的问题",
        "domain": "数学文字问题",
        "size": "与Alg514相似",
        "year": 2016,
        "creators": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.-Y.",
          "Yin, J.",
          "Ma, W."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_LinearEquationSystem",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "线性方程系统的准确性",
        "category": "线性方程系统评估",
        "formula": "正确分类样本数/总样本数"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_LargeScaleDatasetConstruction",
        "entity_type": "Algorithm",
        "name": "Large-Scale Dataset Construction",
        "year": 2016,
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Data Collection",
            "Preprocessing",
            "Answer Extraction",
            "Equation Extraction"
          ],
          "connections": [
            "Yahoo! Answers -> Preprocessing -> Answer Extraction -> Equation Extraction"
          ],
          "mechanisms": [
            "Ranking SVM",
            "Logistic Regression Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Semi-automatic Extraction"
          ],
          "parameter_tuning": [
            "Threshold Setting for Confidence Score"
          ]
        },
        "feature_processing": [
          "TF-IDF",
          "Weighted Jaccard Similarity",
          "Regular Expression Matching"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ImageNet_2009",
        "entity_type": "Dataset",
        "name": "ImageNet",
        "description": "一个大规模的层次化图像数据库，基于WordNet结构构建。",
        "domain": "计算机视觉",
        "size": 3200000,
        "year": 2009,
        "creators": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "AUC_Classification",
        "entity_type": "Metric",
        "name": "AUC",
        "description": "ROC曲线下面积",
        "category": "分类评估",
        "formula": "ROC曲线下的面积"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_NN_voting",
        "entity_type": "Algorithm",
        "name": "NN-voting",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ],
        "task": "对象识别",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "Accuracy",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "最近邻搜索",
            "投票机制"
          ],
          "connections": [
            "候选图像与目标类别的树结构"
          ],
          "mechanisms": [
            "基于像素距离的相似性匹配"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习"
          ],
          "parameter_tuning": [
            "候选图像数量"
          ]
        },
        "feature_processing": [
          "下采样到32x32"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_NBNN",
        "entity_type": "Algorithm",
        "name": "NBNN",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ],
        "task": "对象识别",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "Accuracy",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "朴素贝叶斯最近邻",
            "SIFT特征描述符"
          ],
          "connections": [
            "查询图像与类别特征的距离计算"
          ],
          "mechanisms": [
            "基于特征级信息的分类"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习"
          ],
          "parameter_tuning": [
            "特征描述符数量"
          ]
        },
        "feature_processing": [
          "SIFT特征提取"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_Tree_max_classifier",
        "entity_type": "Algorithm",
        "name": "Tree-max Classifier",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ],
        "task": "图像分类",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "AUC"
        ],
        "architecture": {
          "components": [
            "树结构分类器",
            "AdaBoost-based分类器"
          ],
          "connections": [
            "节点分类得分与子节点分类得分的最大值"
          ],
          "mechanisms": [
            "利用层次结构进行分类"
          ]
        },
        "methodology": {
          "training_strategy": [
            "有监督学习"
          ],
          "parameter_tuning": [
            "训练图像数量"
          ]
        },
        "feature_processing": [
          "无"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "TinyImage_2008",
        "entity_type": "Dataset",
        "name": "TinyImage",
        "description": "一个包含8000万张32x32低分辨率图像的数据集，通过将WordNet中的所有单词作为查询发送到图像搜索引擎收集。",
        "domain": "计算机视觉",
        "size": 80000000,
        "year": 2008,
        "creators": [
          "Torralba, A.",
          "Fergus, R.",
          "Freeman, W."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ESP_dataset_2004",
        "entity_type": "Dataset",
        "name": "ESP dataset",
        "description": "通过在线游戏ESP Game收集的图像数据集，玩家独立为同一张图片提供标签，目标是在规定时间内匹配尽可能多的词汇。",
        "domain": "计算机视觉",
        "size": 60000,
        "year": 2004,
        "creators": [
          "von Ahn, L.",
          "Dabbish, L."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Caltech101_2004",
        "entity_type": "Dataset",
        "name": "Caltech101",
        "description": "一个包含101个类别的图像数据集，每个类别大约有40到800张图像。",
        "domain": "计算机视觉",
        "size": 9146,
        "year": 2004,
        "creators": [
          "Fei-Fei, L.",
          "Fergus, R.",
          "Perona, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Caltech256_2007",
        "entity_type": "Dataset",
        "name": "Caltech256",
        "description": "一个包含256个类别的图像数据集，每个类别大约有80张图像。",
        "domain": "计算机视觉",
        "size": 30607,
        "year": 2007,
        "creators": [
          "Griffin, G.",
          "Holub, A.",
          "Perona, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MSRC_2006",
        "entity_type": "Dataset",
        "name": "MSRC",
        "description": "一个包含24个类别的图像分割数据集。",
        "domain": "计算机视觉",
        "size": 591,
        "year": 2006,
        "creators": [
          "Shotton, J.",
          "Winn, J.",
          "Rother, C.",
          "Criminisi, A."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PASCAL_2008",
        "entity_type": "Dataset",
        "name": "PASCAL",
        "description": "一个包含20个类别的图像分割和物体检测数据集。",
        "domain": "计算机视觉",
        "size": 10000,
        "year": 2008,
        "creators": [
          "Everingham, M.",
          "Van Gool, L.",
          "Williams, C. K. I.",
          "Winn, J.",
          "Zisserman, A."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "LabelMe_2008",
        "entity_type": "Dataset",
        "name": "LabelMe",
        "description": "一个包含30,000张标注和分割的图像数据集。",
        "domain": "计算机视觉",
        "size": 30000,
        "year": 2008,
        "creators": [
          "Russell, B.",
          "Torralba, A.",
          "Murphy, K.",
          "Freeman, W."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Lotus_Hill_2007",
        "entity_type": "Dataset",
        "name": "Lotus Hill",
        "description": "一个包含50,000张标注和分割的图像数据集，以及587,000帧视频。",
        "domain": "计算机视觉",
        "size": 50000,
        "year": 2007,
        "creators": [
          "Yao, B.",
          "Yang, X.",
          "Zhu, S."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_AMT_image_verification",
        "entity_type": "Algorithm",
        "name": "AMT Image Verification",
        "year": 2009,
        "authors": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": "Image Annotation",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Amazon Mechanical Turk",
            "User Voting System"
          ],
          "connections": [
            "Image Querying",
            "User Feedback Loop"
          ],
          "mechanisms": [
            "Duplicate Removal",
            "Quality Control"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Crowdsourcing"
          ],
          "parameter_tuning": [
            "Number of Votes Required",
            "Confidence Score Threshold"
          ]
        },
        "feature_processing": [
          "Image Downsampling",
          "Image Duplication Removal"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WordNet_1998",
        "entity_type": "Dataset",
        "name": "WordNet",
        "description": "A large lexical database of English",
        "domain": "Natural Language Processing",
        "size": 80000,
        "year": 1998,
        "creators": [
          "Fellbaum, C."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Confidence_Score_Verification",
        "entity_type": "Metric",
        "name": "Confidence Score",
        "description": "Probability of an image being correctly classified based on user votes",
        "category": "Image Annotation",
        "formula": "Calculated based on user votes and predefined thresholds"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collins2008_Active_Learning_Approach",
        "entity_type": "Algorithm",
        "name": "Active Learning Approach",
        "year": 2008,
        "authors": [
          "Collins, B.",
          "Deng, J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": "Dataset Construction",
        "dataset": [
          "ImageNet_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Active Learning Module",
            "Image Collection Module"
          ],
          "connections": [
            "Feedback Loop",
            "Data Selection"
          ],
          "mechanisms": [
            "Query Strategy",
            "Model Update"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Active Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Data Augmentation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "FERET_Faces_1998",
        "entity_type": "Dataset",
        "name": "FERET Faces",
        "description": "Face recognition database",
        "domain": "Computer Vision",
        "size": 14000,
        "year": 1998,
        "creators": [
          "Phillips, P.",
          "Wechsler, H.",
          "Huang, J.",
          "Rauss, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Labeled_Faces_in_the_Wild_2007",
        "entity_type": "Dataset",
        "name": "Labeled Faces in the Wild",
        "description": "Unconstrained face recognition database",
        "domain": "Computer Vision",
        "size": 13000,
        "year": 2007,
        "creators": [
          "Huang, G.",
          "Ramesh, M.",
          "Berg, T.",
          "Learned-Miller, E."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "True_Positive_Rate_Detection",
        "entity_type": "Metric",
        "name": "True Positive Rate",
        "description": "Rate of correctly identified positive instances",
        "category": "Detection Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "False_Positive_Rate_Detection",
        "entity_type": "Metric",
        "name": "False Positive Rate",
        "description": "Rate of incorrectly identified positive instances",
        "category": "Detection Evaluation",
        "formula": "False Positives / (False Positives + True Negatives)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Boiman2008_Nearest_Neighbor_Based_Classification",
        "entity_type": "Algorithm",
        "name": "Nearest Neighbor Based Classification",
        "year": 2008,
        "authors": [
          "Boiman, O.",
          "Shechtman, E.",
          "Irani, M."
        ],
        "task": "Image Classification",
        "dataset": [
          "Caltech101_2004",
          "Caltech256_2007"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Precision_Classification",
          "Recall_Classification"
        ],
        "architecture": {
          "components": [
            "Nearest Neighbor Classifier",
            "Bag-of-Features Representation"
          ],
          "connections": [
            "Feature Matching",
            "Distance Calculation"
          ],
          "mechanisms": [
            "Voting Scheme",
            "Feature Aggregation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "K Value",
            "Distance Metric"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Normalization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fergus2005_Object_Category_Learning",
        "entity_type": "Algorithm",
        "name": "Object Category Learning",
        "year": 2005,
        "authors": [
          "Fergus, R.",
          "Fei-Fei, L.",
          "Perona, P.",
          "Zisserman, A."
        ],
        "task": "Object Recognition",
        "dataset": [
          "TinyImage_2008"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Category Model",
            "Image Search Engine"
          ],
          "connections": [
            "Query Expansion",
            "Image Retrieval"
          ],
          "mechanisms": [
            "Semantic Mapping",
            "Category Refinement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "Thresholds",
            "Query Terms"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Image Preprocessing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_ImageNet_Hierarchy_Exploitation",
        "entity_type": "Algorithm",
        "name": "ImageNet Hierarchy Exploitation",
        "year": 2009,
        "authors": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ],
        "task": "Image Classification",
        "dataset": [
          "ImageNet_2009"
        ],
        "metrics": [
          "AUC_Classification"
        ],
        "architecture": {
          "components": [
            "Tree-max Classifier"
          ],
          "connections": [
            "Parent-child relationships in the hierarchy"
          ],
          "mechanisms": [
            "Hierarchical classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "AdaBoost-based classifier"
          ],
          "parameter_tuning": [
            "Number of images per category"
          ]
        },
        "feature_processing": [
          "Feature extraction from full-resolution images"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ImageNet_2011",
        "entity_type": "Dataset",
        "name": "ImageNet",
        "description": "A large-scale hierarchical image database",
        "domain": "Computer Vision",
        "size": 50000000,
        "year": 2011,
        "creators": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Average_AUC_Classification",
        "entity_type": "Metric",
        "name": "Average AUC",
        "description": "Average Area Under the ROC Curve",
        "category": "Classification Evaluation",
        "formula": "Mean(AUC of all categories)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hajishirzi2013_NECO",
        "entity_type": "Algorithm",
        "name": "NECO",
        "title": "Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves",
        "year": 2013,
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": "Coreference Resolution and Named-Entity Linking",
        "dataset": [
          "ACE 2004 Newswire",
          "CoNLL 2011"
        ],
        "metrics": [
          "MUC",
          "B3",
          "Pairwise",
          "F1"
        ],
        "architecture": {
          "components": [
            "Stanford sieve-based model",
            "NEL-informed mention-merging sieves",
            "mention detection",
            "mention pruning",
            "NEL constraints"
          ],
          "connections": [
            "mention detection -> NEL",
            "NEL -> coreference resolution",
            "coreference resolution -> NEL"
          ],
          "mechanisms": [
            "multi-pass sieves",
            "automatic mention detection",
            "entity link propagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "deterministic",
            "no learning phase"
          ],
          "parameter_tuning": [
            "confidence thresholds for NEL systems"
          ]
        },
        "feature_processing": [
          "mention detection",
          "NEL constraints",
          "fine-grained attributes from Freebase and Wikipedia"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004_NWIRE_2004",
        "entity_type": "Dataset",
        "name": "ACE 2004 Newswire",
        "description": "Newswire subset of the ACE 2004 corpus",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CONLL2011_2011",
        "entity_type": "Dataset",
        "name": "CoNLL 2011",
        "description": "Coreference dataset from five different domains: broadcast conversation, broadcast news, magazine, newswire, and web data",
        "domain": "Natural Language Processing",
        "size": 625,
        "year": 2011,
        "creators": [
          "Pradhan et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "B3_Coreference",
        "entity_type": "Metric",
        "name": "B3",
        "description": "Computes the proportion of intersection between predicted and gold clusters for every mention",
        "category": "Coreference Evaluation",
        "formula": "Intersection proportion between predicted and gold clusters"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_Coreference",
        "entity_type": "Metric",
        "name": "Pairwise",
        "description": "Measures the pairwise agreement between predicted and gold clusters",
        "category": "Coreference Evaluation",
        "formula": "Pairwise agreement between predicted and gold clusters"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_NEL",
        "entity_type": "Metric",
        "name": "F1",
        "description": "Harmonic mean of precision and recall",
        "category": "Named-Entity Linking Evaluation",
        "formula": "2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Stanford2013_SieveModel",
        "entity_type": "Algorithm",
        "name": "Stanford Sieve Model",
        "year": 2013,
        "authors": [
          "Lee, H.",
          "Raghunathan, K.",
          "Surdeanu, M.",
          "Jurafsky, D."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004_NWIRE_2004",
          "CONLL2011_2011"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "Pairwise_Coreference"
        ],
        "architecture": {
          "components": [
            "mention detection",
            "cluster merging operations"
          ],
          "connections": [
            "deterministic rules",
            "sieves"
          ],
          "mechanisms": [
            "mention clustering",
            "coreference resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "pipeline of sieves"
          ],
          "parameter_tuning": [
            "mention detection",
            "cluster merging"
          ]
        },
        "feature_processing": [
          "noun phrases",
          "pronouns",
          "named entities"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ratinov2011_GLOW",
        "entity_type": "Algorithm",
        "name": "GLOW",
        "year": 2011,
        "authors": [
          "Ratinov, L.",
          "Downey, D.",
          "Anderson, M."
        ],
        "task": "Named Entity Linking",
        "dataset": [
          "ACE2004_NWIRE_2004"
        ],
        "metrics": [
          "F1_NEL"
        ],
        "architecture": {
          "components": [
            "mention detection",
            "integer linear programming"
          ],
          "connections": [
            "local constraints",
            "global constraints"
          ],
          "mechanisms": [
            "entity link co-occurrence"
          ]
        },
        "methodology": {
          "training_strategy": [
            "optimization problem"
          ],
          "parameter_tuning": [
            "confidence values"
          ]
        },
        "feature_processing": [
          "local constraints",
          "global constraints"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Milne2008_WikipediaMiner",
        "entity_type": "Algorithm",
        "name": "WikipediaMiner",
        "year": 2008,
        "authors": [
          "Milne, D.",
          "Witten, I.H."
        ],
        "task": "Named Entity Linking",
        "dataset": [
          "ACE2004_NWIRE_2004"
        ],
        "metrics": [
          "F1_NEL"
        ],
        "architecture": {
          "components": [
            "mention linking",
            "semantic similarity"
          ],
          "connections": [
            "Wikipedia pages",
            "context"
          ],
          "mechanisms": [
            "disambiguation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "semantic scoring function"
          ],
          "parameter_tuning": [
            "n-gram statistics",
            "shared links"
          ]
        },
        "feature_processing": [
          "semantic similarity",
          "context"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hajishirzi2013_RelaxedNELsieve",
        "entity_type": "Algorithm",
        "name": "Relaxed NEL sieve",
        "year": 2013,
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": "Coreference resolution and named-entity linking",
        "dataset": [
          "ACE2004_NWIRE_2004",
          "CONLL2011_2011"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "Pairwise_Coreference",
          "F1_NEL"
        ],
        "architecture": {
          "components": [
            "Fine-grained attributes",
            "Freebase notable types",
            "Wikipedia categories"
          ],
          "connections": [
            "Mention merging",
            "Cluster merging"
          ],
          "mechanisms": [
            "Attribute comparison",
            "Entity linking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic rules",
            "NEL constraints"
          ],
          "parameter_tuning": [
            "Confidence thresholds"
          ]
        },
        "feature_processing": [
          "Fine-grained attribute extraction",
          "Head link assignment"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hajishirzi2013_ExactNELsieve",
        "entity_type": "Algorithm",
        "name": "Exact NEL sieve",
        "year": 2013,
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": "Coreference resolution and named-entity linking",
        "dataset": [
          "ACE2004_NWIRE_2004",
          "CONLL2011_2011"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "Pairwise_Coreference",
          "F1_NEL"
        ],
        "architecture": {
          "components": [
            "Entity links",
            "Wikipedia pages"
          ],
          "connections": [
            "Mention merging",
            "Cluster merging"
          ],
          "mechanisms": [
            "Link matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic rules",
            "NEL constraints"
          ],
          "parameter_tuning": [
            "Confidence thresholds"
          ]
        },
        "feature_processing": [
          "Exact link assignment"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004_NWIRE_NEL_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-NWIRE-NEL",
        "description": "A subset of ACE 2004 newswire data annotated with gold-standard entity links.",
        "domain": "Natural Language Processing",
        "size": 12,
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hajishirzi2013_NECO_GoldNEL",
        "entity_type": "Algorithm",
        "name": "NECO with Gold NEL",
        "year": 2013,
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": "Coreference Resolution and Named-Entity Linking",
        "dataset": [
          "ACE2004_NWIRE_2004"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "Pairwise_Coreference"
        ],
        "architecture": {
          "components": [
            "Stanford Sieve Model",
            "NEL Constraints",
            "Mention Detection",
            "Mention Attributes"
          ],
          "connections": [
            "Mention Detection -> NEL Constraints -> Cluster Merging"
          ],
          "mechanisms": [
            "Gold Linking",
            "Fine-grained Attributes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gold Standard Annotations"
          ],
          "parameter_tuning": [
            "High Confidence Links"
          ]
        },
        "feature_processing": [
          "Gold Linking",
          "Fine-grained Attributes"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004_NWIRE_NEL_Gold_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-NWIRE-NEL (Gold)",
        "description": "A subset of ACE 2004 newswire data with gold-standard entity links.",
        "domain": "Natural Language Processing",
        "size": 12,
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorReduction_NEL",
        "entity_type": "Metric",
        "name": "Relative Reduction in F1 Error",
        "description": "Relative reduction in F1 error rate for named-entity linking.",
        "category": "Named-Entity Linking",
        "formula": "((Baseline F1 - NECO F1) / Baseline F1) * 100%"
      }
    },
    {
      "metric_entity": {
        "metric_id": "AbsoluteGain_NEL",
        "entity_type": "Metric",
        "name": "Absolute Gain in Precision and Recall",
        "description": "Absolute improvement in precision and recall for named-entity linking.",
        "category": "Named-Entity Linking",
        "formula": "NECO Precision/Recall - Baseline Precision/Recall"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_QuadraticProgrammingSolver",
        "entity_type": "Algorithm",
        "name": "Quadratic Programming Solver",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "Solving Algebra Word Problems",
        "dataset": [
          "Kushman2014_Dataset"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Log-linear model",
            "Quadratic Programming"
          ],
          "connections": [
            "Max-margin objective",
            "Constraint generation"
          ],
          "mechanisms": [
            "Feature extraction",
            "Template matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin objective",
            "Constraint generation"
          ],
          "parameter_tuning": [
            "Parameter C"
          ]
        },
        "feature_processing": [
          "Single slot features",
          "Slot pair features",
          "Solution features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Kushman2014_Dataset_2014",
        "entity_type": "Dataset",
        "name": "Kushman et al. Dataset",
        "description": "Benchmark dataset for algebra word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_LogLinearModel",
        "entity_type": "Algorithm",
        "name": "Log-Linear Model",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Parameter Vector"
          ],
          "connections": [
            "Template Selection",
            "Number Assignment"
          ],
          "mechanisms": [
            "Max-Margin Objective"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Objective",
            "Quadratic Programming"
          ],
          "parameter_tuning": [
            "Parameter Vector θ"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_LogLinearModelForEquationMapping",
        "entity_type": "Algorithm",
        "name": "Log-Linear Model for Equation Mapping",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Log-linear model",
            "Equation system templates"
          ],
          "connections": [
            "Mapping from word problems to equation systems"
          ],
          "mechanisms": [
            "Max-margin objective",
            "Quadratic Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin objective",
            "Constraint generation"
          ],
          "parameter_tuning": [
            "Parameter C"
          ]
        },
        "feature_processing": [
          "Single slot features",
          "Slot pair features",
          "Solution features"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Generalization_Error_Modeling",
        "entity_type": "Metric",
        "name": "Generalization Error",
        "description": "Error rate of the model on unseen data",
        "category": "Model Evaluation",
        "formula": "Error rate on validation/test set"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_ConstraintGeneration",
        "entity_type": "Algorithm",
        "name": "Constraint Generation",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Log-linear Model",
            "Quadratic Programming"
          ],
          "connections": [
            "Max-margin Objective",
            "Slack Variable"
          ],
          "mechanisms": [
            "Constraint Generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Initial Model Training",
            "Constraint Checking",
            "False Derivation Collection"
          ],
          "parameter_tuning": [
            "Parameter C"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "CrossValidationError",
        "entity_type": "Metric",
        "name": "Cross-Validation Error",
        "description": "Error rate measured during cross-validation",
        "category": "Model Evaluation",
        "formula": "Average error across validation folds"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_SingleSlotFeatures",
        "entity_type": "Algorithm",
        "name": "Single Slot Features",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Relation between numbers and the question sentence",
            "Position of a number w.r.t a comparative word",
            "Context of a number",
            "Is one or two?",
            "Is a multiplier?",
            "Is between 0 and 1?"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Relation between numbers and the question sentence",
          "Position of a number w.r.t a comparative word",
          "Context of a number",
          "Is one or two?",
          "Is a multiplier?",
          "Is between 0 and 1?"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_SlotPairFeatures",
        "entity_type": "Algorithm",
        "name": "Slot Pair Features",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Relation between two numbers",
            "Context similarity between two numbers",
            "Coreference relationship",
            "Both multipliers",
            "Same sentence or continuous sentences",
            "Raw path and dependency path",
            "One number is larger than another"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Relation between two numbers",
          "Context similarity between two numbers",
          "Coreference relationship",
          "Both multipliers",
          "Same sentence or continuous sentences",
          "Raw path and dependency path",
          "One number is larger than another"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_SolutionFeatures",
        "entity_type": "Algorithm",
        "name": "Solution Features",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Is integer solution?",
            "Is positive solution?",
            "Is between 0 and 1?"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Is integer solution?",
          "Is positive solution?",
          "Is between 0 and 1?"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_CombinedFeedbackPerceptron",
        "entity_type": "Algorithm",
        "name": "Combined Feedback Perceptron",
        "year": 2014,
        "authors": [
          "Dan Goldwasser",
          "Dan Roth"
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary Perceptron",
            "Structured Perceptron"
          ],
          "connections": [
            "Combines binary and structured updates"
          ],
          "mechanisms": [
            "Loss Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative training with feedback"
          ],
          "parameter_tuning": [
            "Weight updates based on feedback"
          ]
        },
        "feature_processing": [
          "Lexical and syntactic features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geoquery_2014",
        "entity_type": "Dataset",
        "name": "Geoquery",
        "description": "Geographical queries dataset",
        "domain": "Natural Language Processing",
        "size": 500,
        "year": 2014,
        "creators": [
          "Zelle, J.",
          "Mooney, R."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SolitaireCardGame_2014",
        "entity_type": "Dataset",
        "name": "Solitaire Card Game",
        "description": "Instructions and rules for various solitaire card games",
        "domain": "Natural Language Processing",
        "size": "Varies by game",
        "year": 2014,
        "creators": [
          "Goldwasser, D.",
          "Roth, D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_StructuredUpdate",
        "entity_type": "Algorithm",
        "name": "Structured Update",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Input Sentence",
            "Logical Formula"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Weight Update"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Incremental Learning",
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Weight Vector"
          ]
        },
        "feature_processing": [
          "Lexical Information",
          "Syntactic Patterns"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_SimpleBinaryUpdate",
        "entity_type": "Algorithm",
        "name": "Simple Binary Update",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Input Sentence",
            "Logical Formula"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Weight Demotion"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Binary Classification",
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Weight Vector"
          ]
        },
        "feature_processing": [
          "Lexical Information",
          "Syntactic Patterns"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_ApproximatedStructuralUpdate",
        "entity_type": "Algorithm",
        "name": "Approximated Structural Update",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector",
            "Confidence Score"
          ],
          "connections": [
            "Input Sentence",
            "Logical Formula"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Weight Update",
            "Confidence Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Incremental Learning",
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Weight Vector",
            "Confidence Score"
          ]
        },
        "feature_processing": [
          "Lexical Information",
          "Syntactic Patterns"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1Score_Classification",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 分数",
        "category": "分类评估",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_IntegerLinearProgramming",
        "entity_type": "Algorithm",
        "name": "Integer Linear Programming (ILP)",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Decision Variables",
            "Objective Function",
            "Constraints"
          ],
          "connections": [
            "Feature Functions",
            "Flow Constraints"
          ],
          "mechanisms": [
            "Optimization",
            "Constraint Satisfaction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Learning",
            "Feedback-driven Learning"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features",
          "Dependency Tree Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_CombPercept_w_AprxLoss",
        "entity_type": "Algorithm",
        "name": "CombPercept w AprxLoss",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "Geoquery_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary Update",
            "Structural Update",
            "Loss Approximation"
          ],
          "connections": [
            "Binary Update -> Loss Approximation",
            "Structural Update -> Loss Approximation"
          ],
          "mechanisms": [
            "Loss Approximation",
            "Feature Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-driven Updates"
          ],
          "parameter_tuning": [
            "Weight Vector Adjustment"
          ]
        },
        "feature_processing": [
          "Lexical Similarity",
          "Syntactic Information"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geo880_2014",
        "entity_type": "Dataset",
        "name": "Geo880",
        "description": "Geographical queries dataset",
        "domain": "Natural Language Processing",
        "size": 880,
        "year": 2014,
        "creators": [
          "Zelle, J.",
          "Mooney, R."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Supervised_Accuracy",
        "entity_type": "Metric",
        "name": "Supervised Accuracy",
        "description": "Accuracy of supervised models",
        "category": "Classification Evaluation",
        "formula": "Correct classifications / Total classifications"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Unsupervised_Accuracy",
        "entity_type": "Metric",
        "name": "Unsupervised Accuracy",
        "description": "Accuracy of unsupervised models",
        "category": "Classification Evaluation",
        "formula": "Correct classifications / Total classifications"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clarke2010_DrivingSemanticParsing",
        "entity_type": "Algorithm",
        "name": "Driving Semantic Parsing",
        "year": 2010,
        "authors": [
          "Clarke, J.",
          "Goldwasser, D.",
          "Chang, M.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "Geoquery_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Parser",
            "Feedback Function"
          ],
          "connections": [
            "World Response",
            "Behavioral Feedback"
          ],
          "mechanisms": [
            "Supervised Learning",
            "Unsupervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Behavioral Feedback",
            "World Response"
          ],
          "parameter_tuning": [
            "Feedback Function"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kate2008_TransformingMeaningRepresentation",
        "entity_type": "Algorithm",
        "name": "Transforming Meaning Representation",
        "year": 2008,
        "authors": [
          "Kate, R."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "CoNLL_2008"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Meaning Representation Grammars"
          ],
          "connections": [
            "Semantic Parsing",
            "Grammar Transformation"
          ],
          "mechanisms": [
            "Inductive Logic Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Grammar Transformation"
          ],
          "parameter_tuning": [
            "Meaning Representation"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL_2008",
        "entity_type": "Dataset",
        "name": "CoNLL",
        "description": "Conference on Computational Natural Language Learning dataset",
        "domain": "Natural Language Processing",
        "year": 2008,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Branavan2009_ReinforcementLearningMapping",
        "entity_type": "Algorithm",
        "name": "Reinforcement Learning for Mapping Instructions to Actions",
        "year": 2009,
        "authors": [
          "Branavan, S.",
          "Chen, H.",
          "Zettlemoyer, L.S.",
          "Barzilay, R."
        ],
        "task": "Instruction Mapping",
        "dataset": [
          "ACL_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Reinforcement Learning",
            "Instruction Mapping"
          ],
          "connections": [
            "Instructions",
            "Actions"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Instruction Mapping"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Branavan2011_LearningToWin",
        "entity_type": "Algorithm",
        "name": "Learning to Win by Reading Manuals",
        "year": 2011,
        "authors": [
          "Branavan, S.",
          "Silver, D.",
          "Barzilay, R."
        ],
        "task": "Game Playing",
        "dataset": [
          "Monte-Carlo Framework"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Monte-Carlo Framework",
            "Manual Reading"
          ],
          "connections": [
            "Reading Manuals",
            "Game Playing"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Monte-Carlo Framework"
          ],
          "parameter_tuning": [
            "Manual Reading"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2010b_StructuredOutputLearning",
        "entity_type": "Algorithm",
        "name": "Structured Output Learning with Indirect Supervision",
        "year": 2010,
        "authors": [
          "Chang, M.",
          "Goldwasser, D.",
          "Roth, D.",
          "Srikumar, V."
        ],
        "task": "Structured Prediction",
        "dataset": [
          "ICML_2010"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Structured Output Learning",
            "Indirect Supervision"
          ],
          "connections": [
            "Indirect Supervision",
            "Structured Prediction"
          ],
          "mechanisms": [
            "Indirect Supervision"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Indirect Supervision"
          ],
          "parameter_tuning": [
            "Structured Output Learning"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2012_FastOnlineLexicon",
        "entity_type": "Algorithm",
        "name": "Fast Online Lexicon Learning",
        "year": 2012,
        "authors": [
          "Chen, D."
        ],
        "task": "Grounded Language Acquisition",
        "dataset": [
          "ACL_2012"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Lexicon Learning",
            "Grounded Language"
          ],
          "connections": [
            "Lexicon Learning",
            "Language Acquisition"
          ],
          "mechanisms": [
            "Online Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Lexicon Learning"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2008_LearningToSportscast",
        "entity_type": "Algorithm",
        "name": "Learning to Sportscast",
        "year": 2008,
        "authors": [
          "Chen, D.",
          "Mooney, R."
        ],
        "task": "Grounded Language",
        "dataset": [
          "ICML_2008"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Sportscasting",
            "Grounded Language"
          ],
          "connections": [
            "Sportscasting",
            "Language"
          ],
          "mechanisms": [
            "Grounded Language"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Grounded Language"
          ],
          "parameter_tuning": [
            "Sportscasting"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Eisenstein2009_ReadingToLearn",
        "entity_type": "Algorithm",
        "name": "Reading to Learn",
        "year": 2009,
        "authors": [
          "Eisenstein, J.",
          "Clarke, J.",
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Feature Construction",
        "dataset": [
          "EMNLP_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Construction",
            "Semantic Abstracts"
          ],
          "connections": [
            "Reading",
            "Learning"
          ],
          "mechanisms": [
            "Feature Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Feature Construction"
          ],
          "parameter_tuning": [
            "Semantic Abstracts"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Isbell2006_CobotInLambdaMOO",
        "entity_type": "Algorithm",
        "name": "Cobot in LambdaMOO",
        "year": 2006,
        "authors": [
          "Isbell, C.",
          "Kearns, M.",
          "Singh, S.",
          "Shelton, C.",
          "Stone, P.",
          "Kormann, D."
        ],
        "task": "Adaptive Social Statistics Agent",
        "dataset": [
          "AAMAS_2006"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Adaptive Social Statistics Agent",
            "LambdaMOO"
          ],
          "connections": [
            "Adaptive Social Statistics",
            "Agent"
          ],
          "mechanisms": [
            "Adaptive Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adaptive Learning"
          ],
          "parameter_tuning": [
            "Social Statistics"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kate2006_StringKernels",
        "entity_type": "Algorithm",
        "name": "Using String-Kernels for Learning Semantic Parsers",
        "year": 2006,
        "authors": [
          "Kate, R.",
          "Mooney, R."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "ACL_2006"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "String-Kernels",
            "Semantic Parsers"
          ],
          "connections": [
            "String-Kernels",
            "Semantic Parsing"
          ],
          "mechanisms": [
            "Kernel Methods"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Kernel Methods"
          ],
          "parameter_tuning": [
            "String-Kernels"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kim2012_UnsupervisedPCFG",
        "entity_type": "Algorithm",
        "name": "Unsupervised PCFG Induction",
        "year": 2012,
        "authors": [
          "Kim, J.",
          "Mooney, R."
        ],
        "task": "Grounded Language Learning",
        "dataset": [
          "EMNLP_2012"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "PCFG Induction",
            "Grounded Language"
          ],
          "connections": [
            "PCFG Induction",
            "Language Learning"
          ],
          "mechanisms": [
            "Unsupervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "PCFG Induction"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Knox2009_InteractivelyShapingAgents",
        "entity_type": "Algorithm",
        "name": "Interactively Shaping Agents",
        "year": 2009,
        "authors": [
          "Knox, B.",
          "Stone, P."
        ],
        "task": "Human Reinforcement",
        "dataset": [
          "KCAP_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Human Reinforcement",
            "Agent Shaping"
          ],
          "connections": [
            "Human Interaction",
            "Agent"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Human Reinforcement"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kuhlmann2004_GuidingReinforcementLearner",
        "entity_type": "Algorithm",
        "name": "Guiding a Reinforcement Learner with Natural Language Advice",
        "year": 2004,
        "authors": [
          "Kuhlmann, G.",
          "Stone, P.",
          "Mooney, R.",
          "Shavlik, J."
        ],
        "task": "Reinforcement Learning",
        "dataset": [
          "RoboCup Soccer"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Reinforcement Learning",
            "Natural Language Advice"
          ],
          "connections": [
            "Natural Language",
            "Reinforcement Learning"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Natural Language Advice"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2009_LearningSemanticCorrespondences",
        "entity_type": "Algorithm",
        "name": "Learning Semantic Correspondences",
        "year": 2009,
        "authors": [
          "Liang, P.",
          "Jordan, M.",
          "Klein, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "ACL_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Correspondences",
            "Less Supervision"
          ],
          "connections": [
            "Semantic Parsing",
            "Correspondences"
          ],
          "mechanisms": [
            "Supervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Semantic Correspondences"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2011_LearningDependencyBasedCompositional",
        "entity_type": "Algorithm",
        "name": "Learning Dependency-Based Compositional",
        "year": 2011,
        "authors": [
          "Liang, P.",
          "Jordan, M.",
          "Klein, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "ACL_2011"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Dependency-Based Compositional",
            "Semantic Parsing"
          ],
          "connections": [
            "Dependency-Based",
            "Compositional"
          ],
          "mechanisms": [
            "Supervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Dependency-Based Compositional"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Matuszek2012_JointModelOfLanguage",
        "entity_type": "Algorithm",
        "name": "Joint Model of Language and Perception",
        "year": 2012,
        "authors": [
          "Matuszek, C.",
          "FitzGerald, N.",
          "Zettlemoyer, L.",
          "Bo, L.",
          "Fox, D."
        ],
        "task": "Grounded Attribute Learning",
        "dataset": [
          "ICML_2012"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Joint Model",
            "Language",
            "Perception"
          ],
          "connections": [
            "Language",
            "Perception"
          ],
          "mechanisms": [
            "Joint Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint Learning"
          ],
          "parameter_tuning": [
            "Joint Model"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Tellex2011_ApproachingSymbolGrounding",
        "entity_type": "Algorithm",
        "name": "Approaching the Symbol Grounding Problem",
        "year": 2011,
        "authors": [
          "Tellex, S.",
          "Kollar, T.",
          "Dickerson, S.",
          "Walter, M.",
          "Banerjee, A.",
          "Teller, S.",
          "Roy, N."
        ],
        "task": "Symbol Grounding",
        "dataset": [
          "AI Magazine_2011"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Symbol Grounding",
            "Probabilistic Graphical Models"
          ],
          "connections": [
            "Symbol Grounding",
            "Graphical Models"
          ],
          "mechanisms": [
            "Probabilistic Models"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic Models"
          ],
          "parameter_tuning": [
            "Symbol Grounding"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Thomaz2006_ReinforcementLearningWithTeachers",
        "entity_type": "Algorithm",
        "name": "Reinforcement Learning with Human Teachers",
        "year": 2006,
        "authors": [
          "Thomaz, A.",
          "Breazeal, C."
        ],
        "task": "Reinforcement Learning",
        "dataset": [
          "AAAI_2006"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Reinforcement Learning",
            "Human Teachers"
          ],
          "connections": [
            "Human Interaction",
            "Reinforcement Learning"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Human Teachers"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Vogel2010_LearningToFollowDirections",
        "entity_type": "Algorithm",
        "name": "Learning to Follow Navigational Directions",
        "year": 2010,
        "authors": [
          "Vogel, A.",
          "Jurafsky, D."
        ],
        "task": "Navigational Directions",
        "dataset": [
          "ACL_2010"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Navigational Directions",
            "Reinforcement Learning"
          ],
          "connections": [
            "Navigational Directions",
            "Reinforcement Learning"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Navigational Directions"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wong2006_LearningSemanticParsing",
        "entity_type": "Algorithm",
        "name": "Learning for Semantic Parsing",
        "year": 2006,
        "authors": [
          "Wong, Y.",
          "Mooney, R."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "NAACL_2006"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Parsing",
            "Statistical Machine Translation"
          ],
          "connections": [
            "Semantic Parsing",
            "Translation"
          ],
          "mechanisms": [
            "Statistical Machine Translation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Statistical Machine Translation"
          ],
          "parameter_tuning": [
            "Semantic Parsing"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wong2007_LearningSynchronousGrammars",
        "entity_type": "Algorithm",
        "name": "Learning Synchronous Grammars",
        "year": 2007,
        "authors": [
          "Wong, Y.",
          "Mooney, R."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "ACL_2007"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Synchronous Grammars",
            "Lambda Calculus"
          ],
          "connections": [
            "Synchronous Grammars",
            "Semantic Parsing"
          ],
          "mechanisms": [
            "Lambda Calculus"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Lambda Calculus"
          ],
          "parameter_tuning": [
            "Synchronous Grammars"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2009_LearningStructuralSVMs",
        "entity_type": "Algorithm",
        "name": "Learning Structural SVMs",
        "year": 2009,
        "authors": [
          "Yu, C.",
          "Joachims, T."
        ],
        "task": "Structural SVMs",
        "dataset": [
          "ICML_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Structural SVMs",
            "Latent Variables"
          ],
          "connections": [
            "Structural SVMs",
            "Latent Variables"
          ],
          "mechanisms": [
            "Latent Variables"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variables"
          ],
          "parameter_tuning": [
            "Structural SVMs"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zelle1996_LearningToParseDatabase",
        "entity_type": "Algorithm",
        "name": "Learning to Parse Database Queries",
        "year": 1996,
        "authors": [
          "Zelle, J.",
          "Mooney, R."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "AAAI_1996"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Parsing",
            "Database Queries"
          ],
          "connections": [
            "Semantic Parsing",
            "Database"
          ],
          "mechanisms": [
            "Inductive Logic Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Inductive Logic Programming"
          ],
          "parameter_tuning": [
            "Semantic Parsing"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zettlemoyer2005_LearningToMapSentences",
        "entity_type": "Algorithm",
        "name": "Learning to Map Sentences to Logical Form",
        "year": 2005,
        "authors": [
          "Zettlemoyer, L.",
          "Collins, M."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "UAI_2005"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Sentences Mapping",
            "Logical Form"
          ],
          "connections": [
            "Sentences",
            "Logical Form"
          ],
          "mechanisms": [
            "Probabilistic Categorial Grammars"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic Categorial Grammars"
          ],
          "parameter_tuning": [
            "Sentences Mapping"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zettlemoyer2007_OnlineLearningRelaxedCCG",
        "entity_type": "Algorithm",
        "name": "Online Learning of Relaxed CCG Grammars",
        "year": 2007,
        "authors": [
          "Zettlemoyer, L.",
          "Collins, M."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "CoNLL_2007"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Relaxed CCG Grammars",
            "Online Learning"
          ],
          "connections": [
            "Relaxed CCG Grammars",
            "Online Learning"
          ],
          "mechanisms": [
            "Online Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Relaxed CCG Grammars"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zettlemoyer2009_LearningContextDependentMappings",
        "entity_type": "Algorithm",
        "name": "Learning Context-Dependent Mappings",
        "year": 2009,
        "authors": [
          "Zettlemoyer, L.",
          "Collins, M."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "ACL_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Context-Dependent Mappings",
            "Sentences",
            "Logical Form"
          ],
          "connections": [
            "Context-Dependent Mappings",
            "Sentences",
            "Logical Form"
          ],
          "mechanisms": [
            "Context-Dependent Mappings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Context-Dependent Mappings"
          ],
          "parameter_tuning": [
            "Sentences",
            "Logical Form"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_RNNEncoderDecoder",
        "entity_type": "Algorithm",
        "name": "RNN Encoder–Decoder",
        "year": 2014,
        "authors": [
          "Kyunghyun Cho",
          "Bart van Merriënboer",
          "Caglar Gulcehre",
          "Dzmitry Bahdanau",
          "Fethi Bougares",
          "Holger Schwenk",
          "Yoshua Bengio"
        ],
        "task": "Statistical Machine Translation",
        "dataset": [
          "English/French translation task of the WMT’14 workshop"
        ],
        "metrics": [
          "BLEU score"
        ],
        "architecture": {
          "components": [
            "Encoder RNN",
            "Decoder RNN",
            "Hidden Unit with Reset and Update Gates"
          ],
          "connections": [
            "Encoder maps a variable-length source sequence to a fixed-length vector",
            "Decoder maps the fixed-length vector back to a variable-length target sequence"
          ],
          "mechanisms": [
            "Conditional probability maximization",
            "Adaptive remembering and forgetting"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint training to maximize conditional probability",
            "Gradient-based parameter estimation"
          ],
          "parameter_tuning": [
            "Reset gate",
            "Update gate",
            "Hyperparameters ε= 10−6 and ρ= 0.95"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Phrase pairs scoring"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT14_EnglishFrench_2014",
        "entity_type": "Dataset",
        "name": "English/French translation task of the WMT’14 workshop",
        "description": "Large bilingual corpora for English/French translation including Europarl, news commentary, UN, and crawled corpora.",
        "domain": "Machine Translation",
        "size": "Over 2 billion words for language modeling and 348 million words for training the RNN Encoder–Decoder",
        "year": 2014,
        "creators": [
          "WMT’14 workshop organizers"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_Translation",
        "entity_type": "Metric",
        "name": "BLEU score",
        "description": "A metric for evaluating the quality of text which has been machine-translated from one natural language to another.",
        "category": "Translation Evaluation",
        "formula": "Not explicitly defined in the document"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_RecurrentNeuralNetwork",
        "entity_type": "Algorithm",
        "name": "Recurrent Neural Network (RNN)",
        "year": 2014,
        "authors": [
          "Cho, Kyunghyun",
          "van Merriënboer, Bart",
          "Gulcehre, Caglar",
          "Bahdanau, Dzmitry",
          "Bougares, Fethi",
          "Schwenk, Holger",
          "Bengio, Yoshua"
        ],
        "task": "Sequence Modeling",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Hidden State",
            "Output"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent Connections"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_LongShortTermMemory",
        "entity_type": "Algorithm",
        "name": "Long Short-Term Memory (LSTM)",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Sequence Modeling",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Memory Cell",
            "Input Gate",
            "Forget Gate",
            "Output Gate"
          ],
          "connections": [
            "Recurrent Connections"
          ],
          "mechanisms": [
            "Adaptive Information Flow Control"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_AdaptiveHiddenUnit",
        "entity_type": "Algorithm",
        "name": "Adaptive Hidden Unit",
        "year": 2014,
        "authors": [
          "Cho, Kyunghyun",
          "van Merriënboer, Bart",
          "Gulcehre, Caglar",
          "Bahdanau, Dzmitry",
          "Bougares, Fethi",
          "Schwenk, Holger",
          "Bengio, Yoshua"
        ],
        "task": "Sequence Modeling",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Reset Gate",
            "Update Gate"
          ],
          "connections": [
            "Recurrent Connections"
          ],
          "mechanisms": [
            "Adaptive Memory Control"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "ConditionalLogLikelihood_Translation",
        "entity_type": "Metric",
        "name": "Conditional Log-Likelihood",
        "description": "Logarithm of the conditional probability of a target sequence given a source sequence",
        "category": "Translation Evaluation",
        "formula": "log pθ(yn | xn)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Schwenk2012_FeedforwardNeuralNetwork",
        "entity_type": "Algorithm",
        "name": "Feedforward Neural Network",
        "year": 2012,
        "authors": [
          "Schwenk, H."
        ],
        "task": "Phrase Pair Scoring",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layers",
            "Output Layer"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Fixed-size Input and Output"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Devlin2014_NeuralNetworkJointModel",
        "entity_type": "Algorithm",
        "name": "Neural Network Joint Model",
        "year": 2014,
        "authors": [
          "Devlin, J.",
          "Zbib, R.",
          "Huang, Z.",
          "Lamar, T.",
          "Schwartz, R.",
          "Makhoul, J."
        ],
        "task": "Statistical Machine Translation",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layers",
            "Output Layer"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Predicting One Word at a Time"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zou2013_BilingualEmbedding",
        "entity_type": "Algorithm",
        "name": "Bilingual Embedding",
        "year": 2013,
        "authors": [
          "Zou, W.Y.",
          "Socher, R.",
          "Cer, D.M.",
          "Manning, C.D."
        ],
        "task": "Phrase Pair Scoring",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layers",
            "Output Layer"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Bilingual Embedding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chandar2014_BagOfWordsMapping",
        "entity_type": "Algorithm",
        "name": "Bag-of-Words Mapping",
        "year": 2014,
        "authors": [
          "Chandar, S.",
          "Lauly, S.",
          "Larochelle, H.",
          "Khapra, M.",
          "Ravindran, B.",
          "Raykar, V.",
          "Saha, A."
        ],
        "task": "Phrase Pair Scoring",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layers",
            "Output Layer"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Bag-of-Words Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Europarl_2005",
        "entity_type": "Dataset",
        "name": "Europarl",
        "year": 2005,
        "creators": [
          "Koehn, P."
        ],
        "domain": "Machine Translation",
        "size": 61000000,
        "description": "Parallel corpus for statistical machine translation"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NewsCommentary_2014",
        "entity_type": "Dataset",
        "name": "News Commentary",
        "year": 2014,
        "creators": [
          "NAACL"
        ],
        "domain": "Machine Translation",
        "size": 5500000,
        "description": "Parallel corpus for statistical machine translation"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "UNCorpus_2014",
        "entity_type": "Dataset",
        "name": "UN Corpus",
        "year": 2014,
        "creators": [
          "UN"
        ],
        "domain": "Machine Translation",
        "size": 421000000,
        "description": "Parallel corpus for statistical machine translation"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CrawledCorpora_2014",
        "entity_type": "Dataset",
        "name": "Crawled Corpora",
        "year": 2014,
        "creators": [
          "Various Sources"
        ],
        "domain": "Machine Translation",
        "size": 870000000,
        "description": "Parallel corpus for statistical machine translation"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Perplexity_LanguageModel",
        "entity_type": "Metric",
        "name": "Perplexity",
        "category": "Language Model Evaluation",
        "description": "Measure of how well a probability distribution or probability model predicts a sample"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_DeepNeuralNetwork",
        "entity_type": "Algorithm",
        "name": "Deep Neural Network",
        "year": 2014,
        "authors": [
          "Kyunghyun Cho",
          "Bart van Merriënboer",
          "Caglar Gulcehre",
          "Dzmitry Bahdanau",
          "Fethi Bougares",
          "Holger Schwenk",
          "Yoshua Bengio"
        ],
        "task": "Statistical Machine Translation",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent connections"
          ],
          "mechanisms": [
            "Reset gate",
            "Update gate"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based optimization",
            "Joint training"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Batch size"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Phrase pairs scoring"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "TestSet_newstest2012_2014",
        "entity_type": "Dataset",
        "name": "newstest2012",
        "year": 2014,
        "domain": "Machine Translation",
        "size": 70000,
        "creators": [
          "WMT'14 workshop"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "TestSet_newstest2013_2014",
        "entity_type": "Dataset",
        "name": "newstest2013",
        "year": 2014,
        "domain": "Machine Translation",
        "size": 70000,
        "creators": [
          "WMT'14 workshop"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "TestSet_newstest2014_2014",
        "entity_type": "Dataset",
        "name": "newstest2014",
        "year": 2014,
        "domain": "Machine Translation",
        "size": 70000,
        "creators": [
          "WMT'14 workshop"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ValidationPerplexity_LanguageModel",
        "entity_type": "Metric",
        "name": "Validation Perplexity",
        "category": "Language Modeling",
        "formula": "exp(-average_log_probability)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Schwenk2007_ContinuousSpaceLanguageModel",
        "entity_type": "Algorithm",
        "name": "Continuous Space Language Model",
        "year": 2007,
        "authors": [
          "Holger Schwenk"
        ],
        "task": "Language Modeling",
        "dataset": [
          "Target corpus"
        ],
        "metrics": [
          "Perplexity_LanguageModel"
        ],
        "architecture": {
          "components": [
            "Embedding layer",
            "Rectified layers",
            "Softmax output"
          ],
          "connections": [
            "Fully connected"
          ],
          "mechanisms": [
            "Word embeddings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic gradient descent"
          ],
          "parameter_tuning": [
            "Embedding dimension",
            "Layer sizes"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_CSLM",
        "entity_type": "Algorithm",
        "name": "CSLM",
        "year": 2014,
        "authors": [
          "Cho, K.",
          "van Merriënboer, B.",
          "Gulcehre, C.",
          "Bahdanau, D.",
          "Bougares, F.",
          "Schwenk, H.",
          "Bengio, Y."
        ],
        "task": "Statistical Machine Translation",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation",
          "Perplexity_LanguageModel"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Embedding Layer",
            "Rectified Layers",
            "Softmax Layer"
          ],
          "connections": [
            "Input to Embedding",
            "Embedding to Rectified Layers",
            "Rectified Layers to Softmax"
          ],
          "mechanisms": [
            "Word Projection",
            "Concatenation",
            "Non-linear Activation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient Descent",
            "Validation Set Monitoring"
          ],
          "parameter_tuning": [
            "Weight Initialization",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_Score",
        "entity_type": "Metric",
        "name": "BLEU Score",
        "description": "Bilingual Evaluation Understudy Score",
        "category": "Translation Quality",
        "formula": "Exponential average of modified n-gram precision"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_AlgebraWordProblemSolver",
        "entity_type": "Algorithm",
        "name": "Algebra Word Problem Solver",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": "自动求解代数文字题",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "模板选择",
            "槽位实例化",
            "对齐模型"
          ],
          "connections": [
            "模板到方程系统的映射",
            "槽位与文本的对齐"
          ],
          "mechanisms": [
            "联合对数线性分布",
            "模板归纳",
            "隐变量优化"
          ]
        },
        "methodology": {
          "training_strategy": [
            "弱监督学习",
            "完全监督学习"
          ],
          "parameter_tuning": [
            "L-BFGS优化",
            "L2正则化"
          ]
        },
        "feature_processing": [
          "词性标注",
          "词形还原",
          "依存句法分析",
          "名词短语匹配"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Algebra.com_2014",
        "entity_type": "Dataset",
        "name": "Algebra.com",
        "description": "从Algebra.com收集的代数文字题数据集",
        "domain": "代数问题求解",
        "size": 514,
        "year": 2014,
        "creators": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Equation_Accuracy",
        "entity_type": "Metric",
        "name": "Equation Accuracy",
        "description": "系统生成正确方程系统的频率",
        "category": "代数问题求解评估",
        "formula": "正确方程系统数量 / 总问题数量"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Answer_Accuracy",
        "entity_type": "Metric",
        "name": "Answer Accuracy",
        "description": "生成的数值答案正确的频率",
        "category": "代数问题求解评估",
        "formula": "正确答案数量 / 总问题数量"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_EquationTemplateInstantiation",
        "entity_type": "Algorithm",
        "name": "Equation Template Instantiation",
        "year": 2014,
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": "Solving Algebra Word Problems",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Selection",
            "Template Instantiation"
          ],
          "connections": [
            "Template to Equation",
            "Equation to Solution"
          ],
          "mechanisms": [
            "Slot Filling",
            "Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Weak Supervision"
          ],
          "parameter_tuning": [
            "Beam Search",
            "L-BFGS Optimization"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Part-of-Speech Tagging",
          "Lematization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AlgebraWordProblems_2014",
        "entity_type": "Dataset",
        "name": "Algebra Word Problems",
        "description": "A dataset of algebra word problems collected from Algebra.com",
        "domain": "Mathematics",
        "size": 514,
        "year": 2014,
        "creators": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Template_Frequency",
        "entity_type": "Metric",
        "name": "Template Frequency",
        "description": "Frequency of occurrence of equation templates in the dataset",
        "category": "Template Analysis",
        "formula": "Number of occurrences of a template / Total number of problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_LogLinearModel",
        "entity_type": "Algorithm",
        "name": "Log-Linear Model",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": "Automatically solving algebra word problems",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature function",
            "Parameter vector"
          ],
          "connections": [
            "Feature function to parameter vector",
            "Parameter vector to derivation probability"
          ],
          "mechanisms": [
            "Log-linear distribution",
            "Marginal data log-likelihood optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam search inference",
            "Conditional log-likelihood maximization"
          ],
          "parameter_tuning": [
            "L-BFGS optimization",
            "L2-norm regularization"
          ]
        },
        "feature_processing": [
          "Dependency parses",
          "Part-of-speech tags",
          "Lematizations"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TemplateInduction",
        "entity_type": "Algorithm",
        "name": "Template Induction",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "System Templates",
            "Unknown Slots",
            "Number Slots"
          ],
          "connections": [
            "Replacing Variables with Unknown Slots",
            "Replacing Numbers with Number Slots"
          ],
          "mechanisms": [
            "Generalizing Equations to Templates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Conditional Log-Likelihood Maximization"
          ]
        },
        "feature_processing": [
          "Canonicalization of Templates"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_BeamSearchInference",
        "entity_type": "Algorithm",
        "name": "Beam Search Inference",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "Template Selection",
            "Slot Alignment"
          ],
          "connections": [
            "Iterative Alignment of Slots to Words",
            "Pruning of Partial Derivations"
          ],
          "mechanisms": [
            "Canonicalized Ordering for Template Slots"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Approximate Computation"
          ],
          "parameter_tuning": [
            "Top-k Partial Derivations",
            "Maximum Beam Size"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Part-of-Speech Tagging"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "CrossValidation_Accuracy",
        "entity_type": "Metric",
        "name": "Cross-Validation Accuracy",
        "description": "Accuracy measured using 5-fold cross-validation",
        "category": "Classification Evaluation",
        "formula": "Correct Predictions / Total Predictions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_BeamSearchNormalization",
        "entity_type": "Algorithm",
        "name": "Beam Search Normalization",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "Normalization Constant"
          ],
          "connections": [
            "Template Selection",
            "Slot Alignment"
          ],
          "mechanisms": [
            "Exponential Search Space",
            "Canonical Ordering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Approximation"
          ],
          "parameter_tuning": [
            "Top-k Partial Derivations",
            "Pruning Strategy"
          ]
        },
        "feature_processing": [
          "Canonicalized Ordering",
          "Partial Hypotheses"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TemplateCanonicalization",
        "entity_type": "Algorithm",
        "name": "Template Canonicalization",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Symbolic Solution",
            "Mathematical Solver"
          ],
          "connections": [
            "Unknown Slots",
            "Number Slots"
          ],
          "mechanisms": [
            "Normal Form Representation",
            "Maxima Solver"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Canonicalization Process"
          ],
          "parameter_tuning": [
            "Symbolic Solution Generation"
          ]
        },
        "feature_processing": [
          "Mathematical Relations",
          "Symbolic Expressions"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_SlotSignatureGeneration",
        "entity_type": "Algorithm",
        "name": "Slot Signature Generation",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Slot Signatures",
            "Pairwise Slot Signatures"
          ],
          "connections": [
            "System Templates",
            "Constituent Equations"
          ],
          "mechanisms": [
            "Shared Terms",
            "Concatenation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Feature Sharing"
          ],
          "parameter_tuning": [
            "Signature Types"
          ]
        },
        "feature_processing": [
          "Dependency Paths",
          "Lexicalized Features"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Verb_Categorization_Accuracy",
        "entity_type": "Metric",
        "name": "Verb Categorization Accuracy",
        "description": "Accuracy of verb categorization in sentences",
        "category": "Verb Categorization Evaluation",
        "formula": "Correctly categorized verbs / Total verbs"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_StateTransitionModel",
        "entity_type": "Algorithm",
        "name": "State Transition Model",
        "year": 2014,
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "MA1_2014",
          "IXL_2014",
          "MA2_2014"
        ],
        "metrics": [
          "Verb_Categorization_Accuracy",
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Entities",
            "Containers",
            "Attributes",
            "Quantities",
            "Relations"
          ],
          "connections": [
            "State Transitions",
            "Algebraic Operations"
          ],
          "mechanisms": [
            "Observation",
            "Positive/Negative Updates",
            "Transfers",
            "Construction/Destruction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Verb Category Classification"
          ],
          "parameter_tuning": [
            "Support Vector Machines",
            "Feature Extraction"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Named Entity Recognition",
          "Coreference Resolution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ArithmeticWordProblems_2014",
        "entity_type": "Dataset",
        "name": "Arithmetic Word Problems",
        "description": "A corpus of arithmetic word problems focusing on addition and subtraction.",
        "domain": "Natural Language Processing",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Sentence_Categorization_Accuracy",
        "entity_type": "Metric",
        "name": "Sentence Categorization Accuracy",
        "description": "Accuracy of categorizing sentences into different verb categories.",
        "category": "Sentence Classification",
        "formula": "Number of correctly categorized sentences / Total number of sentences"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_VerbCategoryClassifier",
        "entity_type": "Algorithm",
        "name": "Verb Category Classifier",
        "year": 2014,
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "MA1_2014",
          "IXL_2014",
          "MA2_2014"
        ],
        "metrics": [
          "Verb_Categorization_Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Extractor",
            "Support Vector Machine (SVM)"
          ],
          "connections": [
            "Feature Extractor -> SVM"
          ],
          "mechanisms": [
            "Verb Category Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-validation"
          ],
          "parameter_tuning": [
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Similarity-based Features",
          "WordNet-based Features",
          "Structural Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_ARIS2",
        "entity_type": "Algorithm",
        "name": "ARIS2",
        "year": 2014,
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "MA1_2014",
          "IXL_2014",
          "MA2_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Verb_Categorization_Accuracy"
        ],
        "architecture": {
          "components": [
            "Entity Recognition",
            "Container Identification",
            "Verb Category Classification"
          ],
          "connections": [
            "Dependency Parsing",
            "Coreference Resolution"
          ],
          "mechanisms": [
            "State Transition Model",
            "Verb Category Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "No repeated verbs in training and test sets"
          ],
          "parameter_tuning": [
            "Support Vector Machines",
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Similarity-based Features",
          "WordNet-based Features",
          "Structural Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_ARIS_Variant",
        "entity_type": "Algorithm",
        "name": "ARIS Variant",
        "year": 2014,
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": "Solving Arithmetic Word Problems",
        "dataset": [
          "MA1",
          "IXL",
          "MA2"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Verb Category Classifier",
            "State Transition Model"
          ],
          "connections": [
            "Verb Category Classification -> State Transition"
          ],
          "mechanisms": [
            "Verb Categorization",
            "State Progression"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Verb Category Classification",
            "State Transition Learning"
          ],
          "parameter_tuning": [
            "SVM Parameters",
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Coreference Resolution",
          "Named Entity Recognition"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Combined_Dataset_2014",
        "entity_type": "Dataset",
        "name": "Combined Dataset",
        "description": "A combined dataset of arithmetic word problems from MA1, IXL, and MA2",
        "domain": "Natural Language Processing",
        "size": 395,
        "year": 2014,
        "creators": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_FormulaApplication",
        "entity_type": "Algorithm",
        "name": "Formula Application",
        "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
        "year": 2016,
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Part Whole",
            "Change",
            "Comparison"
          ],
          "connections": [
            "Mapping sentences to formulas",
            "Generating equations from formulas"
          ],
          "mechanisms": [
            "Log-linear model",
            "Feature extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Stochastic gradient descent"
          ]
        },
        "feature_processing": [
          "WordNet",
          "ConceptNet",
          "Stanford CoreNLP"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AddSub_2014",
        "entity_type": "Dataset",
        "name": "AddSub",
        "description": "Simple addition-subtraction arithmetic problems for third, fourth, and fifth graders",
        "domain": "Natural Language Understanding",
        "size": 395,
        "year": 2014,
        "creators": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_PartWholeFormula",
        "entity_type": "Algorithm",
        "name": "Part Whole Formula",
        "year": 2016,
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "Solving Arithmetic Word Problems",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Template",
            "Equation Generator"
          ],
          "connections": [
            "Variable Mapping",
            "Equation Formation"
          ],
          "mechanisms": [
            "Slot Filling",
            "Equation Translation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Log-linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Variable Extraction",
          "Attribute Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_ChangeFormula",
        "entity_type": "Algorithm",
        "name": "Change Formula",
        "year": 2016,
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "Solving Arithmetic Word Problems",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Template",
            "Equation Generator"
          ],
          "connections": [
            "Variable Mapping",
            "Equation Formation"
          ],
          "mechanisms": [
            "Slot Filling",
            "Equation Translation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Log-linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Variable Extraction",
          "Attribute Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_ComparisonFormula",
        "entity_type": "Algorithm",
        "name": "Comparison Formula",
        "year": 2016,
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "Solving Arithmetic Word Problems",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Template",
            "Equation Generator"
          ],
          "connections": [
            "Variable Mapping",
            "Equation Formation"
          ],
          "mechanisms": [
            "Slot Filling",
            "Equation Translation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Log-linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Variable Extraction",
          "Attribute Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_LogLinearModel",
        "entity_type": "Algorithm",
        "name": "Log-Linear Model",
        "year": 2016,
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Parameter Vector"
          ],
          "connections": [
            "Feature Vector Mapping",
            "Dot Product"
          ],
          "mechanisms": [
            "Log-Linear Probability Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Conditional Log-Likelihood Maximization"
          ]
        },
        "feature_processing": [
          "Variable Attributes Extraction",
          "Boolean Relation Computation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_FeatureFunction",
        "entity_type": "Algorithm",
        "name": "Feature Function",
        "year": 2016,
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Variable Attributes",
            "Boolean Relations",
            "Semantic Relations"
          ],
          "connections": [
            "Attribute Matching",
            "Relation Computation"
          ],
          "mechanisms": [
            "Contextual Information Extraction",
            "Mathematical Relation Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Vector Computation"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "WordNet Integration",
          "ConceptNet Integration"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorRate_Classification",
        "entity_type": "Metric",
        "name": "Error Rate",
        "description": "Percentage of Incorrect Predictions",
        "category": "Classification Evaluation",
        "formula": "Incorrect Predictions / Total Predictions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_SystemTemplateMapping",
        "entity_type": "Algorithm",
        "name": "System Template Mapping",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "System Templates"
          ],
          "connections": [
            "Mapping from Word Problems to System Templates"
          ],
          "mechanisms": [
            "Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Template Selection"
          ]
        },
        "feature_processing": [
          "Pattern Recognition"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KoncelKedziorski2015_ExpressionTreeMapping",
        "entity_type": "Algorithm",
        "name": "Expression Tree Mapping",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Expression Trees"
          ],
          "connections": [
            "Mapping from Word Problems to Expression Trees"
          ],
          "mechanisms": [
            "Tree Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Tree Structure Optimization"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_EquationGeneration",
        "entity_type": "Algorithm",
        "name": "Equation Generation",
        "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
        "year": 2016,
        "authors": [
          "Mitra, Arindam",
          "Baral, Chitta"
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Formula Application",
            "Feature Extraction",
            "Log-linear Model"
          ],
          "connections": [
            "Formula to Equation Mapping",
            "Feature Vector Calculation"
          ],
          "mechanisms": [
            "Probabilistic Model",
            "Parameter Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Stochastic Gradient Descent"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Semantic Relation Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_BackPropagationThroughTime",
        "entity_type": "Algorithm",
        "name": "Back-Propagation Through Time (BPTT)",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "Sequence modeling",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Recurrent neural networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_RealTimeRecurrentLearning",
        "entity_type": "Algorithm",
        "name": "Real-Time Recurrent Learning (RTRL)",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "Sequence modeling",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Recurrent neural networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Real-time learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_RecurrentCascadeCorrelation",
        "entity_type": "Algorithm",
        "name": "Recurrent Cascade-Correlation",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "Sequence modeling",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Recurrent neural networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cascade correlation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_ElmanNets",
        "entity_type": "Algorithm",
        "name": "Elman Nets",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "Sequence modeling",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Recurrent neural networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Elman's training procedure"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_NeuralSequenceChunker",
        "entity_type": "Algorithm",
        "name": "Neural Sequence Chunker",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "Sequence modeling",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Two interconnected networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Chunking"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_AdaptiveSequenceChunker",
        "entity_type": "Algorithm",
        "name": "Adaptive Sequence Chunker",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "Sequence modeling",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Hierarchical chunker systems"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Sequential network construction"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "EmbeddedReberGrammar_1997",
        "entity_type": "Dataset",
        "name": "Embedded Reber Grammar",
        "description": "A synthetic dataset for evaluating sequence prediction models",
        "domain": "Natural language processing",
        "year": 1997,
        "creators": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SuccessRate_Classification",
        "entity_type": "Metric",
        "name": "Success rate",
        "description": "Proportion of successful trials",
        "category": "Classification evaluation",
        "formula": "Successful trials / Total trials"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_ConstantErrorCarrousel",
        "entity_type": "Algorithm",
        "name": "Constant Error Carrousel (CEC)",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Long-term memory storage",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Linear unit",
            "Fixed self-connection"
          ],
          "connections": [
            "Self-connection"
          ],
          "mechanisms": [
            "Constant error flow"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_MultiplicativeGateUnits",
        "entity_type": "Algorithm",
        "name": "Multiplicative Gate Units",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Controlling access to constant error flow",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Input gate",
            "Output gate"
          ],
          "connections": [
            "Connections to memory cells"
          ],
          "mechanisms": [
            "Opening and closing access to CEC"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_MemoryCellBlock",
        "entity_type": "Algorithm",
        "name": "Memory Cell Block",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Information storage",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Memory cells",
            "Input gate",
            "Output gate"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Protecting memory contents from perturbation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_TemporalOrderProblem",
        "entity_type": "Algorithm",
        "name": "Temporal Order Problem Solver",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Extracting information conveyed by temporal order",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Memory cells",
            "Input gates",
            "Output gates"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Storing relevant inputs"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "AbsoluteError_Regression",
        "entity_type": "Metric",
        "name": "Absolute Error",
        "description": "Difference between predicted and actual value",
        "category": "Regression evaluation",
        "formula": "|predicted_value - actual_value|"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MeanSquaredError_Regression",
        "entity_type": "Metric",
        "name": "Mean Squared Error",
        "description": "Average of the squares of the differences between predicted and actual values",
        "category": "Regression evaluation",
        "formula": "mean((predicted_value - actual_value)^2)"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "TwoSequenceProblem_1994",
        "entity_type": "Dataset",
        "name": "2-sequence problem",
        "description": "A dataset for evaluating sequence prediction models",
        "domain": "Sequence prediction",
        "size": null,
        "year": 1994,
        "creators": [
          "Bengio, Y."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AddingProblem_1997",
        "entity_type": "Dataset",
        "name": "Adding Problem",
        "description": "A dataset for evaluating models on summing specific elements in a sequence",
        "domain": "Sequence prediction",
        "size": null,
        "year": 1997,
        "creators": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MultiplicationProblem_1997",
        "entity_type": "Dataset",
        "name": "Multiplication Problem",
        "description": "A dataset for evaluating models on multiplying specific elements in a sequence",
        "domain": "Sequence prediction",
        "size": null,
        "year": 1997,
        "creators": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_ConstantErrorFlow",
        "entity_type": "Algorithm",
        "name": "Constant Error Flow",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Long-term memory maintenance",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Single unit",
            "Self-connection"
          ],
          "connections": [
            "Single connection to itself"
          ],
          "mechanisms": [
            "Constant error flow"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Avoid vanishing error signals"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_NaiveConstantErrorFlow",
        "entity_type": "Algorithm",
        "name": "Naive Constant Error Flow",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Long-term memory maintenance",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Single unit",
            "Self-connection"
          ],
          "connections": [
            "Single connection to itself"
          ],
          "mechanisms": [
            "Naive constant error flow"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Avoid vanishing error signals"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_InputWeightConflict",
        "entity_type": "Algorithm",
        "name": "Input Weight Conflict",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Long-term memory maintenance",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Single unit",
            "Self-connection",
            "Additional input weight"
          ],
          "connections": [
            "Single connection to itself",
            "Connection to additional input"
          ],
          "mechanisms": [
            "Input weight conflict"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Address conflicting weight update signals"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_OutputWeightConflict",
        "entity_type": "Algorithm",
        "name": "Output Weight Conflict",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Long-term memory maintenance",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Single unit",
            "Self-connection",
            "Additional output weight"
          ],
          "connections": [
            "Single connection to itself",
            "Connection to additional output"
          ],
          "mechanisms": [
            "Output weight conflict"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Address conflicting weight update signals"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_FocusedRecurrentBackprop",
        "entity_type": "Algorithm",
        "name": "Focused Recurrent Backpropagation",
        "year": 1997,
        "authors": [
          "Mozer, M. C."
        ],
        "task": "Temporal Sequence Recognition",
        "dataset": [
          "EmbeddedReberGrammar_1997"
        ],
        "metrics": [
          "ErrorRate_Classification",
          "SuccessRate_Classification"
        ],
        "architecture": {
          "components": [
            "Hidden Units",
            "Output Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Truncated Backpropagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Local Input/Output Representation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_SequentialNetworkConstruction",
        "entity_type": "Algorithm",
        "name": "Sequential Network Construction",
        "year": 1997,
        "authors": [
          "Fahlman, S. E."
        ],
        "task": "Long Time Lag Problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Memory Cells",
            "Gate Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Incremental Addition of Units"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_OutputGateBias",
        "entity_type": "Algorithm",
        "name": "Output Gate Bias Initialization",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Long Time Lag Problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Output Gates"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Negative Initial Bias"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Initial Bias Values"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_StateDriftRemedies",
        "entity_type": "Algorithm",
        "name": "State Drift Remedies",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Long Time Lag Problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Input Gates"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Zero-Biased Input Gates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Input Gate Bias"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "MeanAbsoluteDifference_Regression",
        "entity_type": "Metric",
        "name": "Mean Absolute Difference",
        "category": "Regression",
        "formula": "Average of absolute differences between predicted and actual values"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goyal2017_VQA_LSTM_CNN",
        "entity_type": "Algorithm",
        "name": "Deeper LSTM Question + norm Image",
        "year": 2017,
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_v2.0"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "LSTM",
            "CNN"
          ],
          "connections": [
            "point-wise multiplication"
          ],
          "mechanisms": [
            "multi-layer perceptron classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "re-training on balanced dataset"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image features from VGGNet",
          "question features from LSTM"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lu2016_Hierarchical_Co_attention",
        "entity_type": "Algorithm",
        "name": "Hierarchical Co-attention",
        "year": 2016,
        "authors": [
          "Jiasen Lu",
          "Jianwei Yang",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_v2.0"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "word-level",
            "phrase-level",
            "entire question-level"
          ],
          "connections": [
            "co-attention mechanism"
          ],
          "mechanisms": [
            "multi-level attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "re-training on balanced dataset"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image features from VGGNet",
          "question features from LSTM"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fukui2016_Multimodal_Compact_Bilinear_Pooling",
        "entity_type": "Algorithm",
        "name": "Multimodal Compact Bilinear Pooling",
        "year": 2016,
        "authors": [
          "Akira Fukui",
          "Dhruv Batra",
          "Devi Parikh",
          "Trevor Darrell",
          "Marcus Rohrbach"
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_v2.0"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "bilinear pooling"
          ],
          "connections": [
            "attended image features",
            "language features"
          ],
          "mechanisms": [
            "fully-connected layer"
          ]
        },
        "methodology": {
          "training_strategy": [
            "re-training on balanced dataset"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image features from ResNet",
          "question features from LSTM"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "VQA_v2.0_2017",
        "entity_type": "Dataset",
        "name": "VQA_v2.0",
        "description": "Balanced Visual Question Answering dataset",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 1100000,
        "year": 2017,
        "creators": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Antol2015_VQA",
        "entity_type": "Algorithm",
        "name": "VQA",
        "year": 2015,
        "authors": [
          "Antol, S.",
          "Agrawal, A.",
          "Lu, J.",
          "Mitchell, M.",
          "Batra, D.",
          "Zitnick, C. L.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "CNN",
            "LSTM"
          ],
          "connections": [
            "image embedding",
            "question embedding"
          ],
          "mechanisms": [
            "point-wise multiplication",
            "multi-layer perceptron classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image features",
          "question features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "COCO_2014",
        "entity_type": "Dataset",
        "name": "COCO",
        "description": "Common Objects in Context",
        "domain": "计算机视觉",
        "size": 204000,
        "year": 2014,
        "creators": [
          "Lin, T.-Y.",
          "Maire, M.",
          "Belongie, S.",
          "Hays, J.",
          "Perona, P.",
          "Ramanan, D.",
          "Dolla´r, P.",
          "Zitnick, C. L."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Entropy_Answer_Distribution",
        "entity_type": "Metric",
        "name": "Entropy",
        "description": "衡量答案分布的熵",
        "category": "数据集平衡性评估",
        "formula": "H(X) = -∑ p(x) log p(x)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hodosh2016_Focused_Evaluation",
        "entity_type": "Algorithm",
        "name": "Focused Evaluation",
        "year": 2016,
        "authors": [
          "Hodosh, M.",
          "Hockenmaier, J."
        ],
        "task": "Image Captioning",
        "dataset": [
          "ImageNet_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "binary forced-choice task"
          ],
          "connections": [
            "image caption pairs"
          ],
          "mechanisms": [
            "nearest neighbor selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "human annotation"
          ],
          "parameter_tuning": [
            "none"
          ]
        },
        "feature_processing": [
          "image features",
          "caption features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "VQA_Abstract_Scenes_2016",
        "entity_type": "Dataset",
        "name": "VQA Abstract Scenes",
        "description": "A dataset of abstract scenes made from clipart for visual question answering.",
        "domain": "Computer Vision",
        "year": 2016,
        "creators": [
          "Zhang, P.",
          "Goyal, Y.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "VQA_Accuracy",
        "entity_type": "Metric",
        "name": "VQA Accuracy",
        "description": "Accuracy metric used in Visual Question Answering tasks.",
        "category": "Visual Question Answering Evaluation",
        "formula": "Number of correct answers / Total number of questions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhang2016_Yin_and_Yang",
        "entity_type": "Algorithm",
        "name": "Yin and Yang",
        "title": "Yin and Yang: Balancing and Answering Binary Visual Questions",
        "year": 2016,
        "authors": [
          "Zhang, P.",
          "Goyal, Y.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA Abstract Scenes"
        ],
        "metrics": [
          "VQA Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary Question Handling",
            "Clipart Scene Editing"
          ],
          "connections": [
            "Question-Image Pairing"
          ],
          "mechanisms": [
            "Answer Change Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Human Annotation"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Clipart Scene Modification"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_at_5",
        "entity_type": "Metric",
        "name": "Recall@5",
        "description": "Recall at top-5 ranked items.",
        "category": "Ranking Evaluation",
        "formula": "Number of relevant items in top-5 / Total number of relevant items"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goyal2017_Deep_LSTM_Question_plus_norm_Image",
        "entity_type": "Algorithm",
        "name": "Deeper LSTM Question+ norm Image",
        "year": 2017,
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "VQA_Accuracy"
        ],
        "architecture": {
          "components": [
            "CNN embedding",
            "LSTM embedding",
            "point-wise multiplication",
            "multi-layer perceptron classifier"
          ],
          "connections": [
            "image embedding -> point-wise multiplication",
            "question embedding -> point-wise multiplication",
            "point-wise multiplication -> MLP classifier"
          ],
          "mechanisms": [
            "embedding fusion",
            "classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "CNN feature extraction",
          "LSTM sequence modeling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goyal2017_Hierarchical_Co_attention",
        "entity_type": "Algorithm",
        "name": "Hierarchical Co-attention",
        "year": 2017,
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "VQA_Accuracy"
        ],
        "architecture": {
          "components": [
            "word-level co-attention",
            "phrase-level co-attention",
            "question-level co-attention"
          ],
          "connections": [
            "word-level -> phrase-level",
            "phrase-level -> question-level",
            "co-attention -> answer prediction"
          ],
          "mechanisms": [
            "multi-level co-attention",
            "answer prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image feature extraction",
          "question feature extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goyal2017_Multimodal_Compact_Bilinear_Pooling",
        "entity_type": "Algorithm",
        "name": "Multimodal Compact Bilinear Pooling",
        "year": 2017,
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "VQA_Accuracy"
        ],
        "architecture": {
          "components": [
            "multimodal compact bilinear pooling",
            "fully-connected layer"
          ],
          "connections": [
            "image features -> bilinear pooling",
            "language features -> bilinear pooling",
            "bilinear pooling -> fully-connected layer"
          ],
          "mechanisms": [
            "bilinear pooling",
            "answer prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image feature extraction",
          "language feature extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goyal2017_Language_only",
        "entity_type": "Algorithm",
        "name": "Language-only",
        "year": 2017,
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "VQA_Accuracy"
        ],
        "architecture": {
          "components": [
            "LSTM embedding",
            "multi-layer perceptron classifier"
          ],
          "connections": [
            "question embedding -> MLP classifier"
          ],
          "mechanisms": [
            "language modeling",
            "classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "LSTM sequence modeling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goyal2017_Counter_example_explanation_model",
        "entity_type": "Algorithm",
        "name": "Counter-example Explanation Model",
        "year": 2017,
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Recall_at_5"
        ],
        "architecture": {
          "components": [
            "Shared Base",
            "Answering Head",
            "Explaining Head"
          ],
          "connections": [
            "Joint QI Embedding",
            "Fully Connected Layer",
            "Softmax",
            "Inner Product"
          ],
          "mechanisms": [
            "Point-wise Multiplication",
            "Pairwise Hinge Ranking Loss",
            "Cross-Entropy Loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Pairwise Hinge Ranking Loss"
          ],
          "parameter_tuning": [
            "Hyperparameter M",
            "Trade-off Weight Parameter λ"
          ]
        },
        "feature_processing": [
          "Image CNN Embedding",
          "Question LSTM Embedding"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_Hinge_Ranking_Loss",
        "entity_type": "Metric",
        "name": "Pairwise Hinge Ranking Loss",
        "description": "Loss function that encourages the score of the human-picked image to be higher than all other candidate images by a desired margin.",
        "category": "Ranking Evaluation",
        "formula": "max(0, M - (S(I′) - S(Ii)))"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Cross_Entropy_Loss",
        "entity_type": "Metric",
        "name": "Cross-Entropy Loss",
        "description": "Loss function used for training the answering module.",
        "category": "Classification Evaluation",
        "formula": "-log P(A|I, Q)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_KNOWLEDGE",
        "entity_type": "Algorithm",
        "name": "KNOWLEDGE",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": 2018,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl",
          "Perturb",
          "Aggregate"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Transfer",
            "Dimensional Analysis",
            "Part-Whole Relation",
            "Explicit Math"
          ],
          "connections": [
            "Concept prediction",
            "Declarative rule selection"
          ],
          "mechanisms": [
            "Latent variable modeling",
            "Beam search inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-stage learning",
            "Latent structured SVM"
          ],
          "parameter_tuning": [
            "Weight vectors for concept and rule selection"
          ]
        },
        "feature_processing": [
          "Dependency parsing",
          "Coreference resolution",
          "Verb classification",
          "Rate component detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArith_2017",
        "entity_type": "Dataset",
        "name": "AllArith",
        "description": "Arithmetic word problem dataset",
        "domain": "Natural Language Processing",
        "size": 831,
        "year": 2017,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithLex_2017",
        "entity_type": "Dataset",
        "name": "AllArithLex",
        "description": "Subset of AllArith for testing robustness to new vocabulary",
        "domain": "Natural Language Processing",
        "size": 756,
        "year": 2017,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithTmpl_2017",
        "entity_type": "Dataset",
        "name": "AllArithTmpl",
        "description": "Subset of AllArith for testing robustness to new equation forms",
        "domain": "Natural Language Processing",
        "size": 756,
        "year": 2017,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Perturb_2018",
        "entity_type": "Dataset",
        "name": "Perturb",
        "description": "New dataset created by perturbing original problems",
        "domain": "Natural Language Processing",
        "size": 661,
        "year": 2018,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Aggregate_2018",
        "entity_type": "Dataset",
        "name": "Aggregate",
        "description": "Combined dataset of AllArith and Perturb",
        "domain": "Natural Language Processing",
        "size": 1492,
        "year": 2018,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TemplateBasedSolver",
        "entity_type": "Algorithm",
        "name": "Template Based Solver",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Zettlemoyer, L.",
          "Barzilay, R.",
          "Artzi, Y."
        ],
        "task": "Solving algebra word problems",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Templates"
          ],
          "connections": [
            "Template matching"
          ],
          "mechanisms": [
            "Pattern recognition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Template-based learning"
          ],
          "parameter_tuning": [
            "Template parameters"
          ]
        },
        "feature_processing": [
          "Template extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_LCA",
        "entity_type": "Algorithm",
        "name": "Lowest Common Ancestors (LCA)",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "Arithmetic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Math expression trees"
          ],
          "connections": [
            "Tree traversal"
          ],
          "mechanisms": [
            "Lowest common ancestor finding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Tree-based learning"
          ],
          "parameter_tuning": [
            "Tree parameters"
          ]
        },
        "feature_processing": [
          "Tree structure extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_UNITDEP",
        "entity_type": "Algorithm",
        "name": "Unit Dependency Graph",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "Arithmetic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Unit dependency graph"
          ],
          "connections": [
            "Graph connections"
          ],
          "mechanisms": [
            "Dependency analysis"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Graph-based learning"
          ],
          "parameter_tuning": [
            "Graph parameters"
          ]
        },
        "feature_processing": [
          "Unit extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_FormulaAlignment",
        "entity_type": "Algorithm",
        "name": "Formula Alignment",
        "year": 2016,
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "Arithmetic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Formulas"
          ],
          "connections": [
            "Formula alignment"
          ],
          "mechanisms": [
            "Formula mapping"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Formula-based learning"
          ],
          "parameter_tuning": [
            "Formula parameters"
          ]
        },
        "feature_processing": [
          "Formula extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KoncelKedziorski2015_SingleEquation",
        "entity_type": "Algorithm",
        "name": "Single Equation Solver",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S."
        ],
        "task": "Solving algebra word problems",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Equations"
          ],
          "connections": [
            "Equation solving"
          ],
          "mechanisms": [
            "Single equation generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Equation-based learning"
          ],
          "parameter_tuning": [
            "Equation parameters"
          ]
        },
        "feature_processing": [
          "Equation extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shi2015_NumberWordProblems",
        "entity_type": "Algorithm",
        "name": "Number Word Problem Solver",
        "year": 2015,
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "Solving number word problems",
        "dataset": [
          "Number word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Semantic parsing",
            "Reasoning"
          ],
          "connections": [
            "Parsing and reasoning"
          ],
          "mechanisms": [
            "Semantic analysis"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Semantic-based learning"
          ],
          "parameter_tuning": [
            "Semantic parameters"
          ]
        },
        "feature_processing": [
          "Semantic feature extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TemplateBasedAlgebra",
        "entity_type": "Algorithm",
        "name": "Template Based Algebra Solver",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Zettlemoyer, L.",
          "Barzilay, R.",
          "Artzi, Y."
        ],
        "task": "Solving algebra word problems",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Templates"
          ],
          "connections": [
            "Template matching"
          ],
          "mechanisms": [
            "Pattern recognition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Template-based learning"
          ],
          "parameter_tuning": [
            "Template parameters"
          ]
        },
        "feature_processing": [
          "Template extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_QuadraticProgramming",
        "entity_type": "Algorithm",
        "name": "Quadratic Programming Solver",
        "year": 2015,
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "Solving algebra word problems",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quadratic programming"
          ],
          "connections": [
            "Optimization"
          ],
          "mechanisms": [
            "Quadratic optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization-based learning"
          ],
          "parameter_tuning": [
            "Optimization parameters"
          ]
        },
        "feature_processing": [
          "Optimization feature extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Upadhyay2016_JointLearning",
        "entity_type": "Algorithm",
        "name": "Joint Learning",
        "year": 2016,
        "authors": [
          "Upadhyay, S.",
          "Chang, M.W.",
          "Chang, K.W.",
          "Yih, W.T."
        ],
        "task": "Solving algebra word problems",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Explicit and implicit supervision"
          ],
          "connections": [
            "Joint learning"
          ],
          "mechanisms": [
            "Supervision integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint learning"
          ],
          "parameter_tuning": [
            "Joint learning parameters"
          ]
        },
        "feature_processing": [
          "Supervision feature extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_TransferConcept",
        "entity_type": "Algorithm",
        "name": "Transfer Concept",
        "year": 2018,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "Perturb_2018",
          "Aggregate_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Verb Classification",
            "Coreference Resolution"
          ],
          "connections": [
            "Verb to Operation Mapping",
            "Coreference to Operation Mapping"
          ],
          "mechanisms": [
            "Verb-based Inference",
            "Coreference-based Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Modeling"
          ],
          "parameter_tuning": [
            "Verb Similarity Threshold",
            "Coreference Similarity Score"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Verb Classification",
          "Coreference Resolution"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_DimensionalAnalysis",
        "entity_type": "Algorithm",
        "name": "Dimensional Analysis",
        "year": 2018,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "Perturb_2018",
          "Aggregate_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Unit Extraction",
            "Rate Component Detection"
          ],
          "connections": [
            "Unit to Operation Mapping",
            "Rate Component to Operation Mapping"
          ],
          "mechanisms": [
            "Unit Compatibility Check",
            "Rate Component Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Modeling"
          ],
          "parameter_tuning": [
            "Unit Compatibility Threshold",
            "Rate Component Detection Accuracy"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Unit Extraction",
          "Rate Component Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_PartWholeRelation",
        "entity_type": "Algorithm",
        "name": "Part-Whole Relation",
        "year": 2018,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "Perturb_2018",
          "Aggregate_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Hyponym Detection",
            "Hypernym Detection",
            "Sibling Detection"
          ],
          "connections": [
            "Hyponym to Operation Mapping",
            "Hypernym to Operation Mapping",
            "Sibling to Operation Mapping"
          ],
          "mechanisms": [
            "Hyponymy-based Inference",
            "Hypernymy-based Inference",
            "Sibling-based Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Modeling"
          ],
          "parameter_tuning": [
            "Hyponym Detection Accuracy",
            "Hypernym Detection Accuracy",
            "Sibling Detection Accuracy"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Hyponym Detection",
          "Hypernym Detection",
          "Sibling Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_ExplicitMath",
        "entity_type": "Algorithm",
        "name": "Explicit Math",
        "year": 2018,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "Perturb_2018",
          "Aggregate_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Math Term Detection",
            "Explicit Math Pattern Recognition"
          ],
          "connections": [
            "Math Term to Operation Mapping",
            "Pattern to Operation Mapping"
          ],
          "mechanisms": [
            "Math Term-based Inference",
            "Pattern-based Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Modeling"
          ],
          "parameter_tuning": [
            "Math Term Detection Accuracy",
            "Pattern Recognition Accuracy"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Math Term Detection",
          "Pattern Recognition"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_DeclarativeKnowledgeMapping",
        "entity_type": "Algorithm",
        "name": "Declarative Knowledge Mapping",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": 2018,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith",
          "Perturb",
          "Aggregate"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Concept Selection",
            "Declarative Rule Selection"
          ],
          "connections": [
            "Concept to Operation",
            "Rule to Operation"
          ],
          "mechanisms": [
            "Latent Variable Modeling",
            "Feature Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-stage Learning",
            "Latent Structured SVM"
          ],
          "parameter_tuning": [
            "Weight Vectors",
            "Regularization Parameter C"
          ]
        },
        "feature_processing": [
          "Dependency Parse Labels",
          "Coreference Resolution",
          "Verb Classification"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Hosseini2014_AdditionSubtraction",
        "entity_type": "Dataset",
        "name": "Addition Subtraction Problems",
        "description": "Dataset for addition and subtraction word problems",
        "domain": "Arithmetic Word Problem Solving",
        "year": 2014,
        "creators": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_MathDQN",
        "entity_type": "Algorithm",
        "name": "MathDQN",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Solving Arithmetic Word Problems",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015",
          "ArithS",
          "ArithM"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Deep Q-Network",
            "Feed-forward Neural Network"
          ],
          "connections": [
            "State Representation",
            "Action Selection",
            "Reward Function"
          ],
          "mechanisms": [
            "Reinforcement Learning",
            "Experience Replay",
            "ε-greedy Strategy"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Q-Learning",
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Discount Factor",
            "Replay Memory Size"
          ]
        },
        "feature_processing": [
          "Quantity Schema",
          "Verb Categorization",
          "Unit Dependency Graph"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AI2_2014",
        "entity_type": "Dataset",
        "name": "AI2",
        "description": "Single-step or multi-step arithmetic word problems involving only addition and subtraction",
        "domain": "Arithmetic Word Problems",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IL_2015",
        "entity_type": "Dataset",
        "name": "IL",
        "description": "Single-step word problems with one operator, including addition, subtraction, multiplication, and division",
        "domain": "Arithmetic Word Problems",
        "size": 562,
        "year": 2015,
        "creators": [
          "Roy, Vieira, and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CC_2015",
        "entity_type": "Dataset",
        "name": "CC",
        "description": "Multi-step problems without irrelevant quantities, involving combinations of four types of operators",
        "domain": "Arithmetic Word Problems",
        "size": 600,
        "year": 2015,
        "creators": [
          "Roy and Roth"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Arithmetic",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Arithmetic problem solving precision",
        "category": "Arithmetic Evaluation",
        "formula": "True positives / (True positives + False positives)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_Formula",
        "entity_type": "Algorithm",
        "name": "Formula",
        "year": 2016,
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2_2014"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Template-Based Method",
            "Predefined Formulas"
          ],
          "connections": [
            "Mapping Identified Variables",
            "Attributes to Formulas"
          ],
          "mechanisms": [
            "Rule-Based Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based System"
          ],
          "parameter_tuning": [
            "Formula Definition"
          ]
        },
        "feature_processing": [
          "Variable Identification",
          "Attribute Mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_TagBased",
        "entity_type": "Algorithm",
        "name": "Tag-Based Approach",
        "year": 2016,
        "authors": [
          "Liang, C.",
          "Hsu, K.",
          "Huang, C.",
          "Li, C.",
          "Miao, S.",
          "Su, K."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2_2014"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Tag Rules",
            "Logic Forms"
          ],
          "connections": [
            "Converting Variables",
            "Values to Logic Statements"
          ],
          "mechanisms": [
            "Inference Techniques"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based System"
          ],
          "parameter_tuning": [
            "Tag Annotation",
            "Rule Generation"
          ]
        },
        "feature_processing": [
          "Tag Annotation",
          "Rule Generation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_ExpressionTree",
        "entity_type": "Algorithm",
        "name": "Expression Tree",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Classifiers"
          ],
          "connections": [
            "Quantity Relevance Prediction",
            "Operator Classification"
          ],
          "mechanisms": [
            "Scoring Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Classifier Training"
          ]
        },
        "feature_processing": [
          "Quantity Identification",
          "Operator Selection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KoncelKedziorski2015_EnumerateTrees",
        "entity_type": "Algorithm",
        "name": "Enumerate Trees",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming",
            "Candidate Trees"
          ],
          "connections": [
            "Enumerating Possible Equation Trees",
            "Ranking Candidate Trees"
          ],
          "mechanisms": [
            "Scoring Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Scoring Function Parameters"
          ]
        },
        "feature_processing": [
          "Equation Tree Enumeration",
          "Candidate Tree Ranking"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_UnitDep",
        "entity_type": "Algorithm",
        "name": "Unit Dependency Graphs (UDGs)",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Unit Dependency Graphs",
            "Scoring Factor"
          ],
          "connections": [
            "Capturing Units Consistency",
            "Reasoning About Units"
          ],
          "mechanisms": [
            "Enhanced Scoring Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Unit Dependency Graph Construction"
          ]
        },
        "feature_processing": [
          "Unit Consistency Checking",
          "Rate Unit Handling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TemplateBased",
        "entity_type": "Algorithm",
        "name": "Template-Based Solution",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Zettlemoyer, L.",
          "Barzilay, R.",
          "Artzi, Y."
        ],
        "task": "Equation Set Problem Solving",
        "dataset": [
          "Dolphin_2016"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Predefined Templates",
            "Unknown Slots"
          ],
          "connections": [
            "Finding Matching Template",
            "Inferring Unknown Slots"
          ],
          "mechanisms": [
            "Template Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based System"
          ],
          "parameter_tuning": [
            "Template Definition"
          ]
        },
        "feature_processing": [
          "Template Matching",
          "Slot Inference"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_StructuredOutput",
        "entity_type": "Algorithm",
        "name": "Structured-Output Learning Framework",
        "year": 2015,
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "Equation Set Problem Solving",
        "dataset": [
          "Dolphin_2016"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Structured-Output Learning",
            "Explicit and Implicit Signals"
          ],
          "connections": [
            "Joint Learning of Signals"
          ],
          "mechanisms": [
            "Signal Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Signal Learning Parameters"
          ]
        },
        "feature_processing": [
          "Signal Extraction",
          "Joint Learning"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin_2016",
        "entity_type": "Dataset",
        "name": "Dolphin",
        "year": 2016,
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.",
          "Yin, J.",
          "Ma, W."
        ],
        "domain": "Arithmetic Word Problems",
        "description": "Harvested from community question-answering web pages",
        "size": "Large and diverse"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_ReorderMechanism",
        "entity_type": "Algorithm",
        "name": "Reorder Mechanism",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Precision",
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quantity Schema",
            "Reorder Mechanism",
            "Expression Tree"
          ],
          "connections": [
            "Quantity Sorting",
            "Tree Construction"
          ],
          "mechanisms": [
            "Rate Unit Detection",
            "Priority Assignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Reinforcement Learning",
            "Two-layer Feed-forward Neural Network"
          ],
          "parameter_tuning": [
            "Discount Factor",
            "Learning Rate",
            "Mini-batch Size"
          ]
        },
        "feature_processing": [
          "Verb Categorization",
          "Rate Unit Detection",
          "Context Feature Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_DeepReinforcementLearningFramework",
        "entity_type": "Algorithm",
        "name": "Deep Reinforcement Learning Framework",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Precision",
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "State Representation",
            "Action Selection",
            "Reward Function"
          ],
          "connections": [
            "State Transition",
            "Policy Update"
          ],
          "mechanisms": [
            "Q-Learning",
            "Experience Replay"
          ]
        },
        "methodology": {
          "training_strategy": [
            "ε-greedy Strategy",
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Discount Factor",
            "Learning Rate",
            "Mini-batch Size"
          ]
        },
        "feature_processing": [
          "Quantity Schema Features",
          "Pair Features",
          "Question Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ArithS_2018",
        "entity_type": "Dataset",
        "name": "ArithS",
        "description": "Subset of AI2, IL, and CC containing single-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 890,
        "year": 2018,
        "creators": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ArithM_2018",
        "entity_type": "Dataset",
        "name": "ArithM",
        "description": "Collected from AI2, IL, and CC containing multi-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 667,
        "year": 2018,
        "creators": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_MathDQNReorder",
        "entity_type": "Algorithm",
        "name": "MathDQN-Reorder",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Precision"
        ],
        "architecture": {
          "components": [
            "Deep Q-Network",
            "Re-order Mechanism"
          ],
          "connections": [
            "State Representation",
            "Action Selection",
            "Reward Function"
          ],
          "mechanisms": [
            "Reinforcement Learning",
            "Deep Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "ε-greedy Strategy",
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Discount Factor",
            "Replay Memory Size"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Feature Concatenation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_M1",
        "entity_type": "Algorithm",
        "name": "M1",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2",
          "CC"
        ],
        "metrics": [
          "Precision"
        ],
        "architecture": {
          "components": [
            "Two-layer Feed-forward Neural Network"
          ],
          "connections": [
            "State Representation",
            "Action Selection",
            "Reward Function"
          ],
          "mechanisms": [
            "Sarsa",
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "ε-greedy Strategy",
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Discount Factor",
            "Replay Memory Size"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Feature Concatenation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_M2",
        "entity_type": "Algorithm",
        "name": "M2",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2",
          "CC"
        ],
        "metrics": [
          "Precision"
        ],
        "architecture": {
          "components": [
            "Two-layer Feed-forward Neural Network"
          ],
          "connections": [
            "Feature Extraction",
            "Operator Classification"
          ],
          "mechanisms": [
            "Neural Network Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden Layer Dimensions"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Feature Concatenation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_ErrorAnalysis",
        "entity_type": "Algorithm",
        "name": "Error Analysis Framework",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Accuracy",
          "Precision"
        ],
        "architecture": {
          "components": [
            "Error Identification Module",
            "Reason Analysis Module"
          ],
          "connections": [
            "Error Identification -> Reason Analysis"
          ],
          "mechanisms": [
            "Missing Quantities Detection",
            "Relevance Classifier Evaluation",
            "Feature Limitation Analysis",
            "State Representation Evaluation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Exploration vs Exploitation"
          ],
          "parameter_tuning": [
            "ε-greedy Strategy"
          ]
        },
        "feature_processing": [
          "Quantity Schema Analysis",
          "Context Feature Extraction"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorRate_Analysis",
        "entity_type": "Metric",
        "name": "Error Rate",
        "description": "Percentage of incorrectly solved problems",
        "category": "Error Analysis",
        "formula": "Number of Incorrect Solutions / Total Number of Problems"
      }
    },
    {
      "metric_entity": {
        "metric_id": "RelevanceClassifierAccuracy",
        "entity_type": "Metric",
        "name": "Relevance Classifier Accuracy",
        "description": "Accuracy of identifying relevant quantities",
        "category": "Classification",
        "formula": "Correctly Identified Relevant Quantities / Total Identified Quantities"
      }
    },
    {
      "metric_entity": {
        "metric_id": "FeatureEffectivenessScore",
        "entity_type": "Metric",
        "name": "Feature Effectiveness Score",
        "description": "Effectiveness of crafted features in classification tasks",
        "category": "Feature Evaluation",
        "formula": "Performance Improvement Due to Features"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2016_MultiTaskSeq2Seq",
        "entity_type": "Algorithm",
        "name": "Multi-task sequence to sequence learning",
        "year": 2016,
        "authors": [
          "Minh-Thang Luong",
          "Quoc V. Le",
          "Ilya Sutskever",
          "Oriol Vinyals",
          "Lukasz Kaiser"
        ],
        "task": "multi-task learning",
        "dataset": [
          "WMT'15 English-German translation",
          "Penn Tree Bank parsing",
          "High-confidence parsing corpus",
          "image caption generation"
        ],
        "metrics": [
          "BLEU",
          "F1",
          "perplexity"
        ],
        "architecture": {
          "components": [
            "encoder",
            "decoder"
          ],
          "connections": [
            "recurrent connections",
            "embeddings"
          ],
          "mechanisms": [
            "attention mechanism",
            "autoencoder",
            "skip-thought vectors"
          ]
        },
        "methodology": {
          "training_strategy": [
            "one-to-many setting",
            "many-to-one setting",
            "many-to-many setting"
          ],
          "parameter_tuning": [
            "mixing ratio",
            "learning rate halving"
          ]
        },
        "feature_processing": [
          "input sequence reversal",
          "dropout"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT15_EnglishGermanTranslation_2015",
        "entity_type": "Dataset",
        "name": "WMT'15 English-German translation",
        "description": "Parallel corpus for English-German translation",
        "domain": "machine translation",
        "size": 4500000,
        "year": 2015,
        "creators": [
          "Bojar, Ondřej",
          "Chatterjee, Rajen",
          "Federmann, Christian",
          "Haddow, Barry",
          "Huck, Matthias",
          "Hokamp, Chris",
          "Koehn, Philipp",
          "Logacheva, Varvara",
          "Monz, Christof",
          "Negri, Matteo",
          "Post, Matt",
          "Scarton, Carolina",
          "Specia, Lucia",
          "Turchi, Marco"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreeBankParsing_1993",
        "entity_type": "Dataset",
        "name": "Penn Tree Bank parsing",
        "description": "Corpus for syntactic parsing",
        "domain": "constituency parsing",
        "size": 40000,
        "year": 1993,
        "creators": [
          "Marcus, Mitchell P.",
          "Marcinkiewicz, Mary Ann",
          "Santorini, Beatrice"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "HighConfidenceParsingCorpus_2015",
        "entity_type": "Dataset",
        "name": "High-confidence parsing corpus",
        "description": "Large corpus for syntactic parsing",
        "domain": "constituency parsing",
        "size": 11000000,
        "year": 2015,
        "creators": [
          "Vinyals, Oriol",
          "Kaiser, Lukasz",
          "Koo, Terry",
          "Petrov, Slav",
          "Sutskever, Ilya",
          "Hinton, Geoffrey"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ImageCaptionGeneration_2015",
        "entity_type": "Dataset",
        "name": "image caption generation",
        "description": "Dataset of image and caption pairs",
        "domain": "image captioning",
        "size": 596000,
        "year": 2015,
        "creators": [
          "Vinyals, Oriol",
          "Toshev, Alexander",
          "Bengio, Samy",
          "Erhan, Dumitru"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Parsing",
        "entity_type": "Metric",
        "name": "F1",
        "description": "Evaluation metric for parsing",
        "category": "parsing evaluation",
        "formula": "2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Perplexity_LanguageModeling",
        "entity_type": "Metric",
        "name": "perplexity",
        "description": "Evaluation metric for language modeling",
        "category": "language modeling evaluation",
        "formula": "exp(-1/N * sum(log p(x_i))"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_Seq2Seq",
        "entity_type": "Algorithm",
        "name": "Sequence to Sequence Learning",
        "year": 2014,
        "authors": [
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Le, Quoc V."
        ],
        "task": "Sequence Modeling",
        "dataset": [
          "WMT'15 English-German Translation",
          "Penn Tree Bank Parsing",
          "High-Confidence Parsing Corpus",
          "Image Caption Generation"
        ],
        "metrics": [
          "BLEU",
          "F1",
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks",
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Conditional Probability Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Parameter Updates Allocation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Mini-Batch Size",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Input Sequence Reversal"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bahdanau2015_AttentionMechanism",
        "entity_type": "Algorithm",
        "name": "Attention Mechanism",
        "year": 2015,
        "authors": [
          "Bahdanau, Dzmitry",
          "Cho, Kyunghyun",
          "Bengio, Yoshua"
        ],
        "task": "Sequence Modeling",
        "dataset": [
          "WMT'15 English-German Translation",
          "Penn Tree Bank Parsing"
        ],
        "metrics": [
          "BLEU",
          "F1",
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Attention Layer"
          ],
          "connections": [
            "Encoder Hidden States",
            "Decoder Attention Weights"
          ],
          "mechanisms": [
            "Alignment Weights Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Mini-Batch Size"
          ]
        },
        "feature_processing": [
          "Context Vector Computation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Dai2015_Autoencoder",
        "entity_type": "Algorithm",
        "name": "Autoencoder",
        "year": 2015,
        "authors": [
          "Dai, Andrew M.",
          "Le, Quoc V."
        ],
        "task": "Unsupervised Learning",
        "dataset": [
          "Monolingual Corpora"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks"
          ],
          "mechanisms": [
            "Reconstruction Loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pretraining",
            "Joint Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Mini-Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kiros2015_SkipThoughtVectors",
        "entity_type": "Algorithm",
        "name": "Skip-Thought Vectors",
        "year": 2015,
        "authors": [
          "Kiros, Ryan",
          "Zhu, Yukun",
          "Salakhutdinov, Ruslan",
          "Zemel, Richard S.",
          "Torralba, Antonio",
          "Urtasun, Raquel",
          "Fidler, Sanja"
        ],
        "task": "Unsupervised Learning",
        "dataset": [
          "Monolingual Corpora"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks"
          ],
          "mechanisms": [
            "Sentence Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Mini-Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MonolingualCorpora_2015",
        "entity_type": "Dataset",
        "name": "Monolingual Corpora",
        "year": 2015,
        "creators": [
          "WMT'15 Contributors"
        ],
        "domain": "Natural Language Processing",
        "size": "Large",
        "description": "Monolingual corpora used for unsupervised learning tasks."
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2016_OneToManySetting",
        "entity_type": "Algorithm",
        "name": "One-to-Many Setting",
        "year": 2016,
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "Multi-task Sequence-to-Sequence Learning",
        "dataset": [
          "WMT15_EnglishGermanTranslation_2015",
          "PennTreeBankParsing_1993"
        ],
        "metrics": [
          "BLEU_Translation",
          "F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Multiple Decoders"
          ],
          "connections": [
            "Shared Encoder",
            "Separate Decoders"
          ],
          "mechanisms": [
            "Parameter Sharing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Mixing Ratios"
          ],
          "parameter_tuning": [
            "Mixing Coefficients"
          ]
        },
        "feature_processing": [
          "Sequence Processing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2016_ManyToOneSetting",
        "entity_type": "Algorithm",
        "name": "Many-to-One Setting",
        "year": 2016,
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "Multi-task Sequence-to-Sequence Learning",
        "dataset": [
          "WMT15_EnglishGermanTranslation_2015",
          "ImageCaptionGeneration_2015"
        ],
        "metrics": [
          "BLEU_Translation",
          "Perplexity_LanguageModeling"
        ],
        "architecture": {
          "components": [
            "Multiple Encoders",
            "Single Decoder"
          ],
          "connections": [
            "Shared Decoder",
            "Separate Encoders"
          ],
          "mechanisms": [
            "Parameter Sharing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Mixing Ratios"
          ],
          "parameter_tuning": [
            "Mixing Coefficients"
          ]
        },
        "feature_processing": [
          "Sequence Processing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2016_ManyToManySetting",
        "entity_type": "Algorithm",
        "name": "Many-to-Many Setting",
        "year": 2016,
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "Multi-task Sequence-to-Sequence Learning",
        "dataset": [
          "WMT15_EnglishGermanTranslation_2015",
          "MonolingualCorpora_2015"
        ],
        "metrics": [
          "BLEU_Translation",
          "Perplexity_LanguageModeling"
        ],
        "architecture": {
          "components": [
            "Multiple Encoders",
            "Multiple Decoders"
          ],
          "connections": [
            "Shared Encoders and Decoders"
          ],
          "mechanisms": [
            "Parameter Sharing",
            "Unsupervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Mixing Ratios"
          ],
          "parameter_tuning": [
            "Mixing Coefficients"
          ]
        },
        "feature_processing": [
          "Sequence Processing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2016_AttentionFreeSeq2Seq",
        "entity_type": "Algorithm",
        "name": "Attention-Free Sequence to Sequence Model",
        "year": 2016,
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "Sequence to Sequence Learning",
        "dataset": [
          "WMT'15 English-German Translation",
          "Penn Tree Bank Parsing",
          "High-Confidence Parsing Corpus"
        ],
        "metrics": [
          "BLEU",
          "F1",
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks"
          ],
          "mechanisms": [
            "No Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Multi-task Learning"
          ],
          "parameter_tuning": [
            "Mixing Ratios"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_TranslationQuality",
        "entity_type": "Metric",
        "name": "BLEU",
        "description": "Bilingual Evaluation Understudy",
        "category": "Translation Quality",
        "formula": "Exponential average of precision scores"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_ConstituentParsing",
        "entity_type": "Metric",
        "name": "F1",
        "description": "F1 Score",
        "category": "Constituent Parsing",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sundaram2015_SimpleWordProblemSolver",
        "entity_type": "Algorithm",
        "name": "Simple Word Problem Solver",
        "title": "Natural Language Processing for Solving Simple Word Problems",
        "year": 2015,
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Knowledge Representation",
            "Temporal Schemas",
            "Common Sense Law of Inertia"
          ],
          "connections": [
            "Schemas",
            "Temporal Ordering",
            "Heuristics"
          ],
          "mechanisms": [
            "Transfer-In-Ownership",
            "Change-Out",
            "Combine",
            "Compare Plus",
            "Compare Minus",
            "Increase",
            "Reduction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge-based NLP",
            "Pre-stored routines"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Stanford CoreNLP Suite",
          "Conjunction resolution",
          "Co-reference resolution",
          "Entity resolution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DS1_2014",
        "entity_type": "Dataset",
        "name": "DS1",
        "description": "Dataset with simple arithmetic word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DS2_2014",
        "entity_type": "Dataset",
        "name": "DS2",
        "description": "Dataset with arithmetic word problems containing irrelevant information",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DS3_2014",
        "entity_type": "Dataset",
        "name": "DS3",
        "description": "Dataset with complex arithmetic word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2007_ROBUST",
        "entity_type": "Algorithm",
        "name": "ROBUST",
        "year": 2007,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "Not specified"
        ],
        "metrics": [
          "Not specified"
        ],
        "architecture": {
          "components": [
            "Schemas",
            "Temporal reasoning"
          ],
          "connections": [
            "Keyword matching",
            "Schema application"
          ],
          "mechanisms": [
            "Transfer-In-Ownership",
            "Change-Out"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge-based"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Keyword extraction",
          "Sentence parsing"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Hosseini2014_Datasets",
        "entity_type": "Dataset",
        "name": "Hosseini et al. datasets",
        "year": 2014,
        "creators": [
          "Hosseini, M.J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "domain": "Arithmetic word problems",
        "size": "Not specified",
        "description": "Three datasets (DS1, DS2, DS3) with increasing difficulty in terms of natural language and irrelevant information."
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sundaram2015_SentenceSimplifier",
        "entity_type": "Algorithm",
        "name": "Sentence Simplifier",
        "year": 2015,
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Conjunction Resolver",
            "Currency Preprocessor",
            "Co-reference Resolver",
            "Entity Resolver"
          ],
          "connections": [
            "Simplification Phase -> Analysis Phase"
          ],
          "mechanisms": [
            "Dependency Parsing",
            "POS Tagging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Conjunction Resolution",
          "Currency Preprocessing",
          "Co-reference Resolution",
          "Entity Resolution"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sundaram2015_KnowledgeRepresentation",
        "entity_type": "Algorithm",
        "name": "Knowledge Representation",
        "year": 2015,
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Temporal Schemas",
            "Common Sense Law of Inertia"
          ],
          "connections": [
            "Information Extraction -> Knowledge Representation"
          ],
          "mechanisms": [
            "Temporal Ordering",
            "Variable Substitution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Temporal Ordering",
          "Default Assumptions",
          "Heuristics"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sundaram2015_TemporalSchemas",
        "entity_type": "Algorithm",
        "name": "Temporal Schemas",
        "year": 2015,
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "Solving Addition/Subtraction Word Problems",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Time Stamps",
            "Default Assumptions",
            "Heuristics"
          ],
          "connections": [
            "Temporal Ordering",
            "Event Matching"
          ],
          "mechanisms": [
            "Common Sense Law of Inertia"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge Representation"
          ],
          "parameter_tuning": [
            "Temporal Reasoning"
          ]
        },
        "feature_processing": [
          "Entity Resolution",
          "Temporal Event Handling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sundaram2015_SchemaBasedReasoning",
        "entity_type": "Algorithm",
        "name": "Schema-Based Reasoning",
        "year": 2015,
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "Solving Addition/Subtraction Word Problems",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Schemas",
            "Keyword Mapping"
          ],
          "connections": [
            "Schema Matching",
            "Event Update"
          ],
          "mechanisms": [
            "Change In",
            "Change Out",
            "Combine",
            "Compare Plus",
            "Compare Minus",
            "Increase",
            "Reduction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge Representation"
          ],
          "parameter_tuning": [
            "Schema Design"
          ]
        },
        "feature_processing": [
          "Keyword Extraction",
          "Entity Resolution"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sundaram2015_NaturalLanguageProcessor",
        "entity_type": "Algorithm",
        "name": "Natural Language Processor",
        "title": "Natural Language Processing for Solving Simple Word Problems",
        "year": 2015,
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "ErrorRate_Classification"
        ],
        "architecture": {
          "components": [
            "Stanford CoreNLP Suite",
            "Dependency Parser",
            "Co-reference Resolver"
          ],
          "connections": [
            "Simplification Phase",
            "Analysis Phase"
          ],
          "mechanisms": [
            "Conjunction Resolution",
            "Currency Preprocessing",
            "Co-reference Resolution",
            "Entity Resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based parsing",
            "Heuristic-based reasoning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Conjunction resolution",
          "Currency preprocessing",
          "Co-reference resolution",
          "Entity resolution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "StanfordCoreNLPSuite_2014",
        "entity_type": "Dataset",
        "name": "Stanford CoreNLP Suite",
        "description": "A set of tools for natural language processing",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Manning, C. D.",
          "Surdeanu, M.",
          "Bauer, J.",
          "Finkel, J.",
          "Bethard, S. J.",
          "McClosky, D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2018_CASS",
        "entity_type": "Algorithm",
        "name": "CASS",
        "title": "Neural Math Word Problem Solver with Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Danqing Huang",
          "Jing Liu",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514_2014",
          "NumWord_2015",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Solution_Accuracy"
        ],
        "architecture": {
          "components": [
            "Sequence-to-sequence model",
            "Copy mechanism",
            "Alignment mechanism"
          ],
          "connections": [
            "Encoder-decoder architecture",
            "Attention mechanism"
          ],
          "mechanisms": [
            "Copy and alignment",
            "Policy gradient reinforcement learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement learning",
            "Pre-training with maximum likelihood"
          ],
          "parameter_tuning": [
            "Hyper-parameter λ for supervised attention",
            "Learning rate decay",
            "Dropout rate"
          ]
        },
        "feature_processing": [
          "Number mapping",
          "Post-processing for number recovery"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NumWord_2015",
        "entity_type": "Dataset",
        "name": "NumWord",
        "description": "Contains 2,871 number word problems with 1,183 templates",
        "domain": "Mathematics",
        "size": 2871,
        "year": 2015,
        "creators": [
          "Shuming Shi",
          "Yuehui Wang",
          "Chin-Yew Lin",
          "Xiaojiang Liu",
          "Yong Rui"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Solution_Accuracy",
        "entity_type": "Metric",
        "name": "Solution Accuracy",
        "description": "Accuracy of the final solution to the math word problem",
        "category": "Mathematical problem solving",
        "formula": "Number of correctly solved problems / Total number of problems"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "T6_2018",
        "entity_type": "Dataset",
        "name": "T6",
        "description": "A subset setting representing problems for which the associated template appeared equal to or more than six times in the subset.",
        "domain": "Math Word Problems",
        "year": 2018,
        "creators": [
          "Huang, D.",
          "Liu, J.",
          "Lin, C.-Y.",
          "Yin, J."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Equation_Likelihood",
        "entity_type": "Metric",
        "name": "Equation Likelihood",
        "description": "The likelihood of generating a correct equation during training.",
        "category": "Training Evaluation",
        "formula": "Not explicitly defined in the paper."
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bahdanau2015_Seq2SeqWithAttention",
        "entity_type": "Algorithm",
        "name": "Seq2Seq with Attention",
        "year": 2015,
        "authors": [
          "Bahdanau, D.",
          "Cho, K.",
          "Bengio, Y."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Attention Mechanism"
          ],
          "connections": [
            "Bidirectional GRU",
            "Context Vector"
          ],
          "mechanisms": [
            "Attention Scores",
            "Softmax"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Number Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jia2016_CopyMechanism",
        "entity_type": "Algorithm",
        "name": "Copy Mechanism",
        "year": 2016,
        "authors": [
          "Jia, R.",
          "Liang, P."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Copy Mechanism",
            "Attention-Based Copy"
          ],
          "connections": [
            "Source Tokens",
            "Target Vocabulary"
          ],
          "mechanisms": [
            "Generation Probability",
            "Sigmoid Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Token Mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mi2016_AlignmentMechanism",
        "entity_type": "Algorithm",
        "name": "Alignment Mechanism",
        "year": 2016,
        "authors": [
          "Mi, H.",
          "Wang, Z.",
          "Ittycheriah, A."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Supervised Alignment",
            "Cross Entropy Loss"
          ],
          "connections": [
            "Source Tokens",
            "Target Tokens"
          ],
          "mechanisms": [
            "True Alignment",
            "Predicted Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Token Mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Williams1992_REINFORCE",
        "entity_type": "Algorithm",
        "name": "REINFORCE",
        "year": 1992,
        "authors": [
          "Williams, R.J."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Policy Gradient",
            "Reward Function"
          ],
          "connections": [
            "Action Space",
            "State Space"
          ],
          "mechanisms": [
            "Expected Reward",
            "Gradient Descent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Token Mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2018_FeatureBasedModel",
        "entity_type": "Algorithm",
        "name": "Feature-Based Model",
        "year": 2018,
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.-Y.",
          "Yin, J."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Retrieval",
            "Equation Ranking"
          ],
          "connections": [
            "Feature Vector Creation",
            "Learning to Rank"
          ],
          "mechanisms": [
            "Candidate Template Derivation",
            "Number Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Template Matching",
          "Equation Generation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2018_HybridModel",
        "entity_type": "Algorithm",
        "name": "Hybrid Model",
        "year": 2018,
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.-Y.",
          "Yin, J."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Neural Model",
            "Feature-Based Model"
          ],
          "connections": [
            "Neural Template Feature",
            "Neural Answer Feature"
          ],
          "mechanisms": [
            "Model Combination",
            "Feature Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Neural Output Incorporation",
          "Feature-Based Model Enhancement"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "LinearSubset_NumWord_2015",
        "entity_type": "Dataset",
        "name": "Linear Subset of NumWord",
        "year": 2015,
        "creators": [
          "Shi, S.",
          "Yuehui, W.",
          "Lin, C.-Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "domain": "Math Word Problems",
        "size": 986,
        "description": "A subset of the NumWord dataset containing linear problems."
      }
    },
    {
      "metric_entity": {
        "metric_id": "HitAtN_TemplateRetrieval",
        "entity_type": "Metric",
        "name": "Hit@N",
        "year": 2018,
        "category": "Template Retrieval Evaluation",
        "description": "Accuracy of retrieving the correct template within the top N candidates.",
        "formula": "Percentage of problems where the correct template is in the top N list"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2018_PolicyGradient",
        "entity_type": "Algorithm",
        "name": "Policy Gradient",
        "year": 2018,
        "authors": [
          "Danqing Huang",
          "Jing Liu",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Policy Network",
            "Reward Function"
          ],
          "connections": [
            "Input: Math Problem Description",
            "Output: Equation Tokens"
          ],
          "mechanisms": [
            "REINFORCE Algorithm",
            "Policy Gradient Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pre-training with MLE",
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Beam Size for Sampling"
          ]
        },
        "feature_processing": [
          "Equation Generation",
          "Number Alignment"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Reward_Function_TaskLevel",
        "entity_type": "Metric",
        "name": "Reward Function",
        "description": "A binary reward function that assigns +1 for correct solutions and -1 for incorrect or invalid equations.",
        "category": "Reinforcement Learning Evaluation",
        "formula": "R(xi, yi) = +1 if yi yields correct solution, -1 otherwise"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Gradient_Approximation",
        "entity_type": "Metric",
        "name": "Gradient Approximation",
        "description": "Approximation of the gradient using top-k equations in the beam to handle large search spaces.",
        "category": "Reinforcement Learning Training",
        "formula": "∇θLRL ≈ −∑i ∑yi pθ(yi|xi)R(xi, yi)∇θ log pθ(yi|xi)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Mixed_Objective_Function",
        "entity_type": "Metric",
        "name": "Mixed Objective Function",
        "description": "Combines the reinforcement learning loss with the alignment loss to improve number alignment.",
        "category": "Reinforcement Learning Training",
        "formula": "L = LRL + λ * δ(ai, âi)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_ALGES",
        "entity_type": "Algorithm",
        "name": "ALGES",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": 2015,
        "authors": [
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi",
          "Ashish Sabharwal",
          "Oren Etzioni",
          "Siena Dumas Ang"
        ],
        "task": "Solving algebraic word problems",
        "dataset": [
          "SINGLEEQ"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming (ILP)",
            "Local discriminative model",
            "Global discriminative model"
          ],
          "connections": [
            "Equation tree generation",
            "Equation tree scoring"
          ],
          "mechanisms": [
            "Type-consistent algebraic equations",
            "Bottom-up approach for learning correspondences between spans of text and arithmetic operators"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weakly supervised learning",
            "Using word problems and their correct answers as training data"
          ],
          "parameter_tuning": [
            "Learning local and global models from a small number of word problems and their solutions"
          ]
        },
        "feature_processing": [
          "Quantified Sets (Qsets)",
          "Dependency parse relations",
          "Semantic and intertextual relationships"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SINGLEEQ_2015",
        "entity_type": "Dataset",
        "name": "SINGLEEQ",
        "description": "Grade-school algebra word problems that map to single equations",
        "domain": "Natural Language Processing",
        "size": 508,
        "year": 2015,
        "creators": [
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi",
          "Ashish Sabharwal",
          "Oren Etzioni",
          "Siena Dumas Ang"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ADDSUB_2014",
        "entity_type": "Dataset",
        "name": "ADDSUB",
        "description": "Addition and subtraction word problems with irrelevant distractor quantities",
        "domain": "Elementary Mathematics",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorReduction_Performance",
        "entity_type": "Metric",
        "name": "Error Reduction",
        "description": "Percentage reduction in errors compared to baseline",
        "category": "Performance Evaluation",
        "formula": "((Baseline Errors - New Method Errors) / Baseline Errors) * 100%"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_ILP_EquationTreeGenerator",
        "entity_type": "Algorithm",
        "name": "ILP-based Equation Tree Generator",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "Algebraic Word Problem Solving",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming",
            "Equation Trees"
          ],
          "connections": [
            "Qset Extraction",
            "Equation Tree Generation"
          ],
          "mechanisms": [
            "Type Consistency",
            "Global Constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision",
            "Unannotated Data"
          ],
          "parameter_tuning": [
            "Max Stack Depth",
            "Number of Candidates"
          ]
        },
        "feature_processing": [
          "Qset Properties",
          "Semantic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_LocalQsetRelationshipModel",
        "entity_type": "Algorithm",
        "name": "Local Qset Relationship Model",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "Algebraic Word Problem Solving",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multi-class SVM",
            "Feature Vectors"
          ],
          "connections": [
            "Qset Pairs",
            "Math Operators"
          ],
          "mechanisms": [
            "Pairwise Relationships",
            "Semantic Features"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Feature Engineering"
          ],
          "parameter_tuning": [
            "RBF Kernel Parameters"
          ]
        },
        "feature_processing": [
          "Single Qset Features",
          "Relational Features",
          "Target Quantity Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_GlobalEquationModel",
        "entity_type": "Algorithm",
        "name": "Global Equation Model",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "Algebraic Word Problem Solving",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Discriminative Model",
            "Feature Vectors"
          ],
          "connections": [
            "Equation Trees",
            "Problem Text"
          ],
          "mechanisms": [
            "Soft Constraints",
            "Global Structure"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Feature Engineering"
          ],
          "parameter_tuning": [
            "Global Classifier Parameters"
          ]
        },
        "feature_processing": [
          "Soft Constraint Features",
          "Global Lexical Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_QsetReordering",
        "entity_type": "Algorithm",
        "name": "Qset Reordering",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "Algebraic Word Problem Solving",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Qset Reordering Rules"
          ],
          "connections": [
            "Container Match Rule",
            "Question Keywords Rule"
          ],
          "mechanisms": [
            "Semantic and Textual Information"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Semantic Properties",
          "Textual Properties"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_CombineFunction",
        "entity_type": "Algorithm",
        "name": "Combine Function",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "Algebraic Word Problem Solving",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Combine Function"
          ],
          "connections": [
            "Arithmetic Operators",
            "Qsets"
          ],
          "mechanisms": [
            "Recursive Combination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Qset Properties",
          "Arithmetic Operations"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_ILP_Optimization",
        "entity_type": "Algorithm",
        "name": "ILP Optimization",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "Algebraic Word Problem Solving",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming",
            "Postfix Notation",
            "Equation Tree Generation"
          ],
          "connections": [
            "Type Consistency",
            "Global Constraints",
            "Expression Complexity"
          ],
          "mechanisms": [
            "Constraint Satisfaction",
            "Soft Constraint Minimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision",
            "Type Consistency",
            "Global Structure"
          ],
          "parameter_tuning": [
            "Stack Depth Limits",
            "Soft Constraint Weights"
          ]
        },
        "feature_processing": [
          "Postfix Expression Encoding",
          "Symbol Type Assignment"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "TemplateOverlap_Performance",
        "entity_type": "Metric",
        "name": "Template Overlap",
        "description": "Average number of problems with the same template in a dataset",
        "category": "Template-based Evaluation",
        "formula": "Total number of problems with the same template / Number of unique templates"
      }
    },
    {
      "metric_entity": {
        "metric_id": "LexicalOverlap_Performance",
        "entity_type": "Metric",
        "name": "Lexical Overlap",
        "description": "Total number of content words in a dataset divided by the number of unique content words",
        "category": "Lexical-based Evaluation",
        "formula": "Total number of content words / Number of unique content words"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_CompositionalVectorGrammar",
        "entity_type": "Algorithm",
        "name": "Compositional Vector Grammar (CVG)",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "Syntactic Parsing",
        "dataset": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score",
          "Labeled F1"
        ],
        "architecture": {
          "components": [
            "Probabilistic Context-Free Grammar (PCFG)",
            "Recursive Neural Network (RNN)",
            "Syntactically Untied Recursive Neural Network (SU-RNN)"
          ],
          "connections": [
            "PCFG rules",
            "Continuous vector compositions"
          ],
          "mechanisms": [
            "Soft notion of head words",
            "Composition functions based on syntactic categories"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin training objective",
            "Two-stage training"
          ],
          "parameter_tuning": [
            "Regularization parameter λ",
            "AdaGrad learning rate α",
            "Mini-batch size"
          ]
        },
        "feature_processing": [
          "Distributional word vectors",
          "POS tags"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreebank_WSJ_2013",
        "entity_type": "Dataset",
        "name": "Penn Treebank WSJ",
        "year": 2013,
        "creators": [
          "Various contributors"
        ],
        "domain": "Natural Language Processing",
        "size": "Varies by section",
        "description": "A widely used dataset for syntactic parsing, containing Wall Street Journal articles."
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Parsing",
        "entity_type": "Metric",
        "name": "F1 Score",
        "category": "Parsing Evaluation",
        "description": "Harmonic mean of precision and recall, commonly used for evaluating parsing accuracy.",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Labeled_F1_Parsing",
        "entity_type": "Metric",
        "name": "Labeled F1",
        "category": "Parsing Evaluation",
        "description": "F1 score that considers the labels of the parse tree nodes.",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_SyntacticallyUntiedRecursiveNeuralNetwork",
        "entity_type": "Algorithm",
        "name": "Syntactically Untied Recursive Neural Network (SU-RNN)",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "Syntactic Parsing",
        "dataset": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score",
          "Labeled F1"
        ],
        "architecture": {
          "components": [
            "Recursive Neural Network",
            "Syntactically Untied Weights"
          ],
          "connections": [
            "Parent-child connections based on syntactic categories"
          ],
          "mechanisms": [
            "Composition function conditioned on syntactic categories"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin training objective",
            "Backpropagation through structure"
          ],
          "parameter_tuning": [
            "Subgradient methods",
            "AdaGrad"
          ]
        },
        "feature_processing": [
          "Word vector representations",
          "POS tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_StandardRecursiveNeuralNetwork",
        "entity_type": "Algorithm",
        "name": "Standard Recursive Neural Network (RNN)",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "Syntactic Parsing",
        "dataset": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score",
          "Labeled F1"
        ],
        "architecture": {
          "components": [
            "Recursive Neural Network"
          ],
          "connections": [
            "Fully tied weights across nodes"
          ],
          "mechanisms": [
            "Single composition function for all types of compositions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin training objective"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word vector representations"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WSJ_Section22_2013",
        "entity_type": "Dataset",
        "name": "WSJ Section 22",
        "year": 2013,
        "creators": [
          "Various contributors to the Penn Treebank"
        ],
        "domain": "Natural Language Processing",
        "size": 1700,
        "description": "Development set used for cross-validation and hyperparameter tuning"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WSJ_Section23_2013",
        "entity_type": "Dataset",
        "name": "WSJ Section 23",
        "year": 2013,
        "creators": [
          "Various contributors to the Penn Treebank"
        ],
        "domain": "Natural Language Processing",
        "size": "Not specified",
        "description": "Final test set used for evaluating the model"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Bracket_Error_Rate_Parsing",
        "entity_type": "Metric",
        "name": "Bracket Error Rate",
        "category": "Parsing Evaluation",
        "description": "Average number of bracket errors per sentence"
      }
    },
    {
      "metric_entity": {
        "metric_id": "PP_Attachment_Accuracy",
        "entity_type": "Metric",
        "name": "PP Attachment Accuracy",
        "category": "Parsing Evaluation",
        "description": "Accuracy of prepositional phrase attachment"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_MaxMarginTrainingObjective",
        "entity_type": "Algorithm",
        "name": "Max-Margin Training Objective",
        "year": 2013,
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing",
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Structured Margin Loss",
            "Compositional Vector Grammar"
          ],
          "connections": [
            "Tree Scoring",
            "Inference"
          ],
          "mechanisms": [
            "Max-Margin Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient Ascent",
            "Backpropagation Through Structure"
          ],
          "parameter_tuning": [
            "Regularization Parameter λ",
            "Learning Rate α"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_BottomUpBeamSearch",
        "entity_type": "Algorithm",
        "name": "Bottom-Up Beam Search",
        "year": 2013,
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing",
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "CKY Dynamic Programming"
          ],
          "connections": [
            "Tree Scoring",
            "Inference"
          ],
          "mechanisms": [
            "Efficient Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-Pass Inference"
          ],
          "parameter_tuning": [
            "Beam Size k"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_SubgradientMethodsAdaGrad",
        "entity_type": "Algorithm",
        "name": "Subgradient Methods and AdaGrad",
        "year": 2013,
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ],
        "task": "Optimization",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing",
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Subgradient Method",
            "AdaGrad"
          ],
          "connections": [
            "Parameter Updates",
            "Minibatch Training"
          ],
          "mechanisms": [
            "Diagonal Variant of AdaGrad"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate α",
            "Mini-batch Size"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WSJ_Section22_DevSet_2013",
        "entity_type": "Dataset",
        "name": "WSJ Section 22 Dev Set",
        "year": 2013,
        "creators": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_PPAttachment",
        "entity_type": "Metric",
        "name": "F1 Score for PP Attachment",
        "category": "Parsing Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ClauseAttachment_Accuracy",
        "entity_type": "Metric",
        "name": "Clause Attachment Accuracy",
        "category": "Parsing Evaluation",
        "formula": "Correct Attachments / Total Attachments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "UnaryRule_Accuracy",
        "entity_type": "Metric",
        "name": "Unary Rule Accuracy",
        "category": "Parsing Evaluation",
        "formula": "Correct Unary Rules / Total Unary Rules"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Klein2003a_ProbabilisticContextFreeGrammar",
        "entity_type": "Algorithm",
        "name": "Probabilistic Context-Free Grammar (PCFG)",
        "year": 2003,
        "authors": [
          "Klein, D.",
          "Manning, C. D."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Grammar Rules",
            "Probabilities"
          ],
          "connections": [
            "Rule Application"
          ],
          "mechanisms": [
            "Probabilistic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Rule Splitting"
          ]
        },
        "feature_processing": [
          "Syntactic Categories"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Petrov2006_LearningAlgorithmForSplittingCategories",
        "entity_type": "Algorithm",
        "name": "Learning Algorithm for Splitting Categories",
        "year": 2006,
        "authors": [
          "Petrov, S.",
          "Klein, D."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Subcategories",
            "Splitting Rules"
          ],
          "connections": [
            "Category Splitting"
          ],
          "mechanisms": [
            "Likelihood Maximization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Split and Merge"
          ],
          "parameter_tuning": [
            "Subcategory Parameters"
          ]
        },
        "feature_processing": [
          "Syntactic Categories"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collins2003_HeadDrivenStatisticalModel",
        "entity_type": "Algorithm",
        "name": "Head-Driven Statistical Model",
        "year": 2003,
        "authors": [
          "Collins, M."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Head Rules",
            "Lexical Items"
          ],
          "connections": [
            "Head Attachment"
          ],
          "mechanisms": [
            "Statistical Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Entropy"
          ],
          "parameter_tuning": [
            "Head Probabilities"
          ]
        },
        "feature_processing": [
          "Lexical Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hall2012_FactoredParser",
        "entity_type": "Algorithm",
        "name": "Factored Parser",
        "year": 2012,
        "authors": [
          "Hall, D.",
          "Klein, D."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Annotation Schemes",
            "Factorization"
          ],
          "connections": [
            "Combined Annotations"
          ],
          "mechanisms": [
            "Joint Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Expectation Propagation"
          ],
          "parameter_tuning": [
            "Factor Parameters"
          ]
        },
        "feature_processing": [
          "Syntactic and Semantic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Taskar2004_MaxMarginParsing",
        "entity_type": "Algorithm",
        "name": "Max-Margin Parsing",
        "year": 2004,
        "authors": [
          "Taskar, B.",
          "Klein, D.",
          "Collins, M.",
          "Koller, D.",
          "Manning, C."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Structured Margin Loss",
            "Max-Margin Objective"
          ],
          "connections": [
            "Loss Function"
          ],
          "mechanisms": [
            "Structured Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Optimization"
          ],
          "parameter_tuning": [
            "Margin Parameters"
          ]
        },
        "feature_processing": [
          "Feature Engineering"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Henderson2003_NeuralNetworkProbabilityEstimation",
        "entity_type": "Algorithm",
        "name": "Neural Network Probability Estimation",
        "year": 2003,
        "authors": [
          "Henderson, J."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Neural Networks",
            "Probability Estimation"
          ],
          "connections": [
            "Parsing Decisions"
          ],
          "mechanisms": [
            "Left-Corner Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": [
            "Network Weights"
          ]
        },
        "feature_processing": [
          "Parsing History"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Costa2003_RecursiveNeuralNetworks",
        "entity_type": "Algorithm",
        "name": "Recursive Neural Networks",
        "year": 2003,
        "authors": [
          "Costa, F.",
          "Frasconi, P.",
          "Lombardo, V.",
          "Soda, G."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Neural Networks",
            "Recursive Structure"
          ],
          "connections": [
            "Node Compositions"
          ],
          "mechanisms": [
            "Phrase Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": [
            "Network Weights"
          ]
        },
        "feature_processing": [
          "Word Vectors"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Menchetti2005_WideCoverageProcessing",
        "entity_type": "Algorithm",
        "name": "Wide Coverage Processing",
        "year": 2005,
        "authors": [
          "Menchetti, S.",
          "Costa, F.",
          "Frasconi, P.",
          "Pontil, M."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Kernel Methods",
            "Neural Networks"
          ],
          "connections": [
            "Structured Data"
          ],
          "mechanisms": [
            "Pattern Recognition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Kernel Methods"
          ],
          "parameter_tuning": [
            "Kernel Parameters"
          ]
        },
        "feature_processing": [
          "Structured Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_SimplifiedStanfordParser",
        "entity_type": "Algorithm",
        "name": "Simplified Stanford Parser",
        "year": 2013,
        "authors": [
          "Klein, D.",
          "Manning, C. D."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "PCFG"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "CKY dynamic programming"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_CharniakSelfTrainedParser",
        "entity_type": "Algorithm",
        "name": "Charniak Self-Trained Parser",
        "year": 2013,
        "authors": [
          "McClosky, D.",
          "Charniak, E.",
          "Johnson, M."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Self-training",
            "Re-ranking"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Bootstrapping",
            "Parsing additional large corpora"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_CharniakJohnsonParser",
        "entity_type": "Algorithm",
        "name": "Charniak-Johnson Parser",
        "year": 2013,
        "authors": [
          "Charniak, E.",
          "Johnson, M."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Self-trained",
            "Discriminatively re-ranked"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Combining multiple approaches"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_BerkeleyParser",
        "entity_type": "Algorithm",
        "name": "Berkeley Parser",
        "year": 2013,
        "authors": [
          "Petrov, S.",
          "Klein, D."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Factored PCFGs"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Expectation Propagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_CollinsParser",
        "entity_type": "Algorithm",
        "name": "Collins Parser",
        "year": 2013,
        "authors": [
          "Collins, M."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Head-driven statistical models"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Generative models"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_SSNParser",
        "entity_type": "Algorithm",
        "name": "SSN Parser",
        "year": 2013,
        "authors": [
          "Henderson, J."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Statistical Neural Network"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Discriminative training"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_FactoredPCFGs",
        "entity_type": "Algorithm",
        "name": "Factored PCFGs",
        "year": 2013,
        "authors": [
          "Hall, D.",
          "Klein, D."
        ],
        "task": "Parsing",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Factored PCFGs"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Expectation Propagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Diff_Label_Error_Parsing",
        "entity_type": "Metric",
        "name": "Diff Label Error",
        "description": "Error in labeling different parts of speech",
        "category": "Parsing Evaluation",
        "formula": "Number of incorrectly labeled constituents / Total number of constituents"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Mod_Attach_Error_Parsing",
        "entity_type": "Metric",
        "name": "Modifier Attachment Error",
        "description": "Error in attaching modifiers to the correct head",
        "category": "Parsing Evaluation",
        "formula": "Number of incorrect modifier attachments / Total number of modifier attachments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "NP_Attach_Error_Parsing",
        "entity_type": "Metric",
        "name": "NP Attachment Error",
        "description": "Error in attaching noun phrases to the correct head",
        "category": "Parsing Evaluation",
        "formula": "Number of incorrect NP attachments / Total number of NP attachments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Coordination_Error_Parsing",
        "entity_type": "Metric",
        "name": "Coordination Error",
        "description": "Error in handling coordination structures",
        "category": "Parsing Evaluation",
        "formula": "Number of incorrect coordination structures / Total number of coordination structures"
      }
    },
    {
      "metric_entity": {
        "metric_id": "One_Word_Span_Error_Parsing",
        "entity_type": "Metric",
        "name": "One-Word Span Error",
        "description": "Error in parsing one-word spans",
        "category": "Parsing Evaluation",
        "formula": "Number of incorrect one-word spans / Total number of one-word spans"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Unary_Error_Parsing",
        "entity_type": "Metric",
        "name": "Unary Error",
        "description": "Error in unary rules",
        "category": "Parsing Evaluation",
        "formula": "Number of incorrect unary rules / Total number of unary rules"
      }
    },
    {
      "metric_entity": {
        "metric_id": "NP_Internal_Structure_Error_Parsing",
        "entity_type": "Metric",
        "name": "NP Internal Structure Error",
        "description": "Error in internal structure of noun phrases",
        "category": "Parsing Evaluation",
        "formula": "Number of incorrect internal structures of NPs / Total number of NPs"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Other_Error_Parsing",
        "entity_type": "Metric",
        "name": "Other Error",
        "description": "Errors not categorized under PP, Clause, Diff Label, Mod Attach, NP Attach, Coordination, One-Word Span, Unary, NP Internal Structure",
        "category": "Parsing Evaluation",
        "formula": "Number of other errors / Total number of errors"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_QuantityExtraction",
        "entity_type": "Algorithm",
        "name": "QuantityExtraction",
        "title": "Reasoning about Quantities in Natural Language",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "Quantity Extraction and Standardization",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Segmentation",
            "Standardization",
            "Unit Inference"
          ],
          "connections": [
            "Segmentation -> Standardization",
            "Standardization -> Unit Inference"
          ],
          "mechanisms": [
            "Sequence Segmentation",
            "Rule-based Standardization",
            "Semantic Role Labeling",
            "Coreference Resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-validation"
          ],
          "parameter_tuning": [
            "Feature Engineering",
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "Word Class Features",
          "Character-based Features",
          "Part of Speech Tags",
          "Contextual Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_QuantityEntailment",
        "entity_type": "Algorithm",
        "name": "QuantityEntailment",
        "title": "Reasoning about Quantities in Natural Language",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "Quantity Entailment",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Extraction Phase",
            "Reasoning Phase"
          ],
          "connections": [
            "Extraction Phase -> Reasoning Phase"
          ],
          "mechanisms": [
            "Implicit Quantity Productions",
            "Quantity Comparisons",
            "Monotonicity Verification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-validation"
          ],
          "parameter_tuning": [
            "Feature Engineering",
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "WordNet Synsets",
          "Coreference Resolution",
          "Semantic Role Labeling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_SolveWordProblem",
        "entity_type": "Algorithm",
        "name": "SolveWordProblem",
        "title": "Reasoning about Quantities in Natural Language",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "Solving Math Word Problems",
        "dataset": [
          "Elementary Math Word Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quantity Pair Classifier",
            "Operation Classifier",
            "Order Classifier"
          ],
          "connections": [
            "Quantity Pair Classifier -> Operation Classifier -> Order Classifier"
          ],
          "mechanisms": [
            "Cascade of Classifiers",
            "Feature-based Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-validation"
          ],
          "parameter_tuning": [
            "Feature Engineering",
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "Unigrams and Bigrams",
          "POS Tags",
          "Quantity Units Matching",
          "Relevant Operations",
          "Relevant Order of Quantities"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "RTE_Datasets_2015",
        "entity_type": "Dataset",
        "name": "RTE Datasets",
        "description": "Textual Entailment datasets used for evaluating Quantity Entailment",
        "domain": "Natural Language Processing",
        "size": 384,
        "year": 2015,
        "creators": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Newswire_Text_2015",
        "entity_type": "Dataset",
        "name": "Newswire Text",
        "description": "Sentences from news articles containing quantity mentions",
        "domain": "Natural Language Processing",
        "size": 600,
        "year": 2015,
        "creators": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Elementary_Math_Word_Problems_2015",
        "entity_type": "Dataset",
        "name": "Elementary Math Word Problems",
        "description": "Math word problems for elementary school students",
        "domain": "Natural Language Processing",
        "size": 869,
        "year": 2015,
        "creators": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Quantitative_Reasoning",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Quantitative Reasoning Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Quantitative_Reasoning",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Proportion of true positive predictions among all positive predictions",
        "category": "Quantitative Reasoning Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Quantitative_Reasoning",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Proportion of true positive predictions among all actual positives",
        "category": "Quantitative Reasoning Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Math_Word_Problems",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correctly solved math word problems",
        "category": "Math Word Problem Solving",
        "formula": "Correct Answers / Total Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Maccartney2008_ModelingSemanticContainment",
        "entity_type": "Algorithm",
        "name": "Modeling Semantic Containment and Exclusion",
        "year": 2008,
        "authors": [
          "Maccartney, B.",
          "Manning, C."
        ],
        "task": "Natural Language Inference",
        "dataset": [
          "RTE Datasets"
        ],
        "metrics": [
          "Accuracy",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Semantic Containment Module",
            "Semantic Exclusion Module"
          ],
          "connections": [
            "Logical Inference Rules"
          ],
          "mechanisms": [
            "Monotonicity Verification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameters for Monotonicity"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Role Labeling"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "RTE2_Dataset_2006",
        "entity_type": "Dataset",
        "name": "RTE2 Dataset",
        "description": "Recognizing Textual Entailment Dataset",
        "domain": "Natural Language Processing",
        "size": 800,
        "year": 2006,
        "creators": [
          "Dagan, I.",
          "Glickman, O.",
          "Magnini, B."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "RTE3_Dataset_2006",
        "entity_type": "Dataset",
        "name": "RTE3 Dataset",
        "description": "Recognizing Textual Entailment Dataset",
        "domain": "Natural Language Processing",
        "size": 800,
        "year": 2006,
        "creators": [
          "Dagan, I.",
          "Glickman, O.",
          "Magnini, B."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "RTE4_Dataset_2006",
        "entity_type": "Dataset",
        "name": "RTE4 Dataset",
        "description": "Recognizing Textual Entailment Dataset",
        "domain": "Natural Language Processing",
        "size": 800,
        "year": 2006,
        "creators": [
          "Dagan, I.",
          "Glickman, O.",
          "Magnini, B."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Textual_Entailment",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Textual Entailment Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Textual_Entailment",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correct predictions",
        "category": "Textual Entailment Evaluation",
        "formula": "Correct Predictions / Total Predictions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Textual_Entailment",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Proportion of true positive predictions among all positive predictions",
        "category": "Textual Entailment Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Textual_Entailment",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Proportion of true positive predictions among all actual positives",
        "category": "Textual Entailment Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_QuantityValueRepresentation",
        "entity_type": "Algorithm",
        "name": "Quantity-Value Representation (QVR)",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "Quantitative Reasoning",
        "dataset": [
          "RTE_Datasets_2015",
          "Newswire_Text_2015"
        ],
        "metrics": [
          "F1_Score_Quantitative_Reasoning",
          "Precision_Quantitative_Reasoning",
          "Recall_Quantitative_Reasoning"
        ],
        "architecture": {
          "components": [
            "Value",
            "Units",
            "Change"
          ],
          "connections": [
            "Value to Units",
            "Value to Change",
            "Units to Change"
          ],
          "mechanisms": [
            "Normalization",
            "Standardization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based",
            "Feature-based"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Segmentation",
          "Standardization",
          "Unit Inference"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_SemiCRFModel",
        "entity_type": "Algorithm",
        "name": "Semi-CRF Model",
        "year": 2015,
        "authors": [
          "Sarawagi, S.",
          "Collins, M.",
          "Freund, Y.",
          "Schapire, R."
        ],
        "task": "Quantity Segmentation",
        "dataset": [
          "RTE_Datasets_2015",
          "Newswire_Text_2015"
        ],
        "metrics": [
          "F1_Score_Quantitative_Reasoning",
          "Precision_Quantitative_Reasoning",
          "Recall_Quantitative_Reasoning"
        ],
        "architecture": {
          "components": [
            "Conditional Random Fields"
          ],
          "connections": [
            "Sequence Segmentation"
          ],
          "mechanisms": [
            "Structured Perceptron Training",
            "Parameter Averaging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization"
          ]
        },
        "feature_processing": [
          "Word Class Features",
          "Character-Based Features",
          "Part of Speech Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_BankOfClassifiers",
        "entity_type": "Algorithm",
        "name": "Bank of Classifiers",
        "year": 2015,
        "authors": [
          "Punyakanok, V.",
          "Roth, D."
        ],
        "task": "Quantity Segmentation",
        "dataset": [
          "RTE_Datasets_2015",
          "Newswire_Text_2015"
        ],
        "metrics": [
          "F1_Score_Quantitative_Reasoning",
          "Precision_Quantitative_Reasoning",
          "Recall_Quantitative_Reasoning"
        ],
        "architecture": {
          "components": [
            "Classifiers"
          ],
          "connections": [
            "Sequential Inference"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Decision Making"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Retraining with New Features"
          ],
          "parameter_tuning": [
            "Thresholds",
            "Weights"
          ]
        },
        "feature_processing": [
          "Word Class Features",
          "Character-Based Features",
          "Part of Speech Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_ImplicitQuantityProductionRules",
        "entity_type": "Algorithm",
        "name": "Implicit Quantity Production Rules",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "Quantity Entailment",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Range Implication",
            "Compatible Term Combination",
            "Ratio to Percentage",
            "Composition"
          ],
          "connections": [
            "Implicit Quantity Production Rules"
          ],
          "mechanisms": [
            "Logical Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Quantity Extraction",
          "Standardization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_LightweightLogicalInference",
        "entity_type": "Algorithm",
        "name": "Lightweight Logical Inference",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "Quantity Entailment",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Implicit Quantity Production Rules",
            "Quantity Comparison"
          ],
          "connections": [
            "Logical Inference"
          ],
          "mechanisms": [
            "Monotonicity Verification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Quantity Extraction",
          "Standardization"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Contradiction_Rate_Textual_Entailment",
        "entity_type": "Metric",
        "name": "Contradiction Rate",
        "description": "Rate at which the system correctly identifies contradictions in textual entailment",
        "category": "Textual Entailment Evaluation",
        "formula": "Correct Contradictions / Total Contradictions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "No_Relation_Rate_Textual_Entailment",
        "entity_type": "Metric",
        "name": "No Relation Rate",
        "description": "Rate at which the system correctly identifies no relation in textual entailment",
        "category": "Textual Entailment Evaluation",
        "formula": "Correct No Relations / Total No Relations"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jung2004_WindowedHoughTransform",
        "entity_type": "Algorithm",
        "name": "Windowed Hough Transform",
        "title": "Rectangle Detection based on a Windowed Hough Transform",
        "year": 2004,
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "Rectangle Detection",
        "dataset": [
          "Synthetic images",
          "Natural images"
        ],
        "metrics": [
          "Detection accuracy"
        ],
        "architecture": {
          "components": [
            "Sliding window",
            "Hough Transform",
            "Peak extraction",
            "Geometric constraints"
          ],
          "connections": [
            "Edge map -> Hough Transform -> Peak extraction -> Rectangle detection"
          ],
          "mechanisms": [
            "Sliding window for local analysis",
            "Enhancement of Hough image",
            "Error minimization for duplicate removal"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Tθ",
            "Tρ",
            "TL",
            "Tα",
            "Dmin",
            "Dmax"
          ]
        },
        "feature_processing": [
          "Edge detection using Canny's operator",
          "Morphological operations"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SyntheticImages_2004",
        "entity_type": "Dataset",
        "name": "Synthetic images",
        "description": "Synthetic images containing geometric objects for testing rectangle detection algorithms",
        "domain": "Computer Vision",
        "size": "Not specified",
        "year": 2004,
        "creators": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NaturalImages_2004",
        "entity_type": "Dataset",
        "name": "Natural images",
        "description": "Real-world images for testing rectangle detection algorithms",
        "domain": "Computer Vision",
        "size": "Not specified",
        "year": 2004,
        "creators": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "DetectionAccuracy_RectangleDetection",
        "entity_type": "Metric",
        "name": "Detection accuracy",
        "description": "Accuracy of detecting rectangles in images",
        "category": "Object detection",
        "formula": "Number of correctly detected rectangles / Total number of rectangles"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_HoughTransform",
        "entity_type": "Algorithm",
        "name": "Hough Transform",
        "title": "Use of the Hough Transform to detect lines and curves in pictures",
        "year": 1972,
        "authors": [
          "R. Duda",
          "P. Hart"
        ],
        "task": "Line and Curve Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Accumulator Array",
            "Edge Points"
          ],
          "connections": [
            "Edge Points -> Accumulator Array"
          ],
          "mechanisms": [
            "Peak Detection",
            "Quantization"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Steps dθ and dρ"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ballard1981_GeneralizedHoughTransform",
        "entity_type": "Algorithm",
        "name": "Generalized Hough Transform (GHT)",
        "title": "Generalizing the Hough Transform to detect arbitrary shapes",
        "year": 1981,
        "authors": [
          "D. Ballard"
        ],
        "task": "Arbitrary Shape Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Accumulator Array",
            "Shape Templates"
          ],
          "connections": [
            "Edge Points -> Accumulator Array"
          ],
          "mechanisms": [
            "Peak Detection",
            "Template Matching"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shen2002_ModifiedHoughTransform",
        "entity_type": "Algorithm",
        "name": "Modified Hough Transform",
        "title": "Corner detection based on modified Hough transform",
        "year": 2002,
        "authors": [
          "F. Shen",
          "H. Wang"
        ],
        "task": "Corner Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Accumulator Array",
            "Edge Points"
          ],
          "connections": [
            "Edge Points -> Accumulator Array"
          ],
          "mechanisms": [
            "Peak Detection",
            "Quantization"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Steps dθ and dρ"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Furukawa2003_AccurateLineSegmentExtraction",
        "entity_type": "Algorithm",
        "name": "Accurate Line Segment Extraction",
        "title": "Accurate and robust line segment extraction by analyzing distribution around peaks in Hough space",
        "year": 2003,
        "authors": [
          "Y. Furukawa",
          "Y. Shinagawa"
        ],
        "task": "Line Segment Extraction",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Accumulator Array",
            "Edge Points"
          ],
          "connections": [
            "Edge Points -> Accumulator Array"
          ],
          "mechanisms": [
            "Peak Detection",
            "Distribution Analysis"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Steps dθ and dρ"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jung2004_RectangleDetectionAlgorithm",
        "entity_type": "Algorithm",
        "name": "Rectangle Detection Algorithm",
        "title": "Rectangle detection based on a windowed Hough Transform",
        "year": 2004,
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "Rectangle Detection",
        "dataset": [
          "SyntheticImages_2004",
          "NaturalImages_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Sliding Window",
            "Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Sliding Window -> Hough Transform",
            "Hough Transform -> Peak Extraction",
            "Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Windowed Hough Transform",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Edge Detection",
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Map Generation",
          "Butterfly Pattern Enhancement"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AerialImages_2004",
        "entity_type": "Dataset",
        "name": "Aerial Images",
        "description": "Aerial imagery used for detecting rectangular structures such as buildings and vehicles.",
        "domain": "Remote Sensing",
        "year": 2004,
        "creators": [
          "Various sources"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "FalsePositiveRate_RectangleDetection",
        "entity_type": "Metric",
        "name": "False Positive Rate",
        "description": "The rate at which non-rectangular structures are incorrectly identified as rectangles.",
        "category": "Detection Evaluation",
        "formula": "False Positives / (True Negatives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorMeasure_RectangleDetection",
        "entity_type": "Metric",
        "name": "Error Measure",
        "description": "A combined measure of angular and distance errors for detected rectangles.",
        "category": "Detection Evaluation",
        "formula": "sqrt(a(Δθk^2 + Δθl^2 + Δα^2) + b(Δρk^2 + Δρl^2))"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lagunovsky1999_StraightLinePrimitiveExtraction",
        "entity_type": "Algorithm",
        "name": "Straight-line-based Primitive Extraction",
        "year": 1999,
        "authors": [
          "D. Lagunovsky",
          "S. Ablameyko"
        ],
        "task": "Object Recognition",
        "dataset": [
          "SyntheticImages_1999"
        ],
        "metrics": [
          "DetectionAccuracy"
        ],
        "architecture": {
          "components": [
            "Edge Detection",
            "Linear Primitive Extraction"
          ],
          "connections": [
            "Edge Elements to Linear Segments"
          ],
          "mechanisms": [
            "Grouping Line Segments"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Not Applicable"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin1998_BuildingDetectionAndDescription",
        "entity_type": "Algorithm",
        "name": "Building Detection and Description",
        "year": 1998,
        "authors": [
          "C. Lin",
          "R. Nevatia"
        ],
        "task": "Building Detection",
        "dataset": [
          "AerialImages_1998"
        ],
        "metrics": [
          "DetectionAccuracy"
        ],
        "architecture": {
          "components": [
            "Line Detection",
            "Anti-Parallel Line Search"
          ],
          "connections": [
            "Initial Line Segment to Search Region"
          ],
          "mechanisms": [
            "Defining Search Regions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Not Applicable"
          ]
        },
        "feature_processing": [
          "Line Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Tao2002_RectangleBuildingExtraction",
        "entity_type": "Algorithm",
        "name": "Rectangle Building Extraction",
        "year": 2002,
        "authors": [
          "W.-B. Tao",
          "J.-W. Tian",
          "J. Liu"
        ],
        "task": "Building Extraction",
        "dataset": [
          "AerialUrbanImages_2002"
        ],
        "metrics": [
          "DetectionAccuracy"
        ],
        "architecture": {
          "components": [
            "Edge Element Detection",
            "Linear Element Extraction"
          ],
          "connections": [
            "Start-Point, End-Point, Orientation"
          ],
          "mechanisms": [
            "Detecting Parallel Lines"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Not Applicable"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhu2003_AutomaticParticleDetection",
        "entity_type": "Algorithm",
        "name": "Automatic Particle Detection",
        "year": 2003,
        "authors": [
          "Y. Zhu",
          "B. Carragher",
          "F. Mouche",
          "C. Potter"
        ],
        "task": "Particle Detection",
        "dataset": [
          "CryoElectronMicroscopyImages_2003"
        ],
        "metrics": [
          "DetectionAccuracy"
        ],
        "architecture": {
          "components": [
            "Rectangular Hough Transform"
          ],
          "connections": [
            "Accumulator Array"
          ],
          "mechanisms": [
            "Detecting Center and Orientation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Not Applicable"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CryoElectronMicroscopyImages_2003",
        "entity_type": "Dataset",
        "name": "Cryo-Electron Microscopy Images",
        "description": "Images used for detecting particles in cryo-electron microscopy",
        "domain": "Cryo-Electron Microscopy",
        "year": 2003,
        "creators": [
          "Y. Zhu",
          "B. Carragher",
          "F. Mouche",
          "C. Potter"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AerialUrbanImages_2002",
        "entity_type": "Dataset",
        "name": "Aerial Urban Images",
        "description": "Aerial images of urban areas used for building detection",
        "domain": "Remote Sensing",
        "year": 2002,
        "creators": [
          "W.-B. Tao",
          "J.-W. Tian",
          "J. Liu"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jung2004_RectangleDetectionOnSyntheticImages",
        "entity_type": "Algorithm",
        "name": "Rectangle Detection on Synthetic Images",
        "year": 2004,
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "Rectangle Detection",
        "dataset": [
          "SyntheticImages_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Windowed Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Edge Map -> Windowed Hough Transform -> Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Sliding Window",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jung2004_RectangleDetectionOnNoisyImages",
        "entity_type": "Algorithm",
        "name": "Rectangle Detection on Noisy Images",
        "year": 2004,
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "Rectangle Detection",
        "dataset": [
          "SyntheticImages_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection",
          "FalsePositiveRate_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Windowed Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Edge Map -> Windowed Hough Transform -> Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Sliding Window",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jung2004_LicensePlateDetection",
        "entity_type": "Algorithm",
        "name": "License Plate Detection",
        "year": 2004,
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "License Plate Detection",
        "dataset": [
          "OriginalImage_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Windowed Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Edge Map -> Windowed Hough Transform -> Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Sliding Window",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Dmin",
            "Dmax",
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jung2004_BuildingDetectionFromAerialImages",
        "entity_type": "Algorithm",
        "name": "Building Detection from Aerial Images",
        "year": 2004,
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "Building Detection",
        "dataset": [
          "AerialImages_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection",
          "FalsePositiveRate_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Windowed Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Edge Map -> Windowed Hough Transform -> Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Sliding Window",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Dmin",
            "Dmax",
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Detection",
          "Morphological Erosion"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_ROBUST",
        "entity_type": "Algorithm",
        "name": "ROBUST",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Understanding arithmetic word problems with extraneous information",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Change formulas",
            "Schema instantiation",
            "Natural language parser"
          ],
          "connections": [
            "Change verbs to schema mapping",
            "Formula instantiation to problem propositions"
          ],
          "mechanisms": [
            "Cautious strategy for schema instantiation",
            "Complex change verb splitting"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Parsing natural language",
          "Identifying change verbs",
          "Splitting complex sentences"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WordProblems_2023",
        "entity_type": "Dataset",
        "name": "Word Problems",
        "description": "A collection of multi-step arithmetic word problems with extraneous information",
        "domain": "Arithmetic problem solving",
        "size": "Not specified",
        "year": 2023,
        "creators": [
          "Bakman, Y."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SolutionCorrectness_ProblemSolving",
        "entity_type": "Metric",
        "name": "Solution Correctness",
        "description": "Correctness of the solution to arithmetic word problems",
        "category": "Problem solving evaluation",
        "formula": "Number of correctly solved problems / Total number of problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Riley1983_ChangeCompareCombineSchemas",
        "entity_type": "Algorithm",
        "name": "Change, Compare, Combine Schemas",
        "year": 1983,
        "authors": [
          "Riley, M.S.",
          "Greeno, J.G.",
          "Heller, J.I."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Simple Arithmetic Word Problems"
        ],
        "metrics": [
          "Schema Matching Accuracy"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kintsch1985_ChangeCompareCombineSchemas",
        "entity_type": "Algorithm",
        "name": "Change, Compare, Combine Schemas",
        "year": 1985,
        "authors": [
          "Kintsch, W.",
          "Greeno, J.G."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Simple Arithmetic Word Problems"
        ],
        "metrics": [
          "Schema Matching Accuracy"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cummins1988_ChangeCompareCombineSchemas",
        "entity_type": "Algorithm",
        "name": "Change, Compare, Combine Schemas",
        "year": 1988,
        "authors": [
          "Cummins, D.",
          "Kintsch, W.",
          "Reusser, K.",
          "Weimer, R."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Simple Arithmetic Word Problems"
        ],
        "metrics": [
          "Schema Matching Accuracy"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Briars1984_CHIPS",
        "entity_type": "Algorithm",
        "name": "CHIPS",
        "year": 1984,
        "authors": [
          "Briars, D.L.",
          "Larkin, J.H."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "One-step Arithmetic Word Problems"
        ],
        "metrics": [
          "Solution Correctness"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Dellarosa1986_ARITHPRO",
        "entity_type": "Algorithm",
        "name": "ARITHPRO",
        "year": 1986,
        "authors": [
          "Dellarosa, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "One-step Arithmetic Word Problems"
        ],
        "metrics": [
          "Solution Correctness"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_CautiousStrategy",
        "entity_type": "Algorithm",
        "name": "Cautious Strategy",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Word Problem Solving",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Schema Instantiation Creation",
            "Formula Matching"
          ],
          "connections": [
            "Problem Propositions -> Schema Instantiations"
          ],
          "mechanisms": [
            "Relevance Checking",
            "Elementary Change Verb Splitting"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Heuristic Method for Schema Relevancy Estimation"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_TransferInPlace",
        "entity_type": "Algorithm",
        "name": "Transfer-In-Place",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Word Problem Solving",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Additional Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Place"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_TransferOutPlace",
        "entity_type": "Algorithm",
        "name": "Transfer-Out-Place",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Word Problem Solving",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Additional Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Place"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_TransferInOwnership",
        "entity_type": "Algorithm",
        "name": "Transfer-In-Ownership",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Word Problem Solving",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Additional Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Owner"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_TransferOutOwnership",
        "entity_type": "Algorithm",
        "name": "Transfer-Out-Ownership",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Word Problem Solving",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Additional Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Owner"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_Creation",
        "entity_type": "Algorithm",
        "name": "Creation",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Word Problem Solving",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Created Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Place/Owner"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_Termination",
        "entity_type": "Algorithm",
        "name": "Termination",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Word Problem Solving",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Terminated Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Place/Owner"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_ChangeFormula",
        "entity_type": "Algorithm",
        "name": "Change Formula",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Formula Variables"
          ],
          "connections": [
            "Correspondence between sentence members and formula variables"
          ],
          "mechanisms": [
            "Instantiation of change schema"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parsing natural language",
            "Matching propositions to schema instantiations"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Parsing problem sentences",
          "Identifying change verbs"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_ROBUSTSimulation",
        "entity_type": "Algorithm",
        "name": "ROBUST Simulation",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Understanding Arithmetic Word Problems",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Parser",
            "Schema Instantiation Creator",
            "Change Formula Recognizer"
          ],
          "connections": [
            "Parser -> Schema Instantiation Creator",
            "Schema Instantiation Creator -> Change Formula Recognizer"
          ],
          "mechanisms": [
            "Natural Language Parsing",
            "Schema Matching",
            "Formula Instantiation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None - Rule-Based System"
          ],
          "parameter_tuning": [
            "None - Rule-Based System"
          ]
        },
        "feature_processing": [
          "Natural Language Processing",
          "Sentence Splitting",
          "Variable Substitution"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SchemaRelevancy_ProblemSolving",
        "entity_type": "Metric",
        "name": "Schema Relevancy",
        "description": "Measures whether all components of a schema have been found among the problem propositions",
        "category": "Problem Solving Evaluation",
        "formula": "All schema components found in problem propositions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_SemanticParserWithOntologyMatching",
        "entity_type": "Algorithm",
        "name": "Semantic Parser with On-the-fly Ontology Matching",
        "year": 2013,
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall",
          "Precision",
          "F1"
        ],
        "architecture": {
          "components": [
            "Probabilistic CCG",
            "Ontology Matching Model"
          ],
          "connections": [
            "CCG Parsing",
            "Logical Form Transformation"
          ],
          "mechanisms": [
            "Domain-independent Parsing",
            "Structure Matching",
            "Constant Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Perceptron"
          ],
          "parameter_tuning": [
            "Feature Weights"
          ]
        },
        "feature_processing": [
          "CCG Parse Features",
          "Structural Features",
          "Lexical Features",
          "Knowledge Base Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "GeoQuery_1996",
        "entity_type": "Dataset",
        "name": "GeoQuery",
        "year": 1996,
        "creators": [
          "Zelle, J.",
          "Mooney, R."
        ],
        "domain": "Geography",
        "description": "A geography database with a small ontology and questions with relatively complex, compositional structure."
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "FreebaseQA_2013",
        "entity_type": "Dataset",
        "name": "Freebase QA",
        "year": 2013,
        "creators": [
          "Cai, Q.",
          "Yates, A."
        ],
        "domain": "Open-domain Question Answering",
        "description": "A large community-authored database that spans many sub-domains, containing 917 questions labeled with logical form meaning representations for querying Freebase."
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_QuestionAnswering",
        "entity_type": "Metric",
        "name": "Recall",
        "category": "Question Answering",
        "description": "Percentage of total questions answered correctly.",
        "formula": "Number of correctly answered questions / Total number of questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_QuestionAnswering",
        "entity_type": "Metric",
        "name": "Precision",
        "category": "Question Answering",
        "description": "Percentage of produced queries with correct answers.",
        "formula": "Number of correct queries / Total number of produced queries"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_QuestionAnswering",
        "entity_type": "Metric",
        "name": "F1 Score",
        "category": "Question Answering",
        "description": "Harmonic mean of precision and recall.",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_ProbabilisticCCG",
        "entity_type": "Algorithm",
        "name": "Probabilistic Combinatory Categorial Grammar (CCG)",
        "year": 2013,
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "CCG Parser",
            "Lexical Categories",
            "Combinatory Rules"
          ],
          "connections": [
            "CCG Lexical Entries",
            "Logical Forms"
          ],
          "mechanisms": [
            "Syntax-Semantics Mapping",
            "Logical Form Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Learning",
            "Question-Answer Pairs"
          ],
          "parameter_tuning": [
            "Linear Model Parameters"
          ]
        },
        "feature_processing": [
          "POS Tagging",
          "Lexical Templates"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_OntologyMatchingModel",
        "entity_type": "Algorithm",
        "name": "Ontology Matching Model",
        "year": 2013,
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "Type-Equivalent Domain-Specific Meanings",
            "Lexical Similarity"
          ],
          "connections": [
            "Domain-Independent Constants",
            "Domain-Dependent Constants"
          ],
          "mechanisms": [
            "Structure Matching",
            "Constant Replacement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Learning",
            "Question-Answer Pairs"
          ],
          "parameter_tuning": [
            "Linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Knowledge Base Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_DomainIndependentCCGParser",
        "entity_type": "Algorithm",
        "name": "Domain-Independent CCG Parser",
        "year": 2013,
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "CCG Grammar",
            "Lexical Categories",
            "Combinatory Rules"
          ],
          "connections": [
            "Lexical Category Assignment",
            "Logical Form Construction"
          ],
          "mechanisms": [
            "Syntactic Parsing",
            "Logical Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic CCG Parsing",
            "Latent Variable Learning"
          ],
          "parameter_tuning": [
            "Linear Model Estimation"
          ]
        },
        "feature_processing": [
          "POS Tagging",
          "Wiktionary Integration"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_StructureMatchingOperators",
        "entity_type": "Algorithm",
        "name": "Structure Matching Operators",
        "year": 2013,
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "Collapse Literal to Constant",
            "Collapse Literal to Literal",
            "Split Literal"
          ],
          "connections": [
            "Logical Form Transformation",
            "Ontology Alignment"
          ],
          "mechanisms": [
            "Literal Simplification",
            "Predicate Expansion"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic CCG Parsing",
            "Latent Variable Learning"
          ],
          "parameter_tuning": [
            "Linear Model Estimation"
          ]
        },
        "feature_processing": [
          "Logical Form Manipulation",
          "Type Checking"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_ConstantReplacementOperators",
        "entity_type": "Algorithm",
        "name": "Constant Replacement Operators",
        "year": 2013,
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "Entity-Typed Constants",
            "Domain-Independent Constants"
          ],
          "connections": [
            "Logical Form Transformation",
            "Ontology Alignment"
          ],
          "mechanisms": [
            "Constant Substitution",
            "Type Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic CCG Parsing",
            "Latent Variable Learning"
          ],
          "parameter_tuning": [
            "Linear Model Estimation"
          ]
        },
        "feature_processing": [
          "Lexical Similarity",
          "Wiktionary Definitions"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_DynamicProgramForDerivations",
        "entity_type": "Algorithm",
        "name": "Dynamic Program for Derivations",
        "year": 2013,
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "CKY-style chart parser",
            "Hyper-graph chart structure"
          ],
          "connections": [
            "Logical form generation",
            "Derivation scoring"
          ],
          "mechanisms": [
            "Pruning strategies",
            "Constant matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online learning",
            "Perceptron"
          ],
          "parameter_tuning": [
            "Feature weights initialization",
            "Pruning parameters"
          ]
        },
        "feature_processing": [
          "CCG parse features",
          "Structural features",
          "Lexical features",
          "Knowledge base features"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Score_Derivation",
        "entity_type": "Metric",
        "name": "Score",
        "description": "Score of a derivation",
        "category": "Derivation Evaluation",
        "formula": "Linear function decomposed over the parse tree and individual ontology-matching steps"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_OnlineLearningAlgorithm",
        "entity_type": "Algorithm",
        "name": "Online Learning Algorithm",
        "year": 2013,
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "Question Answering",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "Perceptron",
            "Feature Vector",
            "Weight Vector"
          ],
          "connections": [
            "Feature Extraction",
            "Weight Update"
          ],
          "mechanisms": [
            "Margin-based Separation",
            "Parameter Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Perceptron Update Rule",
            "Margin-based Learning"
          ],
          "parameter_tuning": [
            "Initial Weight Initialization",
            "Iteration Control"
          ]
        },
        "feature_processing": [
          "Indicator Features",
          "Lexical Features",
          "Structural Features",
          "Knowledge Base Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2019_SemanticallyAlignedEquationGeneration",
        "entity_type": "Algorithm",
        "name": "Semantically-Aligned Equation Generation",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": 2019,
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack"
          ],
          "connections": [
            "Encoder-Decoder",
            "Decoder-Stack"
          ],
          "mechanisms": [
            "Semantic Transformer",
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Semantic Representation Extraction",
          "External Constant Leveraging"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_EquationParsing",
        "entity_type": "Algorithm",
        "name": "Equation Parsing",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Sentence Parsing",
            "Equation Generation"
          ],
          "connections": [
            "Sentence to Equation"
          ],
          "mechanisms": [
            "Semantic Parsing",
            "Equation Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Parsing Rules"
          ]
        },
        "feature_processing": [
          "Hand-Crafted Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ling2017_ProgramInduction",
        "entity_type": "Algorithm",
        "name": "Program Induction",
        "year": 2017,
        "authors": [
          "Ling, W.",
          "Yogatama, D.",
          "Dyer, C.",
          "Blunsom, P."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Rationale Generation",
            "Equation Generation"
          ],
          "connections": [
            "Rationale to Equation"
          ],
          "mechanisms": [
            "Rationale-Based Equation Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Rationale Generation Parameters"
          ]
        },
        "feature_processing": [
          "Hand-Crafted Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin18K_2015",
        "entity_type": "Dataset",
        "name": "Dolphin18K",
        "year": 2015,
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "Math Word Problem Solving",
        "description": "Contains 18,460 math word problems with logical forms",
        "domain": "Natural Language Processing"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AQuA_2017",
        "entity_type": "Dataset",
        "name": "AQuA",
        "year": 2017,
        "authors": [
          "Ling, W.",
          "Yogatama, D.",
          "Dyer, C.",
          "Blunsom, P."
        ],
        "task": "Math Word Problem Solving",
        "description": "Contains 100,000 math word problems with rationales",
        "domain": "Natural Language Processing"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2019_EndToEndNeuralMathSolver",
        "entity_type": "Algorithm",
        "name": "End-to-End Neural Math Solver",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": 2019,
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "Solving Math Word Problems",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Encoder-Decoder connection",
            "Stack operations",
            "Semantic alignment"
          ],
          "mechanisms": [
            "BLSTM for constant representation extraction",
            "Attention mechanism",
            "Gating mechanisms",
            "Semantic transformation functions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning",
            "Postfix equation generation"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Dropout rate"
          ]
        },
        "feature_processing": [
          "Constant representation extraction",
          "External constant leveraging",
          "Semantic representation of operands"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_MathWordProblems",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correctly solved math word problems",
        "category": "Math Word Problem Solving",
        "formula": "Number of correctly solved problems / Total number of problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2019_WordBasedModel",
        "entity_type": "Algorithm",
        "name": "Word-Based Model",
        "year": 2019,
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblems"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Encoder-Decoder",
            "Stack-Decoder",
            "Semantic Transformer-Decoder"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Gating Mechanism",
            "Semantic Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Postfix Equation Transformation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Constant Representation Extraction",
          "External Constant Leveraging"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2019_CharBasedModel",
        "entity_type": "Algorithm",
        "name": "Character-Based Model",
        "year": 2019,
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblems"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Encoder-Decoder",
            "Stack-Decoder",
            "Semantic Transformer-Decoder"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Gating Mechanism",
            "Semantic Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Postfix Equation Transformation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Character-Level Embedding",
          "Constant Representation Extraction",
          "External Constant Leveraging"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2019_ConstantEmbeddingAnalysis",
        "entity_type": "Algorithm",
        "name": "Constant Embedding Analysis",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": 2019,
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblems"
        ],
        "architecture": {
          "components": [
            "Self-Attention Mechanism",
            "Semantic Representations"
          ],
          "connections": [
            "Encoder-Decoder Framework"
          ],
          "mechanisms": [
            "Semantic Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden State Size"
          ]
        },
        "feature_processing": [
          "Self-Attention on Constants"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2019_DecodingProcessVisualization",
        "entity_type": "Algorithm",
        "name": "Decoding Process Visualization",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": 2019,
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblems"
        ],
        "architecture": {
          "components": [
            "Attention Mechanism",
            "Gating Mechanisms"
          ],
          "connections": [
            "Encoder-Decoder Framework"
          ],
          "mechanisms": [
            "Semantic Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden State Size"
          ]
        },
        "feature_processing": [
          "Attention Map Visualization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Knuth1968_ContextFreeLanguagesAlgorithm",
        "entity_type": "Algorithm",
        "name": "Context-Free Languages Algorithm",
        "year": 1968,
        "authors": [
          "KNUTH, D.E."
        ],
        "task": "Derivation Tree Analysis",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Directed Graph Construction"
          ],
          "connections": [
            "Vertices and Arcs"
          ],
          "mechanisms": [
            "Addition of Directed Graphs"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_SequenceToSequenceLearning",
        "entity_type": "Algorithm",
        "name": "Sequence to Sequence Learning with Neural Networks",
        "title": "Sequence to Sequence Learning with Neural Networks",
        "year": 2014,
        "authors": [
          "Ilya Sutskever",
          "Oriol Vinyals",
          "Quoc V. Le"
        ],
        "task": "Machine Translation",
        "dataset": [
          "WMT-14 English to French"
        ],
        "metrics": [
          "BLEU score"
        ],
        "architecture": {
          "components": [
            "Multilayered LSTM",
            "Deep LSTM"
          ],
          "connections": [
            "Input sequence to fixed-dimensional vector",
            "Fixed-dimensional vector to output sequence"
          ],
          "mechanisms": [
            "Long Short-Term Memory",
            "Reversed source sentences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised backpropagation",
            "Left-to-right beam-search decoder"
          ],
          "parameter_tuning": [
            "4-layer LSTM",
            "1000 cells per layer",
            "1000-dimensional word embeddings",
            "Batch size of 128",
            "Fixed learning rate of 0.7"
          ]
        },
        "feature_processing": [
          "Reversing the order of words in source sentences"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT-14_English_to_French_2014",
        "entity_type": "Dataset",
        "name": "WMT-14 English to French",
        "description": "A dataset for English to French translation task",
        "domain": "Natural Language Processing",
        "size": 12000000,
        "year": 2014,
        "creators": [
          "WMT"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_score_Translation",
        "entity_type": "Metric",
        "name": "BLEU score",
        "description": "A method for automatic evaluation of machine translation",
        "category": "Translation Evaluation",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kalchbrenner2013_RecurrentContinuousTranslationModels",
        "entity_type": "Algorithm",
        "name": "Recurrent Continuous Translation Models",
        "year": 2013,
        "authors": [
          "Kalchbrenner, N.",
          "Blunsom, P."
        ],
        "task": "Machine Translation",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Convolutional Neural Networks",
            "Recurrent Neural Networks"
          ],
          "connections": [
            "Input to Vector",
            "Vector to Output"
          ],
          "mechanisms": [
            "Mapping sentences to vectors"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training"
          ],
          "parameter_tuning": [
            "Hyperparameters tuning"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bahdanau2014_NeuralMachineTranslation",
        "entity_type": "Algorithm",
        "name": "Neural Machine Translation with Attention Mechanism",
        "year": 2014,
        "authors": [
          "Bahdanau, D.",
          "Cho, K.",
          "Bengio, Y."
        ],
        "task": "Machine Translation",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Attention Mechanism",
            "Recurrent Neural Networks"
          ],
          "connections": [
            "Input to Attention",
            "Attention to Output"
          ],
          "mechanisms": [
            "Jointly learning to align and translate"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training"
          ],
          "parameter_tuning": [
            "Hyperparameters tuning"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_RNN_Encoder_Decoder",
        "entity_type": "Algorithm",
        "name": "RNN Encoder-Decoder",
        "year": 2014,
        "authors": [
          "Cho, K.",
          "Merrienboer, B.",
          "Gulcehre, C.",
          "Bougares, F.",
          "Schwenk, H.",
          "Bengio, Y."
        ],
        "task": "Machine Translation",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Networks"
          ],
          "connections": [
            "Encoder to Decoder"
          ],
          "mechanisms": [
            "Phrase representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training"
          ],
          "parameter_tuning": [
            "Hyperparameters tuning"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Baseline_SMT_System_2014",
        "entity_type": "Dataset",
        "name": "Baseline SMT System",
        "year": 2014,
        "creators": [
          "Schwenk, H."
        ],
        "domain": "Machine Translation",
        "description": "A phrase-based statistical machine translation system used as a baseline for comparison.",
        "size": "Not specified",
        "tasks": [
          "Machine Translation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_score_37_0",
        "entity_type": "Metric",
        "name": "BLEU Score",
        "year": 2014,
        "category": "Translation Evaluation",
        "description": "A method for automatic evaluation of machine translation.",
        "formula": "Not specified"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_DeepLSTM",
        "entity_type": "Algorithm",
        "name": "Deep LSTM",
        "year": 2014,
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q. V."
        ],
        "task": "Sequence to Sequence Translation",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Input LSTM",
            "Output LSTM"
          ],
          "connections": [
            "Fixed-dimensional vector representation",
            "Recurrent connections"
          ],
          "mechanisms": [
            "Long Short-Term Memory",
            "Backpropagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "Fixed learning rate",
            "Batch normalization"
          ],
          "parameter_tuning": [
            "Learning rate decay",
            "Gradient clipping"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Reversed source sentences"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_BeamSearchDecoder",
        "entity_type": "Algorithm",
        "name": "Beam Search Decoder",
        "year": 2014,
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q. V."
        ],
        "task": "Sequence to Sequence Translation",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "Left-to-right decoding"
          ],
          "connections": [
            "Partial hypotheses",
            "Log probability"
          ],
          "mechanisms": [
            "Beam pruning",
            "End-of-sentence token"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Approximate decoding",
            "Simple implementation"
          ],
          "parameter_tuning": [
            "Beam size"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_SentenceRepresentation",
        "entity_type": "Algorithm",
        "name": "Sentence Representation",
        "year": 2014,
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q. V."
        ],
        "task": "Sequence to Sequence Translation",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Fixed-dimensional vector",
            "Hidden states"
          ],
          "connections": [
            "Input sequence",
            "Output sequence"
          ],
          "mechanisms": [
            "PCA projection",
            "Word order sensitivity"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mapping sequences to vectors",
            "Training on reversed sentences"
          ],
          "parameter_tuning": [
            "Vocabulary size"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Auli2013_JointLanguageAndTranslationModeling",
        "entity_type": "Algorithm",
        "name": "Joint Language and Translation Modeling with Recurrent Neural Networks",
        "year": 2013,
        "authors": [
          "M. Auli",
          "M. Galley",
          "C. Quirk",
          "G. Zweig"
        ],
        "task": "Statistical Machine Translation",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Networks",
            "Topic Model"
          ],
          "connections": [
            "Input Sentence to Topic Model",
            "Topic Model to Neural Network"
          ],
          "mechanisms": [
            "Joint Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rescoring n-best Lists"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Topic Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Devlin2014_FastAndRobustNeuralNetworkJointModels",
        "entity_type": "Algorithm",
        "name": "Fast and Robust Neural Network Joint Models for Statistical Machine Translation",
        "year": 2014,
        "authors": [
          "J. Devlin",
          "R. Zbib",
          "Z. Huang",
          "T. Lamar",
          "R. Schwartz",
          "J. Makhoul"
        ],
        "task": "Statistical Machine Translation",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Decoder"
          ],
          "connections": [
            "Input Sentence to Decoder",
            "Decoder to Neural Network"
          ],
          "mechanisms": [
            "Alignment Information"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rescoring n-best Lists"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Alignment Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "PougetAbadie2014_AutomaticSegmentation",
        "entity_type": "Algorithm",
        "name": "Overcoming the Curse of Sentence Length for Neural Machine Translation Using Automatic Segmentation",
        "year": 2014,
        "authors": [
          "J. Pouget-Abadie",
          "D. Bahdanau",
          "B. van Merrienboer",
          "K. Cho",
          "Y. Bengio"
        ],
        "task": "Neural Machine Translation",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Segmentation"
          ],
          "connections": [
            "Input Sentence to Segmentation Module",
            "Segmentation Module to Neural Network"
          ],
          "mechanisms": [
            "Automatic Segmentation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rescoring n-best Lists"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Segmentation Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hermann2014_MultilingualDistributedRepresentations",
        "entity_type": "Algorithm",
        "name": "Multilingual Distributed Representations Without Word Alignment",
        "year": 2014,
        "authors": [
          "K. M. Hermann",
          "P. Blunsom"
        ],
        "task": "Multilingual Representation Learning",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Feedforward Networks"
          ],
          "connections": [
            "Input Sentence to Feedforward Network"
          ],
          "mechanisms": [
            "Distributed Representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_SimpleLSTMApproach",
        "entity_type": "Algorithm",
        "name": "Simple LSTM Approach",
        "year": 2014,
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q. V."
        ],
        "task": "Machine Translation",
        "dataset": [
          "WMT-14 English to French"
        ],
        "metrics": [
          "BLEU score"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder"
          ],
          "connections": [
            "Fixed-dimensional Vector Representation"
          ],
          "mechanisms": [
            "Reversed Input Sentences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end Training"
          ],
          "parameter_tuning": [
            "Limited Vocabulary"
          ]
        },
        "feature_processing": [
          "Word Order Sensitivity",
          "Active/Passive Voice Invariance"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wiseman2016_BeamSearchOptimization",
        "entity_type": "Algorithm",
        "name": "Beam Search Optimization (BSO)",
        "year": 2016,
        "authors": [
          "Sam Wiseman",
          "Alexander M. Rush"
        ],
        "task": "Sequence-to-Sequence Learning",
        "dataset": [
          "Word Ordering",
          "Dependency Parsing",
          "Machine Translation"
        ],
        "metrics": [
          "BLEU Score",
          "UAS",
          "LAS"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network (RNN)",
            "Long Short-Term Memory (LSTM)",
            "Global Attention Model"
          ],
          "connections": [
            "Encoder-Decoder Architecture"
          ],
          "mechanisms": [
            "Beam Search",
            "LaSO Framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Training",
            "Curriculum Beam Strategy",
            "Pre-training with Cross-Entropy Loss"
          ],
          "parameter_tuning": [
            "Mini-batch Adagrad",
            "Gradient Renormalization",
            "Learning Rates"
          ]
        },
        "feature_processing": [
          "Input Feeding",
          "Dropout Regularization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PTB_2015",
        "entity_type": "Dataset",
        "name": "Penn Treebank (PTB)",
        "description": "Standard dataset for parsing and word ordering tasks",
        "domain": "Natural Language Processing",
        "year": 2015,
        "creators": [
          "Zhang, Y.",
          "Clark, S."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IWSLT2014_GermanToEnglish",
        "entity_type": "Dataset",
        "name": "IWSLT 2014 German-to-English",
        "description": "Dataset for machine translation from German to English",
        "domain": "Machine Translation",
        "year": 2014,
        "creators": [
          "Cettolo, M.",
          "Niehues, J.",
          "Stüker, S.",
          "Bentivogli, L.",
          "Federico, M."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_SentenceLevel",
        "entity_type": "Metric",
        "name": "BLEU Score",
        "description": "Evaluation metric for machine translation and word ordering",
        "category": "Sequence-Level Evaluation",
        "formula": "Smoothed, sentence-level BLEU score"
      }
    },
    {
      "metric_entity": {
        "metric_id": "UAS_Parsing",
        "entity_type": "Metric",
        "name": "UAS",
        "description": "Unlabeled Attachment Score for dependency parsing",
        "category": "Parsing Evaluation",
        "formula": "Percentage of correct head-word attachments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "LAS_Parsing",
        "entity_type": "Metric",
        "name": "LAS",
        "description": "Labeled Attachment Score for dependency parsing",
        "category": "Parsing Evaluation",
        "formula": "Percentage of correct head-word attachments with correct labels"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "DaumeIII2005_LearningAsSearchOptimization",
        "entity_type": "Algorithm",
        "name": "Learning as Search Optimization (LaSO)",
        "year": 2005,
        "authors": [
          "Daume III, H.",
          "Marcu, D."
        ],
        "task": "Structured Prediction",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "Custom Loss Functions"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "Non-probabilistic Scoring Function"
          ],
          "connections": [
            "RNN Decoder"
          ],
          "mechanisms": [
            "Margin Loss",
            "Beam Search Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Training",
            "LaSO Framework"
          ],
          "parameter_tuning": [
            "Beam Size",
            "Loss Function Parameters"
          ]
        },
        "feature_processing": [
          "Hard Constraints on Successor Sequences"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ranzato2016_SequenceLevelTraining",
        "entity_type": "Algorithm",
        "name": "Sequence Level Training with Recurrent Neural Networks",
        "year": 2016,
        "authors": [
          "Ranzato, M.A.",
          "Chopra, S.",
          "Auli, M.",
          "Zaremba, W."
        ],
        "task": "Sequence Prediction",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "BLEU Score"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network",
            "Actor-Critic"
          ],
          "connections": [
            "Policy Gradient"
          ],
          "mechanisms": [
            "Scheduled Sampling",
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Policy Gradient",
            "Scheduled Sampling"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Beam Size"
          ]
        },
        "feature_processing": [
          "Sequence-Level Cost Functions"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_SequenceToSequence",
        "entity_type": "Algorithm",
        "name": "Sequence-to-Sequence Learning with Neural Networks",
        "year": 2014,
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q.V."
        ],
        "task": "Sequence Generation",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "Perplexity",
          "BLEU Score"
        ],
        "architecture": {
          "components": [
            "Encoder-Decoder",
            "RNN"
          ],
          "connections": [
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Conditional Language Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Word-Level Cross-Entropy Loss"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_SentenceLevel_Smoothed",
        "entity_type": "Metric",
        "name": "Smoothed Sentence-Level BLEU",
        "year": 2014,
        "description": "A smoothed version of the BLEU score for evaluating sentence-level translation quality.",
        "category": "Machine Translation Evaluation",
        "formula": "Smoothed BLEU = (BP * exp(Σ(wn * log pn)))"
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_PartialSentence",
        "entity_type": "Metric",
        "name": "Partial Sentence-Level BLEU",
        "year": 2002,
        "description": "A BLEU score calculated on partial sentences during training or evaluation.",
        "category": "Machine Translation Evaluation",
        "formula": "Partial BLEU = (BP * exp(Σ(wn * log pn))) for partial sentences"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2011_NeuralLanguageModel",
        "entity_type": "Algorithm",
        "name": "Neural Language Model",
        "year": 2011,
        "authors": [
          "Sutskever, I.",
          "Martens, J.",
          "Hinton, G.E."
        ],
        "task": "Text Generation",
        "dataset": [
          "Various Text Corpora"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network (RNN)",
            "Softmax Layer"
          ],
          "connections": [
            "Sequential Word Generation"
          ],
          "mechanisms": [
            "Conditional Probability Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Cross-Entropy Loss"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Filippova2015_SentenceCompression",
        "entity_type": "Algorithm",
        "name": "Sentence Compression",
        "year": 2015,
        "authors": [
          "Filippova, K.",
          "Alfonseca, E.",
          "Colmenares, C.A.",
          "Kaiser, L.",
          "Vinyals, O."
        ],
        "task": "Sentence Compression",
        "dataset": [
          "Various Text Corpora"
        ],
        "metrics": [
          "ROUGE"
        ],
        "architecture": {
          "components": [
            "LSTM"
          ],
          "connections": [
            "Sequential Deletion"
          ],
          "mechanisms": [
            "Deletion with LSTMs"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross-Entropy Loss"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Vinyals2015_GrammarAsForeignLanguage",
        "entity_type": "Algorithm",
        "name": "Grammar as a Foreign Language",
        "year": 2015,
        "authors": [
          "Vinyals, O.",
          "Kaiser, L.",
          "Koo, T.",
          "Petrov, S.",
          "Sutskever, I.",
          "Hinton, G."
        ],
        "task": "Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "UAS",
          "LAS"
        ],
        "architecture": {
          "components": [
            "Encoder-Decoder Framework",
            "Attention Layer"
          ],
          "connections": [
            "Sequential Parsing"
          ],
          "mechanisms": [
            "Grammar Encoding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross-Entropy Loss"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Serban2016_DialogueSystems",
        "entity_type": "Algorithm",
        "name": "Dialogue Systems",
        "year": 2016,
        "authors": [
          "Serban, I.V.",
          "Sordoni, A.",
          "Bengio, Y.",
          "Courville, A.C.",
          "Pineau, J."
        ],
        "task": "Dialogue Generation",
        "dataset": [
          "Various Dialogue Corpora"
        ],
        "metrics": [
          "BLEU",
          "ROUGE"
        ],
        "architecture": {
          "components": [
            "Hierarchical Neural Network"
          ],
          "connections": [
            "Sequential Dialogue Generation"
          ],
          "mechanisms": [
            "Generative Hierarchical Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross-Entropy Loss"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wiseman2016_ConstrainedBeamSearchOptimization",
        "entity_type": "Algorithm",
        "name": "Constrained Beam Search Optimization (ConBSO)",
        "year": 2016,
        "authors": [
          "Wiseman, S.",
          "Rush, A.M."
        ],
        "task": "Sequence-to-Sequence Learning",
        "dataset": [
          "PTB_2015",
          "IWSLT2014_GermanToEnglish"
        ],
        "metrics": [
          "BLEU_SentenceLevel",
          "UAS_Parsing",
          "LAS_Parsing"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder",
            "Global Attention Model"
          ],
          "connections": [
            "Input Feeding",
            "Beam Search"
          ],
          "mechanisms": [
            "Hard Constraints",
            "Sequence-Level Scoring"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Optimization",
            "Curriculum Beam Strategy"
          ],
          "parameter_tuning": [
            "Pre-training with Cross-Entropy Loss",
            "Mini-batch Adagrad",
            "Gradient Renormalization"
          ]
        },
        "feature_processing": [
          "Word Embeddings Initialization",
          "Digit Normalization",
          "Singleton Words Replacement"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2015_GlobalAttentionModel",
        "entity_type": "Algorithm",
        "name": "Global Attention Model",
        "year": 2015,
        "authors": [
          "Luong, T.",
          "Pham, H.",
          "Manning, C.D."
        ],
        "task": "Sequence-to-Sequence Learning",
        "dataset": [
          "PTB_2015",
          "IWSLT2014_GermanToEnglish"
        ],
        "metrics": [
          "BLEU_SentenceLevel",
          "UAS_Parsing",
          "LAS_Parsing"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder"
          ],
          "connections": [
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Global Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Standard Seq2Seq Training"
          ],
          "parameter_tuning": [
            "Mini-batch Adagrad"
          ]
        },
        "feature_processing": [
          "Word Embeddings Initialization",
          "Digit Normalization",
          "Singleton Words Replacement"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Srivastava2014_Dropout",
        "entity_type": "Algorithm",
        "name": "Dropout",
        "year": 2014,
        "authors": [
          "Srivastava, N.",
          "Hinton, G.",
          "Krizhevsky, A.",
          "Sutskever, I.",
          "Salakhutdinov, R."
        ],
        "task": "Regularization",
        "architecture": {
          "components": [
            "Dropout Layer"
          ],
          "connections": [
            "Randomly Dropping Units"
          ],
          "mechanisms": [
            "Preventing Overfitting"
          ]
        }
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duchi2011_AdaptiveSubgradientMethods",
        "entity_type": "Algorithm",
        "name": "Adaptive Subgradient Methods (AdaGrad)",
        "year": 2011,
        "authors": [
          "Duchi, J.",
          "Hazan, E.",
          "Singer, Y."
        ],
        "task": "Optimization",
        "architecture": {
          "components": [
            "Parameter Updates"
          ],
          "connections": [
            "Adaptive Learning Rates"
          ],
          "mechanisms": [
            "Accumulating Squared Gradients"
          ]
        }
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2015_InputFeeding",
        "entity_type": "Algorithm",
        "name": "Input Feeding",
        "year": 2015,
        "authors": [
          "Luong, T.",
          "Pham, H.",
          "Manning, C.D."
        ],
        "task": "Neural Machine Translation",
        "dataset": [
          "IWSLT2014_GermanToEnglish"
        ],
        "metrics": [
          "BLEU_SentenceLevel"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder",
            "Attention Mechanism"
          ],
          "connections": [
            "Input Feeding from Attention Distribution"
          ],
          "mechanisms": [
            "Attention Distribution Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Standard Word-Level Cross-Entropy Loss"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Gradient Clipping"
          ]
        },
        "feature_processing": [
          "Attention Distribution from Previous Time-Step"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PTB_2015_WordOrdering",
        "entity_type": "Dataset",
        "name": "PTB Word Ordering",
        "year": 2015,
        "creators": [
          "Zhang, Y.",
          "Clark, S."
        ],
        "domain": "Natural Language Processing",
        "size": "Varies",
        "description": "Penn Treebank dataset used for word ordering experiments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_Permutation",
        "entity_type": "Metric",
        "name": "BLEU Score for Permutations",
        "description": "BLEU score calculated for permutations of word sequences",
        "category": "Word Ordering Evaluation",
        "formula": "BLEU score for correctly ordered sentences"
      }
    },
    {
      "metric_entity": {
        "metric_id": "UAS_ConstrainedParsing",
        "entity_type": "Metric",
        "name": "UAS for Constrained Parsing",
        "description": "Unlabeled Attachment Score for parsing with constraints",
        "category": "Dependency Parsing Evaluation",
        "formula": "Percentage of correct head-word attachments excluding punctuation"
      }
    },
    {
      "metric_entity": {
        "metric_id": "LAS_ConstrainedParsing",
        "entity_type": "Metric",
        "name": "LAS for Constrained Parsing",
        "description": "Labeled Attachment Score for parsing with constraints",
        "category": "Dependency Parsing Evaluation",
        "formula": "Percentage of correct head-word attachments with correct labels excluding punctuation"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "StanfordDependencies_2014",
        "entity_type": "Dataset",
        "name": "Stanford Dependencies",
        "year": 2014,
        "creators": [
          "Chen, D.",
          "Manning, C.D."
        ],
        "domain": "Natural Language Processing",
        "size": "Varies",
        "description": "Dependency parsing dataset with Stanford dependency labels"
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_SentenceBLEUCost",
        "entity_type": "Metric",
        "name": "Sentence BLEU Cost",
        "description": "Cost function based on sentence-level BLEU score",
        "category": "Machine Translation Evaluation",
        "formula": "1 - smoothed sentence-level BLEU score"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IWSLT2014_TEDTalks",
        "entity_type": "Dataset",
        "name": "IWSLT 2014 TED Talks",
        "year": 2014,
        "creators": [
          "Cettolo, M.",
          "Niehues, J.",
          "Stüker, S.",
          "Bentivogli, L.",
          "Federico, M."
        ],
        "domain": "Machine Translation",
        "size": "153K training sentences, 7K development sentences, 7K test sentences",
        "description": "Dataset from translated TED talks for German-to-English machine translation"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_SimpleCoreferenceResolution",
        "entity_type": "Algorithm",
        "name": "Simple Coreference Resolution",
        "title": "Simple Coreference Resolution with Rich Syntactic and Semantic Features",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST",
          "BLIPP",
          "WIKI"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module",
            "Selection Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists Extraction",
            "Tree Distance Minimization"
          ],
          "mechanisms": [
            "Syntactic Constraints",
            "Semantic Compatibility Filtering",
            "Selection of Closest Compatible Mention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning",
            "Deterministic Function of Rich Features"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Lists Extraction",
          "Appositive Annotation",
          "Predicate Nominative Annotation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-ROTH-DEV_2009",
        "entity_type": "Dataset",
        "name": "ACE2004-ROTH-DEV",
        "description": "Development set split of the ACE 2004 training set",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": 2009,
        "creators": [
          "Bengston and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-CULOTTA-TEST_2009",
        "entity_type": "Dataset",
        "name": "ACE2004-CULOTTA-TEST",
        "description": "Test set split of the ACE 2004 training set",
        "domain": "Natural Language Processing",
        "size": 107,
        "year": 2009,
        "creators": [
          "Culotta et al.",
          "Bengston and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-NWIRE_2009",
        "entity_type": "Dataset",
        "name": "ACE2004-NWIRE",
        "description": "ACE 2004 Newswire set",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": 2009,
        "creators": [
          "Poon and Domingos"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MUC-6-TEST_2009",
        "entity_type": "Dataset",
        "name": "MUC-6-TEST",
        "description": "MUC6 formal evaluation set",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": 2009,
        "creators": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "BLIPP_2009",
        "entity_type": "Dataset",
        "name": "BLIPP",
        "description": "1.8 million sentences of newswire parsed with the Charniak parser",
        "domain": "Natural Language Processing",
        "size": 1800000,
        "year": 2009,
        "creators": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WIKI_2009",
        "entity_type": "Dataset",
        "name": "WIKI",
        "description": "25k articles of English Wikipedia abstracts parsed by the Klein and Manning parser",
        "domain": "Natural Language Processing",
        "size": 25000,
        "year": 2009,
        "creators": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_F1_Coreference",
        "entity_type": "Metric",
        "name": "Pairwise F1",
        "description": "Precision, recall, and F1 over all pairs of mentions in the same entity cluster",
        "category": "Coreference Evaluation",
        "formula": "F1 = 2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "b3_Coreference",
        "entity_type": "Metric",
        "name": "b3",
        "description": "For each mention, form the intersection between the predicted cluster and the true cluster for that mention",
        "category": "Coreference Evaluation",
        "formula": "F1 = 2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "CEAF_Coreference",
        "entity_type": "Metric",
        "name": "CEAF",
        "description": "Scores the best match between true and predicted clusters using a similarity function",
        "category": "Coreference Evaluation",
        "formula": "Best match score using φ3 similarity function"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_SyntacticSemanticCoreference",
        "entity_type": "Algorithm",
        "name": "Syntactic and Semantic Coreference Resolution",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module",
            "Selection Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists Extraction",
            "Tree Distance Minimization"
          ],
          "mechanisms": [
            "Deterministic Syntactic Constraints",
            "Semantic Compatibility Filtering",
            "Closest Mention Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning from Unlabeled Corpus"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Recall_F1_Coreference",
        "entity_type": "Metric",
        "name": "Precision, Recall, F1",
        "description": "Evaluation metrics for coreference resolution",
        "category": "Coreference Evaluation",
        "formula": "Precision = TP / (TP + FP), Recall = TP / (TP + FN), F1 = 2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Entity_Type_Agreement",
        "entity_type": "Metric",
        "name": "Entity Type Agreement",
        "description": "Agreement in entity type between coreferent mentions",
        "category": "Coreference Evaluation",
        "formula": "Based on NER labels"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Number_Agreement",
        "entity_type": "Metric",
        "name": "Number Agreement",
        "description": "Agreement in number between coreferent mentions",
        "category": "Coreference Evaluation",
        "formula": "Based on head and POS tag"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Person_Agreement",
        "entity_type": "Metric",
        "name": "Person Agreement",
        "description": "Agreement in person between coreferent mentions",
        "category": "Coreference Evaluation",
        "formula": "Based on linguistic theory"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_AppositiveConstraint",
        "entity_type": "Algorithm",
        "name": "Appositive Constraint",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Appositive Annotation",
            "Coreference Constraint"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_PredicateNominativeConstraint",
        "entity_type": "Algorithm",
        "name": "Predicate Nominative Constraint",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Predicate Nominative Annotation",
            "Coreference Constraint"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Coreference",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Coreference Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Coreference",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Proportion of true positive coreference links among all predicted links",
        "category": "Coreference Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Coreference",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Proportion of true positive coreference links among all actual links",
        "category": "Coreference Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_SyntacticSalience",
        "entity_type": "Algorithm",
        "name": "Syntactic Salience",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Syntactic Paths",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Tree Distance Minimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_AgreementConstraints",
        "entity_type": "Algorithm",
        "name": "Agreement Constraints",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Number Feature Assignment",
            "NER Labeling"
          ],
          "mechanisms": [
            "Person, Number, and Entity Type Agreement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_SyntacticConfigurationConstraints",
        "entity_type": "Algorithm",
        "name": "Syntactic Configuration Constraints",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Appositive Annotation",
            "i-within-i Constraint"
          ],
          "mechanisms": [
            "NP Appositive Annotation",
            "Role Appositives"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_SemanticKnowledgeExtraction",
        "entity_type": "Algorithm",
        "name": "Semantic Knowledge Extraction",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "BLIPP",
          "WIKI"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Tree Fragments Extraction",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Bootstrapping Technique",
            "Coreference Patterns"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_DeterministicCoreference",
        "entity_type": "Algorithm",
        "name": "Deterministic Coreference Resolution",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module",
            "Selection Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists",
            "Tree Distance Minimization"
          ],
          "mechanisms": [
            "Syntactic Constraints",
            "Semantic Compatibility",
            "Deterministic Decision Making"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning",
            "Treebank Parsing"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2016_ExpressionTreeBasedSolver",
        "entity_type": "Algorithm",
        "name": "Expression Tree Based Solver",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2016,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2 Dataset",
          "IL Dataset",
          "Commoncore Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Monotonic Expression Tree",
            "Quantity Schema"
          ],
          "connections": [
            "Decomposition Strategy",
            "Constrained Inference Framework"
          ],
          "mechanisms": [
            "LCA Operation Prediction",
            "Relevance Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Multiclass SVM",
            "Binary SVM"
          ],
          "parameter_tuning": [
            "wIRR"
          ]
        },
        "feature_processing": [
          "Unit Features",
          "Related NP Features",
          "Miscellaneous Features",
          "Question Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AI2_Dataset_2014",
        "entity_type": "Dataset",
        "name": "AI2 Dataset",
        "description": "A collection of 395 addition and subtraction problems",
        "domain": "Arithmetic Word Problems",
        "size": 395,
        "year": 2014,
        "creators": [
          "M. J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IL_Dataset_2015",
        "entity_type": "Dataset",
        "name": "IL Dataset",
        "description": "A collection of arithmetic problems that can be solved by performing one operation",
        "domain": "Arithmetic Word Problems",
        "size": 562,
        "year": 2015,
        "creators": [
          "S. Roy",
          "T. Vieira",
          "D. Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Commoncore_Dataset_2016",
        "entity_type": "Dataset",
        "name": "Commoncore Dataset",
        "description": "A new dataset of multi-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 600,
        "year": 2016,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_VerbCategoryBasedSolver",
        "entity_type": "Algorithm",
        "name": "Verb Category Based Solver",
        "year": 2014,
        "authors": [
          "M. J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Verb Categorization",
            "Addition/Subtraction Operations"
          ],
          "connections": [
            "Dependency Parsing",
            "Verb Classification"
          ],
          "mechanisms": [
            "Feature Extraction from Text"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Verb Category Labels"
          ]
        },
        "feature_processing": [
          "Verb Categorization Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_PipelineClassifiers",
        "entity_type": "Algorithm",
        "name": "Pipeline Classifiers",
        "year": 2015,
        "authors": [
          "S. Roy",
          "T. Vieira",
          "D. Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "IL_Dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multiple Classifiers"
          ],
          "connections": [
            "Sequential Processing"
          ],
          "mechanisms": [
            "Feature Extraction from Text"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Classifier Parameters"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Neighborhood Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2016_MonotonicExpressionTree",
        "entity_type": "Algorithm",
        "name": "Monotonic Expression Tree",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2016,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2_Dataset_2014",
          "IL_Dataset_2015",
          "Commoncore_Dataset_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Monotonic Property",
            "LCA Node"
          ],
          "connections": [
            "Leaf Nodes to Internal Nodes",
            "Internal Nodes to Root"
          ],
          "mechanisms": [
            "Decomposition Strategy",
            "Constrained Inference Framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Multiclass Classification",
            "Binary Classification"
          ],
          "parameter_tuning": [
            "wIRR"
          ]
        },
        "feature_processing": [
          "Quantity Schemas",
          "Dependency Parsing",
          "Shallow Parsing"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "PositiveAnswer_Constraint",
        "entity_type": "Metric",
        "name": "Positive Answer",
        "description": "Ensures the answer is a positive number",
        "category": "Arithmetic Problem Constraints",
        "formula": "Reject expressions generating negative answer"
      }
    },
    {
      "metric_entity": {
        "metric_id": "IntegralAnswer_Constraint",
        "entity_type": "Metric",
        "name": "Integral Answer",
        "description": "Ensures the answer is an integer",
        "category": "Arithmetic Problem Constraints",
        "formula": "Only consider integral solutions as legitimate outputs"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2016_RelevanceClassifier",
        "entity_type": "Algorithm",
        "name": "Relevance Classifier",
        "year": 2016,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2_Dataset_2014",
          "IL_Dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary SVM Classifier"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Gold Annotations"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Unit Features",
          "Related NP Features",
          "Miscellaneous Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2016_LCAOperationClassifier",
        "entity_type": "Algorithm",
        "name": "LCA Operation Classifier",
        "year": 2016,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2_Dataset_2014",
          "IL_Dataset_2015",
          "Commoncore_Dataset_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multi-class SVM Classifier"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Gold Annotations"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Individual Quantity Features",
          "Quantity Pair Features",
          "Question Features"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Relax_Accuracy",
        "entity_type": "Metric",
        "name": "Relax Accuracy",
        "description": "Fraction of quantities or quantity pairs correctly predicted",
        "category": "Classification Evaluation",
        "formula": "Correct Predictions / Total Predictions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Strict_Accuracy",
        "entity_type": "Metric",
        "name": "Strict Accuracy",
        "description": "Fraction of math problems for which all quantities or quantity pairs were correctly classified",
        "category": "Classification Evaluation",
        "formula": "Correctly Classified Problems / Total Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2016_GlobalInferenceModule",
        "entity_type": "Algorithm",
        "name": "Global Inference Module",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2016,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AI2 Dataset",
          "IL Dataset",
          "Commoncore Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Scoring Functions",
            "Beam Search",
            "Constrained Optimization"
          ],
          "connections": [
            "PAIR Scoring Function",
            "IRR Scoring Function"
          ],
          "mechanisms": [
            "Monotonic Expression Trees",
            "Quantity Schemas"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-validation"
          ],
          "parameter_tuning": [
            "wIRR"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Beam Search Pruning"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_SolvingArithmeticProblems",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correctly solved arithmetic word problems",
        "category": "Arithmetic Problem Solving Evaluation",
        "formula": "Number of Correct Solutions / Total Number of Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2015_GEOS",
        "entity_type": "Algorithm",
        "name": "GEOS",
        "title": "Solving Geometry Problems: Combining Text and Diagram Interpretation",
        "year": 2015,
        "authors": [
          "Minjoon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni",
          "Clint Malcolm"
        ],
        "task": "Solving SAT-level geometry problems",
        "dataset": [
          "SAT Geometry Questions_2015"
        ],
        "metrics": [
          "Accuracy_Classification",
          "F1_Score"
        ],
        "architecture": {
          "components": [
            "Text Parsing",
            "Diagram Parsing",
            "Relation Identification",
            "Relation Completion",
            "Optimization",
            "Solver"
          ],
          "connections": [
            "Text Parsing -> Relation Identification -> Relation Completion -> Optimization -> Solver",
            "Diagram Parsing -> Optimization -> Solver"
          ],
          "mechanisms": [
            "Submodular Optimization",
            "Greedy Maximization",
            "Logical Representation",
            "Geometric Solver"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Rule-based Parsing"
          ],
          "parameter_tuning": [
            "λ (trade-off parameter)",
            "Threshold for text scores"
          ]
        },
        "feature_processing": [
          "Concept Identification",
          "Relation Identification",
          "Relation Completion",
          "Intermediate Representation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SAT_Geometry_Questions_2015",
        "entity_type": "Dataset",
        "name": "SAT Geometry Questions",
        "description": "A dataset of SAT plane geometry questions with textual descriptions and diagrams",
        "domain": "Geometry",
        "size": 186,
        "year": 2015,
        "creators": [
          "Minjoon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni",
          "Clint Malcolm"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2015_LogicalExpressionDerivation",
        "entity_type": "Algorithm",
        "name": "Logical Expression Derivation",
        "year": 2015,
        "authors": [
          "Seo, M.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O.",
          "Malcolm, C."
        ],
        "task": "Geometry Problem Solving",
        "dataset": [
          "SAT_Geometry_Questions_2015"
        ],
        "metrics": [
          "Accuracy_Classification",
          "F1_Score"
        ],
        "architecture": {
          "components": [
            "Text Parsing",
            "Diagram Parsing",
            "Literal Selection"
          ],
          "connections": [
            "Text-Diagram Integration",
            "Submodular Optimization"
          ],
          "mechanisms": [
            "Hypergraph Representation",
            "Log-linear Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Submodular Optimization"
          ],
          "parameter_tuning": [
            "Trade-off Parameter λ"
          ]
        },
        "feature_processing": [
          "Concept Identification",
          "Relation Identification",
          "Relation Completion"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Text_Interpretation",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Precision of text interpretation",
        "category": "Text Interpretation Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Text_Interpretation",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Recall of text interpretation",
        "category": "Text Interpretation Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Text_Interpretation",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 Score of text interpretation",
        "category": "Text Interpretation Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zettlemoyer2005_SentenceToLogicalForm",
        "entity_type": "Algorithm",
        "name": "SentenceToLogicalForm",
        "year": 2005,
        "authors": [
          "Zettlemoyer, L.S.",
          "Collins, M."
        ],
        "task": "Mapping sentences to logical form",
        "dataset": [
          "None specified"
        ],
        "metrics": [
          "None specified"
        ],
        "architecture": {
          "components": [
            "Probabilistic Categorial Grammars"
          ],
          "connections": [
            "None specified"
          ],
          "mechanisms": [
            "Structured classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None specified"
          ],
          "parameter_tuning": [
            "None specified"
          ]
        },
        "feature_processing": [
          "None specified"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Berant2013_SemanticParsingOnFreebase",
        "entity_type": "Algorithm",
        "name": "SemanticParsingOnFreebase",
        "year": 2013,
        "authors": [
          "Berant, J.",
          "Chou, A.",
          "Frostig, R.",
          "Liang, P."
        ],
        "task": "Semantic parsing on Freebase",
        "dataset": [
          "Question-answer pairs"
        ],
        "metrics": [
          "None specified"
        ],
        "architecture": {
          "components": [
            "None specified"
          ],
          "connections": [
            "None specified"
          ],
          "mechanisms": [
            "None specified"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None specified"
          ],
          "parameter_tuning": [
            "None specified"
          ]
        },
        "feature_processing": [
          "None specified"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "EMNLP_Corpora_2014",
        "entity_type": "Dataset",
        "name": "EMNLP Corpora",
        "year": 2014,
        "creators": [
          "Various authors"
        ],
        "domain": "Natural Language Processing",
        "size": "Not specified",
        "description": "Corpora used in EMNLP conference papers"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Dependency_Parsing_Accuracy",
        "entity_type": "Metric",
        "name": "Dependency Parsing Accuracy",
        "description": "Accuracy of dependency parsing",
        "category": "Parsing Evaluation",
        "formula": "Correct parses / Total parses"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2015_HypergraphRepresentation",
        "entity_type": "Algorithm",
        "name": "Hypergraph Representation",
        "year": 2015,
        "authors": [
          "Seo, Minjoon",
          "Hajishirzi, Hannaneh",
          "Farhadi, Ali",
          "Etzioni, Oren",
          "Malcolm, Clint"
        ],
        "task": "Geometry Question Interpretation",
        "dataset": [
          "SAT_Geometry_Questions_2015"
        ],
        "metrics": [
          "Accuracy_Classification",
          "F1_Score_Text_Interpretation"
        ],
        "architecture": {
          "components": [
            "Concept Nodes",
            "Relations",
            "Edges"
          ],
          "connections": [
            "Concept Nodes to Relations"
          ],
          "mechanisms": [
            "Concept Identification",
            "Relation Identification",
            "Literal Parsing",
            "Relation Completion"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Log-linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Concept Identification Features",
          "Relation Type Features",
          "Geometry Language Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2015_LogLinearModel",
        "entity_type": "Algorithm",
        "name": "Log-linear Model",
        "year": 2015,
        "authors": [
          "Seo, Minjoon",
          "Hajishirzi, Hannaneh",
          "Farhadi, Ali",
          "Etzioni, Oren",
          "Malcolm, Clint"
        ],
        "task": "Relation Scoring",
        "dataset": [
          "SAT_Geometry_Questions_2015"
        ],
        "metrics": [
          "Accuracy_Classification",
          "F1_Score_Text_Interpretation"
        ],
        "architecture": {
          "components": [
            "Feature Vectors",
            "Parameters"
          ],
          "connections": [
            "Feature Vector to Score"
          ],
          "mechanisms": [
            "Maximum Likelihood Estimation",
            "L2 Regularization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "L2 Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Structural Features",
          "Geometry Language Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Stanford_Dependency_Parser_2014",
        "entity_type": "Dataset",
        "name": "Stanford Dependency Parser",
        "year": 2014,
        "creators": [
          "Chen, Danqi",
          "Manning, Christopher D."
        ],
        "domain": "Natural Language Processing",
        "description": "A dependency parser for syntactic analysis",
        "size": "Not specified"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_DiagramParser",
        "entity_type": "Algorithm",
        "name": "Diagram Parser",
        "year": 2014,
        "authors": [
          "Seo, Minjoon",
          "Hajishirzi, Hannaneh",
          "Farhadi, Ali",
          "Etzioni, Oren",
          "Malcolm, Clint"
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "SAT_Geometry_Questions_2015"
        ],
        "metrics": [
          "Diagram Score",
          "High-confidence Visual Literals"
        ],
        "architecture": {
          "components": [
            "Visual Element Extraction",
            "Coordinate Calculation",
            "Relationship Identification",
            "Entity Alignment"
          ],
          "connections": [
            "Text-Diagram Alignment",
            "Literal Grounding"
          ],
          "mechanisms": [
            "Optical Character Recognition",
            "Diagram Score Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Thresholds for High-confidence Literals"
          ]
        },
        "feature_processing": [
          "Visual Feature Extraction",
          "Textual Entity Recognition"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Diagram_Score",
        "entity_type": "Metric",
        "name": "Diagram Score",
        "description": "Score indicating the affinity of each literal with the diagram",
        "category": "Diagram Evaluation",
        "formula": "Relaxed indicator function of whether a literal is true according to the diagram"
      }
    },
    {
      "metric_entity": {
        "metric_id": "High_confidence_Visual_Literals",
        "entity_type": "Metric",
        "name": "High-confidence Visual Literals",
        "description": "Set of literals confidently parsed from the diagram",
        "category": "Diagram Parsing",
        "formula": "Parsed literals that cannot be obtained from the text"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_RelationKnowledgePoweredModel",
        "entity_type": "Algorithm",
        "name": "Relation Knowledge Powered Model",
        "title": "Solving Verbal Questions in IQ Test by Knowledge-Powered Word Embedding",
        "year": 2016,
        "authors": [
          "Huazheng Wang",
          "Fei Tian",
          "Bin Gao",
          "Chengjieren Zhu",
          "Jiang Bian",
          "Tie-Yan Liu"
        ],
        "task": "Verbal Comprehension Questions in IQ Tests",
        "dataset": [
          "wiki2014",
          "Published IQ Test Books"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Question Classifier",
            "Word-Sense and Relation Embedding",
            "Specific Solvers"
          ],
          "connections": [
            "Question Classifier -> Word-Sense and Relation Embedding -> Specific Solvers"
          ],
          "mechanisms": [
            "Multi-Sense Clustering",
            "Relational Knowledge Integration",
            "Co-Learning Word-Sense Pair Representations and Relation Representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Learning",
            "Back Propagation Neural Networks"
          ],
          "parameter_tuning": [
            "Window Size",
            "Embedding Dimension",
            "Negative Sampling Count",
            "Epoch Number"
          ]
        },
        "feature_processing": [
          "TF-IDF Features",
          "Context Windows Clustering",
          "Dictionary-Based Relational Knowledge"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "wiki2014_2016",
        "entity_type": "Dataset",
        "name": "wiki2014",
        "description": "A large text snapshot from Wikipedia",
        "domain": "Natural Language Processing",
        "size": 3400000000,
        "year": 2016,
        "creators": [
          "Wikipedia Contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PublishedIQTestBooks_2016",
        "entity_type": "Dataset",
        "name": "Published IQ Test Books",
        "description": "Verbal comprehension questions associated with correct answers from published IQ test books",
        "domain": "Intelligence Testing",
        "size": 232,
        "year": 2016,
        "creators": [
          "Philip Carter",
          "Dan Pape",
          "Ken Russell"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengio2003_NeuralProbabilisticLanguageModel",
        "entity_type": "Algorithm",
        "name": "Neural Probabilistic Language Model",
        "year": 2003,
        "authors": [
          "Bengio, Y.",
          "Ducharme, R.",
          "Vincent, P.",
          "Jauvin, C."
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Neural Network"
          ],
          "connections": [
            "Feedforward"
          ],
          "mechanisms": [
            "Probabilistic Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Blei2003_LatentDirichletAllocation",
        "entity_type": "Algorithm",
        "name": "Latent Dirichlet Allocation",
        "year": 2003,
        "authors": [
          "Blei, D.M.",
          "Ng, A.Y.",
          "Jordan, M.I."
        ],
        "task": "Topic Modeling",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Generative Model"
          ],
          "connections": [
            "Bayesian Inference"
          ],
          "mechanisms": [
            "Dirichlet Distribution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Variational Inference"
          ],
          "parameter_tuning": [
            "Number of Topics"
          ]
        },
        "feature_processing": [
          "Bag-of-Words"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WordRep_2014",
        "entity_type": "Dataset",
        "name": "WordRep",
        "year": 2014,
        "creators": [
          "Gao, B.",
          "Bian, J.",
          "Liu, T.-Y."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Perplexity_TopicModeling",
        "entity_type": "Metric",
        "name": "Perplexity",
        "description": "衡量模型对未见数据的预测能力",
        "category": "主题建模评估",
        "formula": "exp(-sum(log(p(w_i)))/N)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collobert2008_UnifiedArchitectureForNLP",
        "entity_type": "Algorithm",
        "name": "Unified Architecture for NLP",
        "year": 2008,
        "authors": [
          "Collobert, R.",
          "Weston, J."
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Deep Neural Networks"
          ],
          "connections": [
            "Multitask Learning"
          ],
          "mechanisms": [
            "Shared Representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2012_ImprovedWordRepresentations",
        "entity_type": "Algorithm",
        "name": "Improved Word Representations",
        "year": 2012,
        "authors": [
          "Huang, E.H.",
          "Socher, R.",
          "Manning, C.D.",
          "Ng, A.Y."
        ],
        "task": "Word Representation",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Global Context",
            "Multiple Word Prototypes"
          ],
          "connections": [
            "Hierarchical Clustering"
          ],
          "mechanisms": [
            "Contextual Information"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "Number of Senses"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_DistributedRepresentationsOfWordsAndPhrases",
        "entity_type": "Algorithm",
        "name": "Distributed Representations of Words and Phrases",
        "year": 2013,
        "authors": [
          "Mikolov, T.",
          "Sutskever, I.",
          "Chen, K.",
          "Corrado, G.S.",
          "Dean, J."
        ],
        "task": "Word Representation",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Continuous Bag-of-Words",
            "Skip-gram"
          ],
          "connections": [
            "Negative Sampling"
          ],
          "mechanisms": [
            "Word Compositionality"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Window Size",
            "Embedding Dimension"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Neelakantan2014_EfficientNonParametricEstimation",
        "entity_type": "Algorithm",
        "name": "Efficient Non-Parametric Estimation",
        "year": 2014,
        "authors": [
          "Neelakantan, A.",
          "Shankar, J.",
          "Passos, A.",
          "McCallum, A."
        ],
        "task": "Word Representation",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Multiple Embeddings per Word"
          ],
          "connections": [
            "Vector Space"
          ],
          "mechanisms": [
            "Non-Parametric Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "Number of Embeddings"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_MultiSenseIdentification",
        "entity_type": "Algorithm",
        "name": "Multi-Sense Identification",
        "year": 2016,
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "Verbal Comprehension Question Answering",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Skip-gram",
            "Context Windows Clustering",
            "Dictionary Matching"
          ],
          "connections": [
            "Word-Sense Pair Labeling",
            "Cluster to Sense Matching"
          ],
          "mechanisms": [
            "TF-IDF Weighting",
            "Spherical k-means Clustering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "Window Size",
            "Number of Clusters"
          ]
        },
        "feature_processing": [
          "Context Window Representation",
          "Weighted Average Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_CoLearningWordSensePairRepresentations",
        "entity_type": "Algorithm",
        "name": "Co-Learning Word-Sense Pair Representations and Relation Representations",
        "year": 2016,
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "Verbal Comprehension Question Answering",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Skip-gram Objective Function",
            "Relational Knowledge Regularization"
          ],
          "connections": [
            "Word-Sense Pair Embedding",
            "Relation Embedding"
          ],
          "mechanisms": [
            "Margin-Based Regularization",
            "Translation Operations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Back Propagation Neural Networks"
          ],
          "parameter_tuning": [
            "Margin Hyper-parameter",
            "Combination Coefficient"
          ]
        },
        "feature_processing": [
          "Soft Norm Constraint"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_AnalogySolver",
        "entity_type": "Algorithm",
        "name": "Analogy Solver",
        "year": 2016,
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "Analogy Question Answering",
        "dataset": [
          "PublishedIQTestBooks_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Cosine Similarity Calculation"
          ],
          "connections": [
            "Word-Sense Pair Embedding"
          ],
          "mechanisms": [
            "Optimization Method"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Window Size"
          ]
        },
        "feature_processing": [
          "Word-Sense Pair Indexing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_ClassificationSolver",
        "entity_type": "Algorithm",
        "name": "Classification Solver",
        "year": 2016,
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "Classification Question Answering",
        "dataset": [
          "PublishedIQTestBooks_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Mean Vector Calculation",
            "Distance Calculation"
          ],
          "connections": [
            "Word-Sense Pair Embedding"
          ],
          "mechanisms": [
            "Closest Mean Vector Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Window Size"
          ]
        },
        "feature_processing": [
          "Word-Sense Pair Indexing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_SynonymSolver",
        "entity_type": "Algorithm",
        "name": "Synonym Solver",
        "year": 2016,
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "Synonym Question Answering",
        "dataset": [
          "PublishedIQTestBooks_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Distance Calculation",
            "Translation Distance Minimization"
          ],
          "connections": [
            "Word-Sense Pair Embedding"
          ],
          "mechanisms": [
            "Offset Vector Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Window Size"
          ]
        },
        "feature_processing": [
          "Word-Sense Pair Indexing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_AntonymSolver",
        "entity_type": "Algorithm",
        "name": "Antonym Solver",
        "year": 2016,
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "Antonym Question Answering",
        "dataset": [
          "PublishedIQTestBooks_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Distance Calculation",
            "Translation Distance Minimization"
          ],
          "connections": [
            "Word-Sense Pair Embedding"
          ],
          "mechanisms": [
            "Offset Vector Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Window Size"
          ]
        },
        "feature_processing": [
          "Word-Sense Pair Indexing"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "OnlineIQTestQuestions_2016",
        "entity_type": "Dataset",
        "name": "Online IQ Test Questions",
        "description": "Verbal comprehension questions collected from online IQ test websites",
        "domain": "Natural Language Processing",
        "size": 150,
        "year": 2016,
        "creators": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "OverallAccuracy_VerbalComprehension",
        "entity_type": "Metric",
        "name": "Overall Accuracy",
        "description": "Overall accuracy on verbal comprehension questions",
        "category": "Verbal Comprehension Evaluation",
        "formula": "Correct Answers / Total Questions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_RandomGuessModel",
        "entity_type": "Algorithm",
        "name": "Random Guess Model",
        "year": 2016,
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "Verbal Comprehension Questions",
        "dataset": [
          "OnlineIQTestQuestions_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Blei2003_LatentDirichletAllocationModel",
        "entity_type": "Algorithm",
        "name": "Latent Dirichlet Allocation Model",
        "year": 2003,
        "authors": [
          "Blei, D.M.",
          "Ng, A.Y.",
          "Jordan, M.I."
        ],
        "task": "Verbal Comprehension Questions",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_SkipGramModel",
        "entity_type": "Algorithm",
        "name": "Skip-Gram Model",
        "year": 2013,
        "authors": [
          "Mikolov, T.",
          "Sutskever, I.",
          "Chen, K.",
          "Corrado, G.S.",
          "Dean, J."
        ],
        "task": "Verbal Comprehension Questions",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_GloVeModel",
        "entity_type": "Algorithm",
        "name": "GloVe Model",
        "year": 2014,
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C.D."
        ],
        "task": "Verbal Comprehension Questions",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2012_MultiSenseModel",
        "entity_type": "Algorithm",
        "name": "Multi-Sense Model",
        "year": 2012,
        "authors": [
          "Huang, E.H.",
          "Socher, R.",
          "Manning, C.D.",
          "Ng, A.Y."
        ],
        "task": "Verbal Comprehension Questions",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AmazonMechanicalTurkWorkers_2016",
        "entity_type": "Dataset",
        "name": "Amazon Mechanical Turk Workers",
        "description": "Crowdsourced human responses to IQ test questions",
        "domain": "Human Intelligence",
        "year": 2016,
        "creators": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "AverageAccuracy_HumanPerformance",
        "entity_type": "Metric",
        "name": "Average Accuracy",
        "description": "Average performance of human participants",
        "category": "Human Performance Evaluation",
        "formula": "Sum of correct answers / Total number of questions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Tian2014_ProbabilisticModelForMultiPrototypeWordEmbeddings",
        "entity_type": "Algorithm",
        "name": "Probabilistic Model for Multi-Prototype Word Embeddings",
        "year": 2014,
        "authors": [
          "Fei Tian",
          "Hanjun Dai",
          "Jiang Bian",
          "Bin Gao",
          "Rui Zhang",
          "Enhong Chen",
          "Tie-Yan Liu"
        ],
        "task": "Word Embedding",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Probabilistic Model",
            "Multi-Prototype Embeddings"
          ],
          "connections": [
            "Word-Sense Pair Representation",
            "Contextual Information"
          ],
          "mechanisms": [
            "Probabilistic Inference",
            "Multi-Sense Clustering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic Learning",
            "Context Window Clustering"
          ],
          "parameter_tuning": [
            "Embedding Dimension",
            "Window Size",
            "Negative Sampling Count"
          ]
        },
        "feature_processing": [
          "Context Window Extraction",
          "TF-IDF Weighting"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2014_GenProblem",
        "entity_type": "Algorithm",
        "name": "GenProblem",
        "title": "Synthesis of Geometry Proof Problems",
        "year": 2014,
        "authors": [
          "Chris Alvin",
          "Sumit Gulwani",
          "Rupak Majumdar",
          "Supratik Mukhopadhyay"
        ],
        "task": "Geometry Proof Problem Generation",
        "dataset": [
          "Figures from geometry textbooks"
        ],
        "metrics": [
          "Number of generated problems",
          "Time taken to generate problems"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Minimal Assumption Generation",
            "Strictly Interesting Problem Synthesis"
          ],
          "connections": [
            "Hypergraph nodes and edges",
            "Derive function",
            "Minimal set enumeration"
          ],
          "mechanisms": [
            "Hypergraph reachability",
            "Fixed-point procedure",
            "Non-deterministic choices"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Semi-automated methodology"
          ],
          "parameter_tuning": [
            "Axioms selection",
            "Figure input"
          ]
        },
        "feature_processing": [
          "Implicit and explicit facts extraction",
          "Predicate derivation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Figures_from_geometry_textbooks_2014",
        "entity_type": "Dataset",
        "name": "Figures from geometry textbooks",
        "description": "A set of 110 geometric figures taken from standard mathematics textbooks",
        "domain": "High School Geometry",
        "size": 110,
        "year": 2014,
        "creators": [
          "Chris Alvin",
          "Sumit Gulwani",
          "Rupak Majumdar",
          "Supratik Mukhopadhyay"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Number_of_generated_problems_Generation",
        "entity_type": "Metric",
        "name": "Number of generated problems",
        "description": "The number of geometry proof problems generated per figure",
        "category": "Problem Generation",
        "formula": "Total number of problems / Number of figures"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Time_taken_to_generate_problems_Generation",
        "entity_type": "Metric",
        "name": "Time taken to generate problems",
        "description": "Average time taken to generate problems per figure",
        "category": "Performance Evaluation",
        "formula": "Total time / Number of figures"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2014_HypergraphConstruction",
        "entity_type": "Algorithm",
        "name": "Hypergraph Construction",
        "year": 2014,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "Geometry Proof Problem Generation",
        "dataset": [
          "Figures_from_geometry_textbooks_2014"
        ],
        "metrics": [
          "Number_of_generated_problems_Generation",
          "Time_taken_to_generate_problems_Generation"
        ],
        "architecture": {
          "components": [
            "Nodes",
            "Edges",
            "Predicates"
          ],
          "connections": [
            "Directed Hyperedges"
          ],
          "mechanisms": [
            "Derivation of Predicates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Enumerating all facts",
            "Connecting source facts to target facts using axioms"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Analyzing pictorial representations",
          "Enumerating implicit and explicit facts"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2014_MinimalAssumptionGeneration",
        "entity_type": "Algorithm",
        "name": "Minimal Assumption Generation",
        "year": 2014,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "Geometry Proof Problem Generation",
        "dataset": [
          "Figures_from_geometry_textbooks_2014"
        ],
        "metrics": [
          "Number_of_generated_problems_Generation",
          "Time_taken_to_generate_problems_Generation"
        ],
        "architecture": {
          "components": [
            "Minimal Sets",
            "Fixed-point Procedure"
          ],
          "connections": [
            "Iterative Enumeration"
          ],
          "mechanisms": [
            "Checking minimality of assumption sets"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Systematic enumeration of minimal sets"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Ensuring minimality of assumption sets"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2014_StrictlyInterestingProblemSynthesis",
        "entity_type": "Algorithm",
        "name": "Strictly Interesting Problem Synthesis",
        "year": 2014,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "Geometry Proof Problem Generation",
        "dataset": [
          "Figures_from_geometry_textbooks_2014"
        ],
        "metrics": [
          "Number_of_generated_problems_Generation",
          "Time_taken_to_generate_problems_Generation"
        ],
        "architecture": {
          "components": [
            "Goal Sets",
            "Non-deterministic Choices"
          ],
          "connections": [
            "Growing Goal Sets"
          ],
          "mechanisms": [
            "Ensuring strict interestingness"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Generating strictly interesting problems"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Choosing new goals based on existing assumptions"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Number_of_deduced_facts_per_figure_2014",
        "entity_type": "Metric",
        "name": "Number of deduced facts per figure",
        "description": "The number of deduced facts per figure in the generated problems.",
        "category": "Problem Generation Evaluation",
        "formula": "Average number of deduced facts per figure"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Mean_number_of_explicit_facts_2014",
        "entity_type": "Metric",
        "name": "Mean number of explicit facts",
        "description": "The mean number of explicit facts per figure.",
        "category": "Problem Generation Evaluation",
        "formula": "Mean number of explicit facts per figure"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Median_number_of_explicit_facts_2014",
        "entity_type": "Metric",
        "name": "Median number of explicit facts",
        "description": "The median number of explicit facts per figure.",
        "category": "Problem Generation Evaluation",
        "formula": "Median number of explicit facts per figure"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Standard_deviation_of_explicit_facts_2014",
        "entity_type": "Metric",
        "name": "Standard deviation of explicit facts",
        "description": "The standard deviation of the number of explicit facts per figure.",
        "category": "Problem Generation Evaluation",
        "formula": "Standard deviation of explicit facts per figure"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Number_of_strictly_interesting_problems_per_pair_2014",
        "entity_type": "Metric",
        "name": "Number of strictly interesting problems per pair",
        "description": "The number of strictly interesting problems generated per figure-axiom pair.",
        "category": "Problem Generation Evaluation",
        "formula": "Number of strictly interesting problems per pair"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Number_of_strictly_complete_problems_per_pair_2014",
        "entity_type": "Metric",
        "name": "Number of strictly complete problems per pair",
        "description": "The number of strictly complete problems generated per figure-axiom pair.",
        "category": "Problem Generation Evaluation",
        "formula": "Number of strictly complete problems per pair"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Mean_number_of_problems_per_pair_2014",
        "entity_type": "Metric",
        "name": "Mean number of problems per pair",
        "description": "The mean number of problems generated per figure-axiom pair.",
        "category": "Problem Generation Evaluation",
        "formula": "Mean number of problems per pair"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Median_number_of_problems_per_pair_2014",
        "entity_type": "Metric",
        "name": "Median number of problems per pair",
        "description": "The median number of problems generated per figure-axiom pair.",
        "category": "Problem Generation Evaluation",
        "formula": "Median number of problems per pair"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Time_taken_to_process_hypergraph_2014",
        "entity_type": "Metric",
        "name": "Time taken to process hypergraph",
        "description": "The time taken to construct the saturated hypergraph for each figure-axiom pair.",
        "category": "Problem Generation Efficiency",
        "formula": "Time taken to process hypergraph"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Correlation_between_explicit_facts_and_processing_time_2014",
        "entity_type": "Metric",
        "name": "Correlation between explicit facts and processing time",
        "description": "The correlation between the number of explicit facts and the time taken to process the hypergraph.",
        "category": "Problem Generation Efficiency",
        "formula": "Correlation coefficient"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2014_QueryInterface",
        "entity_type": "Algorithm",
        "name": "Query Interface for Problem Generation",
        "year": 2014,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "Geometry Proof Problem Generation",
        "dataset": [
          "Figures_from_geometry_textbooks_2014"
        ],
        "metrics": [
          "Number_of_generated_problems_Generation",
          "Time_taken_to_generate_problems_Generation"
        ],
        "architecture": {
          "components": [
            "Relational Database",
            "Query Engine"
          ],
          "connections": [
            "User Input -> Query Engine -> Relational Database -> Generated Problems"
          ],
          "mechanisms": [
            "Relational Query Processing",
            "Feature Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Input of (Fig, Axm) Pairs"
          ],
          "parameter_tuning": [
            "Feature Specification Parameters"
          ]
        },
        "feature_processing": [
          "Feature Extraction from Problem Characteristics"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2019_TemplateBasedSolver",
        "entity_type": "Algorithm",
        "name": "Template-Based Math Word Problem Solver with Recursive Neural Networks",
        "year": 2019,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K",
          "MAWPS"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Bi-LSTM",
            "Self Attention",
            "Recursive Neural Network"
          ],
          "connections": [
            "Seq2Seq Model -> Template Prediction",
            "Bi-LSTM -> Quantity Embedding",
            "Recursive Neural Network -> Operator Inference"
          ],
          "mechanisms": [
            "Tree Structure Template",
            "Suffix Expression",
            "Equation Normalization",
            "Operator Encapsulation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-stage Training",
            "Template Prediction",
            "Answer Generation"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "SGD Optimizer",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Quantity Detection",
          "Equation Template Annotation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_TagBasedApproach",
        "entity_type": "Algorithm",
        "name": "Tag-Based Approach",
        "year": 2016,
        "authors": [
          "Liang, C.",
          "Hsu, K.",
          "Huang, C.",
          "Li, C.",
          "Miao, S.",
          "Su, K."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "TagBased_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Map Rules",
            "Logic Forms"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KoncelKedziorski2015_IntegerLinearProgramming",
        "entity_type": "Algorithm",
        "name": "Integer Linear Programming",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "IntegerLinearProgramming_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Enumerated Trees"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_UnitDependencyGraph",
        "entity_type": "Algorithm",
        "name": "Unit Dependency Graph",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "UnitDependencyGraph_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Rate Unit Consistency"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018b_DeepReinforcementLearning",
        "entity_type": "Algorithm",
        "name": "Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H. T."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "MathDQN_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_BidirectionalLSTM",
        "entity_type": "Algorithm",
        "name": "Bidirectional LSTM",
        "year": 2018,
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "BidirectionalLSTM_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Self Attention"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ARIS_Dataset_2014",
        "entity_type": "Dataset",
        "name": "ARIS Dataset",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Formula_Dataset_2016",
        "entity_type": "Dataset",
        "name": "Formula Dataset",
        "year": 2016,
        "creators": [
          "Mitra, A.",
          "Baral, C."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "TagBased_Dataset_2016",
        "entity_type": "Dataset",
        "name": "Tag-Based Dataset",
        "year": 2016,
        "creators": [
          "Liang, C.",
          "Hsu, K.",
          "Huang, C.",
          "Li, C.",
          "Miao, S.",
          "Su, K."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ExpressionTree_Dataset_2015",
        "entity_type": "Dataset",
        "name": "Expression Tree Dataset",
        "year": 2015,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IntegerLinearProgramming_Dataset_2015",
        "entity_type": "Dataset",
        "name": "Integer Linear Programming Dataset",
        "year": 2015,
        "creators": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "UnitDependencyGraph_Dataset_2017",
        "entity_type": "Dataset",
        "name": "Unit Dependency Graph Dataset",
        "year": 2017,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MathDQN_Dataset_2018",
        "entity_type": "Dataset",
        "name": "MathDQN Dataset",
        "year": 2018,
        "creators": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H. T."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "BidirectionalLSTM_Dataset_2018",
        "entity_type": "Dataset",
        "name": "Bidirectional LSTM Dataset",
        "year": 2018,
        "creators": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2019_RecursiveNN",
        "entity_type": "Algorithm",
        "name": "Recursive Neural Network (Recursive NN)",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": 2019,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bi-LSTM",
            "Self Attention",
            "Recursive NN"
          ],
          "connections": [
            "Quantity Embedding Layer -> Bi-LSTM -> Self Attention -> Recursive NN"
          ],
          "mechanisms": [
            "Bottom-up Operator Inference",
            "Suffix Expression Processing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Minimizing Loss Function"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "SGD Optimizer"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Quantity Extraction",
          "Equation Normalization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2019_Seq2SeqModel",
        "entity_type": "Algorithm",
        "name": "Seq2Seq Model",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": 2019,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder (Bi-LSTM)",
            "Decoder (LSTM)",
            "Attention Layer"
          ],
          "connections": [
            "Input Sequence -> Encoder -> Decoder -> Output Sequence"
          ],
          "mechanisms": [
            "Conditional Probability Estimation",
            "Sequence-to-Sequence Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Minimizing Loss Function"
          ],
          "parameter_tuning": [
            "Adam Optimizer"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Suffix Expression Generation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "FailureRate_TemplatePrediction",
        "entity_type": "Metric",
        "name": "Failure Rate",
        "description": "Percentage of invalid templates generated by the seq2seq model",
        "category": "Template Prediction Evaluation",
        "formula": "Number of Invalid Templates / Total Number of Templates"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2019_BiLSTMwithSelfAttention",
        "entity_type": "Algorithm",
        "name": "Bi-LSTM with Self Attention",
        "year": 2019,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bi-LSTM",
            "Self Attention"
          ],
          "connections": [
            "Bidirectional LSTM layers",
            "Attention mechanism"
          ],
          "mechanisms": [
            "Contextualized word embeddings",
            "Long-range dependencies modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-layer Bi-LSTM",
            "Two-layer LSTM"
          ],
          "parameter_tuning": [
            "Adam optimizer",
            "SGD optimizer"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Quantity extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DNS_Dataset_2017",
        "entity_type": "Dataset",
        "name": "DNS",
        "year": 2017,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "description": "Dataset used for arithmetic word problem solving",
        "domain": "Natural Language Processing",
        "size": 60000,
        "creators": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_TemplatePrediction",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of template prediction by the seq2seq model",
        "category": "Template Prediction Evaluation",
        "formula": "Number of correctly predicted templates / Total number of templates"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_AnswerGeneration",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of answer generation module",
        "category": "Answer Generation Evaluation",
        "formula": "Number of correctly solved problems / Total number of problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2019_Seq2SeqTemplatePrediction",
        "entity_type": "Algorithm",
        "name": "Seq2Seq Template Prediction Model",
        "year": 2019,
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Dai, B.T.",
          "Shen, H.T."
        ],
        "task": "Template Prediction",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_TemplatePrediction"
        ],
        "architecture": {
          "components": [
            "Encoder (Bi-LSTM)",
            "Decoder (LSTM)",
            "Attention Layer"
          ],
          "connections": [
            "Encoder-Decoder Connection",
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Sequence-to-Sequence Translation",
            "Attention Scoring"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Teacher Forcing"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Positional Encoding"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Percentage_IllegalTemplates",
        "entity_type": "Metric",
        "name": "Percentage of Illegal Templates",
        "description": "Percentage of templates that cannot be converted into valid expression trees",
        "category": "Template Prediction Evaluation",
        "formula": "Number of illegal templates / Total number of templates"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_AnswerGenerationModule",
        "entity_type": "Metric",
        "name": "Accuracy of Answer Generation Module",
        "description": "Accuracy of the answer generation module in generating correct answers",
        "category": "Answer Generation Evaluation",
        "formula": "Number of correctly solved problems / Total number of problems"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_TemplateLength",
        "entity_type": "Metric",
        "name": "Accuracy for Increasing Length of Templates",
        "description": "Accuracy of solving problems with templates of varying lengths",
        "category": "Template Length Evaluation",
        "formula": "Number of correctly solved problems with specific template length / Total number of problems with that template length"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Top10Templates_Math23K",
        "entity_type": "Dataset",
        "name": "Top 10 Most Frequent Templates in Math23K",
        "description": "Dataset containing the top 10 most frequent templates in the Math23K dataset",
        "domain": "Arithmetic Word Problems",
        "size": 10,
        "year": 2019,
        "creators": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Dai, B.T.",
          "Shen, H.T."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_EquationNormalization",
        "entity_type": "Algorithm",
        "name": "Equation Normalization",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Rule 1",
            "Rule 2",
            "Expression Tree"
          ],
          "connections": [
            "Normalization Rules",
            "Postorder Traversal"
          ],
          "mechanisms": [
            "Order Duplication Handling",
            "Bracket Duplication Handling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SEQ2SEQ Framework"
          ],
          "parameter_tuning": [
            "Rule Application"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_SEQ2SEQFramework",
        "entity_type": "Algorithm",
        "name": "SEQ2SEQ Framework",
        "year": 2017,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Attention Mechanism"
          ],
          "connections": [
            "Source Sequence",
            "Target Sequence"
          ],
          "mechanisms": [
            "Conditional Probability Maximization",
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-stage Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_ProblemToEquationMapping",
        "entity_type": "Algorithm",
        "name": "Problem-to-Equation Mapping",
        "year": 2017,
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ model"
          ],
          "connections": [
            "Maps problem text to equation templates"
          ],
          "mechanisms": [
            "Conditional probability maximization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximizes conditional probability P(Tp|P)"
          ],
          "parameter_tuning": [
            "Token-wise probabilities"
          ]
        },
        "feature_processing": [
          "Uses beam search for decoding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_OrderNormalizationRule1",
        "entity_type": "Algorithm",
        "name": "Order Normalization Rule 1",
        "year": 2018,
        "authors": [
          "Wang, L.",
          "Wang, Y.",
          "Cai, D.",
          "Zhang, D.",
          "Liu, X."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Normalization Rules"
          ],
          "connections": [
            "Equation Templates Transformation"
          ],
          "mechanisms": [
            "Shortest Template Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Normalization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Token Ordering"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_OrderNormalizationRule2",
        "entity_type": "Algorithm",
        "name": "Order Normalization Rule 2",
        "year": 2018,
        "authors": [
          "Wang, L.",
          "Wang, Y.",
          "Cai, D.",
          "Zhang, D.",
          "Liu, X."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Normalization Rules"
          ],
          "connections": [
            "Equation Templates Transformation"
          ],
          "mechanisms": [
            "Order Preservation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Normalization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Token Ordering"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_BracketNormalization",
        "entity_type": "Algorithm",
        "name": "Bracket Normalization",
        "year": 2018,
        "authors": [
          "Wang, L.",
          "Wang, Y.",
          "Cai, D.",
          "Zhang, D.",
          "Liu, X."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree"
          ],
          "connections": [
            "Equation Templates Transformation"
          ],
          "mechanisms": [
            "Bracket Elimination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Normalization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Bracket Handling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_BiLSTM",
        "entity_type": "Algorithm",
        "name": "BiLSTM",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Global Attention Mechanism"
          ],
          "connections": [
            "Forward LSTM",
            "Backward LSTM"
          ],
          "mechanisms": [
            "Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-layer Bi-LSTM encoder",
            "Two-layer LSTM decoder",
            "Adam optimizer"
          ],
          "parameter_tuning": [
            "Learning rate 1e-3",
            "β1=0.9",
            "β2=0.99",
            "Dropout rate 0.5"
          ]
        },
        "feature_processing": [
          "Number Mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Gehring2017_ConvS2S",
        "entity_type": "Algorithm",
        "name": "ConvS2S",
        "year": 2017,
        "authors": [
          "Jonas Gehring",
          "Michael Auli",
          "David Grangier",
          "Denis Yarats",
          "Yann N Dauphin"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Convolutional Encoder",
            "Convolutional Decoder",
            "Gate Linear Units"
          ],
          "connections": [
            "Convolutional Layers"
          ],
          "mechanisms": [
            "Gated Linear Units"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Four-layer encoder",
            "Three-layer decoder",
            "Early stopping",
            "Learning rate annealing"
          ],
          "parameter_tuning": [
            "Max-epochs 100",
            "Kernel width 3",
            "Hidden size 256"
          ]
        },
        "feature_processing": [
          "Number Mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Vaswani2017_Transformer",
        "entity_type": "Algorithm",
        "name": "Transformer",
        "year": 2017,
        "authors": [
          "Ashish Vaswani",
          "Noam Shazeer",
          "Niki Parmar",
          "Jakob Uszkoreit",
          "Llion Jones",
          "Aidan N Gomez",
          "Łukasz Kaiser",
          "Illia Polosukhin"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multi-head Self-Attention Module",
            "Position-wise Fully-Connected Feed-Forward Network"
          ],
          "connections": [
            "Stack of Identical Layers"
          ],
          "mechanisms": [
            "Self-Attention",
            "Feed-Forward"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Four-layer deep",
            "Adam optimizer"
          ],
          "parameter_tuning": [
            "Learning rate 1e-3",
            "β1=0.9",
            "β2=0.99",
            "Dropout rate 0.3",
            "nhead=16",
            "dk=12",
            "dv=32",
            "dmodel=512"
          ]
        },
        "feature_processing": [
          "Number Mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_EnsembleModel",
        "entity_type": "Algorithm",
        "name": "Ensemble Model",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "ConvS2S",
            "Transformer"
          ],
          "connections": [
            "Combination of models"
          ],
          "mechanisms": [
            "Generation Probability Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Combining multiple models"
          ],
          "parameter_tuning": [
            "Selecting the model with the highest generation probability"
          ]
        },
        "feature_processing": [
          "Number Mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_DNS",
        "entity_type": "Algorithm",
        "name": "DNS",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ",
            "GRU",
            "LSTM"
          ],
          "connections": [
            "encoder-decoder"
          ],
          "mechanisms": [
            "attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "maximum likelihood estimation"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "number mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_DNSHybrid",
        "entity_type": "Algorithm",
        "name": "DNS-Hybrid",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ",
            "GRU",
            "LSTM",
            "retrieval-based solver"
          ],
          "connections": [
            "encoder-decoder"
          ],
          "mechanisms": [
            "attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "maximum likelihood estimation"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "number mapping"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_MathWordProblemSolving",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of solving math word problems",
        "category": "Math Word Problem Solving",
        "formula": "Number of correctly solved problems / Total number of problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fletcher1985_WORDPRO",
        "entity_type": "Algorithm",
        "name": "WORDPRO",
        "title": "Understanding and solving arithmetic word problems: A computer simulation",
        "year": 1985,
        "authors": [
          "Charles R. Fletcher"
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Production rules",
            "Set schema",
            "Transfer schema",
            "Superset schema",
            "More-than/Less-than schema"
          ],
          "connections": [
            "STM (Short-Term Memory)",
            "LTM (Long-Term Memory)"
          ],
          "mechanisms": [
            "Meaning postulates",
            "Arithmetic strategies",
            "Problem-solving procedures"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Simulating third-grade children's problem-solving processes"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Propositional representation",
          "Bilevel representation (text base and problem model)"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KintschGreeno1985_TransferSchema",
        "entity_type": "Algorithm",
        "name": "Transfer Schema",
        "year": 1985,
        "authors": [
          "W. Kintsch",
          "J. G. Greeno"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "start set",
            "transfer set",
            "result set"
          ],
          "connections": [
            "transfer-in slot",
            "start slot",
            "result slot"
          ],
          "mechanisms": [
            "addition",
            "subtraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "propositional representation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KintschGreeno1985_SupersetSchema",
        "entity_type": "Algorithm",
        "name": "Superset Schema",
        "year": 1985,
        "authors": [
          "W. Kintsch",
          "J. G. Greeno"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "superset",
            "subset1",
            "subset2"
          ],
          "connections": [
            "organize subsets"
          ],
          "mechanisms": [
            "addition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "propositional representation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KintschGreeno1985_ComparisonSchema",
        "entity_type": "Algorithm",
        "name": "Comparison Schema",
        "year": 1985,
        "authors": [
          "W. Kintsch",
          "J. G. Greeno"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "small set",
            "large set",
            "difference set"
          ],
          "connections": [
            "compare sets"
          ],
          "mechanisms": [
            "subtraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "propositional representation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "NumberOfProductionRulesFired_Performance",
        "entity_type": "Metric",
        "name": "Number of Production Rules Fired",
        "description": "The number of production rules applied during problem solving",
        "category": "Performance Evaluation",
        "formula": "Count of production rules applied"
      }
    },
    {
      "metric_entity": {
        "metric_id": "NumberOfConversions_Performance",
        "entity_type": "Metric",
        "name": "Number of Conversions",
        "description": "The number of conversions from one schema to another",
        "category": "Performance Evaluation",
        "formula": "Count of schema conversions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "NumberOfLTMSearches_Performance",
        "entity_type": "Metric",
        "name": "Number of LTM Searches",
        "description": "The number of searches performed in long-term memory",
        "category": "Performance Evaluation",
        "formula": "Count of LTM searches"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MaximumChunksHeldOver_Performance",
        "entity_type": "Metric",
        "name": "Maximum Chunks Held Over",
        "description": "The maximum number of chunks held over from one processing cycle to the next",
        "category": "Performance Evaluation",
        "formula": "Maximum count of chunks held over"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fletcher1985_MeaningPostulates",
        "entity_type": "Algorithm",
        "name": "Meaning Postulates",
        "year": 1985,
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "Understanding and solving arithmetic word problems",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Conditions",
            "Actions"
          ],
          "connections": [
            "Triggered by propositions",
            "Modify short-term memory"
          ],
          "mechanisms": [
            "Add propositions to text base",
            "Add information to problem model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Propositional representation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fletcher1985_ArithmeticStrategies",
        "entity_type": "Algorithm",
        "name": "Arithmetic Strategies",
        "year": 1985,
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "Construct higher-level schemata",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Set schemata",
            "Higher-level schemata"
          ],
          "connections": [
            "Add new schemata to STM",
            "Fill slots of schemata"
          ],
          "mechanisms": [
            "Request set schemata",
            "Complete higher-level schemata"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Set schemata"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fletcher1985_ProblemSolvingProcedures",
        "entity_type": "Algorithm",
        "name": "Problem Solving Procedures",
        "year": 1985,
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "Derive solutions",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Operations on mental blocks",
            "Conversion of schemata"
          ],
          "connections": [
            "Perform operations on STM",
            "Convert one schema to another"
          ],
          "mechanisms": [
            "Adding or deleting blocks",
            "Counting blocks",
            "Matching blocks"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Higher-level schemata"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "RunTimeStatistics_Performance",
        "entity_type": "Metric",
        "name": "Run-Time Statistics",
        "description": "Statistics collected during the operation of the program",
        "category": "Performance evaluation",
        "formula": "Number of production rules fired, number of conversions, number of LTM searches, maximum number of chunks held over"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fletcher1985_WORDPRO_Expansion",
        "entity_type": "Algorithm",
        "name": "WORDPRO Expansion",
        "year": 1985,
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Transfer Schema",
            "Superset Schema",
            "Comparison Schema"
          ],
          "connections": [
            "Meaning Postulates",
            "Arithmetic Strategies",
            "Problem-Solving Procedures"
          ],
          "mechanisms": [
            "Production Rules",
            "STM and LTM Interaction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Expanding Problem Domain",
            "Adapting to Different Ability Levels",
            "Interfacing with Parser"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Surface Representation Parsing"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PropositionalRepresentations_1985",
        "entity_type": "Dataset",
        "name": "Propositional Representations",
        "description": "Propositional representations for 14 texts used in WORDPRO",
        "domain": "Arithmetic Word Problems",
        "size": 14,
        "year": 1985,
        "creators": [
          "Fletcher, C. R."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SampleWordProblems_1985",
        "entity_type": "Dataset",
        "name": "Sample Word Problems",
        "description": "A set of arithmetic word problems designed for third-grade children.",
        "domain": "Education",
        "year": 1985,
        "creators": [
          "Fletcher, C. R."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "EmpiricalPredictions_TheoryValidation",
        "entity_type": "Metric",
        "name": "Empirical Predictions",
        "description": "Predictions derived from the program's behavior for experimental tests of the theory.",
        "category": "Theory Validation",
        "formula": "Not applicable"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_BEATRIX",
        "entity_type": "Algorithm",
        "name": "BEATRIX",
        "title": "Understanding Natural Language with Diagrams",
        "year": 1990,
        "authors": [
          "Novak, G. S.",
          "Bulko, W."
        ],
        "task": "Physics Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "English Parser",
            "Diagram Parser",
            "Coreference Resolver",
            "Inference Module"
          ],
          "connections": [
            "TEXT and PICTURE levels",
            "TEXT-MODEL and PICTURE-MODEL levels",
            "PROBLEM-MODEL level"
          ],
          "mechanisms": [
            "Blackboard Architecture",
            "Opportunistic Co-parsing",
            "Constraint Satisfaction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None (Rule-based system)"
          ],
          "parameter_tuning": [
            "None (Rule-based system)"
          ]
        },
        "feature_processing": [
          "Natural Language Processing",
          "Diagram Parsing",
          "Coreference Resolution"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_BlackboardArchitecture",
        "entity_type": "Algorithm",
        "name": "Blackboard Architecture",
        "year": 1990,
        "authors": [
          "Novak, G. S.",
          "Bulko, W."
        ],
        "task": "Understanding Natural Language with Diagrams",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "TEXT",
            "PICTURE",
            "TEXT-MODEL",
            "PICTURE-MODEL",
            "PROBLEM-MODEL"
          ],
          "connections": [
            "TEXT to TEXT-MODEL",
            "PICTURE to PICTURE-MODEL",
            "TEXT-MODEL and PICTURE-MODEL to PROBLEM-MODEL"
          ],
          "mechanisms": [
            "Opportunistic Co-parsing",
            "Coreference Resolution",
            "Semantic Inference"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Recognition",
          "Semantic Processing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_AugmentedTransitionNetworkGrammar",
        "entity_type": "Algorithm",
        "name": "Augmented Transition Network Grammar",
        "year": 1990,
        "authors": [
          "Novak, G. S."
        ],
        "task": "English Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Grammar Rules",
            "Parse Tree"
          ],
          "connections": [
            "Input Sentence to Parse Tree"
          ],
          "mechanisms": [
            "Top-down Parsing",
            "Semantic Delay"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Noun Phrase Parsing",
          "Verb Clause Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_PictureGrammar",
        "entity_type": "Algorithm",
        "name": "Picture Grammar",
        "year": 1990,
        "authors": [
          "Novak, G. S."
        ],
        "task": "Diagram Parsing",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Diagram Elements",
            "Combinations of Elements"
          ],
          "connections": [
            "Element Combinations to Meaningful Groupings"
          ],
          "mechanisms": [
            "Syntactic Recognition",
            "Forward Inference"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Line Recognition",
          "Circle Recognition",
          "Angle Recognition"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_KnowledgeSources",
        "entity_type": "Algorithm",
        "name": "Knowledge Sources",
        "year": 1990,
        "authors": [
          "Novak, G. S.",
          "Bulko, W."
        ],
        "task": "Physics Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Control KS",
            "Identify KS",
            "Parse KS",
            "Match KS",
            "Retrieve KS",
            "Semantic KS",
            "Special KS"
          ],
          "connections": [
            "TEXT",
            "PICTURE",
            "TEXT-MODEL",
            "PICTURE-MODEL",
            "PROBLEM-MODEL"
          ],
          "mechanisms": [
            "Coreference Resolution",
            "Syntactic Recognition",
            "Semantic Processing"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PhysicsProblems_1990",
        "entity_type": "Dataset",
        "name": "Physics Problems",
        "description": "Textbook physics problems with accompanying diagrams",
        "domain": "Physics Education",
        "size": null,
        "year": 1990,
        "creators": [
          "Novak, G. S.",
          "Bulko, W."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "CoreferenceResolutionAccuracy_Physics",
        "entity_type": "Metric",
        "name": "Coreference Resolution Accuracy",
        "description": "Accuracy of identifying when parts of the text and diagram refer to the same object",
        "category": "Natural Language Processing",
        "formula": "Correct coreference links / Total coreference links"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_TransitionNetworkParser",
        "entity_type": "Algorithm",
        "name": "Transition Network Parser",
        "year": 1990,
        "authors": [
          "Novak, G."
        ],
        "task": "Natural Language Parsing",
        "architecture": {
          "components": [
            "ATN Grammar",
            "Meta-language"
          ],
          "connections": [
            "Parsing of sentences",
            "Semantic networks or case frames"
          ],
          "mechanisms": [
            "Syntactic parsing",
            "Top-down parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parsing English text"
          ],
          "parameter_tuning": [
            "None mentioned"
          ]
        },
        "feature_processing": [
          "Deferred semantic processing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_DiagramParsingKS",
        "entity_type": "Algorithm",
        "name": "Diagram Parsing Knowledge Sources",
        "year": 1990,
        "authors": [
          "Novak, G."
        ],
        "task": "Diagram Parsing",
        "architecture": {
          "components": [
            "Knowledge sources",
            "Picture elements"
          ],
          "connections": [
            "Recognition of related groups of diagram elements"
          ],
          "mechanisms": [
            "Syntactic recognition",
            "Triggering additional KS’s"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parsing diagram elements"
          ],
          "parameter_tuning": [
            "None mentioned"
          ]
        },
        "feature_processing": [
          "Local analysis of combinations of diagram elements"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_UnderstandingModule",
        "entity_type": "Algorithm",
        "name": "Understanding Module",
        "year": 1990,
        "authors": [
          "Novak, G."
        ],
        "task": "Unified Model Creation",
        "architecture": {
          "components": [
            "Text and diagram parsing",
            "Semantic processing"
          ],
          "connections": [
            "TEXT-MODEL and PICTURE-MODEL levels",
            "PROBLEM-MODEL level"
          ],
          "mechanisms": [
            "Coreference resolution",
            "Property inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Controlled parsing of text and diagram"
          ],
          "parameter_tuning": [
            "None mentioned"
          ]
        },
        "feature_processing": [
          "Forward inferences",
          "Common-sense physics"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "CoreferenceResolutionAccuracy_TextDiagram",
        "entity_type": "Metric",
        "name": "Coreference Resolution Accuracy",
        "description": "Accuracy of matching objects between text and diagram",
        "category": "Coreference Resolution",
        "formula": "Correct matches / Total matches"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_ATNParser",
        "entity_type": "Algorithm",
        "name": "ATN Parser",
        "year": 1990,
        "authors": [
          "Novak, G. S."
        ],
        "task": "Natural Language Parsing",
        "architecture": {
          "components": [
            "Augmented Transition Network"
          ],
          "connections": [
            "State transitions"
          ],
          "mechanisms": [
            "Parsing rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based parsing"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Part-of-speech tagging"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_PropagateAngleROTN",
        "entity_type": "Algorithm",
        "name": "Propagate-Angle-ROTN",
        "year": 1990,
        "authors": [
          "Novak, G. S."
        ],
        "task": "Diagram Interpretation",
        "architecture": {
          "components": [
            "Angle propagation"
          ],
          "connections": [
            "Angle relationships"
          ],
          "mechanisms": [
            "Rotation inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based inference"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Angle detection",
          "Surface orientation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_IdentifyPulleySystem",
        "entity_type": "Algorithm",
        "name": "Identify-Pulley-System",
        "year": 1990,
        "authors": [
          "Novak, G. S."
        ],
        "task": "Diagram Interpretation",
        "architecture": {
          "components": [
            "Pulley recognition"
          ],
          "connections": [
            "Pulley and rope relationships"
          ],
          "mechanisms": [
            "Component association"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based recognition"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Circle detection",
          "Line intersection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_MatchNormalForce",
        "entity_type": "Algorithm",
        "name": "Match-Normal-Force",
        "year": 1990,
        "authors": [
          "Novak, G. S."
        ],
        "task": "Coreference Resolution",
        "architecture": {
          "components": [
            "Force matching"
          ],
          "connections": [
            "Text and diagram correlation"
          ],
          "mechanisms": [
            "Feature alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based matching"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Force detection",
          "Surface contact"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_FindCOEF",
        "entity_type": "Algorithm",
        "name": "Find-COEF",
        "year": 1990,
        "authors": [
          "Novak, G. S."
        ],
        "task": "Coreference Resolution",
        "architecture": {
          "components": [
            "Coefficient matching"
          ],
          "connections": [
            "Text and diagram correlation"
          ],
          "mechanisms": [
            "Feature alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based matching"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Coefficient detection",
          "Surface contact"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_PostTheProblem",
        "entity_type": "Algorithm",
        "name": "Post-the-Problem",
        "year": 1990,
        "authors": [
          "Novak, G. S."
        ],
        "task": "Initialization",
        "architecture": {
          "components": [
            "Text and diagram posting"
          ],
          "connections": [
            "Blackboard initialization"
          ],
          "mechanisms": [
            "Data placement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based initialization"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Text parsing",
          "Diagram parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bulko1988_BEATRIX",
        "entity_type": "Algorithm",
        "name": "BEATRIX",
        "title": "Understanding Text With an Accompanying Diagram",
        "year": 1988,
        "authors": [
          "William C. Bulko"
        ],
        "task": "Physics Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Graphic Interface",
            "Blackboard System",
            "Knowledge Sources"
          ],
          "connections": [
            "TEXT level to TEXT-MODEL level",
            "PICTURE level to PICTURE-MODEL level",
            "PROBLEM-MODEL level"
          ],
          "mechanisms": [
            "Coreference Resolution",
            "Parsing English Text",
            "Parsing Diagrams"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Correction Facility",
          "Automatic Correction of Drawing Errors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CollegeLevelPhysicsTextbooks_1988",
        "entity_type": "Dataset",
        "name": "College-Level Physics Textbooks",
        "description": "Collections of ready-made test cases in the form of college-level textbooks",
        "domain": "Physics Education",
        "size": null,
        "year": 1988,
        "creators": [
          "Various Authors"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1976_ISAAC",
        "entity_type": "Algorithm",
        "name": "ISAAC",
        "year": 1976,
        "authors": [
          "Novak, G. S."
        ],
        "task": "Physics Problem Solving",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correctness of Solution"
        ],
        "architecture": {
          "components": [
            "English Parser",
            "Equation Solver",
            "Diagram Generator"
          ],
          "connections": [
            "Text Parsing -> Equation Solving -> Diagram Generation"
          ],
          "mechanisms": [
            "Natural Language Processing",
            "Symbolic Reasoning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Parsing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntax Parsing",
          "Semantic Analysis"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kook1987_VIEWER",
        "entity_type": "Algorithm",
        "name": "VIEWER",
        "year": 1987,
        "authors": [
          "Kook, H. J."
        ],
        "task": "Physics Problem Modeling",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Model Accuracy"
        ],
        "architecture": {
          "components": [
            "Object Recognition",
            "Canonical Model Generation"
          ],
          "connections": [
            "Object Recognition -> Canonical Model Generation"
          ],
          "mechanisms": [
            "Expert System",
            "Inference Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Inference"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Object Classification",
          "Model Transformation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bulko1988_BlackboardControlStructure",
        "entity_type": "Algorithm",
        "name": "Blackboard Control Structure",
        "year": 1988,
        "authors": [
          "William C. Bulko"
        ],
        "task": "Physics Problem Solving",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correctness and Completeness of Problem Model"
        ],
        "architecture": {
          "components": [
            "Knowledge Sources",
            "Blackboard Levels"
          ],
          "connections": [
            "PICTURE level",
            "TEXT level",
            "PICTURE-MODEL level",
            "TEXT-MODEL level",
            "PROBLEM-MODEL level"
          ],
          "mechanisms": [
            "Coreference Resolution",
            "Object Identification",
            "Semantic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Pixel-Level Analysis",
          "Touch Relation Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bulko1988_IdentifyClassKS",
        "entity_type": "Algorithm",
        "name": "Identify Class Knowledge Source",
        "year": 1988,
        "authors": [
          "William C. Bulko"
        ],
        "task": "Object Identification",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correct Object Identification"
        ],
        "architecture": {
          "components": [
            "Identify-Class KSes"
          ],
          "connections": [
            "PICTURE level",
            "PICTURE-MODEL level"
          ],
          "mechanisms": [
            "Hypothesis Generation",
            "Abstract Object Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Object Shape Analysis",
          "Special Point Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bulko1988_ParseClassKS",
        "entity_type": "Algorithm",
        "name": "Parse Class Knowledge Source",
        "year": 1988,
        "authors": [
          "William C. Bulko"
        ],
        "task": "Text Parsing",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correct Sentence Parsing"
        ],
        "architecture": {
          "components": [
            "Parse-Class KSes"
          ],
          "connections": [
            "TEXT level",
            "TEXT-MODEL level"
          ],
          "mechanisms": [
            "Syntax Parsing",
            "Semantic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Sentence Structure Analysis",
          "Modifier Handling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bulko1988_MatchClassKS",
        "entity_type": "Algorithm",
        "name": "Match Class Knowledge Source",
        "year": 1988,
        "authors": [
          "William C. Bulko"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correct Coreference Resolution"
        ],
        "architecture": {
          "components": [
            "Match-Class KSes"
          ],
          "connections": [
            "PICTURE-MODEL level",
            "TEXT-MODEL level",
            "PROBLEM-MODEL level"
          ],
          "mechanisms": [
            "Object Matching",
            "Ambiguity Resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Object Property Comparison",
          "Best Fit Calculation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "CorrectnessAndCompletenessOfProblemModel_Physics",
        "entity_type": "Metric",
        "name": "Correctness and Completeness of Problem Model",
        "description": "Evaluates whether the generated model accurately represents the problem and includes all necessary elements.",
        "category": "Physics Problem Solving",
        "formula": "Not explicitly defined, evaluated by comparing the generated model to the expected solution."
      }
    },
    {
      "metric_entity": {
        "metric_id": "CorrectObjectIdentification_Physics",
        "entity_type": "Metric",
        "name": "Correct Object Identification",
        "description": "Measures the accuracy of identifying objects from the diagram.",
        "category": "Physics Problem Solving",
        "formula": "Number of correctly identified objects / Total number of objects."
      }
    },
    {
      "metric_entity": {
        "metric_id": "CorrectSentenceParsing_Physics",
        "entity_type": "Metric",
        "name": "Correct Sentence Parsing",
        "description": "Measures the accuracy of parsing English sentences into a meaningful structure.",
        "category": "Physics Problem Solving",
        "formula": "Number of correctly parsed sentences / Total number of sentences."
      }
    },
    {
      "metric_entity": {
        "metric_id": "CorrectCoreferenceResolution_Physics",
        "entity_type": "Metric",
        "name": "Correct Coreference Resolution",
        "description": "Measures the accuracy of resolving references between objects in the text and diagram.",
        "category": "Physics Problem Solving",
        "formula": "Number of correctly resolved coreferences / Total number of coreferences."
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bulko1988_PictureGrammarApproach",
        "entity_type": "Algorithm",
        "name": "Picture Grammar Approach",
        "year": 1988,
        "authors": [
          "William C. Bulko"
        ],
        "task": "Picture Parsing",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "CorrectnessAndCompletenessOfProblemModel_Physics"
        ],
        "architecture": {
          "components": [
            "Parse Tree",
            "Hierarchical Structure"
          ],
          "connections": [
            "Object Relationships"
          ],
          "mechanisms": [
            "Syntax Rules for Picture Elements"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Object Classification",
          "Spatial Relationship Identification"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "FeasibilityOfPictureGrammars_Physics",
        "entity_type": "Metric",
        "name": "Feasibility of Picture Grammars",
        "description": "Measure of how effectively picture grammars can be applied to parse physics problems.",
        "category": "Parsing Evaluation",
        "formula": "Number of suitable applications / Total number of analyzed problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_PairwiseCoreferenceModel",
        "entity_type": "Algorithm",
        "name": "Pairwise Coreference Model",
        "title": "Understanding the Value of Features for Coreference Resolution",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004 English training data"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function",
            "Document-Level Decision Model",
            "Best-Link decision model"
          ],
          "connections": [
            "Pairwise coreference function connects mentions in a graph"
          ],
          "mechanisms": [
            "Pairwise coreference scoring",
            "Graph construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Averaged perceptron learning algorithm",
            "Regularized version in Learning Based Java"
          ],
          "parameter_tuning": [
            "Learning rate: 0.1",
            "Regularization parameter: 3.5",
            "Threshold optimization"
          ]
        },
        "feature_processing": [
          "Mention Types",
          "String Relation Features",
          "Semantic Features",
          "Relative Location Features",
          "Learned Features",
          "Aligned Modifiers",
          "Memorization Features",
          "Predicted Entity Types"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "B-Cubed_F-Score_Coreference",
        "entity_type": "Metric",
        "name": "B-Cubed F-Score",
        "description": "Measure of the overlap of predicted clusters and true clusters",
        "category": "Coreference Evaluation",
        "formula": "Harmonic mean of precision and recall"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_F-Score_Coreference",
        "entity_type": "Metric",
        "name": "MUC F-Score",
        "description": "Official MUC scoring algorithm for coreference evaluation",
        "category": "Coreference Evaluation",
        "formula": "Harmonic mean of precision and recall"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ng2002_BestLinkDecisionModel",
        "entity_type": "Algorithm",
        "name": "Best-Link Decision Model",
        "year": 2002,
        "authors": [
          "Ng, V.",
          "Cardie, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function",
            "Document-Level Decision Model"
          ],
          "connections": [
            "Pairwise Coreference Function -> Document-Level Decision Model"
          ],
          "mechanisms": [
            "Best-Link Antecedent Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Threshold Optimization"
          ]
        },
        "feature_processing": [
          "Pairwise Coreference Scoring"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ng2002_ClosestLinkMethod",
        "entity_type": "Algorithm",
        "name": "Closest-Link Method",
        "year": 2002,
        "authors": [
          "Ng, V.",
          "Cardie, C."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function",
            "Document-Level Decision Model"
          ],
          "connections": [
            "Pairwise Coreference Function -> Document-Level Decision Model"
          ],
          "mechanisms": [
            "Closest-Link Antecedent Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Threshold Optimization"
          ]
        },
        "feature_processing": [
          "Pairwise Coreference Scoring"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Freund1998_AveragedPerceptron",
        "entity_type": "Algorithm",
        "name": "Averaged Perceptron",
        "year": 1998,
        "authors": [
          "Freund, Y.",
          "Schapire, R.E."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function"
          ],
          "connections": [],
          "mechanisms": [
            "Online Learning",
            "Weight Averaging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Pairwise Coreference Scoring"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_GenderMatch",
        "entity_type": "Algorithm",
        "name": "Gender Match",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Gender Determination"
          ],
          "connections": [
            "Gender Matching"
          ],
          "mechanisms": [
            "Gender Lookup Tables"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Gender Lists"
          ]
        },
        "feature_processing": [
          "Proper Name Gender Determination",
          "Common Noun Phrase Gender Determination"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_NumberMatch",
        "entity_type": "Algorithm",
        "name": "Number Match",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Number Determination"
          ],
          "connections": [
            "Number Matching"
          ],
          "mechanisms": [
            "Singular and Plural Lists"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Number Lists"
          ]
        },
        "feature_processing": [
          "Phrase Number Determination"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_WordNetFeatures",
        "entity_type": "Algorithm",
        "name": "WordNet Features",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Synonym Check",
            "Antonym Check",
            "Hypernym Check"
          ],
          "connections": [
            "WordNet Tree Traversal"
          ],
          "mechanisms": [
            "Hypernym Tree Filtering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "WordNet Database"
          ]
        },
        "feature_processing": [
          "Head Noun Phrase Comparison"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_AlignedModifiers",
        "entity_type": "Algorithm",
        "name": "Aligned Modifiers",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Modifier Relationship Determination"
          ],
          "connections": [
            "Modifier Alignment"
          ],
          "mechanisms": [
            "Hypernym Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Modifier Lists"
          ]
        },
        "feature_processing": [
          "Modifier Comparison"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_MemorizationFeatures",
        "entity_type": "Algorithm",
        "name": "Memorization Features",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Noun Pair Memorization"
          ],
          "connections": [
            "Noun Pair Matching"
          ],
          "mechanisms": [
            "Pattern Recognition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Noun Pair Lists"
          ]
        },
        "feature_processing": [
          "Final Head Noun Comparison"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_PredictedEntityType",
        "entity_type": "Algorithm",
        "name": "Predicted Entity Type",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Entity Type Prediction"
          ],
          "connections": [
            "Type Matching"
          ],
          "mechanisms": [
            "List Lookup"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Entity Type Lists"
          ]
        },
        "feature_processing": [
          "Entity Type Comparison"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_AnaphoricityClassifier",
        "entity_type": "Algorithm",
        "name": "Anaphoricity Classifier",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Anaphoricity Detection"
          ],
          "connections": [
            "Anaphoricity Matching"
          ],
          "mechanisms": [
            "Feature Conjunctions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Anaphoricity Features"
          ]
        },
        "feature_processing": [
          "Mention Type, Quotation Detection, Extent Text"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_RegularizedAveragedPerceptron",
        "entity_type": "Algorithm",
        "name": "Regularized Averaged Perceptron",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference",
          "MUC_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Perceptron",
            "Regularization"
          ],
          "connections": [
            "Input Layer -> Output Layer"
          ],
          "mechanisms": [
            "Weight Updates",
            "Regularization Parameter"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Threshold Optimization"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Feature Selection",
          "Threshold Application"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Culotta2007_AdvancedSystem",
        "entity_type": "Algorithm",
        "name": "Advanced System",
        "year": 2007,
        "authors": [
          "Culotta, A.",
          "Wick, M.",
          "Hall, R.",
          "McCallum, A."
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference",
          "MUC_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Complex Model",
            "Non-Pairwise Model"
          ],
          "connections": [
            "Partial Clusters of Mentions"
          ],
          "mechanisms": [
            "Feature Computation Over Partial Clusters"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Heuristics for Selecting Training Examples"
          ],
          "parameter_tuning": [
            "Threshold Optimization"
          ]
        },
        "feature_processing": [
          "Feature Computation Over Partial Clusters"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "B-Cubed_F-Score_Improvement",
        "entity_type": "Metric",
        "name": "B-Cubed F-Score Improvement",
        "description": "Improvement in B-Cubed F-Score over a complex model",
        "category": "Coreference Resolution Evaluation",
        "formula": "New B-Cubed F-Score - Old B-Cubed F-Score"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_F-Score_Results",
        "entity_type": "Metric",
        "name": "MUC F-Score Results",
        "description": "Official MUC scoring algorithm results",
        "category": "Coreference Resolution Evaluation",
        "formula": "Harmonic Mean of Precision and Recall"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_ArithmeticWordProblemSolver",
        "entity_type": "Algorithm",
        "name": "Arithmetic Word Problem Solver",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Irrelevance Classifier",
            "LCA Operation Classifier"
          ],
          "connections": [
            "Irrelevance Classifier -> Constrained Inference Module",
            "LCA Operation Classifier -> Constrained Inference Module"
          ],
          "mechanisms": [
            "Monotonic Expression Tree",
            "Constrained Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Classifier Training",
            "Constrained Inference"
          ],
          "parameter_tuning": [
            "Scaling Parameter (λIRR)"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-based Extraction Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_DecomposedModel",
        "entity_type": "Algorithm",
        "name": "Decomposed Model",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Vertex Classifier",
            "Edge Classifier",
            "Constrained Inference Module"
          ],
          "connections": [
            "Vertex Classifier -> Constrained Inference Module",
            "Edge Classifier -> Constrained Inference Module"
          ],
          "mechanisms": [
            "Structured Prediction",
            "Joint Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Beam Search"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-based Extraction Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_VertexClassifier",
        "entity_type": "Algorithm",
        "name": "Vertex Classifier",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary Classifier"
          ],
          "connections": [],
          "mechanisms": [
            "Binary Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context Features",
          "Rule-based Extraction Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_EdgeClassifier",
        "entity_type": "Algorithm",
        "name": "Edge Classifier",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multiclass Classifier"
          ],
          "connections": [],
          "mechanisms": [
            "Multiclass Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context Features",
          "Rule-based Extraction Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_ConstrainedInferenceModule",
        "entity_type": "Algorithm",
        "name": "Constrained Inference Module",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Inference Module"
          ],
          "connections": [
            "Vertex Classifier -> Constrained Inference Module",
            "Edge Classifier -> Constrained Inference Module"
          ],
          "mechanisms": [
            "Constrained Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_JointInferenceProcedure",
        "entity_type": "Algorithm",
        "name": "Joint Inference Procedure",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Joint Inference Module"
          ],
          "connections": [
            "Decomposed Model -> Joint Inference Procedure"
          ],
          "mechanisms": [
            "Joint Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_RuleBasedExtraction",
        "entity_type": "Algorithm",
        "name": "Rule Based Extraction",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Unit Extraction",
        "dataset": [
          "AllArith_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Rule-based system"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context Features",
          "Rule based Extraction Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_EDGELABEL",
        "entity_type": "Algorithm",
        "name": "EDGELABEL",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Edge Label Prediction",
        "dataset": [
          "AllArith_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Algorithm 1"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Heuristic-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context Features",
          "Rule based Extraction Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_MonotonicExpressionTree",
        "entity_type": "Algorithm",
        "name": "Monotonic Expression Tree",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Binary Tree Representation"
          ],
          "connections": [
            "Addition/Subtraction Nodes",
            "Multiplication/Division Nodes"
          ],
          "mechanisms": [
            "Normalization of Expression Trees"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Monotonic Restriction"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_IrrelevanceClassifier",
        "entity_type": "Algorithm",
        "name": "Irrelevance Classifier",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary Classifier"
          ],
          "connections": [],
          "mechanisms": [
            "Relevance Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-Based Extraction Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_LCAOperationClassifier",
        "entity_type": "Algorithm",
        "name": "LCA Operation Classifier",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multiclass Classifier"
          ],
          "connections": [],
          "mechanisms": [
            "Lowest Common Ancestor Node Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-Based Extraction Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_LCA++",
        "entity_type": "Algorithm",
        "name": "LCA++",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Irrelevance Classifier",
            "LCA Operation Classifier"
          ],
          "connections": [
            "Monotonic Expression Tree"
          ],
          "mechanisms": [
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross Validation"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Neighborhood Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TemplateBasedAlgebraSolver",
        "entity_type": "Algorithm",
        "name": "TEMPLATE",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Zettlemoyer, L.",
          "Barzilay, R.",
          "Artzi, Y."
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Template Matching"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Template Matching"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KoncelKedziorski2015_SingleEquationSolver",
        "entity_type": "Algorithm",
        "name": "SINGLEEQ",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S."
        ],
        "task": "Single Equation Word Problem Solving",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Single Equation Parsing"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Single Equation Parsing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_HoughTransformation",
        "entity_type": "Algorithm",
        "name": "Hough Transformation",
        "year": 1972,
        "authors": [
          "Richard O. Duda",
          "Peter E. Hart"
        ],
        "task": "Line and Curve Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Point-Line Transformation",
            "Parameter Space Quantization"
          ],
          "connections": [
            "Figure Points to Sinusoidal Curves",
            "Accumulator Array"
          ],
          "mechanisms": [
            "Normal Parameterization",
            "Angle-Radius Parameters"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Quantization of Parameter Space"
          ],
          "parameter_tuning": [
            "Quantization Intervals for θ and ρ"
          ]
        },
        "feature_processing": [
          "Intensity Changes Detection",
          "Binary Image Conversion"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_NormalParameterization",
        "entity_type": "Algorithm",
        "name": "Normal Parameterization",
        "year": 1972,
        "authors": [
          "Richard O. Duda",
          "Peter E. Hart"
        ],
        "task": "Line Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Angle",
            "Radius"
          ],
          "connections": [
            "Point-Line Transformation"
          ],
          "mechanisms": [
            "Parameter Space Mapping"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "CoincidentPoints_CurveDetection",
        "entity_type": "Metric",
        "name": "Coincident Points",
        "description": "Number of points intersecting at a common point in the parameter space",
        "category": "Curve Detection",
        "formula": "Number of intersections at a specific (θ, p) in the parameter space"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_AccumulatorImplementation",
        "entity_type": "Algorithm",
        "name": "Accumulator Implementation",
        "year": 1972,
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "Line Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Two-dimensional accumulator array",
            "Parameter space"
          ],
          "connections": [
            "Mapping figure points to parameter space",
            "Incrementing cell counts"
          ],
          "mechanisms": [
            "Quantization of parameter space",
            "Finding high-count cells"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization intervals for θ and ρ"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "HighCounts_ConcurrentCurves",
        "entity_type": "Metric",
        "name": "High Counts",
        "description": "Number of concurrent curves intersecting at a point in the parameter space",
        "category": "Curve Detection",
        "formula": "Count of intersections in accumulator cells"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Threshold_ColinearPoints",
        "entity_type": "Metric",
        "name": "Threshold",
        "description": "Minimum number of colinear points required to detect a line",
        "category": "Line Detection",
        "formula": "Arbitrary threshold value (e.g., 35)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_TransformApproachExample",
        "entity_type": "Algorithm",
        "name": "Transform Approach Example",
        "year": 1972,
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "Line Detection",
        "dataset": [
          "Box Image"
        ],
        "metrics": [
          "Number of Colinear Points"
        ],
        "architecture": {
          "components": [
            "Point-to-Curve Transformation",
            "Accumulator Array"
          ],
          "connections": [
            "Figure Points -> Sinusoidal Curves -> Accumulator Cells"
          ],
          "mechanisms": [
            "Quantization of Parameter Space",
            "Counting Intersections"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "Quantization Intervals for θ and p"
          ]
        },
        "feature_processing": [
          "Simple Differencing Operation for Edge Detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "BoxImage_1972",
        "entity_type": "Dataset",
        "name": "Box Image",
        "description": "Digitized version of a television monitor view of a box",
        "domain": "Computer Vision",
        "size": "120x120 pixels",
        "year": 1972,
        "creators": [
          "Duda, R.O.",
          "Hart, P.E."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "NumberOfColinearPoints_Detection",
        "entity_type": "Metric",
        "name": "Number of Colinear Points",
        "description": "The number of figure points that lie on parallel lines",
        "category": "Line Detection",
        "formula": "k figure points lie on parallel lines for which θ = θ0, and p lies between p0 and p0 + Δp"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_GeneralizedTransformMethod",
        "entity_type": "Algorithm",
        "name": "Generalized Transform Method",
        "year": 1972,
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "Curve Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Parameter Space",
            "Accumulator Array"
          ],
          "connections": [
            "Point-Curve Transformation",
            "Parameter Quantization"
          ],
          "mechanisms": [
            "Intersection Detection",
            "High Count Accumulation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Intervals"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_CircularConfigurationDetection",
        "entity_type": "Algorithm",
        "name": "Circular Configuration Detection",
        "year": 1972,
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "Circle Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Three-Dimensional Parameter Space",
            "Accumulator Array"
          ],
          "connections": [
            "Point-Surface Transformation",
            "Cone Intersection"
          ],
          "mechanisms": [
            "Intersection Detection",
            "High Count Accumulation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Intervals"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_SlopeInterceptParameterization",
        "entity_type": "Algorithm",
        "name": "Slope-Intercept Parameterization",
        "year": 1972,
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "Line Detection",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Two-Dimensional Parameter Space"
          ],
          "connections": [
            "Point-Line Transformation"
          ],
          "mechanisms": [
            "Intersection Detection",
            "High Count Accumulation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Resolution_Sensitivity",
        "entity_type": "Metric",
        "name": "Resolution Sensitivity",
        "description": "Sensitivity of results to the quantization of parameters",
        "category": "Parameter Sensitivity",
        "formula": "Not explicitly defined"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ComputationTime_Efficiency",
        "entity_type": "Metric",
        "name": "Computation Time Efficiency",
        "description": "Efficiency in terms of computation time",
        "category": "Computational Efficiency",
        "formula": "Not explicitly defined"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MS_COCO_2014",
        "entity_type": "Dataset",
        "name": "MS COCO",
        "description": "Microsoft Common Objects in Context dataset",
        "domain": "Computer Vision",
        "size": 204721,
        "year": 2014,
        "creators": [
          "T.-Y. Lin",
          "M. Maire",
          "S. Belongie",
          "J. Hays",
          "P. Perona",
          "D. Ramanan",
          "P. Dollar",
          "C. L. Zitnick"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Abstract_Scenes_2015",
        "entity_type": "Dataset",
        "name": "Abstract Scenes",
        "description": "Dataset of abstract scenes for VQA",
        "domain": "Computer Vision",
        "size": 50000,
        "year": 2015,
        "creators": [
          "Stanislaw Antol",
          "Aishwarya Agrawal",
          "Jiasen Lu",
          "Margaret Mitchell",
          "Dhruv Batra",
          "C. Lawrence Zitnick",
          "Devi Parikh"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Open-Answer",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for open-answer task",
        "category": "Classification Evaluation",
        "formula": "min(# humans that provided that answer / 3, 1)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Multiple-Choice",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for multiple-choice task",
        "category": "Classification Evaluation",
        "formula": "scaled by 3 and clipped at 1"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Malinowski2014_MultiWorldQA",
        "entity_type": "Algorithm",
        "name": "Multi-World Approach to Question Answering",
        "year": 2014,
        "authors": [
          "Malinowski, M.",
          "Fritz, M."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "MS COCO"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Uncertain Input Handling"
          ],
          "connections": [
            "Multi-World Model"
          ],
          "mechanisms": [
            "Scene Understanding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Uncertain Input Training"
          ],
          "parameter_tuning": [
            "Uncertainty Parameters"
          ]
        },
        "feature_processing": [
          "Scene Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Malinowski2015_NeuralQA",
        "entity_type": "Algorithm",
        "name": "Neural-Based Approach to Answering Questions about Images",
        "year": 2015,
        "authors": [
          "Malinowski, M.",
          "Rohrbach, M.",
          "Fritz, M."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "MS COCO"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Neural Network"
          ],
          "connections": [
            "Image and Question Fusion"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Neural Network Parameters"
          ]
        },
        "feature_processing": [
          "Image Features",
          "Question Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "YouTube2Text_2013",
        "entity_type": "Dataset",
        "name": "YouTube2Text",
        "description": "Dataset for recognizing and describing arbitrary activities using semantic hierarchies and zero-shot recognition",
        "domain": "Video Captioning",
        "size": 15,
        "year": 2013,
        "creators": [
          "Guadarrama, S.",
          "Krishnamoorthy, N.",
          "Malkarnenkar, G.",
          "Venugopalan, S.",
          "Mooney, R.",
          "Darrell, T.",
          "Saenko, K."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ROUGE_Score",
        "entity_type": "Metric",
        "name": "ROUGE Score",
        "description": "Recall-Oriented Understudy for Gisting Evaluation",
        "category": "Summarization and Captioning Evaluation",
        "formula": "Recall-based evaluation of overlapping n-grams, word pairs, and word sequences"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MS_COCO_Images_2014",
        "entity_type": "Dataset",
        "name": "MS COCO Images",
        "description": "Dataset containing 123,287 training and validation images and 81,434 test images.",
        "domain": "Computer Vision",
        "size": 204721,
        "year": 2014,
        "creators": [
          "Lin, T.-Y.",
          "Maire, M.",
          "Belongie, S.",
          "Hays, J.",
          "Perona, P.",
          "Ramanan, D.",
          "Dolla´r, P.",
          "Zitnick, C. L."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Human_Accuracy_Open-Answer",
        "entity_type": "Metric",
        "name": "Human Accuracy (Open-Answer)",
        "description": "Accuracy of human subjects answering open-ended questions.",
        "category": "Human Evaluation",
        "formula": "Percentage of correct answers provided by human subjects"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Human_Accuracy_Multiple-Choice",
        "entity_type": "Metric",
        "name": "Human Accuracy (Multiple-Choice)",
        "description": "Accuracy of human subjects answering multiple-choice questions.",
        "category": "Human Evaluation",
        "formula": "Percentage of correct answers provided by human subjects"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Antol2015_MLP_VQA",
        "entity_type": "Algorithm",
        "name": "MLP VQA",
        "year": 2015,
        "authors": [
          "Antol, S.",
          "Agrawal, A.",
          "Lu, J.",
          "Mitchell, M.",
          "Batra, D.",
          "Zitnick, C. L.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "MS_COCO_2014"
        ],
        "metrics": [
          "Accuracy_Open-Answer",
          "Accuracy_Multiple-Choice"
        ],
        "architecture": {
          "components": [
            "Multi-layer Perceptron",
            "Hidden Layers",
            "Dropout",
            "Tanh Activation"
          ],
          "connections": [
            "Fully Connected Layers"
          ],
          "mechanisms": [
            "Dropout Regularization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Bag-of-Words",
          "Image Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Antol2015_LSTM_VQA",
        "entity_type": "Algorithm",
        "name": "LSTM VQA",
        "year": 2015,
        "authors": [
          "Antol, S.",
          "Agrawal, A.",
          "Lu, J.",
          "Mitchell, M.",
          "Batra, D.",
          "Zitnick, C. L.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "MS_COCO_2014"
        ],
        "metrics": [
          "Accuracy_Open-Answer",
          "Accuracy_Multiple-Choice"
        ],
        "architecture": {
          "components": [
            "Long Short-Term Memory",
            "Softmax Layer"
          ],
          "connections": [
            "Recurrent Connections"
          ],
          "mechanisms": [
            "Gated Recurrent Units"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Embedding Size"
          ]
        },
        "feature_processing": [
          "One-Hot Encoding",
          "Image Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "VQA_TrainVal_2015",
        "entity_type": "Dataset",
        "name": "VQA TrainVal",
        "description": "Dataset used for training and validation of VQA models",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 204721,
        "year": 2015,
        "creators": [
          "Antol, S.",
          "Agrawal, A.",
          "Lu, J.",
          "Mitchell, M.",
          "Batra, D.",
          "Zitnick, C. L.",
          "Parikh, D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Top_K_Accuracy",
        "entity_type": "Metric",
        "name": "Top-K Accuracy",
        "description": "Accuracy of selecting the correct answer from the top K predictions",
        "category": "Classification Evaluation",
        "formula": "Number of correct answers in top K / Total number of questions"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "VQA_Dataset_2015",
        "entity_type": "Dataset",
        "name": "VQA Dataset",
        "description": "包含超过250K张图像、760K个问题和约10M个答案的数据集",
        "domain": "计算机视觉与自然语言处理",
        "size": 250000,
        "year": 2015,
        "creators": [
          "Antol, S.",
          "Agrawal, A.",
          "Lu, J.",
          "Mitchell, M.",
          "Batra, D.",
          "Zitnick, C. L.",
          "Parikh, D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Human_Agreement_Rate",
        "entity_type": "Metric",
        "name": "Human Agreement Rate",
        "description": "人类回答者之间的同意率",
        "category": "一致性评估",
        "formula": "同意的答案数量 / 总答案数量"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Inter_Human_Agreement",
        "entity_type": "Metric",
        "name": "Inter-Human Agreement",
        "description": "不同人类回答者之间的一致性",
        "category": "一致性评估",
        "formula": "一致答案的数量 / 总答案数量"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Commonsense_Question_Ratio",
        "entity_type": "Metric",
        "name": "Commonsense Question Ratio",
        "description": "需要常识推理的问题比例",
        "category": "问题类型评估",
        "formula": "需要常识推理的问题数量 / 总问题数量"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Question_Type_Distribution",
        "entity_type": "Metric",
        "name": "Question Type Distribution",
        "description": "不同类型问题的分布情况",
        "category": "问题类型评估",
        "formula": "每种问题类型的数量 / 总问题数量"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Answer_Length_Distribution",
        "entity_type": "Metric",
        "name": "Answer Length Distribution",
        "description": "答案长度的分布情况",
        "category": "答案评估",
        "formula": "不同长度答案的数量 / 总答案数量"
      }
    }
  ],
  "is_complete": false,
  "extraction_time": 1749317281.5866914
}