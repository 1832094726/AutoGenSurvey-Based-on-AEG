{
  "entities": [
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_L3M",
        "entity_type": "Algorithm",
        "name": "Latent Left Linking model (L3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE",
          "Ontonotes"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Latent Variables",
            "Constraints"
          ],
          "connections": [
            "Latent Variables to Clusters"
          ],
          "mechanisms": [
            "Stochastic Gradient Descent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Feature Engineering for Coreference"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE_2013",
        "entity_type": "Dataset",
        "name": "ACE",
        "description": "ACE dataset for coreference resolution",
        "domain": "Natural Language Processing",
        "year": 2013,
        "creators": [
          "ACE Project"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Ontonotes_2013",
        "entity_type": "Dataset",
        "name": "Ontonotes",
        "description": "Ontonotes dataset for coreference resolution",
        "domain": "Natural Language Processing",
        "year": 2013,
        "creators": [
          "Ontonotes Project"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Coreference",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 Score for coreference resolution",
        "category": "Coreference Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_SemanticParsingAndReasoning",
        "entity_type": "Algorithm",
        "name": "Semantic Parsing and Reasoning",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": 2016,
        "authors": [
          "Shuming Shi",
          "Yuehui Wang",
          "Chin-Yew Lin",
          "Xiaojiang Liu",
          "Yong Rui"
        ],
        "task": "Solving Math Word Problems",
        "dataset": [
          "ACE_2013"
        ],
        "metrics": [
          "F1_Score_Classification",
          "Precision_Classification"
        ],
        "architecture": {
          "components": [
            "CFG Parser",
            "Meaning Representation Language"
          ],
          "connections": [
            "Natural Language Text",
            "Math Expressions"
          ],
          "mechanisms": [
            "Semantic Parsing",
            "Reasoning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Grammar Rules"
          ]
        },
        "feature_processing": [
          "Pattern Matching",
          "Verb Categorization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_DeepNeuralSolver",
        "entity_type": "Algorithm",
        "name": "Deep Neural Solver",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Yan Wang",
          "Xiaojiang Liu",
          "Shuming Shi"
        ],
        "task": "Solving Math Word Problems",
        "dataset": [
          "LargeDataset_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network (RNN)",
            "Similarity-based Retrieval Model"
          ],
          "connections": [
            "Math Word Problems",
            "Equation Templates"
          ],
          "mechanisms": [
            "Translation",
            "Hybrid Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Hyperparameters"
          ]
        },
        "feature_processing": [
          "Feature Engineering"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "LargeDataset_2017",
        "entity_type": "Dataset",
        "name": "Large Dataset",
        "description": "A large dataset of math word problems",
        "domain": "Natural Language Processing",
        "size": "Not specified",
        "year": 2017,
        "creators": [
          "Yan Wang",
          "Xiaojiang Liu",
          "Shuming Shi"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Classification",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Classification accuracy",
        "category": "Classification Evaluation",
        "formula": "Correct classifications / Total samples"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Classification",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Classification Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Classification",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Proportion of true positive predictions among all positive predictions",
        "category": "Classification Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_NeuralDependencyParser",
        "entity_type": "Algorithm",
        "name": "Neural Dependency Parser",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English Penn Treebank"
        ],
        "metrics": [
          "Unlabeled Attachment Score",
          "Labeled Attachment Score"
        ],
        "architecture": {
          "components": [
            "Neural Network Classifier",
            "Greedy Transition-based Parser"
          ],
          "connections": [
            "Input Layer",
            "Hidden Layers",
            "Output Layer"
          ],
          "mechanisms": [
            "Feature Learning",
            "Transition Actions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Part-of-Speech Tags"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "EnglishPennTreebank_2014",
        "entity_type": "Dataset",
        "name": "English Penn Treebank",
        "description": "A widely used dataset for parsing tasks",
        "domain": "Natural Language Processing",
        "size": "Not specified",
        "year": 2014,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "UnlabeledAttachmentScore_Parsing",
        "entity_type": "Metric",
        "name": "Unlabeled Attachment Score",
        "description": "Measures the accuracy of unlabeled dependencies",
        "category": "Parsing Evaluation",
        "formula": "Correct unlabeled dependencies / Total dependencies"
      }
    },
    {
      "metric_entity": {
        "metric_id": "LabeledAttachmentScore_Parsing",
        "entity_type": "Metric",
        "name": "Labeled Attachment Score",
        "description": "Measures the accuracy of labeled dependencies",
        "category": "Parsing Evaluation",
        "formula": "Correct labeled dependencies / Total dependencies"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_MultiPassSieve",
        "entity_type": "Algorithm",
        "name": "Multi-Pass Sieve",
        "title": "A Multi-Pass Sieve for Coreference Resolution",
        "year": 2010,
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE",
          "Ontonotes"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Sieves",
            "Entity Clusters"
          ],
          "connections": [
            "Tier-based processing",
            "Global information propagation"
          ],
          "mechanisms": [
            "Deterministic coreference models",
            "Modular architecture"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None (unsupervised)"
          ],
          "parameter_tuning": [
            "None (unsupervised)"
          ]
        },
        "feature_processing": [
          "High precision features",
          "Low precision features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ConstrainedLatentVariableModel",
        "entity_type": "Algorithm",
        "name": "Constrained Latent Variable Model (CL3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE",
          "Ontonotes"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Latent Left Linking Model (L3M)",
            "Knowledge-based constraints"
          ],
          "connections": [
            "Latent structured prediction",
            "Efficient inference"
          ],
          "mechanisms": [
            "Stochastic gradient learning",
            "Constraint augmentation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic gradient descent"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Regularization parameters"
          ]
        },
        "feature_processing": [
          "Pairwise mention features",
          "Higher-order interactions"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Ontonotes_2010",
        "entity_type": "Dataset",
        "name": "Ontonotes",
        "description": "A large-scale dataset for coreference resolution and other NLP tasks",
        "domain": "Natural Language Processing",
        "size": "Large",
        "year": 2010,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "KoncelKedziorski2015_ALGES",
        "entity_type": "Algorithm",
        "name": "ALGES",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "Solving algebraic word problems",
        "dataset": [
          "Alg514",
          "Dolphin1878"
        ],
        "metrics": [
          "Equation likelihood",
          "Solution accuracy"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming(ILP)",
            "Local and global discriminative models"
          ],
          "connections": [
            "Equation tree generation",
            "Scoring equation likelihood"
          ],
          "mechanisms": [
            "Learning local and global models"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Integer Linear Programming(ILP)"
          ],
          "parameter_tuning": [
            "Equation likelihood maximization"
          ]
        },
        "feature_processing": [
          "Equation tree generation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Alg514_2015",
        "entity_type": "Dataset",
        "name": "Alg514",
        "description": "A dataset containing 514 algebra problems",
        "domain": "Mathematics",
        "size": 514,
        "year": 2015,
        "creators": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin1878_2015",
        "entity_type": "Dataset",
        "name": "Dolphin1878",
        "description": "A dataset containing 1878 algebra problems",
        "domain": "Mathematics",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "EquationLikelihood_Classification",
        "entity_type": "Metric",
        "name": "Equation likelihood",
        "description": "The likelihood of an equation being correct",
        "category": "Classification",
        "formula": "Not explicitly defined"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SolutionAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Solution accuracy",
        "description": "The accuracy of the solution to the word problem",
        "category": "Classification",
        "formula": "Correct solutions / Total solutions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2016_MultiTaskSeq2Seq",
        "entity_type": "Algorithm",
        "name": "Multi-task Sequence to Sequence Learning",
        "title": "Multi-task Sequence to Sequence Learning",
        "year": 2016,
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "Sequence to Sequence Learning",
        "dataset": [
          "Machine Translation",
          "Syntactic Parsing",
          "Image Caption Generation"
        ],
        "metrics": [
          "BLEU Score",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Feed-forward Neural Network"
          ],
          "connections": [
            "Shared Encoder",
            "Shared Decoder"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation",
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size",
            "Number of Layers"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Embedding"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT_2014",
        "entity_type": "Dataset",
        "name": "WMT",
        "description": "Web-scale Machine Translation dataset",
        "domain": "Natural Language Processing",
        "size": "Large",
        "year": 2014,
        "creators": [
          "WMT Community"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreebank_2014",
        "entity_type": "Dataset",
        "name": "Penn Treebank",
        "description": "Corpus of syntactically annotated English text",
        "domain": "Natural Language Processing",
        "size": "Large",
        "year": 2014,
        "creators": [
          "Marcus, Mitchell P.",
          "Marcinkiewicz, Mary Ann",
          "Santorini, Beatrice"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MSCOCO_2014",
        "entity_type": "Dataset",
        "name": "MS COCO",
        "description": "Common Objects in Context dataset",
        "domain": "Computer Vision",
        "size": "Large",
        "year": 2014,
        "creators": [
          "Lin, Tsung-Yi",
          "Maire, Michael",
          "Belongie, Serge",
          "Hays, James",
          "Perona, Pietro",
          "Ramanan, Deva",
          "Dollár, Piotr",
          "Zitnick, C. Lawrence"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_Score_Translation",
        "entity_type": "Metric",
        "name": "BLEU Score",
        "description": "Bilingual Evaluation Understudy Score",
        "category": "Translation Evaluation",
        "formula": "BLEU = BP × exp(∑_{n=1}^{N} w_n log p_n)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Parsing",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Parsing Evaluation",
        "formula": "F1 = 2 × (Precision × Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_DiagramUnderstanding",
        "entity_type": "Algorithm",
        "name": "Diagram Understanding",
        "title": "Diagram Understanding in Geometry Questions",
        "year": 2014,
        "authors": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ],
        "task": "Geometry Question Solving",
        "dataset": [
          "Geometry Questions Dataset_2014"
        ],
        "metrics": [
          "F1 Score_DiagramUnderstanding",
          "Accuracy_DiagramAlignment"
        ],
        "architecture": {
          "components": [
            "Visual Element Identification",
            "Textual Alignment"
          ],
          "connections": [
            "Visual Elements to Textual Descriptions"
          ],
          "mechanisms": [
            "Submodular Objective Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximizing Agreement Between Textual and Visual Data"
          ],
          "parameter_tuning": [
            "Submodular Function Optimization"
          ]
        },
        "feature_processing": [
          "Visual Feature Extraction",
          "Textual Feature Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "GeometryQuestionsDataset_2014",
        "entity_type": "Dataset",
        "name": "Geometry Questions Dataset",
        "description": "Dataset of geometry questions with textual descriptions and diagrams",
        "domain": "Geometry Education",
        "size": "Not specified",
        "year": 2014,
        "creators": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_DiagramUnderstanding",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 score for identifying visual elements",
        "category": "Diagram Understanding",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_DiagramAlignment",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for aligning visual elements with textual descriptions",
        "category": "Diagram Alignment",
        "formula": "Correct Alignments / Total Alignments"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_RNNEncoderDecoder",
        "entity_type": "Algorithm",
        "name": "RNN Encoder–Decoder",
        "title": "Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation",
        "year": 2014,
        "authors": [
          "Kyunghyun Cho",
          "Bart van Merriënboer",
          "Caglar Gulcehre",
          "Dzmitry Bahdanau",
          "Fethi Bougares",
          "Holger Schwenk",
          "Yoshua Bengio"
        ],
        "task": "Statistical Machine Translation",
        "dataset": [
          "English-French translation dataset"
        ],
        "metrics": [
          "BLEU Score"
        ],
        "architecture": {
          "components": [
            "Encoder RNN",
            "Decoder RNN"
          ],
          "connections": [
            "Fixed-length vector representation"
          ],
          "mechanisms": [
            "Conditional probability maximization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint training of encoder and decoder"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Batch size"
          ]
        },
        "feature_processing": [
          "Phrase representation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "EnglishFrenchTranslationDataset_2014",
        "entity_type": "Dataset",
        "name": "English-French translation dataset",
        "description": "Dataset for translating English to French",
        "domain": "Natural Language Processing",
        "size": "Not specified",
        "year": 2014,
        "creators": [
          "Not specified"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_ExpressionTree",
        "entity_type": "Algorithm",
        "name": "Expression Tree",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Benchmark datasets of arithmetic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Constrained Inference Framework"
          ],
          "connections": [
            "Decomposition of arithmetic problem to classification problems"
          ],
          "mechanisms": [
            "Quantity Schemas"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Decomposing the problem into simpler prediction problems"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Quantity Schemas"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "BenchmarkArithmeticWordProblems_2015",
        "entity_type": "Dataset",
        "name": "Benchmark datasets of arithmetic word problems",
        "year": 2015,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_ArithmeticWordProblems",
        "entity_type": "Metric",
        "name": "Accuracy",
        "category": "Arithmetic Word Problem Solving",
        "formula": "Correctly solved problems / Total problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2016_UnitDependencyGraph",
        "entity_type": "Algorithm",
        "name": "Unit Dependency Graph",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2016,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "BenchmarkArithmeticWordProblems_2015"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "Unit Extraction",
            "Dependency Graph Construction"
          ],
          "connections": [
            "Unit Relationships",
            "Question Dependencies"
          ],
          "mechanisms": [
            "Global Reasoning",
            "Domain Knowledge Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Prediction",
            "Decomposed Model"
          ],
          "parameter_tuning": [
            "Unit Compatibility Parameters"
          ]
        },
        "feature_processing": [
          "Rate Detection",
          "Unit Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2015_GEOS",
        "entity_type": "Algorithm",
        "name": "GEOS",
        "title": "Solving Geometry Problems: Combining Text and Diagram Interpretation",
        "year": 2015,
        "authors": [
          "Minjoon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni",
          "Clint Malcolm"
        ],
        "task": "Geometry Problem Solving",
        "dataset": [
          "GeometryQuestionsDataset_2014"
        ],
        "metrics": [
          "Accuracy_GeometryProblems",
          "F1_Score_DiagramUnderstanding"
        ],
        "architecture": {
          "components": [
            "Text Parsing",
            "Diagram Parsing",
            "Submodular Optimization"
          ],
          "connections": [
            "Text-Diagram Alignment",
            "Formal Problem Description"
          ],
          "mechanisms": [
            "Geometric Solver Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Submodular Optimization",
            "Greedy Algorithm"
          ],
          "parameter_tuning": [
            "Text-Diagram Compatibility Parameters"
          ]
        },
        "feature_processing": [
          "Diagram Element Recognition",
          "Textual Reference Resolution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Math23K_2017",
        "entity_type": "Dataset",
        "name": "Math23K",
        "description": "Large dataset of arithmetic word problems",
        "domain": "Mathematics",
        "size": 23164,
        "year": 2017,
        "creators": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MAWPS_2017",
        "entity_type": "Dataset",
        "name": "MAWPS",
        "description": "Dataset of arithmetic word problems",
        "domain": "Mathematics",
        "size": 2373,
        "year": 2017,
        "creators": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_GeometryProblems",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of solving geometry problems",
        "category": "Geometry Problem Solving",
        "formula": "Correctly solved problems / Total problems"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_GeometryProblems",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 Score for geometry problem solving",
        "category": "Geometry Problem Solving",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_TemplateBasedSolver",
        "entity_type": "Algorithm",
        "name": "Template-Based Math Word Problem Solver",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2017"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Recursive Neural Network",
            "Bi-LSTM",
            "Self Attention"
          ],
          "connections": [
            "Template Prediction",
            "Quantity Encoding"
          ],
          "mechanisms": [
            "Bottom-Up Inference",
            "Tree Structure Template"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Recursive Neural Network Training",
            "Template-Based Approach"
          ],
          "parameter_tuning": [
            "Template Space Reduction",
            "Equation Normalization"
          ]
        },
        "feature_processing": [
          "Quantity Embedding",
          "Operator Inference"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_EquationNormalization",
        "entity_type": "Algorithm",
        "name": "Equation Normalization",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2016,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "SEQ2SEQ Model"
          ],
          "connections": [
            "Equation Duplication Handling",
            "Ensemble Model"
          ],
          "mechanisms": [
            "Uniqueness of Expression Tree",
            "Model Combination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SEQ2SEQ Framework",
            "Ensemble Learning"
          ],
          "parameter_tuning": [
            "Equation Normalization Parameters"
          ]
        },
        "feature_processing": [
          "Equation Duplication Handling",
          "Model Ensemble Techniques"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_MathWordProblems",
        "entity_type": "Metric",
        "name": "Accuracy",
        "year": 2018,
        "category": "Math Word Problem Solving",
        "description": "The accuracy of the math word problem solver in providing correct answers.",
        "formula": "Correct answers / Total number of problems"
      }
    }
  ],
  "is_complete": false,
  "extraction_time": 1749401475.29892
}