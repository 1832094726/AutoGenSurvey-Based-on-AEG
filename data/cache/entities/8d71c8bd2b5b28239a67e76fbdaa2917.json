{
  "entities": [
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_LatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Latent Left-Linking Model (L3M)",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Pairwise Scorer",
            "Left-Linking Model"
          ],
          "connections": [
            "Pairwise Compatibility Scores",
            "Best-Left-Link Inference"
          ],
          "mechanisms": [
            "Efficient Inference",
            "Constraint-Augmented Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Pairwise Weight Vector",
            "Threshold"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Pairwise Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ConstrainedLatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Constrained Latent Left-Linking Model (CL3M)",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Pairwise Scorer",
            "Left-Linking Model",
            "Domain Knowledge-Based Constraints"
          ],
          "connections": [
            "Pairwise Compatibility Scores",
            "Best-Left-Link Inference",
            "Constraint-Augmented Scoring Function"
          ],
          "mechanisms": [
            "Efficient Inference",
            "Constraint-Augmented Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Pairwise Weight Vector",
            "Threshold",
            "Constraint Scores"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Pairwise Features",
          "Constraint Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ProbabilisticLatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Probabilistic Latent Left-Linking Model (PL3M)",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Pairwise Scorer",
            "Left-Linking Model",
            "Probability Distribution"
          ],
          "connections": [
            "Pairwise Compatibility Scores",
            "Best-Left-Link Inference",
            "Probability-Based Clustering"
          ],
          "mechanisms": [
            "Efficient Inference",
            "Constraint-Augmented Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Likelihood-Based Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Pairwise Weight Vector",
            "Temperature Parameter Î³"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Pairwise Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE_2004",
        "entity_type": "Dataset",
        "name": "ACE 2004",
        "year": 2004,
        "creators": [
          "NIST"
        ],
        "description": "A dataset containing 443 documents used for coreference resolution.",
        "domain": "Natural Language Processing"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Ontonotes_2012",
        "entity_type": "Dataset",
        "name": "Ontonotes-5.0",
        "year": 2012,
        "creators": [
          "Pradhan et al."
        ],
        "description": "A large annotated corpus for coreference resolution containing 3,145 documents from various sources.",
        "domain": "Natural Language Processing"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_Coreference",
        "entity_type": "Metric",
        "name": "MUC",
        "description": "Metric for evaluating coreference resolution performance.",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper."
      }
    },
    {
      "metric_entity": {
        "metric_id": "BCUB_Coreference",
        "entity_type": "Metric",
        "name": "BCUB",
        "description": "Metric for evaluating coreference resolution performance.",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper."
      }
    },
    {
      "metric_entity": {
        "metric_id": "CEAF_EntityBased",
        "entity_type": "Metric",
        "name": "Entity-based CEAF",
        "description": "Metric for evaluating coreference resolution performance.",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper."
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1Score_Average",
        "entity_type": "Metric",
        "name": "Average F1 Score",
        "description": "Average of F1 scores across multiple metrics.",
        "category": "Coreference Evaluation",
        "formula": "Average of MUC, BCUB, and CEAF F1 scores."
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_NeuralNetworkDependencyParser",
        "entity_type": "Algorithm",
        "name": "Neural Network Dependency Parser",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "PTB_2014",
          "CTB_2014"
        ],
        "metrics": [
          "UAS_Parsing",
          "LAS_Parsing",
          "Parsing_Speed"
        ],
        "architecture": {
          "components": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Arc Label Embeddings",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Input Layer -> Hidden Layer",
            "Hidden Layer -> Softmax Layer"
          ],
          "mechanisms": [
            "Cube Activation Function",
            "Pre-trained Word Embeddings Initialization",
            "POS and Arc Label Embeddings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mini-batched AdaGrad",
            "Dropout"
          ],
          "parameter_tuning": [
            "Embedding Size",
            "Hidden Layer Size",
            "Regularization Parameter",
            "Initial Learning Rate"
          ]
        },
        "feature_processing": [
          "Dense Feature Representation",
          "Pre-computation Trick"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PTB_2014",
        "entity_type": "Dataset",
        "name": "English Penn Treebank",
        "description": "Standard dataset for English syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 39832,
        "year": 2014,
        "creators": [
          "Johansson, R.",
          "Nugues, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CTB_2014",
        "entity_type": "Dataset",
        "name": "Chinese Penn Treebank",
        "description": "Standard dataset for Chinese syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 16091,
        "year": 2014,
        "creators": [
          "Zhang, Y.",
          "Clark, S."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "UAS_Parsing",
        "entity_type": "Metric",
        "name": "Unlabeled Attachment Score",
        "description": "Percentage of words with correct head",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly attached words / Total words"
      }
    },
    {
      "metric_entity": {
        "metric_id": "LAS_Parsing",
        "entity_type": "Metric",
        "name": "Labeled Attachment Score",
        "description": "Percentage of words with correct head and label",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly attached and labeled words / Total words"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Parsing_Speed",
        "entity_type": "Metric",
        "name": "Parsing Speed",
        "description": "Number of sentences parsed per second",
        "category": "Dependency Parsing Efficiency",
        "formula": "Sentences parsed / Time taken"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_MultiPassSieve",
        "entity_type": "Algorithm",
        "name": "Multi-Pass Sieve",
        "title": "A Multi-Pass Sieve for Coreference Resolution",
        "year": 2010,
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV2",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC",
          "B3"
        ],
        "architecture": {
          "components": [
            "Pass 1- Exact Match",
            "Pass 2- Precise Constructs",
            "Pass 3- Strict Head Matching",
            "Pass 4- Variants of Strict Head",
            "Pass 5- Variants of Strict Head",
            "Pass 6- Relaxed Head Matching",
            "Pass 7- Pronouns"
          ],
          "connections": [
            "Each pass builds on the previous pass's entity cluster output"
          ],
          "mechanisms": [
            "Attribute sharing",
            "Mention selection",
            "Search pruning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised",
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic information",
          "Attribute sharing",
          "Cluster-level features",
          "Acronym detection",
          "Demonym detection",
          "Animacy detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-ROTH-DEV2_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-ROTH-DEV2",
        "description": "Development split of Bengston and Roth(2008) from the 2004 Automatic Content Extraction (ACE) evaluation",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": 2004,
        "creators": [
          "Bengston and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-CULOTTA-TEST_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-CULOTTA-TEST",
        "description": "Partition of ACE 2004 corpus reserved for testing by several previous works",
        "domain": "Natural Language Processing",
        "size": 107,
        "year": 2004,
        "creators": [
          "Culotta et al.",
          "Bengston and Roth",
          "Haghighi and Klein"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-NWIRE_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-NWIRE",
        "description": "Newswire subset of the ACE 2004 corpus",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": 2004,
        "creators": [
          "Poon and Domingos",
          "Haghighi and Klein"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MUC6-TEST_1995",
        "entity_type": "Dataset",
        "name": "MUC6-TEST",
        "description": "Test corpus from the sixth Message Understanding Conference (MUC-6) evaluation",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": 1995,
        "creators": [
          "Vilain et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_F1",
        "entity_type": "Metric",
        "name": "Pairwise F1",
        "description": "Computed over mention pairs in the same entity cluster",
        "category": "Coreference Resolution",
        "formula": "2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_Clustering",
        "entity_type": "Metric",
        "name": "MUC",
        "description": "Measures how many predicted clusters need to be merged to cover the gold clusters",
        "category": "Coreference Resolution",
        "formula": "Not specified in the paper"
      }
    },
    {
      "metric_entity": {
        "metric_id": "B3_Clustering",
        "entity_type": "Metric",
        "name": "B3",
        "description": "Uses the intersection between predicted and gold clusters for a given mention to mark correct mentions and the sizes of the predicted and gold clusters as denominators for precision and recall",
        "category": "Coreference Resolution",
        "formula": "Not specified in the paper"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
        "entity_type": "Algorithm",
        "name": "Structured Self-attentive Sentence Embedding",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Sentence Representation",
        "dataset": [
          "Age dataset",
          "Yelp dataset",
          "SNLI Corpus"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Self-Attention Mechanism",
            "Penalization Term"
          ],
          "connections": [
            "LSTM hidden states to attention mechanism",
            "Attention mechanism to sentence embedding"
          ],
          "mechanisms": [
            "Self-attention",
            "Penalization for diversity"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Batch size",
            "Dropout",
            "L2 regularization",
            "Penalization term coefficient"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Max pooling",
          "Averaging"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Age_dataset_2017",
        "entity_type": "Dataset",
        "name": "Age dataset",
        "description": "Twitter tweets in English, Spanish, and Dutch with age and gender labels",
        "domain": "Social Media",
        "size": 76485,
        "year": 2017,
        "creators": [
          "PAN 2016 Author Profiling Task"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Yelp_dataset_2017",
        "entity_type": "Dataset",
        "name": "Yelp dataset",
        "description": "2.7M Yelp reviews with star ratings",
        "domain": "Sentiment Analysis",
        "size": 2700000,
        "year": 2017,
        "creators": [
          "Yelp"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SNLI_Corpus_2015",
        "entity_type": "Dataset",
        "name": "SNLI Corpus",
        "description": "570k human-written English sentence pairs manually labeled for entailment, contradiction, and neutral",
        "domain": "Textual Entailment",
        "size": 570000,
        "year": 2015,
        "creators": [
          "Bowman et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Classification",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "åç±»åç¡®ç",
        "category": "åç±»è¯ä¼°",
        "formula": "æ­£ç¡®åç±»æ ·æ¬æ°/æ»æ ·æ¬æ°"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "BiLSTM_MaxPooling_MLP",
        "entity_type": "Algorithm",
        "name": "BiLSTM with Max Pooling and MLP",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Sentence Representation",
        "dataset": [
          "Age dataset",
          "Yelp dataset"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Max Pooling",
            "Multilayer Perceptron"
          ],
          "connections": [
            "LSTM hidden states to max pooling",
            "Max pooling to MLP"
          ],
          "mechanisms": [
            "Max pooling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Batch size",
            "Dropout",
            "L2 regularization"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "CNN_MaxPooling_MLP",
        "entity_type": "Algorithm",
        "name": "CNN with Max Pooling and MLP",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Sentence Representation",
        "dataset": [
          "Age dataset",
          "Yelp dataset"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Convolutional Neural Network",
            "Max Pooling",
            "Multilayer Perceptron"
          ],
          "connections": [
            "CNN hidden states to max pooling",
            "Max pooling to MLP"
          ],
          "mechanisms": [
            "Max pooling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Batch size",
            "Dropout",
            "L2 regularization"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_TagBasedSolver",
        "entity_type": "Algorithm",
        "name": "Tag-based statistical math word problem solver",
        "title": "A Tag-based English Math Word Problem Solver with Understanding, Reasoning and Explanation",
        "year": 2016,
        "authors": [
          "Chao-Chun Liang",
          "Kuang-Yi Hsu",
          "Chien-Tsung Huang",
          "Chung-Min Li",
          "Shen-Yu Miao",
          "Keh-Yih Su"
        ],
        "task": "Solving math word problems",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Solution_Type_Accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "LA -> STC",
            "STC -> LFC",
            "LFC -> IE",
            "IE -> EG"
          ],
          "mechanisms": [
            "Tag-based annotation",
            "First-order logic predicates",
            "Logic inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning with SVM classifier"
          ],
          "parameter_tuning": [
            "Linear kernel functions"
          ]
        },
        "feature_processing": [
          "Verb category features",
          "Keyword indicators",
          "Pattern-matching indicators"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MA1_2014",
        "entity_type": "Dataset",
        "name": "MA1",
        "description": "Simple math word problems on addition and subtraction for third, fourth, and fifth graders",
        "domain": "Mathematics education",
        "size": 395,
        "year": 2014,
        "creators": [
          "M. J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MA2_2014",
        "entity_type": "Dataset",
        "name": "MA2",
        "description": "Math word problems with more irrelevant information",
        "domain": "Mathematics education",
        "size": 395,
        "year": 2014,
        "creators": [
          "M. J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IXL_2014",
        "entity_type": "Dataset",
        "name": "IXL",
        "description": "Math word problems with more information gaps",
        "domain": "Mathematics education",
        "size": 395,
        "year": 2014,
        "creators": [
          "M. J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Solution_Type_Accuracy",
        "entity_type": "Metric",
        "name": "Solution Type Accuracy",
        "description": "Accuracy of identifying the correct solution type",
        "category": "Solution type classification",
        "formula": "Correct solution types / Total solution types"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_EasyFirstNonDirectionalParser",
        "entity_type": "Algorithm",
        "name": "Easy-First Non-Directional Dependency Parsing",
        "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing",
        "year": 2010,
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "WSJ Treebank",
          "CoNLL 2007 English dataset"
        ],
        "metrics": [
          "Accuracy",
          "Root",
          "Complete"
        ],
        "architecture": {
          "components": [
            "ATTACHLEFT",
            "ATTACHRIGHT"
          ],
          "connections": [
            "Dependency edges"
          ],
          "mechanisms": [
            "Non-directional parsing",
            "Best-first parsing",
            "Greedy algorithm"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured perceptron"
          ],
          "parameter_tuning": [
            "Feature representation",
            "Weight vector updates"
          ]
        },
        "feature_processing": [
          "Binary valued features",
          "POS tags",
          "Head word forms",
          "Left-most and right-most children POS tags",
          "Preposition and coordinator lexicalization",
          "Structural features",
          "Unigram features",
          "Bigram features",
          "PP-attachment features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WSJ_Treebank_2010",
        "entity_type": "Dataset",
        "name": "WSJ Treebank",
        "description": "Wall Street Journal corpus converted to dependency structures",
        "domain": "Natural Language Processing",
        "size": "Sections 2-21 for training, Section 22 for development, Section 23 for testing",
        "year": 2010,
        "creators": [
          "Yamada and Matsumoto"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL_2007_English_dataset_2007",
        "entity_type": "Dataset",
        "name": "CoNLL 2007 English dataset",
        "description": "English dataset derived from WSJ Treebank with a different conversion procedure",
        "domain": "Natural Language Processing",
        "size": "Smaller in size compared to WSJ Treebank",
        "year": 2007,
        "creators": [
          "CoNLL 2007 Shared Task"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Root_Prediction",
        "entity_type": "Metric",
        "name": "Root",
        "description": "Percentage of sentences in which the ROOT attachment is correct",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correct ROOT attachments / Total sentences"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Complete_Parsing",
        "entity_type": "Metric",
        "name": "Complete",
        "description": "Percentage of sentences in which all tokens were assigned their correct parent",
        "category": "Dependency Parsing Evaluation",
        "formula": "Sentences with all correct token assignments / Total sentences"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Earley1970_EfficientParsingAlgorithm",
        "entity_type": "Algorithm",
        "name": "Efficient Context-Free Parsing Algorithm",
        "title": "An Efficient Context-Free Parsing Algorithm",
        "year": 1970,
        "authors": [
          "Jay Earley"
        ],
        "task": "Parsing context-free grammars",
        "dataset": [],
        "metrics": [
          "Time complexity",
          "Space complexity"
        ],
        "architecture": {
          "components": [
            "Predictor",
            "Completer",
            "Scanner"
          ],
          "connections": [
            "State transitions",
            "Look-ahead"
          ],
          "mechanisms": [
            "State sets",
            "Derivation trees"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Look-ahead strings",
          "State representation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "TimeComplexity_Parsing",
        "entity_type": "Metric",
        "name": "Time complexity",
        "description": "Time required to parse a string",
        "category": "Algorithm performance",
        "formula": "O(n^3) for general context-free grammars, O(n^2) for unambiguous grammars, O(n) for bounded state grammars"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpaceComplexity_Parsing",
        "entity_type": "Metric",
        "name": "Space complexity",
        "description": "Memory required to parse a string",
        "category": "Algorithm performance",
        "formula": "O(n^2)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2015_GeoTutor",
        "entity_type": "Algorithm",
        "name": "GeoTutor",
        "title": "Automatic Synthesis of Geometry Problems for an Intelligent Tutoring System",
        "year": 2015,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "Euclidean Geometry Problem Synthesis",
        "dataset": [
          "High School Geometry Problems_2015"
        ],
        "metrics": [
          "Interesting_Problems",
          "Strictly_Interesting_Problems",
          "Converse_Problems",
          "Proof_Width",
          "Proof_Length",
          "Deductive_Steps"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Pebbling Algorithm",
            "Problem Synthesis"
          ],
          "connections": [
            "Forward Edges",
            "Back-Edges"
          ],
          "mechanisms": [
            "Traversal Algorithm",
            "Coarse Problem Homomorphism",
            "Goal Analogous Problems"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Breadth-First Pebbling",
            "User Query-Based Restrictions"
          ],
          "parameter_tuning": [
            "Deductive Steps Range",
            "Proof Width Range",
            "Proof Length Range"
          ]
        },
        "feature_processing": [
          "Coordinate-Based Computation",
          "Assumption Filtering"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "High_School_Geometry_Problems_2015",
        "entity_type": "Dataset",
        "name": "High School Geometry Problems",
        "description": "A corpus of high school geometry problems from standard geometry textbooks",
        "domain": "Education",
        "size": 155,
        "year": 2015,
        "creators": [
          "Sinclair et al.",
          "Boyd et al.",
          "Larson et al.",
          "Jurgensen et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Interesting_Problems",
        "entity_type": "Metric",
        "name": "Interesting Problems",
        "description": "Problems that require at least one or more of the assumptions and are minimal with respect to the goal",
        "category": "Problem Synthesis Evaluation",
        "formula": "Number of problems that meet the criteria for interestingness"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Strictly_Interesting_Problems",
        "entity_type": "Metric",
        "name": "Strictly Interesting Problems",
        "description": "Problems that use all the assumptions in the statement for their solution",
        "category": "Problem Synthesis Evaluation",
        "formula": "Number of problems that strictly use all assumptions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Converse_Problems",
        "entity_type": "Metric",
        "name": "Converse Problems",
        "description": "Problems that reverse the goal and assumptions of the original problem",
        "category": "Problem Synthesis Evaluation",
        "formula": "Number of converse problems generated"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Proof_Width",
        "entity_type": "Metric",
        "name": "Proof Width",
        "description": "Width of the problem hypergraph",
        "category": "Problem Complexity",
        "formula": "Maximum number of nodes at any level of the hypergraph"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Proof_Length",
        "entity_type": "Metric",
        "name": "Proof Length",
        "description": "Diameter of the problem hypergraph",
        "category": "Problem Complexity",
        "formula": "Longest path from source to goal in the hypergraph"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Deductive_Steps",
        "entity_type": "Metric",
        "name": "Deductive Steps",
        "description": "Number of hyperedges in the problem hypergraph",
        "category": "Problem Complexity",
        "formula": "Total number of deductive steps required to solve the problem"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shi2015_SigmaDolphin",
        "entity_type": "Algorithm",
        "name": "SigmaDolphin",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": 2015,
        "authors": [
          "Shi, Shuming",
          "Wang, Yuehui",
          "Lin, Chin-Yew",
          "Liu, Xiaojiang",
          "Rui, Yong"
        ],
        "task": "èªå¨æ±è§£æ°å­¦æå­é¢",
        "dataset": [
          "Algebra.com_2015",
          "YahooAnswers.com_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "CFG Parser",
            "Reasoning Module",
            "Semantic Representation Language DOL"
          ],
          "connections": [
            "NL Text -> DOL Trees -> Math Expressions"
          ],
          "mechanisms": [
            "Context-Free Grammar Parsing",
            "Semantic Interpretation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CFGè§ååå»º",
            "åèªå¨åè¯­æ³æå»º"
          ],
          "parameter_tuning": [
            "æ "
          ]
        },
        "feature_processing": [
          "èªç¶è¯­è¨ææ¬è§£æ",
          "æ°å­¦è¡¨è¾¾å¼æ¨å¯¼"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Algebra.com_2015",
        "entity_type": "Dataset",
        "name": "Algebra.com",
        "description": "ä¸ä¸ªç¨æ·åå¸æ°å­¦é®é¢å¹¶è·å¾å¯¼å¸å¸®å©çç½ç«",
        "domain": "æ°å­¦æè²",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Algebra.com"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "YahooAnswers.com_2015",
        "entity_type": "Dataset",
        "name": "Yahoo Answers",
        "description": "ä¸ä¸ªé®ç­ç½ç«ï¼å¶ä¸­åå«æ°å­¦é®é¢",
        "domain": "æ°å­¦æè²",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Yahoo Answers"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Classification",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "ç²¾ç¡®ç",
        "category": "åç±»è¯ä¼°",
        "formula": "æ­£ç¡®åç±»æ ·æ¬æ° / æ»åç±»æ ·æ¬æ°"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Classification",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "å¬åç",
        "category": "åç±»è¯ä¼°",
        "formula": "æ­£ç¡®åç±»æ ·æ¬æ° / æ»å®éæ­£æ ·æ¬æ°"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Classification",
        "entity_type": "Metric",
        "name": "F1",
        "description": "F1åæ°",
        "category": "åç±»è¯ä¼°",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_KAZB",
        "entity_type": "Algorithm",
        "name": "KAZB",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "èªå¨æ±è§£ä»£æ°æå­é¢",
        "dataset": [
          "LinearT2_2015",
          "LinearT6_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Learning-Based Statistical Method"
          ],
          "connections": [
            "é®é¢æ å°å°æ¹ç¨æ¨¡æ¿"
          ],
          "mechanisms": [
            "æ¹ç¨æ¨¡æ¿å¹é"
          ]
        },
        "methodology": {
          "training_strategy": [
            "æ¹ç¨æ¨¡æ¿ç¡®å®"
          ],
          "parameter_tuning": [
            "æ "
          ]
        },
        "feature_processing": [
          "é®é¢ç¹å¾æå"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_VerbCategorization",
        "entity_type": "Algorithm",
        "name": "Verb Categorization",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": 2014,
        "authors": [
          "Hosseini, M.J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "èªå¨æ±è§£ç®æ¯æå­é¢",
        "dataset": [
          "æªæå®"
        ],
        "metrics": [
          "æªæå®"
        ],
        "architecture": {
          "components": [
            "å¨è¯åç±»"
          ],
          "connections": [
            "é®é¢æ å°å°å¨è¯åç±»"
          ],
          "mechanisms": [
            "å¨è¯åç±»å­¦ä¹ "
          ]
        },
        "methodology": {
          "training_strategy": [
            "å¨è¯åç±»å­¦ä¹ "
          ],
          "parameter_tuning": [
            "æ "
          ]
        },
        "feature_processing": [
          "é®é¢ç¹å¾æå"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_Aristo",
        "entity_type": "Algorithm",
        "name": "Aristo",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY Regents Science Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "IR Solver",
            "PMI Solver",
            "SVM Solver",
            "RULE Solver",
            "ILP Solver"
          ],
          "connections": [
            "Logistic Regression Combiner"
          ],
          "mechanisms": [
            "Information Retrieval",
            "Pointwise Mutual Information",
            "Support Vector Machine",
            "Rule-based Reasoning",
            "Integer Linear Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Logistic Regression Calibration"
          ],
          "parameter_tuning": [
            "Solver-specific Feature Weights"
          ]
        },
        "feature_processing": [
          "TF-IDF Scoring",
          "Lexical Chunk Matching",
          "Syntactic Pattern Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NY_Regents_Science_Exam_2016",
        "entity_type": "Dataset",
        "name": "NY Regents Science Exam",
        "description": "Standardized science exams for 4th grade students",
        "domain": "Elementary Education",
        "size": 237,
        "year": 2016,
        "creators": [
          "New York State Education Department"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_IRSolver",
        "entity_type": "Algorithm",
        "name": "IR Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY Regents Science Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Lucene Search Engine"
          ],
          "connections": [],
          "mechanisms": [
            "Information Retrieval"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Non-stopword Overlap"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_PMISolver",
        "entity_type": "Algorithm",
        "name": "PMI Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY Regents Science Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Pointwise Mutual Information Calculation"
          ],
          "connections": [],
          "mechanisms": [
            "Statistical Association"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Unigrams, Bigrams, Trigrams, Skip-Bigrams"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_SVMSolver",
        "entity_type": "Algorithm",
        "name": "SVM Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY Regents Science Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Support Vector Machine"
          ],
          "connections": [],
          "mechanisms": [
            "Word Embeddings",
            "Cosine Similarity"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SVM Ranker"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Domain-appropriate Embeddings"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_RULESolver",
        "entity_type": "Algorithm",
        "name": "RULE Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY Regents Science Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Probabilistic First-Order Logic Rules"
          ],
          "connections": [],
          "mechanisms": [
            "Rule-based Reasoning",
            "Textual Entailment"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Structure Mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_ILPSolver",
        "entity_type": "Algorithm",
        "name": "ILP Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY Regents Science Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming"
          ],
          "connections": [],
          "mechanisms": [
            "Structured Knowledge Representation",
            "Proof Graph Construction"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Lexical Chunk Matching",
          "Table Joining"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Khot2015_Praline",
        "entity_type": "Algorithm",
        "name": "Praline",
        "title": "Exploring Markov Logic Networks for Question Answering",
        "year": 2015,
        "authors": [
          "Tushar Khot",
          "Niranjan Balasubramanian",
          "Erik Gribkoff",
          "Ashish Sabharwal",
          "Peter Clark",
          "Oren Etzioni"
        ],
        "task": "Elementary Science Question Answering",
        "dataset": [
          "NY Regents Science Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Markov Logic Networks"
          ],
          "connections": [],
          "mechanisms": [
            "Lexical Alignment",
            "Controlled Inference"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_BiLSTMClassifier",
        "entity_type": "Algorithm",
        "name": "BiLSTM Classifier",
        "year": 2018,
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "Solving Algebra Word Problems",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Softmax Layer"
          ],
          "connections": [
            "Word Embedding -> BiLSTM -> Softmax"
          ],
          "mechanisms": [
            "Cross Entropy Loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden State Size"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_StructuredSelfAttention",
        "entity_type": "Algorithm",
        "name": "Structured Self-Attention",
        "year": 2017,
        "authors": [
          "Lin, Z.",
          "Feng, M.",
          "Santos, C.N.d.",
          "Yu, M.",
          "Xiang, B.",
          "Zhou, B.",
          "Bengio, Y."
        ],
        "task": "Solving Algebra Word Problems",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Multi-hop Self-Attention"
          ],
          "connections": [
            "Word Embedding -> BiLSTM -> Self-Attention -> Fixed Sized Embedding"
          ],
          "mechanisms": [
            "Redundancy Reduction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end Training"
          ],
          "parameter_tuning": [
            "Attention Hop Constraints"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_Seq2Seq",
        "entity_type": "Algorithm",
        "name": "Seq2Seq Model",
        "year": 2014,
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q.V."
        ],
        "task": "Solving Algebra Word Problems",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Generation"
        ],
        "architecture": {
          "components": [
            "Encoder LSTM",
            "Decoder LSTM",
            "Attention Mechanism"
          ],
          "connections": [
            "Word Embedding -> Encoder LSTM -> Attention -> Decoder LSTM"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Sequence Prediction"
          ],
          "parameter_tuning": [
            "Hidden State Size",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DRAW_2016",
        "entity_type": "Dataset",
        "name": "DRAW",
        "year": 2016,
        "creators": [
          "Upadhyay, S.",
          "Chang, M.W."
        ],
        "domain": "Algebra Word Problems",
        "size": 1000,
        "description": "A challenging and diverse algebra word problem set"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MAWPS_2016",
        "entity_type": "Dataset",
        "name": "MAWPS",
        "year": 2016,
        "creators": [
          "Koncel-Kedziorski, R.",
          "Roy, S.",
          "Amini, A.",
          "Kushman, N.",
          "Hajishirzi, H."
        ],
        "domain": "Algebra Word Problems",
        "size": 2373,
        "description": "A math word problem repository"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Math23K_2017",
        "entity_type": "Dataset",
        "name": "Math23K",
        "year": 2017,
        "creators": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "domain": "Algebra Word Problems",
        "size": 23164,
        "description": "A large dataset of Chinese algebra word problems"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Generation",
        "entity_type": "Metric",
        "name": "Accuracy",
        "category": "Generation",
        "description": "Proportion of correctly generated equation templates",
        "formula": "Correct Generated Templates / Total Templates"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Oracle_Accuracy",
        "entity_type": "Metric",
        "name": "Oracle Accuracy",
        "category": "Upper Bound",
        "description": "Number of test equation templates which appear in the training data",
        "formula": "Test Templates in Training Data / Total Test Templates"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_RNNBasedSeq2SeqModel",
        "entity_type": "Algorithm",
        "name": "RNN-based Seq2Seq Model",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "èªå¨æ±è§£æ°å­¦æå­é¢",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "GRU",
            "LSTM"
          ],
          "connections": [
            "ç¼ç å¨-è§£ç å¨"
          ],
          "mechanisms": [
            "é¨æ§å¾ªç¯åå",
            "é¿ç­æè®°å¿ç½ç»"
          ]
        },
        "methodology": {
          "training_strategy": [
            "dropout",
            "mini-batch"
          ],
          "parameter_tuning": [
            "å­¦ä¹ ç",
            "dropoutæ¦ç"
          ]
        },
        "feature_processing": [
          "æ¾èæ°å­è¯å«"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_HybridModel",
        "entity_type": "Algorithm",
        "name": "Hybrid Model",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "èªå¨æ±è§£æ°å­¦æå­é¢",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "RNN-based Seq2Seq Model",
            "æ£ç´¢æ¨¡å"
          ],
          "connections": [
            "åºäºç¸ä¼¼åº¦çéæ©æºå¶"
          ],
          "mechanisms": [
            "Jaccardç¸ä¼¼åº¦"
          ]
        },
        "methodology": {
          "training_strategy": [
            "éå¼è®¾ç½®"
          ],
          "parameter_tuning": [
            "ç¸ä¼¼åº¦éå¼"
          ]
        },
        "feature_processing": [
          "æ¾èæ°å­è¯å«"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_SignificantNumberIdentification",
        "entity_type": "Algorithm",
        "name": "Significant Number Identification",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "è¯å«æ°å­¦æå­é¢ä¸­çéè¦æ°å­",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "LSTM"
          ],
          "connections": [
            "åå±LSTM"
          ],
          "mechanisms": [
            "äºååç±»æ¨¡å"
          ]
        },
        "methodology": {
          "training_strategy": [
            "ä¸ä¸æçªå£"
          ],
          "parameter_tuning": [
            "èç¹æ°é"
          ]
        },
        "feature_processing": [
          "æ°å­åå¶ä¸ä¸æ"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Alg514_2014",
        "entity_type": "Dataset",
        "name": "Alg514",
        "description": "åå«514ä¸ªçº¿æ§ä»£æ°é®é¢çæ°æ®é",
        "domain": "èªç¶è¯­è¨å¤ç",
        "size": 514,
        "year": 2014,
        "creators": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_G-ALIGNER",
        "entity_type": "Algorithm",
        "name": "G-ALIGNER",
        "title": "Diagram Understanding in Geometry Questions",
        "year": 2014,
        "authors": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "Geometry Questions Dataset_2014"
        ],
        "metrics": [
          "F1 Score_Identifying Primitives",
          "F1 Score_Aligning Visual Elements"
        ],
        "architecture": {
          "components": [
            "Primitive Detection",
            "Textual Mention Extraction",
            "Alignment Constraint Function"
          ],
          "connections": [
            "Coupling Textual and Visual Information",
            "Submodular Optimization"
          ],
          "mechanisms": [
            "Hough Transform",
            "Submodular Objective Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Optimization",
            "Greedy Approximation"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "OCR for Label Positioning",
          "Harris Corner Detector"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geometry Questions Dataset_2014",
        "entity_type": "Dataset",
        "name": "Geometry Questions Dataset",
        "description": "Dataset of geometry questions including textual descriptions and diagrams",
        "domain": "Geometry",
        "size": 100,
        "year": 2014,
        "creators": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1 Score_Identifying Primitives",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall for identifying primitives",
        "category": "Identifying Primitives",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1 Score_Aligning Visual Elements",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall for aligning visual elements with textual mentions",
        "category": "Aligning Visual Elements",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Watanabe1991_IntegrationFramework",
        "entity_type": "Algorithm",
        "name": "Integration Framework",
        "title": "Diagram Understanding Using Integration of Layout Information and Textual Information",
        "year": 1991,
        "authors": [
          "Watanabe, Yasuhiko",
          "Nagao, Makoto"
        ],
        "task": "Diagram Understanding",
        "dataset": [
          "PBF Diagrams"
        ],
        "metrics": [
          "Semantic Analysis Success Rate"
        ],
        "architecture": {
          "components": [
            "Layout Information",
            "Natural Language Information"
          ],
          "connections": [
            "Connection",
            "Adjacency"
          ],
          "mechanisms": [
            "Symbol-based Classification",
            "Expression Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Annotation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Japanese Morphological Analysis",
          "Pattern Matching"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PBF_Diagrams_1991",
        "entity_type": "Dataset",
        "name": "PBF Diagrams",
        "description": "Diagrams from Pictorial Books of Flora",
        "domain": "Botanical Illustrations",
        "size": 31,
        "year": 1991,
        "creators": [
          "Watanabe, Yasuhiko",
          "Nagao, Makoto"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SemanticAnalysisSuccessRate_Classification",
        "entity_type": "Metric",
        "name": "Semantic Analysis Success Rate",
        "description": "Rate of successful semantic interpretation of diagram elements",
        "category": "Classification Evaluation",
        "formula": "Number of correctly interpreted elements / Total number of elements"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_DimensionallyGuidedSynthesis",
        "entity_type": "Algorithm",
        "name": "Dimensionally Guided Synthesis",
        "title": "Dimensionally Guided Synthesis of Mathematical Word Problems",
        "year": 2016,
        "authors": [
          "Ke Wang",
          "Zhendong Su"
        ],
        "task": "Mathematical Word Problem Generation",
        "dataset": [],
        "metrics": [
          "Statistical Indistinguishability",
          "Error Rate"
        ],
        "architecture": {
          "components": [
            "Equation Generator",
            "Narrative Generator"
          ],
          "connections": [
            "Equation Generation Procedure",
            "Binary Expression Tree Representation"
          ],
          "mechanisms": [
            "Dimensional Unit Assignment",
            "Recursive Narrative Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Equation Generation",
            "Variable Unrolling"
          ],
          "parameter_tuning": [
            "Dimensional Units",
            "Operational Rules"
          ]
        },
        "feature_processing": [
          "Dimensional Unit Classification",
          "Keyword Assignment",
          "Sub-story Generation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "StatisticalIndistinguishability_Authenticity",
        "entity_type": "Metric",
        "name": "Statistical Indistinguishability",
        "description": "è¡¡éçæçé®é¢ä¸æç§ä¹¦é®é¢å¨ç»è®¡ä¸æ¯å¦æ æ³åºå",
        "category": "é®é¢çå®æ§è¯ä¼°",
        "formula": "éè¿éå¯¹Tæ£éªåå¡æ¹ç¬ç«æ§æ£éªè¿è¡è¯ä¼°"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorRate_Difficulty",
        "entity_type": "Metric",
        "name": "Error Rate",
        "description": "å­¦çè§£ç­é®é¢æ¶çéè¯¯ç",
        "category": "é®é¢é¾åº¦è¯ä¼°",
        "formula": "éè¯¯ç­æ¡æ°é / æ»ç­æ¡æ°é"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_SkipGram",
        "entity_type": "Algorithm",
        "name": "Skip-gram",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Learning high-quality distributed vector representations",
        "dataset": [
          "News articles dataset"
        ],
        "metrics": [
          "Accuracy",
          "Syntactic accuracy",
          "Semantic accuracy"
        ],
        "architecture": {
          "components": [
            "Input layer",
            "Hidden layer",
            "Output layer"
          ],
          "connections": [
            "Input to hidden connections",
            "Hidden to output connections"
          ],
          "mechanisms": [
            "Negative Sampling",
            "Hierarchical Softmax",
            "Subsampling of frequent words"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Negative Sampling",
            "Hierarchical Softmax",
            "Subsampling of frequent words"
          ],
          "parameter_tuning": [
            "Dimensionality",
            "Context size",
            "Number of negative samples",
            "Subsampling rate"
          ]
        },
        "feature_processing": [
          "Word tokenization",
          "Phrase identification"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NewsArticles_2013",
        "entity_type": "Dataset",
        "name": "News articles dataset",
        "description": "A large dataset consisting of various news articles",
        "domain": "Natural Language Processing",
        "size": "One billion words",
        "year": 2013,
        "creators": [
          "Google Inc."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_AnalogicalReasoning",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy on the analogical reasoning task",
        "category": "Analogical reasoning evaluation",
        "formula": "Correct answers / Total questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SyntacticAccuracy_AnalogicalReasoning",
        "entity_type": "Metric",
        "name": "Syntactic accuracy",
        "description": "Accuracy on syntactic analogical reasoning",
        "category": "Analogical reasoning evaluation",
        "formula": "Correct syntactic analogies / Total syntactic questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SemanticAccuracy_AnalogicalReasoning",
        "entity_type": "Metric",
        "name": "Semantic accuracy",
        "description": "Accuracy on semantic analogical reasoning",
        "category": "Analogical reasoning evaluation",
        "formula": "Correct semantic analogies / Total semantic questions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_HierarchicalSoftmax",
        "entity_type": "Algorithm",
        "name": "Hierarchical Softmax",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Efficient computation of word probabilities",
        "dataset": [
          "News articles dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary tree",
            "Inner nodes",
            "Leaf nodes"
          ],
          "connections": [
            "Path from root to leaf"
          ],
          "mechanisms": [
            "Logarithmic evaluation of nodes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Binary Huffman tree"
          ],
          "parameter_tuning": [
            "Tree structure"
          ]
        },
        "feature_processing": [
          "Word frequency grouping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_NegativeSampling",
        "entity_type": "Algorithm",
        "name": "Negative Sampling",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Efficient training of word representations",
        "dataset": [
          "News articles dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Target word",
            "Noise distribution"
          ],
          "connections": [
            "Logistic regression"
          ],
          "mechanisms": [
            "Logistic loss function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Noise distribution Pn(w)",
            "Unigram distribution U(w)^(3/4)"
          ],
          "parameter_tuning": [
            "Number of negative samples k"
          ]
        },
        "feature_processing": [
          "Word frequency grouping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_PhraseSkipGram",
        "entity_type": "Algorithm",
        "name": "Phrase Skip-gram",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Learning vector representations for phrases",
        "dataset": [
          "News articles dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Input layer",
            "Hidden layer",
            "Output layer"
          ],
          "connections": [
            "Input to hidden connections",
            "Hidden to output connections"
          ],
          "mechanisms": [
            "Phrase identification",
            "Negative Sampling",
            "Hierarchical Softmax"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Phrase identification based on unigram and bigram counts"
          ],
          "parameter_tuning": [
            "Score threshold",
            "Vector dimensionality",
            "Context size"
          ]
        },
        "feature_processing": [
          "Phrase tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_DEDUCOM",
        "entity_type": "Algorithm",
        "name": "DEDUCOM",
        "title": "Experiments with a Deductive Question-Answering Program",
        "year": 1965,
        "authors": [
          "Slagle, J.R."
        ],
        "task": "Deductive Question-Answering",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Fact Interpreter",
            "Question Reducer",
            "Search Procedure"
          ],
          "connections": [
            "Fact Interpreter -> Question Reducer",
            "Question Reducer -> Search Procedure"
          ],
          "mechanisms": [
            "Depth-First Search",
            "Logical Deduction in Predicate Calculus"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Providing facts and rules"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Fact Representation",
          "Question Parsing"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Time_Efficiency",
        "entity_type": "Metric",
        "name": "Time Efficiency",
        "description": "Time taken by DEDUCOM to answer each question",
        "category": "Performance Evaluation",
        "formula": "Time taken to answer a question"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2016_ImplicitQuantityRelationExtractor",
        "entity_type": "Algorithm",
        "name": "Implicit Quantity Relation Extractor",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": 2016,
        "authors": [
          "Yu, Xinguo",
          "Jian, Pengpeng",
          "Wang, Mingshu",
          "Wu, Shuang"
        ],
        "task": "Extracting implicit quantity relations in arithmetic word problems",
        "dataset": [
          "Elementary school arithmetic application problem_2011",
          "Suzhou Education Publishing House_dataset"
        ],
        "metrics": [
          "Classification Accuracy"
        ],
        "architecture": {
          "components": [
            "Chinese phrase parse",
            "SVM classification",
            "Instantiation method of required general implicit quantity relations with semantic models"
          ],
          "connections": [
            "Chinese phrase parse -> SVM classification -> Instantiation method"
          ],
          "mechanisms": [
            "Semantic models",
            "Sequence alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SVM with slack variable",
            "Bag of words feature extraction"
          ],
          "parameter_tuning": [
            "C value for slack variable"
          ]
        },
        "feature_processing": [
          "Normalization of common units",
          "Chinese phrase parsing",
          "Bag of words extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Elementary_school_arithmetic_application_problem_2011",
        "entity_type": "Dataset",
        "name": "Elementary school arithmetic application problem",
        "description": "Arithmetic word problems for elementary school students",
        "domain": "Education",
        "size": 627,
        "year": 2011,
        "creators": [
          "People's Education Press"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Suzhou_Education_Publishing_House_dataset",
        "entity_type": "Dataset",
        "name": "Suzhou Education Publishing House dataset",
        "description": "Arithmetic word problems for training",
        "domain": "Education",
        "year": 2016,
        "creators": [
          "Suzhou Education Publishing House"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Classification_Accuracy",
        "entity_type": "Metric",
        "name": "Classification Accuracy",
        "description": "Accuracy of classifying arithmetic word problems into different types",
        "category": "Classification evaluation",
        "formula": "Number of correctly classified samples / Total number of samples"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_FrameBasedCalculus",
        "entity_type": "Algorithm",
        "name": "Frame-Based Calculus",
        "title": "Frame-Based Calculus of solving Arithmetic Multi-Step Addition and Subtraction word problems",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "Solving multi-step addition and subtraction word problems",
        "dataset": [],
        "metrics": [
          "Effectiveness of solving multi-step word problems"
        ],
        "architecture": {
          "components": [
            "MSWPAS-NP",
            "MSWPAS-CP"
          ],
          "connections": [
            "Natural language processing and frame construction",
            "Frame-based calculus"
          ],
          "mechanisms": [
            "Means-end Analysis",
            "Production rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Comprehension and representation of word problems",
          "Problem-solving planning",
          "Trying to solve and assessment"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ChineseElementarySchoolWordProblems_2010",
        "entity_type": "Dataset",
        "name": "Chinese Elementary School Word Problems",
        "description": "Word problems gathered from four publishers in Chinese (one book from Peopleâs Education Press, one book from Beijing Normal University Press, and two books from DONGBEI Normal University Press)",
        "domain": "Mathematics education",
        "size": "Not specified",
        "year": 2010,
        "creators": [
          "Various publishers"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Effectiveness_SolvingMultiStepWordProblems",
        "entity_type": "Metric",
        "name": "Effectiveness",
        "description": "Effectiveness of solving multi-step word problems",
        "category": "Problem-solving performance",
        "formula": "Not specified"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "deMarneffe2006_TypedDependencyExtraction",
        "entity_type": "Algorithm",
        "name": "Typed Dependency Extraction",
        "title": "Generating Typed Dependency Parses from Phrase Structure Parses",
        "year": 2006,
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": "Natural Language Processing",
        "dataset": [
          "Penn Treebank",
          "Brown Corpus"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Dependency Extraction Rules",
            "Dependency Typing Rules"
          ],
          "connections": [
            "Phrase Structure Trees -> Dependency Extraction -> Dependency Typing"
          ],
          "mechanisms": [
            "Head Identification",
            "Pattern Matching",
            "Collapsing Dependencies"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Treebank-trained Statistical Parsers"
          ],
          "parameter_tuning": [
            "Collins Head Rules",
            "Tregex Patterns"
          ]
        },
        "feature_processing": [
          "Semantic Head Retrieval",
          "Preposition and Conjunction Collapsing"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreebank_1999",
        "entity_type": "Dataset",
        "name": "Penn Treebank",
        "description": "A widely used corpus for English syntactic parsing",
        "domain": "Natural Language Processing",
        "size": "Over 4.5 million words",
        "year": 1999,
        "creators": [
          "University of Pennsylvania"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "BrownCorpus_1964",
        "entity_type": "Dataset",
        "name": "Brown Corpus",
        "description": "A standard corpus of present-day edited American English",
        "domain": "Natural Language Processing",
        "size": "1 million words",
        "year": 1964,
        "creators": [
          "Henry Kucera",
          "W. Nelson Francis"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "DependencyAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Dependency Accuracy",
        "description": "Accuracy of dependency relations in a sentence",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly identified dependencies / Total dependencies"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collins1999_HeadDrivenStatisticalModels",
        "entity_type": "Algorithm",
        "name": "Head-Driven Statistical Models",
        "title": "Head-Driven Statistical Models for Natural Language Parsing",
        "year": 1999,
        "authors": [
          "Michael Collins"
        ],
        "task": "Natural Language Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Parsing Accuracy"
        ],
        "architecture": {
          "components": [
            "Statistical Models",
            "Head Rules"
          ],
          "connections": [
            "Phrase Structure Trees -> Head Identification"
          ],
          "mechanisms": [
            "Statistical Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Treebank-trained Statistical Parsers"
          ],
          "parameter_tuning": [
            "Head Rules"
          ]
        },
        "feature_processing": [
          "Syntactic Head Retrieval"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Klein2003_AccurateUnlexicalizedParsing",
        "entity_type": "Algorithm",
        "name": "Accurate Unlexicalized Parsing",
        "title": "Accurate Unlexicalized Parsing",
        "year": 2003,
        "authors": [
          "Dan Klein",
          "Christopher D. Manning"
        ],
        "task": "Natural Language Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Parsing Accuracy"
        ],
        "architecture": {
          "components": [
            "Unlexicalized Parsing Model"
          ],
          "connections": [
            "Phrase Structure Trees -> Parsing"
          ],
          "mechanisms": [
            "Unlexicalized Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Treebank-trained Statistical Parsers"
          ],
          "parameter_tuning": [
            "Unlexicalized Features"
          ]
        },
        "feature_processing": [
          "Syntactic Feature Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin1998_MINIPAR",
        "entity_type": "Algorithm",
        "name": "MINIPAR",
        "title": "Dependency-based evaluation of MINIPAR",
        "year": 1998,
        "authors": [
          "Dekang Lin"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Dependency Parser"
          ],
          "connections": [
            "Sentence -> Dependency Parse"
          ],
          "mechanisms": [
            "Dependency Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Treebank-trained Statistical Parsers"
          ],
          "parameter_tuning": [
            "Dependency Parsing Rules"
          ]
        },
        "feature_processing": [
          "Dependency Relation Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sleator1993_LinkParser",
        "entity_type": "Algorithm",
        "name": "Link Parser",
        "title": "Parsing English with a Link Grammar",
        "year": 1993,
        "authors": [
          "Daniel D. Sleator",
          "Davy Temperley"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Link Grammar"
          ],
          "connections": [
            "Sentence -> Dependency Parse"
          ],
          "mechanisms": [
            "Link Grammar Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Treebank-trained Statistical Parsers"
          ],
          "parameter_tuning": [
            "Link Grammar Rules"
          ]
        },
        "feature_processing": [
          "Dependency Relation Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Gelernter1959_GeometryMachine",
        "entity_type": "Algorithm",
        "name": "Geometry Machine",
        "year": 1959,
        "authors": [
          "Gelernter"
        ],
        "task": "Geometry Theorem Proving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Heuristic Knowledge",
            "Backward Chaining Search Strategy"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Diagram-based Heuristic"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "CeruttiDavis1969_FORMAC",
        "entity_type": "Algorithm",
        "name": "FORMAC",
        "year": 1969,
        "authors": [
          "Cerutti",
          "Davis"
        ],
        "task": "Elementary Analytic Geometry Theorem Proving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Symbolic Manipulation",
            "Descartes' Method"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Coordinate Assignment to Points"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1999_GeoRep",
        "entity_type": "Algorithm",
        "name": "GeoRep",
        "title": "GeoRep: A Flexible Tool for Spatial Representation of Line Drawings",
        "year": 1999,
        "authors": [
          "Ronald W. Ferguson",
          "Kenneth D. Forbus"
        ],
        "task": "Spatial Representation and Reasoning",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Low-Level Relational Describer (LLRD)",
            "High-Level Relational Describer (HLRD)"
          ],
          "connections": [
            "LLRD feeds into HLRD",
            "HLRD uses LLRD's output for domain-specific reasoning"
          ],
          "mechanisms": [
            "Visual operations library",
            "Rule engine (LTRE)",
            "Proximity detection",
            "Reference frame relations",
            "Parallel lines detection",
            "Interval relations",
            "Connectivity detection",
            "Polygon and polyline detection",
            "Boundary description",
            "Grouping"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Proximity detection",
          "Reference frame adaptation",
          "Visual operations"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PolygonFigures_1996",
        "entity_type": "Dataset",
        "name": "Polygon Figures",
        "description": "Set of randomly-generated polygons used in symmetry detection experiments",
        "domain": "Symmetry Detection",
        "size": 240,
        "year": 1996,
        "creators": [
          "Ferguson, R. W.",
          "Aminoff, A.",
          "Gentner, D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_SymmetryJudgment",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of symmetry judgment",
        "category": "Symmetry Detection",
        "formula": "Correct judgments / Total judgments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "QualitativeFactors_SymmetryJudgment",
        "entity_type": "Metric",
        "name": "Qualitative Factors",
        "description": "Effect of qualitative visual structure on symmetry judgment",
        "category": "Symmetry Detection",
        "formula": "Significant effect on accuracy even after accounting for metric measures of asymmetry"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_GloVe",
        "entity_type": "Algorithm",
        "name": "GloVe",
        "title": "GloVe: Global Vectors for Word Representation",
        "year": 2014,
        "authors": [
          "Jeffrey Pennington",
          "Richard Socher",
          "Christopher D. Manning"
        ],
        "task": "Word Representation",
        "dataset": [
          "Wikipedia_2010",
          "Wikipedia_2014",
          "Gigaword_5",
          "Gigaword5_Wikipedia2014",
          "Common_Crawl_2014"
        ],
        "metrics": [
          "Accuracy_Analogy",
          "Spearman_Rank_Correlation_Similarity",
          "F1_NER"
        ],
        "architecture": {
          "components": [
            "Global Log-Bilinear Regression Model",
            "Weighted Least Squares Model"
          ],
          "connections": [
            "Word-Word Co-occurrence Matrix",
            "Dot Product of Word Vectors"
          ],
          "mechanisms": [
            "Logarithmic Transformation",
            "Bias Terms"
          ]
        },
        "methodology": {
          "training_strategy": [
            "AdaGrad",
            "Stochastic Sampling"
          ],
          "parameter_tuning": [
            "xmax=100",
            "Î±=3/4",
            "Initial Learning Rate=0.05",
            "50 Iterations for <300 Dimensions",
            "100 Iterations for â¥300 Dimensions"
          ]
        },
        "feature_processing": [
          "Symmetric Context Window",
          "Decreasing Weighting Function"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Wikipedia_2010",
        "entity_type": "Dataset",
        "name": "Wikipedia",
        "description": "2010 Wikipedia Dump",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": 2010,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Wikipedia_2014",
        "entity_type": "Dataset",
        "name": "Wikipedia",
        "description": "2014 Wikipedia Dump",
        "domain": "Natural Language Processing",
        "size": 1600000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Gigaword_5",
        "entity_type": "Dataset",
        "name": "Gigaword 5",
        "description": "Gigaword 5 Corpus",
        "domain": "Natural Language Processing",
        "size": 4300000000,
        "year": 2014,
        "creators": [
          "Various Contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Gigaword5_Wikipedia2014",
        "entity_type": "Dataset",
        "name": "Gigaword5 + Wikipedia2014",
        "description": "Combined Gigaword 5 and 2014 Wikipedia Dump",
        "domain": "Natural Language Processing",
        "size": 6000000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Common_Crawl_2014",
        "entity_type": "Dataset",
        "name": "Common Crawl",
        "description": "Web Data from Common Crawl",
        "domain": "Natural Language Processing",
        "size": 42000000000,
        "year": 2014,
        "creators": [
          "Common Crawl Foundation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Analogy",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy on Word Analogy Task",
        "category": "Word Analogy Evaluation",
        "formula": "Number of Correct Answers / Total Number of Questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Spearman_Rank_Correlation_Similarity",
        "entity_type": "Metric",
        "name": "Spearman Rank Correlation",
        "description": "Correlation between Human Judgments and Cosine Similarity of Word Vectors",
        "category": "Word Similarity Evaluation",
        "formula": "Spearman's Rank Correlation Coefficient"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_NER",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 Score on Named Entity Recognition Task",
        "category": "Named Entity Recognition Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_CBOW",
        "entity_type": "Algorithm",
        "name": "Continuous Bag-of-Words (CBOW)",
        "title": "Efficient Estimation of Word Representations in Vector Space",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "Word Representation",
        "dataset": [
          "Wikipedia_2014",
          "Gigaword_5"
        ],
        "metrics": [
          "Accuracy_Analogy",
          "Spearman_Rank_Correlation_Similarity"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Softmax Layer"
          ],
          "connections": [
            "Inner Product of Word Vectors"
          ],
          "mechanisms": [
            "Hierarchical Softmax",
            "Negative Sampling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Number of Negative Samples"
          ]
        },
        "feature_processing": [
          "Context Window"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lebret2014_HPCA",
        "entity_type": "Algorithm",
        "name": "Hellinger PCA",
        "title": "Word Embeddings through Hellinger PCA",
        "year": 2014,
        "authors": [
          "RÃ©mi Lebret",
          "Ronan Collobert"
        ],
        "task": "Word Representation",
        "dataset": [
          "Wikipedia_2014",
          "Gigaword_5"
        ],
        "metrics": [
          "Accuracy_Analogy",
          "Spearman_Rank_Correlation_Similarity"
        ],
        "architecture": {
          "components": [
            "Principal Component Analysis"
          ],
          "connections": [
            "Hellinger Distance"
          ],
          "mechanisms": [
            "Square Root Transformation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Matrix Factorization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Co-occurrence Matrix"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengio2003_NeuralLM",
        "entity_type": "Algorithm",
        "name": "Neural Probabilistic Language Model",
        "title": "A Neural Probabilistic Language Model",
        "year": 2003,
        "authors": [
          "Yoshua Bengio",
          "RÃ©jean Ducharme",
          "Pascal Vincent",
          "Christian Janvin"
        ],
        "task": "Language Modeling",
        "dataset": [
          "Various Text Corpora"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Neural Network"
          ],
          "connections": [
            "Hidden Layers"
          ],
          "mechanisms": [
            "Probabilistic Output"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Word Sequences"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_ZDC",
        "entity_type": "Algorithm",
        "name": "ZDC",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": 2016,
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "èªå¨è§£æ°å­¦åºç¨é¢",
        "dataset": [
          "Alg514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "æ¹è¿çKAZB"
          ],
          "connections": [
            "åå°åè¯ç­è¯­ä¸åéä¹é´çå¯¹é½"
          ],
          "mechanisms": [
            "æç´¢ç©ºé´ç¼©å°"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_SIM",
        "entity_type": "Algorithm",
        "name": "SIM",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": 2016,
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "èªå¨è§£æ°å­¦åºç¨é¢",
        "dataset": [
          "Alg514_2014",
          "SingleEQ_2015",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "ç®åç¸ä¼¼æ§æ¹æ³"
          ],
          "connections": [
            "é®é¢å¥å­å°æ¹ç¨æ¨¡æ¿æ å°"
          ],
          "mechanisms": [
            "è¯åéTF-IDF",
            "å æJaccardç¸ä¼¼åº¦"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "è¯åéå»ºæ¨¡"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Verb395_2014",
        "entity_type": "Dataset",
        "name": "Verb395",
        "description": "åå«395ä¸ªå åæ³åºç¨é¢çæ°æ®é",
        "domain": "æ°å­¦åºç¨é¢æ±è§£",
        "size": 395,
        "year": 2014,
        "creators": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin1878_2015",
        "entity_type": "Dataset",
        "name": "Dolphin1878",
        "description": "åå«1878ä¸ªæ°å­åºç¨é¢çæ°æ®é",
        "domain": "æ°å­¦åºç¨é¢æ±è§£",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Shuming Shi",
          "Yuehui Wang",
          "Chin-Yew Lin",
          "Xiaojiang Liu",
          "Yong Rui"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DRAW_2015",
        "entity_type": "Dataset",
        "name": "DRAW",
        "description": "åå«1000ä¸ªä»£æ°åºç¨é¢çæ°æ®é",
        "domain": "æ°å­¦åºç¨é¢æ±è§£",
        "size": 1000,
        "year": 2015,
        "creators": [
          "Shyam Upadhyay",
          "Ming-Wei Chang"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SingleEQ_2015",
        "entity_type": "Dataset",
        "name": "SingleEQ",
        "description": "åå«508ä¸ªåä¸çº¿æ§æ¹ç¨åºç¨é¢çæ°æ®é",
        "domain": "æ°å­¦åºç¨é¢æ±è§£",
        "size": 508,
        "year": 2015,
        "creators": [
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi",
          "Ashish Sabharwal",
          "Oren Etzioni",
          "Siena Dumas Ang"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin18K_2016",
        "entity_type": "Dataset",
        "name": "Dolphin18K",
        "description": "åå«è¶è¿18000ä¸ªæ æ³¨çæ°å­¦åºç¨é¢çæ°æ®é",
        "domain": "æ°å­¦åºç¨é¢æ±è§£",
        "size": 18460,
        "year": 2016,
        "creators": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ImageNet_2009",
        "entity_type": "Dataset",
        "name": "ImageNet",
        "description": "ä¸ä¸ªå¤§è§æ¨¡å±æ¬¡åçå¾åæ°æ®åºï¼åºäºWordNetç»ææå»ºã",
        "domain": "è®¡ç®æºè§è§",
        "size": 3200000,
        "year": 2009,
        "creators": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Caltech101_2004",
        "entity_type": "Dataset",
        "name": "Caltech101",
        "description": "ä¸ä¸ªåå«101ä¸ªç±»å«çå°è§æ¨¡å¾åæ°æ®éã",
        "domain": "è®¡ç®æºè§è§",
        "size": 9146,
        "year": 2004,
        "creators": [
          "Fei-Fei, L.",
          "Fergus, R.",
          "Perona, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Caltech256_2007",
        "entity_type": "Dataset",
        "name": "Caltech256",
        "description": "ä¸ä¸ªåå«256ä¸ªç±»å«çå¾åæ°æ®éã",
        "domain": "è®¡ç®æºè§è§",
        "size": 30607,
        "year": 2007,
        "creators": [
          "Griffin, G.",
          "Holub, A.",
          "Perona, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "TinyImage_2008",
        "entity_type": "Dataset",
        "name": "TinyImage",
        "description": "ä¸ä¸ªåå«8000ä¸å¼ 32x32ä½åè¾¨çå¾åçæ°æ®éã",
        "domain": "è®¡ç®æºè§è§",
        "size": 80000000,
        "year": 2008,
        "creators": [
          "Torralba, A.",
          "Fergus, R.",
          "Freeman, W."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ESP_dataset_2004",
        "entity_type": "Dataset",
        "name": "ESP dataset",
        "description": "éè¿å¨çº¿æ¸¸ææ¶éçå¾åæ°æ®éã",
        "domain": "è®¡ç®æºè§è§",
        "size": 60000,
        "year": 2004,
        "creators": [
          "von Ahn, L.",
          "Dabbish, L."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "LabelMe_2008",
        "entity_type": "Dataset",
        "name": "LabelMe",
        "description": "ä¸ä¸ªåå«30000å¼ æ æ³¨ååå²çå¾åæ°æ®éã",
        "domain": "è®¡ç®æºè§è§",
        "size": 30000,
        "year": 2008,
        "creators": [
          "Russell, B.",
          "Torralba, A.",
          "Murphy, K.",
          "Freeman, W."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Lotus_Hill_2007",
        "entity_type": "Dataset",
        "name": "Lotus Hill",
        "description": "ä¸ä¸ªåå«50000å¼ æ æ³¨ååå²çå¾åæ°æ®éã",
        "domain": "è®¡ç®æºè§è§",
        "size": 50000,
        "year": 2007,
        "creators": [
          "Yao, B.",
          "Yang, X.",
          "Zhu, S."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "AUC_Classification",
        "entity_type": "Metric",
        "name": "AUC",
        "description": "ROCæ²çº¿ä¸é¢ç§¯",
        "category": "åç±»è¯ä¼°",
        "formula": "ROCæ²çº¿ä¸çé¢ç§¯"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collins2008_ScalableDatasetConstruction",
        "entity_type": "Algorithm",
        "name": "Scalable Dataset Construction",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Collins, B.",
          "Deng, J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": "æ°æ®éæå»º",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Active Learning Approach"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Active Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Boiman2008_NearestNeighborBasedImageClassification",
        "entity_type": "Algorithm",
        "name": "Nearest Neighbor Based Image Classification",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Boiman, O.",
          "Shechtman, E.",
          "Irani, M."
        ],
        "task": "å¾ååç±»",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Bag-of-Features Representation"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Non-parametric"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "SIFT Descriptors"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Torralba2008_TinyImages",
        "entity_type": "Algorithm",
        "name": "Tiny Images",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Torralba, A.",
          "Fergus, R.",
          "Freeman, W."
        ],
        "task": "éåæ°å¯¹è±¡ååºæ¯è¯å«",
        "dataset": [
          "TinyImage"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Nearest Neighbor Methods"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Non-parametric"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_ImageNetTreeMaxClassifier",
        "entity_type": "Algorithm",
        "name": "Tree-Max Classifier",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": "å¾ååç±»",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "AUC"
        ],
        "architecture": {
          "components": [
            "Hierarchical Structure"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "AdaBoost-based Classifier"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hajishirzi2013_NECO",
        "entity_type": "Algorithm",
        "name": "NECO",
        "title": "Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves",
        "year": 2013,
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": "Coreference Resolution and Named-Entity Linking",
        "dataset": [
          "ACE2004-NWIRE",
          "CONLL2011"
        ],
        "metrics": [
          "MUC",
          "B3",
          "Pairwise",
          "F1"
        ],
        "architecture": {
          "components": [
            "Stanford sieve-based model",
            "NEL-informed sieves",
            "mention detection",
            "mention pruning",
            "attribute assignment"
          ],
          "connections": [
            "NEL constraints",
            "mention clustering",
            "entity link propagation"
          ],
          "mechanisms": [
            "multi-pass sieves",
            "exact and relaxed NEL sieves",
            "fine-grained attributes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "deterministic rules",
            "no learning phase"
          ],
          "parameter_tuning": [
            "confidence thresholds for NEL systems"
          ]
        },
        "feature_processing": [
          "mention detection",
          "NEL constraints",
          "attribute assignment"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CONLL2011_2011",
        "entity_type": "Dataset",
        "name": "CONLL2011",
        "description": "Coreference dataset with text from five different domains",
        "domain": "Natural Language Processing",
        "size": 625,
        "year": 2011,
        "creators": [
          "Pradhan et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "B3_Coreference",
        "entity_type": "Metric",
        "name": "B3",
        "description": "Computes the proportion of intersection between predicted and gold clusters for every mention",
        "category": "Coreference Evaluation",
        "formula": "Intersection proportion between predicted and gold clusters"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_Coreference",
        "entity_type": "Metric",
        "name": "Pairwise",
        "description": "Measures the pairwise agreement between predicted and gold clusters",
        "category": "Coreference Evaluation",
        "formula": "Pairwise agreement between predicted and gold clusters"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_NEL",
        "entity_type": "Metric",
        "name": "F1",
        "description": "Harmonic mean of precision and recall",
        "category": "Named-Entity Linking Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_QuadraticProgrammingSolver",
        "entity_type": "Algorithm",
        "name": "Quadratic Programming Solver",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "èªå¨æ±è§£ä»£æ°æå­é¢",
        "dataset": [
          "Kushman2014_Dataset"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Log-linear Model",
            "Quadratic Programming"
          ],
          "connections": [
            "Max-margin Objective",
            "Constraint Generation"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Template Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin Objective",
            "Constraint Generation"
          ],
          "parameter_tuning": [
            "Parameter C"
          ]
        },
        "feature_processing": [
          "åæ§½ç¹å¾",
          "æ§½å¯¹ç¹å¾",
          "è§£ç¹å¾"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Kushman2014_Dataset_2014",
        "entity_type": "Dataset",
        "name": "Kushman2014_Dataset",
        "description": "ç±Kushmanç­äººæä¾çåºåæ°æ®éï¼ç¨äºè¯ä¼°ä»£æ°æå­é¢æ±è§£å¨",
        "domain": "èªç¶è¯­è¨å¤ç",
        "year": 2014,
        "creators": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_CombinedFeedbackPerceptron",
        "entity_type": "Algorithm",
        "name": "Combined Feedback Perceptron",
        "title": "Learning from natural instructions",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "Solitaire Card Game",
          "Geoquery"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary Update",
            "Structural Update"
          ],
          "connections": [
            "Combines binary and structured learning principles"
          ],
          "mechanisms": [
            "Uses binary feedback as coarse supervision",
            "Approximates structural loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative training with feedback"
          ],
          "parameter_tuning": [
            "Weight updates based on feedback"
          ]
        },
        "feature_processing": [
          "Lexical and syntactic features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_StructuredPerceptron",
        "entity_type": "Algorithm",
        "name": "Structured Perceptron",
        "title": "Learning from natural instructions",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "dataset": [
          "Solitaire Card Game",
          "Geoquery"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature mapping",
            "Decision variables"
          ],
          "connections": [
            "Maps input sentences to logical formulas"
          ],
          "mechanisms": [
            "Optimizes joint objective function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Weight updates based on labeled examples"
          ]
        },
        "feature_processing": [
          "Lexical and syntactic features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geoquery_1996",
        "entity_type": "Dataset",
        "name": "Geoquery",
        "description": "Geographical database queries",
        "domain": "Natural Language Processing",
        "size": 500,
        "year": 1996,
        "creators": [
          "Zelle, J.",
          "Mooney, R."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "LossApproximation_SemanticParsing",
        "entity_type": "Metric",
        "name": "Loss Approximation",
        "description": "Approximated structural loss",
        "category": "Semantic Parsing",
        "formula": "Assigns penalties based on confidence scores of substructures"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_RNNEncoderDecoder",
        "entity_type": "Algorithm",
        "name": "RNN EncoderâDecoder",
        "title": "Learning Phrase Representations using RNN EncoderâDecoder for Statistical Machine Translation",
        "year": 2014,
        "authors": [
          "Kyunghyun Cho",
          "Bart van MerriÃ«nboer",
          "Caglar Gulcehre",
          "Dzmitry Bahdanau",
          "Fethi Bougares",
          "Holger Schwenk",
          "Yoshua Bengio"
        ],
        "task": "Statistical Machine Translation",
        "dataset": [
          "Europarl_2014",
          "News Commentary_2014",
          "UN_2014",
          "Crawled Corpora_2014"
        ],
        "metrics": [
          "BLEU_score_Translation",
          "Perplexity_LanguageModel"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network (RNN)",
            "Hidden Unit with Reset and Update Gates"
          ],
          "connections": [
            "Encoder RNN to Fixed-Length Vector",
            "Fixed-Length Vector to Decoder RNN"
          ],
          "mechanisms": [
            "Conditional Probability Maximization",
            "Adaptive Memory Control"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-Based Algorithm",
            "Joint Training of Encoder and Decoder"
          ],
          "parameter_tuning": [
            "Adadelta",
            "Stochastic Gradient Descent",
            "Hyperparameters: Îµ=10^-6, Ï=0.95"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Phrase Pair Scoring"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Europarl_2014",
        "entity_type": "Dataset",
        "name": "Europarl",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 61000000,
        "year": 2014,
        "creators": [
          "Koehn, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NewsCommentary_2014",
        "entity_type": "Dataset",
        "name": "News Commentary",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 5500000,
        "year": 2014,
        "creators": [
          "Koehn, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "UN_2014",
        "entity_type": "Dataset",
        "name": "UN",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 421000000,
        "year": 2014,
        "creators": [
          "Koehn, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CrawledCorpora_2014",
        "entity_type": "Dataset",
        "name": "Crawled Corpora",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 870000000,
        "year": 2014,
        "creators": [
          "Koehn, P."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_score_Translation",
        "entity_type": "Metric",
        "name": "BLEU Score",
        "description": "Bilingual Evaluation Understudy Score",
        "category": "Translation Performance",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Perplexity_LanguageModel",
        "entity_type": "Metric",
        "name": "Perplexity",
        "description": "Measure of how well a probability distribution or probability model predicts a sample",
        "category": "Language Model Performance",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_EquationSolver",
        "entity_type": "Algorithm",
        "name": "EquationSolver",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": "èªå¨æ±è§£ä»£æ°æå­é¢",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "æ¨¡æ¿éæ©",
            "æ§½ä½å®ä¾å",
            "å¯¹é½æ¨¡å"
          ],
          "connections": [
            "æ¨¡æ¿ä¸æ¹ç¨ç³»ç»çæ å°",
            "æ§½ä½ä¸ææ¬çå¯¹é½"
          ],
          "mechanisms": [
            "èåå¯¹æ°çº¿æ§åå¸",
            "æ¨¡æ¿å½çº³",
            "éåéä¼å"
          ]
        },
        "methodology": {
          "training_strategy": [
            "å¼±çç£å­¦ä¹ ",
            "å®å¨çç£å­¦ä¹ "
          ],
          "parameter_tuning": [
            "L-BFGSä¼å",
            "L2æ­£åå"
          ]
        },
        "feature_processing": [
          "è¯æ§æ æ³¨",
          "è¯å½¢è¿å",
          "ä¾å­å¥æ³åæ",
          "è¯æ±åç¹å¾"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Algebra.com_2014",
        "entity_type": "Dataset",
        "name": "Algebra.com",
        "description": "ä»Algebra.comæ¶éçä»£æ°æå­é¢æ°æ®é",
        "domain": "ä»£æ°",
        "size": 514,
        "year": 2014,
        "creators": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Equation_Accuracy",
        "entity_type": "Metric",
        "name": "Equation Accuracy",
        "description": "ç³»ç»çææ­£ç¡®æ¹ç¨ç»çé¢ç",
        "category": "æ¹ç¨è¯ä¼°",
        "formula": "æ­£ç¡®æ¹ç¨ç»æ°é / æ»æ¹ç¨ç»æ°é"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Answer_Accuracy",
        "entity_type": "Metric",
        "name": "Answer Accuracy",
        "description": "çææ°å¼ç­æ¡æ­£ç¡®çé¢ç",
        "category": "ç­æ¡è¯ä¼°",
        "formula": "æ­£ç¡®ç­æ¡æ°é / æ»ç­æ¡æ°é"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_ARIS",
        "entity_type": "Algorithm",
        "name": "ARIS",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": 2014,
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Verb_Categorization_Accuracy"
        ],
        "architecture": {
          "components": [
            "Entity recognizer",
            "Container recognizer",
            "Attribute recognizer",
            "Quantity recognizer",
            "Verb category classifier"
          ],
          "connections": [
            "Dependency parser",
            "Coreference resolution",
            "Named entity recognizer"
          ],
          "mechanisms": [
            "State transitions",
            "Equation formation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning",
            "Support Vector Machines"
          ],
          "parameter_tuning": [
            "Feature extraction",
            "Regularization"
          ]
        },
        "feature_processing": [
          "Similarity-based features",
          "WordNet-based features",
          "Structural features"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Verb_Categorization_Accuracy",
        "entity_type": "Metric",
        "name": "Verb Categorization Accuracy",
        "description": "Accuracy of verb categorization in sentences",
        "category": "Verb categorization evaluation",
        "formula": "Correctly categorized verbs / Total verbs"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_FormulaApplication",
        "entity_type": "Algorithm",
        "name": "Formula Application",
        "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
        "year": 2016,
        "authors": [
          "Mitra, Arindam",
          "Baral, Chitta"
        ],
        "task": "Solving simple arithmetic word problems",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature extraction",
            "Log-linear model",
            "Probabilistic model"
          ],
          "connections": [
            "Feature extraction -> Log-linear model",
            "Log-linear model -> Probabilistic model"
          ],
          "mechanisms": [
            "Feature function",
            "Parameter estimation",
            "Stochastic gradient descent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Parameter vector Î¸"
          ]
        },
        "feature_processing": [
          "WordNet",
          "ConceptNet",
          "Stanford CoreNLP"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AddSub_2014",
        "entity_type": "Dataset",
        "name": "AddSub",
        "description": "A dataset of simple addition-subtraction arithmetic problems",
        "domain": "Natural Language Processing",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini, Mohammad Javad",
          "Hajishirzi, Hannaneh",
          "Etzioni, Oren",
          "Kushman, Nate"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_LongShortTermMemory",
        "entity_type": "Algorithm",
        "name": "Long Short-Term Memory (LSTM)",
        "title": "Long Short-Term Memory",
        "year": 1997,
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "Sequence Modeling, Long Time Lag Problems",
        "dataset": [],
        "metrics": [
          "Success Rate",
          "Training Time",
          "Error Rate"
        ],
        "architecture": {
          "components": [
            "Memory Cells",
            "Input Gates",
            "Output Gates",
            "Constant Error Carousels (CECs)"
          ],
          "connections": [
            "Fully Connected Hidden Layer",
            "Self-Connections within Memory Cells"
          ],
          "mechanisms": [
            "Constant Error Flow",
            "Multiplicative Gates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated Backpropagation Through Time (BPTT)",
            "Real-Time Recurrent Learning (RTRL)"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Initial Bias Values"
          ]
        },
        "feature_processing": [
          "Handling Noise",
          "Protecting Internal State from Drift"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1991_ConstantErrorCarrousel",
        "entity_type": "Algorithm",
        "name": "Constant Error Carrousel (CEC)",
        "title": "Long Short-Term Memory",
        "year": 1991,
        "authors": [
          "Hochreiter, S."
        ],
        "task": "Long Time Lag Problems",
        "dataset": [],
        "metrics": [
          "Error Rate"
        ],
        "architecture": {
          "components": [
            "Linear Unit with Fixed Self-Connection"
          ],
          "connections": [
            "Self-Connection"
          ],
          "mechanisms": [
            "Constant Error Flow"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated Backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Elman1988_RecurrentCascadeCorrelation",
        "entity_type": "Algorithm",
        "name": "Recurrent Cascade-Correlation",
        "title": "Long Short-Term Memory",
        "year": 1988,
        "authors": [
          "Elman, J. L."
        ],
        "task": "Sequence Modeling",
        "dataset": [],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Hidden Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Recurrent Cascade-Correlation Learning Algorithm"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robinson1987_RealTimeRecurrentLearning",
        "entity_type": "Algorithm",
        "name": "Real-Time Recurrent Learning (RTRL)",
        "title": "Long Short-Term Memory",
        "year": 1987,
        "authors": [
          "Robinson, A. J.",
          "Fallside, F."
        ],
        "task": "Sequence Modeling",
        "dataset": [],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Hidden Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Real-Time Recurrent Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Williams1990_BackPropagationThroughTime",
        "entity_type": "Algorithm",
        "name": "Back-Propagation Through Time (BPTT)",
        "title": "Long Short-Term Memory",
        "year": 1990,
        "authors": [
          "Williams, R. J.",
          "Peng, J."
        ],
        "task": "Sequence Modeling",
        "dataset": [],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Hidden Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Back-Propagation Through Time"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Schmidhuber1992_NeuralSequenceChunker",
        "entity_type": "Algorithm",
        "name": "Neural Sequence Chunker",
        "title": "Long Short-Term Memory",
        "year": 1992,
        "authors": [
          "Schmidhuber, J."
        ],
        "task": "Sequence Modeling",
        "dataset": [],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Two Networks"
          ],
          "connections": [
            "Inter-Network Connections"
          ],
          "mechanisms": [
            "Chunking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Chunking"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "EmbeddedReberGrammar_1989",
        "entity_type": "Dataset",
        "name": "Embedded Reber Grammar",
        "description": "A synthetic dataset for evaluating sequence modeling algorithms",
        "domain": "Natural Language Processing",
        "size": "Not specified",
        "year": 1989,
        "creators": [
          "Smith, A. W.",
          "Zipser, D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SuccessRate_Classification",
        "entity_type": "Metric",
        "name": "Success Rate",
        "description": "Percentage of successful trials",
        "category": "Classification Evaluation",
        "formula": "Number of successful trials / Total number of trials"
      }
    },
    {
      "metric_entity": {
        "metric_id": "TrainingTime_Performance",
        "entity_type": "Metric",
        "name": "Training Time",
        "description": "Time required to train the model",
        "category": "Performance Evaluation",
        "formula": "Total training time"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorRate_Classification",
        "entity_type": "Metric",
        "name": "Error Rate",
        "description": "Average error rate over multiple trials",
        "category": "Classification Evaluation",
        "formula": "Sum of errors / Number of trials"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goyal2017_DeepLSTMNormImage",
        "entity_type": "Algorithm",
        "name": "Deeper LSTM Question + norm Image",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": 2017,
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_2015",
          "Balanced_VQA_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "CNN embedding",
            "LSTM embedding",
            "point-wise multiplication",
            "multi-layer perceptron classifier"
          ],
          "connections": [
            "image embedding -> point-wise multiplication",
            "question embedding -> point-wise multiplication",
            "point-wise multiplication -> MLP classifier"
          ],
          "mechanisms": [
            "embedding",
            "multiplication",
            "classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "CNN feature extraction",
          "LSTM sequence modeling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lu2016_HierarchicalCoAttention",
        "entity_type": "Algorithm",
        "name": "Hierarchical Co-attention",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": 2017,
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_2015",
          "Balanced_VQA_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "word-level attention",
            "phrase-level attention",
            "question-level attention"
          ],
          "connections": [
            "image features -> co-attention",
            "question features -> co-attention",
            "co-attended features -> answer prediction"
          ],
          "mechanisms": [
            "attention",
            "co-attention",
            "recursive combination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image feature extraction",
          "question feature extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fukui2016_MultimodalCompactBilinearPooling",
        "entity_type": "Algorithm",
        "name": "Multimodal Compact Bilinear Pooling",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": 2017,
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "VQA_2015",
          "Balanced_VQA_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "multimodal compact bilinear pooling",
            "fully-connected layer"
          ],
          "connections": [
            "image features -> bilinear pooling",
            "language features -> bilinear pooling",
            "pooled features -> fully-connected layer"
          ],
          "mechanisms": [
            "bilinear pooling",
            "attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image feature extraction",
          "language feature extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "VQA_2015",
        "entity_type": "Dataset",
        "name": "VQA",
        "description": "Visual Question Answering dataset with real images from COCO",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 204000,
        "year": 2015,
        "creators": [
          "Stanislaw Antol",
          "Aishwarya Agrawal",
          "Jiasen Lu",
          "Margaret Mitchell",
          "Dhruv Batra",
          "C. Lawrence Zitnick",
          "Devi Parikh"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Balanced_VQA_2017",
        "entity_type": "Dataset",
        "name": "Balanced VQA",
        "description": "Balanced Visual Question Answering dataset with complementary images",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 443000,
        "year": 2017,
        "creators": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Entropy_AnswerDistribution",
        "entity_type": "Metric",
        "name": "Entropy",
        "description": "Measure of uncertainty in the answer distribution",
        "category": "Distribution Evaluation",
        "formula": "-Î£ p(x) log p(x)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_at_5",
        "entity_type": "Metric",
        "name": "Recall@5",
        "description": "Proportion of times the human-picked counter-example is among the top-5 in the sorted list",
        "category": "Explanation Evaluation",
        "formula": "Number of times human-picked image is in top-5 / Total number of queries"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_KNOWLEDGE",
        "entity_type": "Algorithm",
        "name": "KNOWLEDGE",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": 2018,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith",
          "Perturb",
          "Aggregate"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Transfer",
            "Dimensional Analysis",
            "Part-Whole Relation",
            "Explicit Math"
          ],
          "connections": [
            "Concept Selection",
            "Declarative Rule Selection"
          ],
          "mechanisms": [
            "Latent Variable Modeling",
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two Stage Learning",
            "Latent Structured SVM"
          ],
          "parameter_tuning": [
            "Weight Vectors for Concepts and Rules"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Coreference Resolution",
          "Verb Classification",
          "Rate Component Detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArith_2017",
        "entity_type": "Dataset",
        "name": "AllArith",
        "description": "Arithmetic word problems dataset",
        "domain": "Mathematics",
        "size": 831,
        "year": 2017,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Perturb_2018",
        "entity_type": "Dataset",
        "name": "Perturb",
        "description": "New word problems created by perturbing original problems",
        "domain": "Mathematics",
        "size": 661,
        "year": 2018,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Aggregate_2018",
        "entity_type": "Dataset",
        "name": "Aggregate",
        "description": "Combined dataset of AllArith and Perturb",
        "domain": "Mathematics",
        "size": 1492,
        "year": 2018,
        "creators": [
          "Roy, S.",
          "Roth, D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_MathDQN",
        "entity_type": "Algorithm",
        "name": "MathDQN",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "èªå¨æ±è§£ç®æ¯æå­é¢",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015",
          "ArithS",
          "ArithM"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "ç¶æè¡¨ç¤º",
            "å¨ä½éæ©",
            "å¥å±å½æ°",
            "ä¸¤å±åé¦ç¥ç»ç½ç»"
          ],
          "connections": [
            "ç¶æå°å¨ä½çéæ©",
            "å¥å±åé¦å°ç½ç»åæ°æ´æ°"
          ],
          "mechanisms": [
            "æ·±åº¦å¼ºåå­¦ä¹ æ¡æ¶",
            "Îµ-greedyç­ç¥",
            "ç»éªåæ¾ç¼å²åº"
          ]
        },
        "methodology": {
          "training_strategy": [
            "DQNæ¡æ¶ä¸çè®­ç»",
            "Îµ-greedyç­ç¥",
            "ç»éªåæ¾ç¼å²åº"
          ],
          "parameter_tuning": [
            "å­¦ä¹ çè®¾ç½®ä¸º0.0001",
            "ææ£å å­Î³=0.9",
            "éæ¾ç¼å²åºå¤§å°ä¸º15,000"
          ]
        },
        "feature_processing": [
          "æ°éæ¨¡å¼æå",
          "éæ°æåºæºå¶",
          "ç¹å¾åéè¡¨ç¤º"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AI2_2014",
        "entity_type": "Dataset",
        "name": "AI2",
        "description": "åå«395ä¸ªåæ­¥æå¤æ­¥ç®æ¯æå­é¢ï¼ä»æ¶åå æ³ååæ³",
        "domain": "ç®æ¯æå­é¢æ±è§£",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IL_2015",
        "entity_type": "Dataset",
        "name": "IL",
        "description": "åå«562ä¸ªåæ­¥æå­é¢ï¼æ¶åå æ³ãåæ³ãä¹æ³åé¤æ³",
        "domain": "ç®æ¯æå­é¢æ±è§£",
        "size": 562,
        "year": 2015,
        "creators": [
          "Roy, Vieira, and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CC_2015",
        "entity_type": "Dataset",
        "name": "CC",
        "description": "åå«600ä¸ªå¤æ­¥é®é¢ï¼ä¸åå«æ å³æ°éï¼æ¶ååç§æä½ç¬¦çç»å",
        "domain": "ç®æ¯æå­é¢æ±è§£",
        "size": 600,
        "year": 2015,
        "creators": [
          "Roy and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ArithS",
        "entity_type": "Dataset",
        "name": "ArithS",
        "description": "åå«890ä¸ªåæ­¥ç®æ¯é®é¢ï¼ä»æ¶åä¸ä¸ªæä½ç¬¦",
        "domain": "ç®æ¯æå­é¢æ±è§£",
        "size": 890,
        "year": 2018,
        "creators": [
          "Wang et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ArithM",
        "entity_type": "Dataset",
        "name": "ArithM",
        "description": "åå«667ä¸ªå¤æ­¥ç®æ¯é®é¢ï¼è³å°æ¶åä¸¤ä¸ªæä½ç¬¦",
        "domain": "ç®æ¯æå­é¢æ±è§£",
        "size": 667,
        "year": 2018,
        "creators": [
          "Wang et al."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_ExpTree",
        "entity_type": "Algorithm",
        "name": "ExpTree",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "èªå¨æ±è§£ç®æ¯æå­é¢",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "è¡¨è¾¾å¼æ æå»º",
            "æ°éç¸å³æ§é¢æµåç±»å¨",
            "æä½ç¬¦åç±»å¨"
          ],
          "connections": [
            "æ°éå°æä½ç¬¦çéæ©",
            "è¡¨è¾¾å¼æ çæå»º"
          ],
          "mechanisms": [
            "è¡¨è¾¾å¼æ è¯åå½æ°"
          ]
        },
        "methodology": {
          "training_strategy": [
            "åºäºSVMçåç±»å¨è®­ç»"
          ],
          "parameter_tuning": [
            "æ å·ä½åæ°è°æ´è¯´æ"
          ]
        },
        "feature_processing": [
          "æ°éæ¨¡å¼æå"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_ALGES",
        "entity_type": "Algorithm",
        "name": "ALGES",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "èªå¨æ±è§£ç®æ¯æå­é¢",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "æ´æ°çº¿æ§è§åæä¸¾",
            "åéæ è¯å"
          ],
          "connections": [
            "æ°éå°è¡¨è¾¾å¼æ çæ å°"
          ],
          "mechanisms": [
            "è¯åå½æ°"
          ]
        },
        "methodology": {
          "training_strategy": [
            "åºäºæ´æ°çº¿æ§è§åçæä¸¾"
          ],
          "parameter_tuning": [
            "æ å·ä½åæ°è°æ´è¯´æ"
          ]
        },
        "feature_processing": [
          "æ°éæ¨¡å¼æå"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_UnitDep",
        "entity_type": "Algorithm",
        "name": "UnitDep",
        "title": "Unit Dependency Graph and Its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "èªå¨æ±è§£ç®æ¯æå­é¢",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "åä½ä¾èµå¾",
            "è¯åå½æ°"
          ],
          "connections": [
            "æ°éå°è¡¨è¾¾å¼æ çæ å°"
          ],
          "mechanisms": [
            "è¯åå½æ°"
          ]
        },
        "methodology": {
          "training_strategy": [
            "åºäºè¯åå½æ°çä¼å"
          ],
          "parameter_tuning": [
            "æ å·ä½åæ°è°æ´è¯´æ"
          ]
        },
        "feature_processing": [
          "æ°éæ¨¡å¼æå"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_SequenceToSequenceLearning",
        "entity_type": "Algorithm",
        "name": "Sequence to Sequence Learning",
        "year": 2014,
        "authors": [
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Le, Quoc V."
        ],
        "task": "Machine Translation, Image Caption Generation, Constituency Parsing",
        "dataset": [
          "WMT'15 English-German",
          "Penn Tree Bank",
          "High-Confidence Corpus",
          "Image Captioning Dataset"
        ],
        "metrics": [
          "BLEU",
          "Perplexity",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Recurrent Neural Networks (RNN)",
            "Long Short-Term Memory (LSTM)",
            "Gated Recurrent Unit (GRU)"
          ],
          "connections": [
            "Recurrent Connections",
            "Embeddings"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Parameter Updates Allocation"
          ],
          "parameter_tuning": [
            "Mixing Ratios",
            "Learning Rate Halving"
          ]
        },
        "feature_processing": [
          "Input Sequence Reversal",
          "Dropout"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT15_English-German_2015",
        "entity_type": "Dataset",
        "name": "WMT'15 English-German",
        "description": "Parallel corpus for English-German translation",
        "domain": "Natural Language Processing",
        "size": 4500000,
        "year": 2015,
        "creators": [
          "Bojar, OndÅej",
          "Chatterjee, Rajen",
          "Federmann, Christian",
          "Haddow, Barry",
          "Huck, Matthias",
          "Hokamp, Chris",
          "Koehn, Philipp",
          "Logacheva, Varvara",
          "Monz, Christof",
          "Negri, Matteo",
          "Post, Matt",
          "Scarton, Carolina",
          "Specia, Lucia",
          "Turchi, Marco"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreeBank_1993",
        "entity_type": "Dataset",
        "name": "Penn Tree Bank",
        "description": "Corpus for syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 40000,
        "year": 1993,
        "creators": [
          "Marcus, Mitchell P.",
          "Marcinkiewicz, Mary Ann",
          "Santorini, Beatrice"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "HighConfidenceCorpus_2015",
        "entity_type": "Dataset",
        "name": "High-Confidence Corpus",
        "description": "Large parsing resource for syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 11000000,
        "year": 2015,
        "creators": [
          "Vinyals, Oriol",
          "Kaiser, Lukasz",
          "Koo, Terry",
          "Petrov, Slav",
          "Sutskever, Ilya",
          "Hinton, Geoffrey"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ImageCaptioningDataset_2015",
        "entity_type": "Dataset",
        "name": "Image Captioning Dataset",
        "description": "Dataset of image and caption pairs",
        "domain": "Computer Vision",
        "size": 596000,
        "year": 2015,
        "creators": [
          "Vinyals, Oriol",
          "Toshev, Alexander",
          "Bengio, Samy",
          "Erhan, Dumitru"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_Translation",
        "entity_type": "Metric",
        "name": "BLEU",
        "description": "Bilingual Evaluation Understudy",
        "category": "Translation Evaluation",
        "formula": "Exponential of the weighted harmonic mean of n-gram precision and brevity penalty"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Perplexity_LanguageModeling",
        "entity_type": "Metric",
        "name": "Perplexity",
        "description": "Measure of how well a probability distribution or probability model predicts a sample",
        "category": "Language Modeling Evaluation",
        "formula": "2^(-1/N * sum(log2(P(w_i))))"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1Score_Parsing",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Parsing Evaluation",
        "formula": "2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bahdanau2015_AttentionMechanism",
        "entity_type": "Algorithm",
        "name": "Attention Mechanism",
        "year": 2015,
        "authors": [
          "Bahdanau, Dzmitry",
          "Cho, Kyunghyun",
          "Bengio, Yoshua"
        ],
        "task": "Machine Translation",
        "dataset": [
          "WMT'15 English-German"
        ],
        "metrics": [
          "BLEU",
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder Hidden States",
            "Alignment Weights"
          ],
          "connections": [
            "Random Access Memory"
          ],
          "mechanisms": [
            "Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training"
          ],
          "parameter_tuning": [
            "Mixing Ratios"
          ]
        },
        "feature_processing": [
          "Input Sequence Reversal"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Dai2015_SemiSupervisedSequenceLearning",
        "entity_type": "Algorithm",
        "name": "Semi-Supervised Sequence Learning",
        "year": 2015,
        "authors": [
          "Dai, Andrew M.",
          "Le, Quoc V."
        ],
        "task": "Sequence to Sequence Learning",
        "dataset": [
          "Monolingual Corpora"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Autoencoders",
            "Skip-Thought Vectors"
          ],
          "connections": [
            "Recurrent Connections"
          ],
          "mechanisms": [
            "Unsupervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pretraining and Finetuning"
          ],
          "parameter_tuning": [
            "Mixing Ratios"
          ]
        },
        "feature_processing": [
          "Sentence Splitting"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sundaram2015_WordProblemSolver",
        "entity_type": "Algorithm",
        "name": "Word Problem Solver",
        "title": "Natural Language Processing for Solving Simple Word Problems",
        "year": 2015,
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "Solving arithmetic word problems",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Knowledge Representation",
            "Temporal Schemas",
            "Common Sense Law of Inertia"
          ],
          "connections": [
            "Schemas",
            "Temporal Ordering"
          ],
          "mechanisms": [
            "Change In",
            "Change Out",
            "Combine",
            "Compare Plus",
            "Compare Minus",
            "Increase",
            "Reduction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge-based NLP"
          ],
          "parameter_tuning": [
            "Heuristics"
          ]
        },
        "feature_processing": [
          "Resolving Conjunctions",
          "Preprocessing Currency",
          "Resolving Co-references",
          "Preprocessing Sentences",
          "Resolving Entities"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DS1_2014",
        "entity_type": "Dataset",
        "name": "DS1",
        "description": "Dataset for simple arithmetic word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DS2_2014",
        "entity_type": "Dataset",
        "name": "DS2",
        "description": "Dataset for arithmetic word problems with irrelevant information",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DS3_2014",
        "entity_type": "Dataset",
        "name": "DS3",
        "description": "Dataset for complex arithmetic word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2018_CASS",
        "entity_type": "Algorithm",
        "name": "CASS",
        "title": "Neural Math Word Problem Solver with Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Danqing Huang",
          "Jing Liu",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Sequence-to-sequence model",
            "Copy mechanism",
            "Alignment mechanism"
          ],
          "connections": [
            "Encoder-decoder architecture",
            "Attention mechanism"
          ],
          "mechanisms": [
            "Copy mechanism",
            "Alignment mechanism",
            "Reinforcement learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement learning",
            "Policy gradient",
            "Pre-training with maximum likelihood"
          ],
          "parameter_tuning": [
            "Hyper-parameter Î» for supervised attention",
            "Dropout rate",
            "Beam size"
          ]
        },
        "feature_processing": [
          "Number mapping",
          "Post-processing step to recover tokens"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NumWord_2015",
        "entity_type": "Dataset",
        "name": "NumWord",
        "description": "Contains 2,871 number word problems with 1,183 templates",
        "domain": "Mathematics",
        "size": 2871,
        "year": 2015,
        "creators": [
          "Shuming Shi",
          "Yuehui Wang",
          "Chin-Yew Lin",
          "Xiaojiang Liu",
          "Yong Rui"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Solution_Accuracy",
        "entity_type": "Metric",
        "name": "Solution Accuracy",
        "description": "The proportion of correctly solved math word problems",
        "category": "Math Word Problem Solving Evaluation",
        "formula": "Number of correctly solved problems / Total number of problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seq2SeqAttn_2017",
        "entity_type": "Algorithm",
        "name": "Seq2SeqAttn",
        "title": "Deep Neural Model for Math Word Problem Problems",
        "year": 2017,
        "authors": [
          "Yan Wang",
          "Xiaojiang Liu",
          "Shuming Shi"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Sequence-to-sequence model",
            "Attention mechanism"
          ],
          "connections": [
            "Encoder-decoder architecture"
          ],
          "mechanisms": [
            "Attention mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum likelihood estimation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number mapping"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "FeatureBasedModel_2017",
        "entity_type": "Algorithm",
        "name": "Feature-based Model",
        "title": "Learning Fine-grained Expressions to Solve Math Word Problems",
        "year": 2017,
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Template retrieval",
            "Equation ranking"
          ],
          "connections": [],
          "mechanisms": [
            "Feature extraction",
            "Ranking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Feature extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SINGLEEQ_2015",
        "entity_type": "Dataset",
        "name": "SINGLEEQ",
        "description": "Grade-school algebra word problems that map to single equations",
        "domain": "Mathematics",
        "size": 508,
        "year": 2015,
        "creators": [
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi",
          "Ashish Sabharwal",
          "Oren Etzioni",
          "Siena Dumas Ang"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ADDSUB_2014",
        "entity_type": "Dataset",
        "name": "ADDSUB",
        "description": "Addition and subtraction word problems with irrelevant distractor quantities",
        "domain": "Mathematics",
        "year": 2014,
        "creators": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_CompositionalVectorGrammar",
        "entity_type": "Algorithm",
        "name": "Compositional Vector Grammar (CVG)",
        "title": "Parsing with Compositional Vector Grammars",
        "year": 2013,
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ],
        "task": "èªç¶è¯­è¨å¤çä¸­çå¥æ³åæ",
        "dataset": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Probabilistic Context-Free Grammar (PCFG)",
            "Recursive Neural Network (RNN)",
            "Syntactically Untied Recursive Neural Network (SU-RNN)"
          ],
          "connections": [
            "PCFGä¸RNNç»å",
            "SU-RNNæéä¾èµäºå­èç¹çè¯­æ³ç±»å«"
          ],
          "mechanisms": [
            "ç»ååéè¡¨ç¤º",
            "è¿ç»­è¯­ä¹è¡¨ç¤º"
          ]
        },
        "methodology": {
          "training_strategy": [
            "æå¤§é´éè®­ç»ç®æ ",
            "AdaGradä¼åæ¹æ³"
          ],
          "parameter_tuning": [
            "æ­£åååæ°Î»=10^-4",
            "è¯åéç»´åº¦25"
          ]
        },
        "feature_processing": [
          "åå¸å¼çè¯åéè¡¨ç¤º",
          "åºäºä¸ä¸æçè¯åµå¥"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreebank_WSJ_2013",
        "entity_type": "Dataset",
        "name": "Penn Treebank WSJ",
        "description": "åå°è¡æ¥æ¥é¨åçPenn Treebankè¯­æåº",
        "domain": "èªç¶è¯­è¨å¤ç",
        "size": "æªå·ä½è¯´æ",
        "year": 2013,
        "creators": [
          "æªå·ä½è¯´æ"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Parsing",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "å¥æ³åæçF1å¾å",
        "category": "å¥æ³åæè¯ä¼°",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_StandardRNN",
        "entity_type": "Algorithm",
        "name": "Standard Recursive Neural Network (RNN)",
        "title": "Parsing with Compositional Vector Grammars",
        "year": 2013,
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ],
        "task": "èªç¶è¯­è¨å¤çä¸­çå¥æ³åæ",
        "dataset": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "éå½ç¥ç»ç½ç»"
          ],
          "connections": [
            "ç¸åçæéç©éµåºç¨äºææèç¹"
          ],
          "mechanisms": [
            "ç»åå½æ°ç¨äºè®¡ç®éç»ç«¯èç¹çåéè¡¨ç¤º"
          ]
        },
        "methodology": {
          "training_strategy": [
            "æ åRNNè®­ç»æ¹æ³"
          ],
          "parameter_tuning": [
            "æªå·ä½è¯´æ"
          ]
        },
        "feature_processing": [
          "è¯åéè¡¨ç¤º"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_SyntacticallyUntiedRNN",
        "entity_type": "Algorithm",
        "name": "Syntactically Untied Recursive Neural Network (SU-RNN)",
        "title": "Parsing with Compositional Vector Grammars",
        "year": 2013,
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ],
        "task": "èªç¶è¯­è¨å¤çä¸­çå¥æ³åæ",
        "dataset": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "éå½ç¥ç»ç½ç»"
          ],
          "connections": [
            "æéä¾èµäºå­èç¹çè¯­æ³ç±»å«"
          ],
          "mechanisms": [
            "ç»åå½æ°æ ¹æ®å­èç¹çè¯­æ³ç±»å«åå"
          ]
        },
        "methodology": {
          "training_strategy": [
            "æå¤§é´éè®­ç»ç®æ ",
            "AdaGradä¼åæ¹æ³"
          ],
          "parameter_tuning": [
            "æ­£åååæ°Î»=10^-4",
            "è¯åéç»´åº¦25"
          ]
        },
        "feature_processing": [
          "åå¸å¼çè¯åéè¡¨ç¤º",
          "åºäºä¸ä¸æçè¯åµå¥"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_QuantityExtraction",
        "entity_type": "Algorithm",
        "name": "Quantity Extraction",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "Quantity Recognition and Normalization",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "Precision",
          "Recall",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Segmentation",
            "Standardization",
            "Unit Inference"
          ],
          "connections": [
            "Segmentation -> Standardization",
            "Standardization -> Unit Inference"
          ],
          "mechanisms": [
            "Sequence Segmentation",
            "Rule-Based Standardization",
            "Semantic Role Labeling",
            "Coreference Resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-Validation"
          ],
          "parameter_tuning": [
            "Feature Engineering",
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Word Class Features",
          "Character-Based Features",
          "Part of Speech Tags",
          "Contextual Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_QuantityEntailment",
        "entity_type": "Algorithm",
        "name": "Quantity Entailment",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "Textual Entailment",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "Precision",
          "Recall",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Extraction Phase",
            "Reasoning Phase"
          ],
          "connections": [
            "Extraction Phase -> Reasoning Phase"
          ],
          "mechanisms": [
            "Implicit Quantity Productions",
            "Quantity Comparisons",
            "Monotonicity Verification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-Validation"
          ],
          "parameter_tuning": [
            "Feature Engineering",
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "WordNet Synsets",
          "Coreference Resolution",
          "Semantic Role Labeling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_MathWordProblemSolver",
        "entity_type": "Algorithm",
        "name": "Math Word Problem Solver",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "Elementary School Math Word Problems",
        "dataset": [
          "Math Word Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quantity Pair Classifier",
            "Operation Classifier",
            "Order Classifier"
          ],
          "connections": [
            "Quantity Pair Classifier -> Operation Classifier -> Order Classifier"
          ],
          "mechanisms": [
            "Cascade of Classifiers",
            "Feature Engineering",
            "Sparse Averaged Perceptron"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-Validation"
          ],
          "parameter_tuning": [
            "Feature Engineering",
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Unigrams and Bigrams",
          "POS Tags",
          "Relevant Pair of Quantities",
          "Relevant Operation",
          "Relevant Order"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "RTE_Datasets_2006",
        "entity_type": "Dataset",
        "name": "RTE Datasets",
        "description": "Textual Entailment datasets",
        "domain": "Natural Language Processing",
        "size": 384,
        "year": 2006,
        "creators": [
          "I. Dagan",
          "O. Glickman",
          "B. Magnini"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Newswire_Text_2015",
        "entity_type": "Dataset",
        "name": "Newswire Text",
        "description": "Sentences from news articles containing quantity mentions",
        "domain": "Natural Language Processing",
        "size": 600,
        "year": 2015,
        "creators": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Math_Word_Problems_2015",
        "entity_type": "Dataset",
        "name": "Math Word Problems",
        "description": "Elementary school math word problems",
        "domain": "Education",
        "size": 864,
        "year": 2015,
        "creators": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Classification",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 Score is the harmonic mean of precision and recall",
        "category": "Classification Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jung2004_WindowedHoughTransform",
        "entity_type": "Algorithm",
        "name": "Windowed Hough Transform",
        "title": "Rectangle detection based on a windowed Hough transform",
        "year": 2004,
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "Rectangle detection",
        "dataset": [],
        "metrics": [
          "Detection accuracy"
        ],
        "architecture": {
          "components": [
            "Sliding window",
            "Hough Transform",
            "Peak extraction",
            "Geometric constraints"
          ],
          "connections": [
            "Sliding window -> Hough Transform -> Peak extraction -> Geometric constraints"
          ],
          "mechanisms": [
            "Sliding window over image",
            "Compute Hough Transform in small regions",
            "Extract peaks from Hough image",
            "Detect rectangles using geometric conditions"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Thresholds TÎ¸, TÏ, TL, TÎ±"
          ]
        },
        "feature_processing": [
          "Edge detection",
          "Ring-like search region"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SyntheticImage_2004",
        "entity_type": "Dataset",
        "name": "Synthetic image",
        "description": "Synthetic image containing several geometric objects",
        "domain": "Computer vision",
        "size": "256 Ã 256 pixels",
        "year": 2004,
        "creators": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NaturalImage_2004",
        "entity_type": "Dataset",
        "name": "Natural image",
        "description": "Natural image used for testing rectangle detection",
        "domain": "Computer vision",
        "size": "Not specified",
        "year": 2004,
        "creators": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "DetectionAccuracy_RectangleDetection",
        "entity_type": "Metric",
        "name": "Detection accuracy",
        "description": "Accuracy of detecting rectangles in images",
        "category": "Object detection",
        "formula": "Number of correctly detected rectangles / Total number of rectangles"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorMeasure_RectangleDetection",
        "entity_type": "Metric",
        "name": "Error measure",
        "description": "Error measure for detected rectangles",
        "category": "Object detection",
        "formula": "E(Pk, Pl)= âa(âÎ¸k^2+âÎ¸l^2+âÎ±^2)+ b(âÏk^2+âÏl^2)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_ROBUST",
        "entity_type": "Algorithm",
        "name": "ROBUST",
        "title": "ROBUST UNDERSTANDING OF WORD PROBLEMS WITH EXTRANEOUS INFORMATION",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": "Understanding and solving arithmetic word problems with extraneous information",
        "dataset": [],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Change formulas",
            "Schema instantiations"
          ],
          "connections": [
            "Correspondence between formula variables and problem propositions"
          ],
          "mechanisms": [
            "Parsing natural language",
            "Cautious strategy for schema instantiation creation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Change verb categorization",
          "Elementary component splitting"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_SemanticParser",
        "entity_type": "Algorithm",
        "name": "Semantic Parser with On-the-fly Ontology Matching",
        "year": 2013,
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "Question Answering",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QA",
          "Precision_QA",
          "F1_QA"
        ],
        "architecture": {
          "components": [
            "Probabilistic CCG",
            "Ontology Matching Model"
          ],
          "connections": [
            "CCG Parsing -> Ontology Matching"
          ],
          "mechanisms": [
            "Domain-independent Parsing",
            "Structure Matching",
            "Constant Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Perceptron"
          ],
          "parameter_tuning": [
            "Feature Weights"
          ]
        },
        "feature_processing": [
          "CCG Parse Features",
          "Structural Features",
          "Lexical Features",
          "Knowledge Base Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "GeoQuery_1996",
        "entity_type": "Dataset",
        "name": "GeoQuery",
        "year": 1996,
        "creators": [
          "Zelle, J.",
          "Mooney, R."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "FreebaseQA_2013",
        "entity_type": "Dataset",
        "name": "Freebase QA",
        "year": 2013,
        "creators": [
          "Cai, Q.",
          "Yates, A."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_QA",
        "entity_type": "Metric",
        "name": "Recall",
        "category": "Question Answering Evaluation",
        "formula": "Number of Correct Answers / Total Number of Questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_QA",
        "entity_type": "Metric",
        "name": "Precision",
        "category": "Question Answering Evaluation",
        "formula": "Number of Correct Answers / Number of Produced Queries"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_QA",
        "entity_type": "Metric",
        "name": "F1 Score",
        "category": "Question Answering Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2019_SemanticallyAlignedEquationGeneration",
        "entity_type": "Algorithm",
        "name": "Semantically-Aligned Equation Generation",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": 2019,
        "authors": [
          "Ting-Rui Chiang",
          "Yun-Nung Chen"
        ],
        "task": "Solving and Reasoning Math Word Problems",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Encoder-Decoder",
            "Decoder-Stack",
            "Stack-Semantic Transformer"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Gating Mechanism",
            "Semantic Representation Extraction",
            "Operand Selection",
            "Operator Application"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Fully Supervised Training",
            "Postfix Representation Transformation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Bidirectional LSTM for Semantic Representation",
          "Attention Mechanism for Problem Information Incorporation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Knuth1968_ContextFreeGrammarAlgorithm",
        "entity_type": "Algorithm",
        "name": "Context-Free Grammar Algorithm",
        "title": "Semantics of Context-Free Languages",
        "year": 1968,
        "authors": [
          "Knuth, D. E."
        ],
        "task": "Parsing and semantics analysis of context-free grammars",
        "architecture": {
          "components": [
            "Directed graphs",
            "Derivation trees"
          ],
          "connections": [
            "Paths between vertices",
            "Arcs in directed graphs"
          ],
          "mechanisms": [
            "Graph construction",
            "Cycle detection"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Graph-based representation of grammar structures"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "CycleDetection_Semantics",
        "entity_type": "Metric",
        "name": "Cycle Detection",
        "description": "Detection of oriented cycles in directed graphs",
        "category": "Semantic role validation",
        "formula": "Presence or absence of cycles in directed graphs"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT14_EnglishToFrench",
        "entity_type": "Dataset",
        "name": "WMT'14 English to French",
        "description": "English to French translation dataset used in WMT'14",
        "domain": "Natural Language Processing",
        "size": 12000000,
        "year": 2014,
        "creators": [
          "WMT"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_TranslationQuality",
        "entity_type": "Metric",
        "name": "BLEU score",
        "description": "A method for automatic evaluation of machine translation",
        "category": "Translation Quality",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kalchbrenner2013_RecurrentContinuousTranslationModels",
        "entity_type": "Algorithm",
        "name": "Recurrent Continuous Translation Models",
        "title": "Recurrent Continuous Translation Models",
        "year": 2013,
        "authors": [
          "Kalchbrenner, N.",
          "Blunsom, P."
        ],
        "task": "Machine Translation",
        "dataset": [
          "Not specified in this context"
        ],
        "metrics": [
          "Not specified in this context"
        ],
        "architecture": {
          "components": [
            "Convolutional Neural Networks (CNN)"
          ],
          "connections": [
            "Input sentence to vector",
            "Vector to output sentence"
          ],
          "mechanisms": [
            "Mapping sentences to vectors"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified in this context"
          ],
          "parameter_tuning": [
            "Not specified in this context"
          ]
        },
        "feature_processing": [
          "Not specified in this context"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bahdanau2014_NeuralMachineTranslation",
        "entity_type": "Algorithm",
        "name": "Neural Machine Translation by Jointly Learning to Align and Translate",
        "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
        "year": 2014,
        "authors": [
          "Bahdanau, D.",
          "Cho, K.",
          "Bengio, Y."
        ],
        "task": "Machine Translation",
        "dataset": [
          "Not specified in this context"
        ],
        "metrics": [
          "Not specified in this context"
        ],
        "architecture": {
          "components": [
            "Attention mechanism"
          ],
          "connections": [
            "Input sequence to aligned output sequence"
          ],
          "mechanisms": [
            "Jointly learning to align and translate"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified in this context"
          ],
          "parameter_tuning": [
            "Not specified in this context"
          ]
        },
        "feature_processing": [
          "Not specified in this context"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_LearningPhraseRepresentations",
        "entity_type": "Algorithm",
        "name": "Learning Phrase Representations using RNN Encoder-Decoder",
        "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
        "year": 2014,
        "authors": [
          "Cho, K.",
          "Merrienboer, B.",
          "Gulcehre, C.",
          "Bougares, F.",
          "Schwenk, H.",
          "Bengio, Y."
        ],
        "task": "Machine Translation",
        "dataset": [
          "Not specified in this context"
        ],
        "metrics": [
          "Not specified in this context"
        ],
        "architecture": {
          "components": [
            "RNN Encoder-Decoder"
          ],
          "connections": [
            "Input sequence to fixed-dimensional vector",
            "Fixed-dimensional vector to output sequence"
          ],
          "mechanisms": [
            "Phrase representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified in this context"
          ],
          "parameter_tuning": [
            "Not specified in this context"
          ]
        },
        "feature_processing": [
          "Not specified in this context"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wiseman2016_BSO",
        "entity_type": "Algorithm",
        "name": "Beam Search Optimization (BSO)",
        "title": "Sequence-to-Sequence Learning as Beam-Search Optimization",
        "year": 2016,
        "authors": [
          "Sam Wiseman",
          "Alexander M. Rush"
        ],
        "task": "Sequence-to-Sequence Learning",
        "dataset": [
          "PTB_2015",
          "IWSLT_2014"
        ],
        "metrics": [
          "BLEU_SentenceLevel",
          "UAS_Parsing",
          "LAS_Parsing"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder",
            "Global Attention Model"
          ],
          "connections": [
            "Input Feeding",
            "Beam Search"
          ],
          "mechanisms": [
            "LaSO Framework",
            "Non-probabilistic Scoring Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Training",
            "Curriculum Beam Strategy",
            "Pre-training with Cross-Entropy Loss"
          ],
          "parameter_tuning": [
            "Mini-batch Adagrad",
            "Gradient Renormalization",
            "Learning Rates"
          ]
        },
        "feature_processing": [
          "Word Embeddings Initialization",
          "Dropout Regularization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PTB_2015",
        "entity_type": "Dataset",
        "name": "Penn Treebank",
        "description": "Standard dataset for parsing and language modeling",
        "domain": "Natural Language Processing",
        "size": "Varies by split",
        "year": 2015,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IWSLT_2014",
        "entity_type": "Dataset",
        "name": "IWSLT 2014",
        "description": "German-to-English translation dataset from TED talks",
        "domain": "Machine Translation",
        "size": "153K training sentences, 7K development sentences, 7K test sentences",
        "year": 2014,
        "creators": [
          "Mauro Cettolo",
          "Jan Niehues",
          "Sebastian StÃ¼ker",
          "Luisa Bentivogli",
          "Marcello Federico"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_SentenceLevel",
        "entity_type": "Metric",
        "name": "BLEU",
        "description": "Sentence-level BLEU score for evaluating machine translation",
        "category": "Machine Translation Evaluation",
        "formula": "Smoothed, sentence-level BLEU score"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_SimpleCoreferenceResolution",
        "entity_type": "Algorithm",
        "name": "Simple Coreference Resolution",
        "title": "Simple Coreference Resolution with Rich Syntactic and Semantic Features",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST",
          "BLIPP",
          "WIKI"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module",
            "Selection Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists",
            "Tree Distance Minimization"
          ],
          "mechanisms": [
            "Syntactic Constraints",
            "Semantic Compatibility Filtering",
            "Agreement Constraints",
            "Syntactic Configuration Constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning",
            "Deterministic Function"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining",
          "Appositive Annotation",
          "Predicate Nominative Annotation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-ROTH-DEV_2009",
        "entity_type": "Dataset",
        "name": "ACE2004-ROTH-DEV",
        "description": "Development set split of the ACE 2004 training set",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": 2009,
        "creators": [
          "Bengston, E.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-CULOTTA-TEST_2009",
        "entity_type": "Dataset",
        "name": "ACE2004-CULOTTA-TEST",
        "description": "Test set split of the ACE 2004 training set",
        "domain": "Natural Language Processing",
        "size": 107,
        "year": 2009,
        "creators": [
          "Culotta, A.",
          "Bengston, E.",
          "Roth, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-NWIRE_2009",
        "entity_type": "Dataset",
        "name": "ACE2004-NWIRE",
        "description": "ACE 2004 Newswire set",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": 2009,
        "creators": [
          "Poon, H.",
          "Domingos, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MUC-6-TEST_2009",
        "entity_type": "Dataset",
        "name": "MUC-6-TEST",
        "description": "MUC6 formal evaluation set",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": 2009,
        "creators": [
          "Vilain, M.",
          "Burger, J.",
          "Aberdeen, J.",
          "Connolly, D.",
          "Hirschman, L."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "BLIPP_2009",
        "entity_type": "Dataset",
        "name": "BLIPP",
        "description": "1.8 million sentences of newswire parsed with the Charniak parser",
        "domain": "Natural Language Processing",
        "size": 1800000,
        "year": 2009,
        "creators": [
          "Charniak, E."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WIKI_2009",
        "entity_type": "Dataset",
        "name": "WIKI",
        "description": "25k articles of English Wikipedia abstracts parsed by the Klein and Manning parser",
        "domain": "Natural Language Processing",
        "size": 25000,
        "year": 2009,
        "creators": [
          "Klein, D.",
          "Manning, C."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_F1_Coreference",
        "entity_type": "Metric",
        "name": "Pairwise F1",
        "description": "Precision, recall, and F1 over all pairs of mentions in the same entity cluster",
        "category": "Coreference Resolution",
        "formula": "F1 = 2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "b3_Coreference",
        "entity_type": "Metric",
        "name": "b3",
        "description": "For each mention, form the intersection between the predicted cluster and the true cluster for that mention",
        "category": "Coreference Resolution",
        "formula": "F1 = 2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "CEAF_Coreference",
        "entity_type": "Metric",
        "name": "CEAF",
        "description": "Scores the best match between true and predicted clusters using a similarity function",
        "category": "Coreference Resolution",
        "formula": "Best match using Ï3 similarity function"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2016_ExpressionTreeBasedSolver",
        "entity_type": "Algorithm",
        "name": "Expression Tree Based Solver",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2016,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "èªå¨æ±è§£ç®æ¯æå­é¢",
        "dataset": [
          "AI2 Dataset",
          "IL Dataset",
          "Commoncore Dataset"
        ],
        "metrics": [
          "Accuracy",
          "Relax Accuracy",
          "Strict Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Monotonic Expression Tree",
            "Quantity Schema"
          ],
          "connections": [
            "LCA Operation Prediction",
            "Relevance Classification"
          ],
          "mechanisms": [
            "Constrained Inference Framework",
            "Global Inference Module"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Multiclass SVM Classifier",
            "Binary SVM Classifier"
          ],
          "parameter_tuning": [
            "wIRR"
          ]
        },
        "feature_processing": [
          "Unit Features",
          "Related NP Features",
          "Miscellaneous Features",
          "Question Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AI2_Dataset_2014",
        "entity_type": "Dataset",
        "name": "AI2 Dataset",
        "description": "åå«395ä¸ªå åæ³é®é¢çæ°æ®é",
        "domain": "èªç¶è¯­è¨å¤ç",
        "size": 395,
        "year": 2014,
        "creators": [
          "M. J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IL_Dataset_2015",
        "entity_type": "Dataset",
        "name": "IL Dataset",
        "description": "åå«562ä¸ªç®æ¯é®é¢çæ°æ®éï¼æ¯ä¸ªé®é¢å¯ä»¥éè¿ä¸ä¸ªæä½è§£å³",
        "domain": "èªç¶è¯­è¨å¤ç",
        "size": 562,
        "year": 2015,
        "creators": [
          "S. Roy",
          "T. Vieira",
          "D. Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Commoncore_Dataset_2016",
        "entity_type": "Dataset",
        "name": "Commoncore Dataset",
        "description": "åå«600ä¸ªå¤æ­¥ç®æ¯é®é¢çæ°æ°æ®é",
        "domain": "èªç¶è¯­è¨å¤ç",
        "size": 600,
        "year": 2016,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Relax_Accuracy_Classification",
        "entity_type": "Metric",
        "name": "Relax Accuracy",
        "description": "æ¾æ¾åç¡®çï¼é¨åæ­£ç¡®ï¼",
        "category": "åç±»è¯ä¼°",
        "formula": "é¨åæ­£ç¡®çæ ·æ¬æ°/æ»æ ·æ¬æ°"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Strict_Accuracy_Classification",
        "entity_type": "Metric",
        "name": "Strict Accuracy",
        "description": "ä¸¥æ ¼åç¡®çï¼å®å¨æ­£ç¡®ï¼",
        "category": "åç±»è¯ä¼°",
        "formula": "å®å¨æ­£ç¡®çæ ·æ¬æ°/æ»æ ·æ¬æ°"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_RelationKnowledgePoweredModel",
        "entity_type": "Algorithm",
        "name": "Relation Knowledge Powered Model (RK)",
        "title": "Solving Verbal Questions in IQ Test by Knowledge-Powered Word Embedding",
        "year": 2016,
        "authors": [
          "Huazheng Wang",
          "Fei Tian",
          "Bin Gao",
          "Chengjieren Zhu",
          "Jiang Bian",
          "Tie-Yan Liu"
        ],
        "task": "èªå¨è§£ç­è¯­è¨çè§£ç±»IQæµè¯é¢",
        "dataset": [
          "wiki2014",
          "èªå®ä¹IQæµè¯é"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "é®é¢åç±»å¨",
            "è¯ä¹åå³ç³»åµå¥æ¨¡å",
            "ç¹å®è§£é¢å¨"
          ],
          "connections": [
            "é®é¢åç±»å¨ -> è¯ä¹åå³ç³»åµå¥æ¨¡å -> ç¹å®è§£é¢å¨"
          ],
          "mechanisms": [
            "å¤ä¹è¯èç±»",
            "å³ç³»ç¥è¯åµå¥",
            "ç¿»è¯è·ç¦»æå°å"
          ]
        },
        "methodology": {
          "training_strategy": [
            "è´éæ ·",
            "å¤ä¹è¯èç±»",
            "å³ç³»ç¥è¯åµå¥"
          ],
          "parameter_tuning": [
            "çªå£å¤§å°",
            "åµå¥ç»´åº¦",
            "è´éæ ·æ¬¡æ°",
            "è®­ç»è½®æ¬¡"
          ]
        },
        "feature_processing": [
          "ä¸ä¸æçªå£è¡¨ç¤º",
          "TF-IDFå æ",
          "çå½¢kåå¼èç±»"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "wiki2014_2014",
        "entity_type": "Dataset",
        "name": "wiki2014",
        "description": "æ¥èªç»´åºç¾ç§çå¤§è§æ¨¡ææ¬å¿«ç§",
        "domain": "èªç¶è¯­è¨å¤ç",
        "size": 3400000000,
        "year": 2014,
        "creators": [
          "Wikipedia Contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CustomIQTestSet_2016",
        "entity_type": "Dataset",
        "name": "èªå®ä¹IQæµè¯é",
        "description": "ä»å·²åºççIQæµè¯ä¹¦ä¸­æ¶éçè¯­è¨çè§£ç±»é®é¢åå¶ç­æ¡",
        "domain": "å¿çå­¦",
        "size": 232,
        "year": 2016,
        "creators": [
          "Huazheng Wang",
          "Fei Tian",
          "Bin Gao",
          "Chengjieren Zhu",
          "Jiang Bian",
          "Tie-Yan Liu"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengio2003_NeuralProbabilisticLanguageModel",
        "entity_type": "Algorithm",
        "name": "Neural Probabilistic Language Model",
        "year": 2003,
        "authors": [
          "Yoshua Bengio",
          "Rejean Ducharme",
          "Pascal Vincent",
          "Christian Jauvin"
        ],
        "task": "è¯­è¨å»ºæ¨¡",
        "dataset": [
          "æªæå®"
        ],
        "metrics": [
          "æªæå®"
        ],
        "architecture": {
          "components": [
            "ç¥ç»ç½ç»"
          ],
          "connections": [
            "æªæå®"
          ],
          "mechanisms": [
            "æ¦çè¯­è¨æ¨¡å"
          ]
        },
        "methodology": {
          "training_strategy": [
            "æªæå®"
          ],
          "parameter_tuning": [
            "æªæå®"
          ]
        },
        "feature_processing": [
          "æªæå®"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Blei2003_LatentDirichletAllocation",
        "entity_type": "Algorithm",
        "name": "Latent Dirichlet Allocation (LDA)",
        "year": 2003,
        "authors": [
          "David M Blei",
          "Andrew Y Ng",
          "Michael I Jordan"
        ],
        "task": "ä¸»é¢å»ºæ¨¡",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "æªæå®"
        ],
        "architecture": {
          "components": [
            "æ½å¨çå©åé·åé"
          ],
          "connections": [
            "æªæå®"
          ],
          "mechanisms": [
            "ä¸»é¢åå¸"
          ]
        },
        "methodology": {
          "training_strategy": [
            "æªæå®"
          ],
          "parameter_tuning": [
            "ä¸»é¢æ°é"
          ]
        },
        "feature_processing": [
          "æªæå®"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collobert2008_UnifiedArchitectureForNLP",
        "entity_type": "Algorithm",
        "name": "Unified Architecture for Natural Language Processing",
        "year": 2008,
        "authors": [
          "Ronan Collobert",
          "Jason Weston"
        ],
        "task": "èªç¶è¯­è¨å¤ç",
        "dataset": [
          "æªæå®"
        ],
        "metrics": [
          "æªæå®"
        ],
        "architecture": {
          "components": [
            "æ·±åº¦ç¥ç»ç½ç»"
          ],
          "connections": [
            "å¤ä»»å¡å­¦ä¹ "
          ],
          "mechanisms": [
            "æªæå®"
          ]
        },
        "methodology": {
          "training_strategy": [
            "æªæå®"
          ],
          "parameter_tuning": [
            "æªæå®"
          ]
        },
        "feature_processing": [
          "æªæå®"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_Glove",
        "entity_type": "Algorithm",
        "name": "Glove",
        "year": 2014,
        "authors": [
          "Jeffrey Pennington",
          "Richard Socher",
          "Christopher D Manning"
        ],
        "task": "è¯åéè¡¨ç¤º",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "æªæå®"
        ],
        "architecture": {
          "components": [
            "å¨å±ç©éµåè§£"
          ],
          "connections": [
            "å±ç°ç©éµ"
          ],
          "mechanisms": [
            "å¨å±ç»è®¡ä¿¡æ¯"
          ]
        },
        "methodology": {
          "training_strategy": [
            "æªæå®"
          ],
          "parameter_tuning": [
            "æªæå®"
          ]
        },
        "feature_processing": [
          "æªæå®"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2012_MultiSenseWordEmbedding",
        "entity_type": "Algorithm",
        "name": "Multi-Sense Word Embedding",
        "year": 2012,
        "authors": [
          "Eric H Huang",
          "Richard Socher",
          "Christopher D Manning",
          "Andrew Y Ng"
        ],
        "task": "å¤ä¹è¯åµå¥",
        "dataset": [
          "æªæå®"
        ],
        "metrics": [
          "æªæå®"
        ],
        "architecture": {
          "components": [
            "å¤ä¹è¯åµå¥"
          ],
          "connections": [
            "æªæå®"
          ],
          "mechanisms": [
            "å¨å±ä¸ä¸æ",
            "å¤ä¸ªè¯åå"
          ]
        },
        "methodology": {
          "training_strategy": [
            "æªæå®"
          ],
          "parameter_tuning": [
            "æªæå®"
          ]
        },
        "feature_processing": [
          "æªæå®"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2014_ProblemGenerationAlgorithm",
        "entity_type": "Algorithm",
        "name": "Problem Generation Algorithm",
        "title": "Synthesis of Geometry Proof Problems",
        "year": 2014,
        "authors": [
          "Chris Alvin",
          "Sumit Gulwani",
          "Rupak Majumdar",
          "Supratik Mukhopadhyay"
        ],
        "task": "Geometry Proof Problem Generation",
        "dataset": [],
        "metrics": [
          "Number of Generated Problems",
          "Time Taken to Generate Problems"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Minimal Assumption Generation",
            "Strictly Interesting Problem Synthesis"
          ],
          "connections": [
            "Hypergraph Construction -> Minimal Assumption Generation -> Strictly Interesting Problem Synthesis"
          ],
          "mechanisms": [
            "Hypergraph Reachability",
            "Fixed-Point Procedure",
            "Non-Deterministic Choices"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Implicit Facts",
          "Explicit Facts",
          "Axioms"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Number_of_Generated_Problems",
        "entity_type": "Metric",
        "name": "Number of Generated Problems",
        "description": "The number of geometry proof problems generated by the algorithm",
        "category": "Problem Generation Evaluation",
        "formula": "Total number of problems generated"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Time_Taken_to_Generate_Problems",
        "entity_type": "Metric",
        "name": "Time Taken to Generate Problems",
        "description": "The time taken by the algorithm to generate geometry proof problems",
        "category": "Efficiency Evaluation",
        "formula": "Average time per figure"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Completeness_of_Problems",
        "entity_type": "Metric",
        "name": "Completeness",
        "description": "Whether the problem is completely defined by the assumptions",
        "category": "Problem Quality Evaluation",
        "formula": "Boolean classification of completeness"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2019_TemplateBasedSolver",
        "entity_type": "Algorithm",
        "name": "Template-Based Math Word Problem Solver",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": 2019,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "èªå¨æ±è§£æ°å­¦æå­é¢",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Seq2Seqæ¨¡å",
            "Bi-LSTM",
            "Self Attention",
            "Recursive Neural Network"
          ],
          "connections": [
            "Seq2Seqæ¨¡åé¢æµæ ç»ææ¨¡æ¿",
            "Bi-LSTMç¼ç æ°é",
            "Self Attentionææé¿è·ç¦»ä¾èµ",
            "Recursive Neural Networkæ¨æ­æªç¥æä½ç¬¦"
          ],
          "mechanisms": [
            "æ¹ç¨æ¨¡æ¿å½ä¸å",
            "æä½ç¬¦å°è£"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adamä¼åå¨",
            "SGDä¼åå¨"
          ],
          "parameter_tuning": [
            "å­¦ä¹ çè°æ´",
            "å¨éå å­è®¾ç½®"
          ]
        },
        "feature_processing": [
          "è¯åµå¥",
          "èªæ³¨æåæºå¶"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_DNS",
        "entity_type": "Algorithm",
        "name": "DNS",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Lei Wang",
          "Yongquan Liu",
          "Shuming Shi"
        ],
        "task": "èªå¨æ±è§£æ°å­¦æå­é¢",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Seq2Seqæ¨¡å",
            "LSTM",
            "GRU"
          ],
          "connections": [
            "Seq2Seqæ¨¡åç´æ¥çææ°å­¦è¡¨è¾¾å¼"
          ],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_GenerationModel",
        "entity_type": "Algorithm",
        "name": "Generation Model",
        "title": "Data-driven methods for solving algebra word problems",
        "year": 2018,
        "authors": [
          "Ben Robaidek",
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi"
        ],
        "task": "èªå¨æ±è§£ä»£æ°æå­é¢",
        "dataset": [
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "LSTM",
            "CNN"
          ],
          "connections": [
            "Seq2Seqæ¨¡åç´æ¥çææ°å­¦è¡¨è¾¾å¼"
          ],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018b_MathDQN",
        "entity_type": "Algorithm",
        "name": "MathDQN",
        "title": "MathDQN: Solving arithmetic word problems via deep reinforcement learning",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingwen Song",
          "Lei Guo",
          "Heng Tao Shen"
        ],
        "task": "èªå¨æ±è§£ç®æ¯æå­é¢",
        "dataset": [
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Deep Reinforcement Learning",
            "Expression Tree"
          ],
          "connections": [
            "è¿­ä»£æå»ºè¡¨è¾¾å¼æ "
          ],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_EquationNormalization",
        "entity_type": "Algorithm",
        "name": "Equation Normalization",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Normalization Rules"
          ],
          "connections": [
            "Rule 1",
            "Rule 2",
            "Bracket Elimination"
          ],
          "mechanisms": [
            "Order Duplication Handling",
            "Bracket Duplication Handling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SEQ2SEQ Framework"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_SEQ2SEQFramework",
        "entity_type": "Algorithm",
        "name": "SEQ2SEQ Framework",
        "year": 2017,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Attention Mechanism"
          ],
          "connections": [
            "Bidirectional LSTM",
            "Convolutional SEQ2SEQ",
            "Transformer"
          ],
          "mechanisms": [
            "Global Attention",
            "Multi-head Self-attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_DeepNeuralSolver",
        "entity_type": "Algorithm",
        "name": "Deep Neural Solver",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ Model",
            "GRU Encoder",
            "LSTM Decoder"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_DNSHybrid",
        "entity_type": "Algorithm",
        "name": "DNS-Hybrid",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ Model",
            "Retrieval-based Solver"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_BiLSTM",
        "entity_type": "Algorithm",
        "name": "BiLSTM",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM"
          ],
          "connections": [
            "Two-layer Bi-LSTM Encoder",
            "Two-layer LSTM Decoder"
          ],
          "mechanisms": [
            "Global Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Gehring2017_ConvolutionalSEQ2SEQ",
        "entity_type": "Algorithm",
        "name": "Convolutional SEQ2SEQ",
        "year": 2017,
        "authors": [
          "Jonas Gehring",
          "Michael Auli",
          "David Grangier",
          "Denis Yarats",
          "Yann N Dauphin"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Convolutional Layers"
          ],
          "connections": [
            "Four-layer Encoder",
            "Three-layer Decoder"
          ],
          "mechanisms": [
            "Gate Linear Units"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Early Stopping",
            "Learning Rate Annealing"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Vaswani2017_Transformer",
        "entity_type": "Algorithm",
        "name": "Transformer",
        "year": 2017,
        "authors": [
          "Ashish Vaswani",
          "Noam Shazeer",
          "Niki Parmar",
          "Jakob Uszkoreit",
          "Llion Jones",
          "Aidan N Gomez",
          "Åukasz Kaiser",
          "Illia Polosukhin"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multi-head Self-attention",
            "Position-wise Fully-connected Feed-forward Network"
          ],
          "connections": [
            "Four-layer Stack"
          ],
          "mechanisms": [
            "Self-attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_EnsembleModel",
        "entity_type": "Algorithm",
        "name": "Ensemble Model",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "Convolutional SEQ2SEQ",
            "Transformer"
          ],
          "connections": [
            "Generation Probability Selection"
          ],
          "mechanisms": [
            "Model Combination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fletcher1985_WORDPRO",
        "entity_type": "Algorithm",
        "name": "WORDPRO",
        "title": "Understanding and solving arithmetic word problems: A computer simulation",
        "year": 1985,
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "çè§£å¹¶è§£å³ç®æ¯æå­é®é¢",
        "dataset": [],
        "metrics": [
          "Run-Time Statistics"
        ],
        "architecture": {
          "components": [
            "Production Rules",
            "Set Schema",
            "Transfer Schema",
            "Superset Schema",
            "More-Than/Less-Than Schema"
          ],
          "connections": [
            "STM to LTM",
            "Text Base to Problem Model"
          ],
          "mechanisms": [
            "Meaning Postulates",
            "Arithmetic Strategies",
            "Problem-Solving Procedures"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Simulating third-grade children's problem-solving processes"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Propositional Representation",
          "Bilevel Representation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "RunTimeStatistics_ProblemSolving",
        "entity_type": "Metric",
        "name": "Run-Time Statistics",
        "description": "ç¨åºè¿è¡æ¶ç»è®¡ä¿¡æ¯",
        "category": "ç¨åºæ§è½è¯ä¼°",
        "formula": "åæ¬è§¦åççäº§è§åæ°éãè½¬æ¢æ¬¡æ°ãLTMæç´¢æ¬¡æ°ä»¥åè·¨å¤çå¨æä¿ççæå¤§åæ°"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_BEATRIX",
        "entity_type": "Algorithm",
        "name": "BEATRIX",
        "title": "Understanding Natural Language with Diagrams",
        "year": 1990,
        "authors": [
          "Novak, G. S.",
          "Bulko, W."
        ],
        "task": "çè§£ç©çé®é¢ä¸­çèªç¶è¯­è¨åå¾è¡¨",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "English-parser",
            "Diagram-parser",
            "Coreference-resolver"
          ],
          "connections": [
            "TEXT-MODEL",
            "PICTURE-MODEL",
            "PROBLEM-MODEL"
          ],
          "mechanisms": [
            "Blackboard architecture",
            "Opportunistic co-parsers"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "èªç¶è¯­è¨å¤ç",
          "å¾è¡¨è§£æ",
          "æ ¸å¿ferenceè§£æ"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PhysicsProblems_1990",
        "entity_type": "Dataset",
        "name": "Physics Problems",
        "description": "åå«èªç¶è¯­è¨ææ¬åå¾è¡¨çç©çé®é¢æ°æ®é",
        "domain": "ç©çé®é¢æ±è§£",
        "size": null,
        "year": 1990,
        "creators": [
          "Novak, G. S.",
          "Bulko, W."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Correctness_ProblemModel",
        "entity_type": "Metric",
        "name": "Correctness",
        "description": "é®é¢æ¨¡åçæ­£ç¡®æ§",
        "category": "é®é¢çè§£è¯ä¼°",
        "formula": "æ­£ç¡®çè§£çé®é¢æ°é / æ»é®é¢æ°é"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bulko1988_BEATRIX",
        "entity_type": "Algorithm",
        "name": "BEATRIX",
        "title": "Understanding Text With an Accompanying Diagram",
        "year": 1988,
        "authors": [
          "William C. Bulko"
        ],
        "task": "Physics Problem Solving",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Graphic Interface",
            "Blackboard System",
            "Understanding Module",
            "Parsing Module"
          ],
          "connections": [
            "Text Parsing -> Blackboard",
            "Picture Parsing -> Blackboard",
            "Coreference Resolution -> Problem Model"
          ],
          "mechanisms": [
            "Coreference Resolution",
            "Object Identification",
            "Semantic Network Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Correction Facility",
          "Special Point Detection",
          "Object Hypothesis Generation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CollegeLevelPhysicsTextbooks_1988",
        "entity_type": "Dataset",
        "name": "College-Level Physics Textbooks",
        "description": "Collection of physics problems from college-level textbooks",
        "domain": "Physics",
        "size": "Not specified",
        "year": 1988,
        "creators": [
          "Various Authors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Correctness_Completeness",
        "entity_type": "Metric",
        "name": "Correctness and Completeness",
        "description": "Validation of the correctness and completeness of the generated problem model",
        "category": "Model Validation",
        "formula": "Not specified"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_PairwiseCoreferenceModel",
        "entity_type": "Algorithm",
        "name": "Pairwise Coreference Model",
        "title": "Understanding the Value of Features for Coreference Resolution",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004 English Training Data"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function",
            "Best-Link Decision Model",
            "Averaged Perceptron Learning Algorithm"
          ],
          "connections": [
            "Pairwise Coreference Function -> Best-Link Decision Model"
          ],
          "mechanisms": [
            "Pairwise Classification",
            "Graph-based Linking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Averaged Perceptron"
          ],
          "parameter_tuning": [
            "Threshold Optimization",
            "Regularization Parameter Tuning"
          ]
        },
        "feature_processing": [
          "Mention Types",
          "String Relation Features",
          "Semantic Features",
          "Relative Location Features",
          "Learned Features",
          "Aligned Modifiers",
          "Memorization Features",
          "Predicted Entity Types"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004_EnglishTrainingData",
        "entity_type": "Dataset",
        "name": "ACE 2004 English Training Data",
        "description": "A dataset for coreference resolution provided by NIST",
        "domain": "Natural Language Processing",
        "size": 336,
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "B-Cubed_F-Score",
        "entity_type": "Metric",
        "name": "B-Cubed F-Score",
        "description": "A measure of the overlap of predicted clusters and true clusters",
        "category": "Clustering Evaluation",
        "formula": "Harmonic Mean of Precision and Recall"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_F-Score",
        "entity_type": "Metric",
        "name": "MUC F-Score",
        "description": "Official MUC scoring algorithm",
        "category": "Clustering Evaluation",
        "formula": "Harmonic Mean of Precision and Recall"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ng2002_BestLinkDecisionModel",
        "entity_type": "Algorithm",
        "name": "Best-Link Decision Model",
        "title": "Improving Machine Learning Approaches to Coreference Resolution",
        "year": 2002,
        "authors": [
          "Vincent Ng",
          "Claire Cardie"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004 English Training Data"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Best-Link Decision Model"
          ],
          "connections": [],
          "mechanisms": [
            "Pairwise Classification",
            "Graph-based Linking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Culotta2007_ComplexCoreferenceModel",
        "entity_type": "Algorithm",
        "name": "Complex Coreference Model",
        "title": "First-Order Probabilistic Models for Coreference Resolution",
        "year": 2007,
        "authors": [
          "Arnie Culotta",
          "Michael Wick",
          "Robert Hall",
          "Andrew McCallum"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE 2004 English Training Data"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Complex Coreference Model"
          ],
          "connections": [],
          "mechanisms": [
            "Non-Pairwise Classification",
            "Partial Clusters"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_UNITDEP",
        "entity_type": "Algorithm",
        "name": "UNITDEP",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Vertex Classifier",
            "Edge Classifier",
            "Constrained Inference Module"
          ],
          "connections": [
            "Vertex Classifier -> Constrained Inference Module",
            "Edge Classifier -> Constrained Inference Module"
          ],
          "mechanisms": [
            "Decomposed Model",
            "Joint Inference Procedure"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Beam Search"
          ],
          "parameter_tuning": [
            "Scaling Parameters (Î»IRR, Î»VERTEX, Î»EDGE)"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-based Extraction Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithLex_2017",
        "entity_type": "Dataset",
        "name": "AllArithLex",
        "description": "Subset of AllArith with low lexical overlap",
        "domain": "Natural Language Processing",
        "size": 415,
        "year": 2017,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithTmpl_2017",
        "entity_type": "Dataset",
        "name": "AllArithTmpl",
        "description": "Subset of AllArith with low template overlap",
        "domain": "Natural Language Processing",
        "size": 415,
        "year": 2017,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_LCA++",
        "entity_type": "Algorithm",
        "name": "LCA++",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Irrelevance Classifier",
            "LCA Operation Classifier"
          ],
          "connections": [
            "Irrelevance Classifier -> Constrained Inference Module",
            "LCA Operation Classifier -> Constrained Inference Module"
          ],
          "mechanisms": [
            "Monotonic Expression Tree"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Scaling Parameter (Î»IRR)"
          ]
        },
        "feature_processing": [
          "Context Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TEMPLATE",
        "entity_type": "Algorithm",
        "name": "TEMPLATE",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "N. Kushman",
          "L. Zettlemoyer",
          "R. Barzilay",
          "Y. Artzi"
        ],
        "task": "Algebra Word Problem Solving",
        "dataset": [
          "Algebra Word Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Matching"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Template-based Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_SINGLEEQ",
        "entity_type": "Algorithm",
        "name": "SINGLEEQ",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": 2015,
        "authors": [
          "R. Koncel-Kedziorski",
          "H. Hajishirzi",
          "A. Sabharwal",
          "O. Etzioni",
          "S. Ang"
        ],
        "task": "Single Equation Word Problem Solving",
        "dataset": [
          "Single Equation Word Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Equation Parsing"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Antol2015_VQA",
        "entity_type": "Algorithm",
        "name": "VQA",
        "title": "VQA: Visual Question Answering",
        "year": 2015,
        "authors": [
          "Stanislaw Antol",
          "Aishwarya Agrawal",
          "Jiasen Lu",
          "Margaret Mitchell",
          "Dhruv Batra",
          "C. Lawrence Zitnick",
          "Devi Parikh"
        ],
        "task": "Visual Question Answering",
        "dataset": [
          "MS COCO_2014",
          "Abstract Scenes_2015"
        ],
        "metrics": [
          "Accuracy_OpenAnswer",
          "Accuracy_MultipleChoice"
        ],
        "architecture": {
          "components": [
            "Multi-Layer Perceptron (MLP)",
            "LSTM"
          ],
          "connections": [
            "Question to MLP",
            "Image to MLP",
            "Question to LSTM",
            "Image to LSTM"
          ],
          "mechanisms": [
            "Element-wise Multiplication",
            "Softmax Layer"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Concatenation of Features"
          ],
          "parameter_tuning": [
            "Dropout",
            "Hidden Units",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Bag-of-Words",
          "VGGNet Features",
          "One-Hot Encoding"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MS COCO_2014",
        "entity_type": "Dataset",
        "name": "MS COCO",
        "description": "Microsoft Common Objects in Context dataset",
        "domain": "Computer Vision",
        "size": 204721,
        "year": 2014,
        "creators": [
          "Tsung-Yi Lin",
          "Michael Maire",
          "Serge Belongie",
          "James Hays",
          "Peter Perona",
          "Devon Ramanan",
          "Piotr Dollar",
          "C. Lawrence Zitnick"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Abstract Scenes_2015",
        "entity_type": "Dataset",
        "name": "Abstract Scenes",
        "description": "Dataset of abstract scenes for VQA",
        "domain": "Computer Vision",
        "size": 50000,
        "year": 2015,
        "creators": [
          "Stanislaw Antol",
          "C. Lawrence Zitnick",
          "Devi Parikh"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_OpenAnswer",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for open-answer task",
        "category": "Classification Evaluation",
        "formula": "min(# humans that provided that answer / 3, 1)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_MultipleChoice",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for multiple-choice task",
        "category": "Classification Evaluation",
        "formula": "min(# humans that provided that answer / 3, 1)"
      }
    }
  ],
  "is_complete": true,
  "extraction_time": 1748341714.893279
}