{
  "entities": [
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_L3M",
        "entity_type": "Algorithm",
        "name": "Latent Left Linking model (L3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "ACE",
          "Ontonotes"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Latent structured prediction",
            "Knowledge-based constraints"
          ],
          "connections": [
            "Efficient inference",
            "Stochastic gradient learning"
          ],
          "mechanisms": [
            "Constrained latent variable model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic gradient based learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "evolution_relations": [
          {
            "from_entity": "TraditionalPairwiseModel",
            "to_entity": "Chang2013_L3M",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "引入了潜在变量模型和约束机制",
            "evidence": "Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_NeuralDependencyParser",
        "entity_type": "Algorithm",
        "name": "Neural Dependency Parser",
        "title": "A fast and accurate dependency parser using neural networks",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "Dependency Parsing",
        "dataset": [
          "English Penn Treebank"
        ],
        "metrics": [
          "Unlabeled Attachment Score",
          "Labeled Attachment Score"
        ],
        "architecture": {
          "components": [
            "Neural network classifier"
          ],
          "connections": [
            "Greedy transition-based parsing"
          ],
          "mechanisms": [
            "Dense features"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Greedy transition-based parsing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dense features"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalFeatureBasedParsers",
            "to_entity": "Chen2014_NeuralDependencyParser",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "使用神经网络分类器减少了特征计算成本并提高了解析速度",
            "evidence": "Experiments show that the neural network classifier achieves a 2% improvement in unlabeled and labeled attachment scores.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_MultiPassSieve",
        "entity_type": "Algorithm",
        "name": "Multi-Pass Sieve",
        "title": "A multi-pass sieve for coreference resolution",
        "year": 2010,
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": "Coreference Resolution",
        "dataset": [
          "Standard corpora"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Deterministic coreference models"
          ],
          "connections": [
            "Tiered processing"
          ],
          "mechanisms": [
            "Global information propagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "High precision features"
        ],
        "evolution_relations": [
          {
            "from_entity": "SingleFunctionCoreferenceModels",
            "to_entity": "Raghunathan2010_MultiPassSieve",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过多层筛选模型提高了精度",
            "evidence": "Our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
        "entity_type": "Algorithm",
        "name": "Structured Self-Attentive Sentence Embedding",
        "title": "A Structured Self-Attentive Sentence Embedding",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "Sentence Embedding",
        "dataset": [
          "Author Profiling",
          "Sentiment Classification",
          "Textual Entailment"
        ],
        "metrics": [
          "Performance Gain"
        ],
        "architecture": {
          "components": [
            "2-D matrix representation",
            "Self-attention mechanism"
          ],
          "connections": [
            "Attention on different parts of the sentence"
          ],
          "mechanisms": [
            "Special regularization term"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Self-attention"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "evolution_relations": [
          {
            "from_entity": "TraditionalSentenceEmbeddings",
            "to_entity": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "引入了自注意力机制和特殊正则化项",
            "evidence": "Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2013_LearningFromNaturalInstructions",
        "entity_type": "Algorithm",
        "name": "Learning from Natural Instructions",
        "title": "Learning from natural instructions",
        "year": 2013,
        "authors": [
          "Dan Goldwasser",
          "Dan Roth"
        ],
        "task": "Natural Language Understanding",
        "dataset": [
          "Solitaire card game rules"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Lesson interpretation problem"
          ],
          "connections": [
            "Feedback from final task"
          ],
          "mechanisms": [
            "Joint learning of interpretation and task performance"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "evolution_relations": [
          {
            "from_entity": "TraditionalMachineLearning",
            "to_entity": "Goldwasser2013_LearningFromNaturalInstructions",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过自然语言指令进行学习",
            "evidence": "We show that our learning approach can eventually use natural language instructions to learn the target concept and play the game legally.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Math23K_2017",
        "entity_type": "Dataset",
        "name": "Math23K",
        "description": "大规模数学应用题数据集",
        "domain": "自然语言处理",
        "size": 23000,
        "year": 2017,
        "creators": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "evolution_relations": [
          {
            "from_entity": "SmallerMathWordProblemDatasets",
            "to_entity": "Math23K_2017",
            "relation_type": "Extend",
            "detail": "扩展了数据集规模和问题类型",
            "evidence": "The dataset used in our experiment is provided by(Kushman et al., 2014). Equivalent equation systme templates are automatically merged.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Classification",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "分类准确率",
        "category": "分类评估",
        "formula": "正确分类样本数/总样本数",
        "evolution_relations": [
          {
            "from_entity": "OldMetric_2000",
            "to_entity": "Accuracy_Classification",
            "relation_type": "Improve",
            "detail": "改进了计算方式",
            "evidence": "Experiments conducted on the new dataset lead to interesting and surprising results.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_ARIS",
        "entity_type": "Algorithm",
        "name": "ARIS",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": 2015,
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Standard primary school test questions"
        ],
        "metrics": [
          "Verb Categorization Accuracy",
          "Problem Solving Accuracy"
        ],
        "architecture": {
          "components": [
            "Verb categorization"
          ],
          "connections": [
            "Equation generation"
          ],
          "mechanisms": [
            "Semantic mapping"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Verb categorization"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalRuleBasedApproaches",
            "to_entity": "Roy2015_ARIS",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过动词分类提高了解题能力",
            "evidence": "ARIS learns to categorize verbs with 81.2% accuracy, and is able to solve 77.7% of the problems in a corpus of standard primary school test questions.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_LargeScaleDatasetConstruction",
        "entity_type": "Algorithm",
        "name": "Large-Scale Dataset Construction",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": 2016,
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Community question-answering (CQA) web pages"
        ],
        "metrics": [
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Ranking SVM model"
          ],
          "connections": [
            "Automatic extraction of problem answers"
          ],
          "mechanisms": [
            "Reduced human annotation cost"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Ranking SVM"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Problem answers from CQA users"
        ],
        "evolution_relations": [
          {
            "from_entity": "SmallScaleDatasets",
            "to_entity": "Huang2016_LargeScaleDatasetConstruction",
            "relation_type": "Extend",
            "structure": "Architecture.Mechanism",
            "detail": "构建了更大规模的数据集",
            "evidence": "We build a large-scale dataset which is more than 9 times the size of previous ones, and contains many more problem types.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_SolvingGeneralArithmeticProblems",
        "entity_type": "Algorithm",
        "name": "Solving General Arithmetic Problems",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Benchmark datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression trees"
          ],
          "connections": [
            "Decomposition into classification problems"
          ],
          "mechanisms": [
            "Constrained inference framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Quantity schemas"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalRuleBasedApproaches",
            "to_entity": "Roy2015_SolvingGeneralArithmeticProblems",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过表达树分解和约束推理框架提高了解题能力",
            "evidence": "Experimental results show that our method outperforms existing systems, achieving state-of-the-art performance on benchmark datasets of arithmetic word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_DeepNeuralSolver",
        "entity_type": "Algorithm",
        "name": "Deep Neural Solver",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Yan Wang",
          "Xiaojiang Liu",
          "Shuming Shi"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Large dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network (RNN)"
          ],
          "connections": [
            "Translation to equation templates"
          ],
          "mechanisms": [
            "Neural equation classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Pretrained word embeddings"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalStatisticalMethods",
            "to_entity": "Wang2017_DeepNeuralSolver",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "直接将数学应用题翻译为方程模板",
            "evidence": "Experiments conducted on a large dataset show that the RNN model and the hybrid model significantly outperform state-of-the-art statistical learning methods for math word problem solving.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_UnitDependencyGraph",
        "entity_type": "Algorithm",
        "name": "Unit Dependency Graph (UDG)",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2018,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Benchmark datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Unit Dependency Graph"
          ],
          "connections": [
            "Dependency between units"
          ],
          "mechanisms": [
            "Constrained inference framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Unit extraction"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalUnitExtraction",
            "to_entity": "Roy2018_UnitDependencyGraph",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过单位依赖图减少了错误",
            "evidence": "Introduction of UDGs reduces the error of the solver by over 10%, surpassing all existing systems for solving arithmetic word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_MathDQN",
        "entity_type": "Algorithm",
        "name": "MathDQN",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Benchmark datasets"
        ],
        "metrics": [
          "Average Precision"
        ],
        "architecture": {
          "components": [
            "Deep Q-network"
          ],
          "connections": [
            "States, actions, reward function"
          ],
          "mechanisms": [
            "Feed-forward neural network"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep reinforcement learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "evolution_relations": [
          {
            "from_entity": "TraditionalBeamSearch",
            "to_entity": "Wang2018_MathDQN",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过深度强化学习提高了准确性和运行时间",
            "evidence": "Our MathDQN yields remarkable improvement on most of datasets and boosts the average precision among all the benchmark datasets by 15%.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2018_CASS",
        "entity_type": "Algorithm",
        "name": "CASS",
        "title": "Neural Math Word Problem Solver with Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Danqing Huang",
          "Jing Liu",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Benchmark datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Copy and alignment mechanism"
          ],
          "connections": [
            "Sequence-to-sequence model"
          ],
          "mechanisms": [
            "Reinforcement learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Copy and alignment"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalSeq2Seq",
            "to_entity": "Huang2018_CASS",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过复制和对齐机制解决了生成虚假数字的问题",
            "evidence": "The copy and alignment mechanism is effective to address the two issues;",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2015_GEOS",
        "entity_type": "Algorithm",
        "name": "GEOS",
        "title": "Solving Geometry Problems: Combining Text and Diagram Interpretation",
        "year": 2015,
        "authors": [
          "Minjoon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni",
          "Clint Malcolm"
        ],
        "task": "Geometry Problem Solving",
        "dataset": [
          "Official SAT questions",
          "Practice questions"
        ],
        "metrics": [
          "Score"
        ],
        "architecture": {
          "components": [
            "Submodular optimization"
          ],
          "connections": [
            "Text understanding and diagram interpretation"
          ],
          "mechanisms": [
            "Formal problem description"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Submodular optimization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Text and diagram features"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalGeometrySolvers",
            "to_entity": "Seo2015_GEOS",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "结合文本理解和图表解释",
            "evidence": "GEOS achieves a 49% score on official SAT questions, and a score of 61% on practice questions.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_TranslationToExpressionTree",
        "entity_type": "Algorithm",
        "name": "Translation to Expression Tree",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2017,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression tree"
          ],
          "connections": [
            "Sequence-to-sequence model"
          ],
          "mechanisms": [
            "Equation normalization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Sequence-to-sequence"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Equation normalization"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalSeq2Seq",
            "to_entity": "Wang2017_TranslationToExpressionTree",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过表达树转换提高了准确性",
            "evidence": "The ensemble model with equation normalization significantly outperforms the previous state-of-the-art methods.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_TemplateBasedSolver",
        "entity_type": "Algorithm",
        "name": "Template-Based Solver",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "Math Word Problem Solving",
        "dataset": [
          "Math23K",
          "MAWPS"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Recursive neural network"
          ],
          "connections": [
            "Tree-structure template"
          ],
          "mechanisms": [
            "Bottom-up inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Recursive neural network"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Bi-LSTM and self attention"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalSeq2Seq",
            "to_entity": "Wang2018_TemplateBasedSolver",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过模板和递归神经网络提高了准确性",
            "evidence": "The experimental results clearly establish the superiority of our new framework as we improve the accuracy by a wide margin in two of the largest datasets.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_SequenceToSequence",
        "entity_type": "Algorithm",
        "name": "Sequence-to-Sequence Learning",
        "title": "Sequence to Sequence Learning with Neural Networks",
        "year": 2014,
        "authors": [
          "Ilya Sutskever",
          "Oriol Vinyals",
          "Quoc V. Le"
        ],
        "task": "Sequence Learning",
        "dataset": [
          "WMT-14 English to French translation"
        ],
        "metrics": [
          "BLEU score"
        ],
        "architecture": {
          "components": [
            "Multilayered Long Short-Term Memory (LSTM)"
          ],
          "connections": [
            "Input sequence to vector",
            "Vector to target sequence"
          ],
          "mechanisms": [
            "Fixed dimensionality vector"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Neural networks"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "evolution_relations": [
          {
            "from_entity": "TraditionalPhraseBasedSMT",
            "to_entity": "Sutskever2014_SequenceToSequence",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过序列到序列学习提高了翻译质量",
            "evidence": "The translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2016_MultiTaskSequenceToSequence",
        "entity_type": "Algorithm",
        "name": "Multi-Task Sequence-to-Sequence Learning",
        "title": "Multi-task sequence to sequence learning",
        "year": 2016,
        "authors": [
          "Minh-Thang Luong",
          "Quoc V. Le",
          "Ilya Sutskever",
          "Oriol Vinyals",
          "Lukasz Kaiser"
        ],
        "task": "Sequence-to-Sequence Learning",
        "dataset": [
          "Machine translation",
          "Syntactic parsing",
          "Image caption generation"
        ],
        "metrics": [
          "BLEU score",
          "F1 score"
        ],
        "architecture": {
          "components": [
            "Encoder-decoder"
          ],
          "connections": [
            "Shared components"
          ],
          "mechanisms": [
            "Multi-task learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Multi-task learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "evolution_relations": [
          {
            "from_entity": "TraditionalSeq2Seq",
            "to_entity": "Luong2016_MultiTaskSequenceToSequence",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过多任务学习提高了翻译质量",
            "evidence": "Training on a small amount of parsing and image caption data can improve the translation quality between English and German by up to 1.5 BLEU points.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_CompositionalVectorGrammar",
        "entity_type": "Algorithm",
        "name": "Compositional Vector Grammar (CVG)",
        "title": "Parsing with Compositional Vector Grammars",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "Parsing",
        "dataset": [
          "Standard parsing datasets"
        ],
        "metrics": [
          "F1 score"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming",
            "Recursive neural network"
          ],
          "connections": [
            "Syntactic and semantic representations"
          ],
          "mechanisms": [
            "Syntactico-semantic compositions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Integer Linear Programming"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "evolution_relations": [
          {
            "from_entity": "TraditionalPCFG",
            "to_entity": "Socher2013_CompositionalVectorGrammar",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过组合向量语法提高了解析性能",
            "evidence": "The CVG improves the PCFG of the Stanford Parser by 3.8% to obtain an F1 score of 90.4%.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_MappingToDeclarativeKnowledge",
        "entity_type": "Algorithm",
        "name": "Mapping to Declarative Knowledge",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": 2018,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "Word Problem Solving",
        "dataset": [
          "Benchmark datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Declarative rules"
          ],
          "connections": [
            "Natural language to math expressions"
          ],
          "mechanisms": [
            "Latent variable"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Declarative knowledge"
        ],
        "evolution_relations": [
          {
            "from_entity": "TraditionalRuleBasedApproaches",
            "to_entity": "Roy2018_MappingToDeclarativeKnowledge",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "通过映射到声明性知识提高了准确性",
            "evidence": "Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_UnitDependencyGraph",
        "entity_type": "Algorithm",
        "name": "Unit Dependency Graph (UDG)",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "Arithmetic Word Problem Solving",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Unit Dependency Graph",
            "Constrained Inference Framework"
          ],
          "connections": [
            "Unit Extraction",
            "Domain Knowledge Integration"
          ],
          "mechanisms": [
            "Decomposed Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Unit Extraction",
          "Domain Knowledge Integration"
        ],
        "evolution_relations": [
          {
            "from_entity": "Roy2015_SolvingGeneralArithmetic",
            "to_entity": "Roy2015_UnitDependencyGraph",
            "relation_type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "引入单位依赖图以提高解题准确性",
            "evidence": "通过引入UDG，减少了求解器的误差超过10%",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Classification",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "综合考虑精确率和召回率的评价指标",
        "category": "分类评估",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "evolution_relations": [
          {
            "from_entity": "OldMetric_2000",
            "to_entity": "F1_Score_Classification",
            "relation_type": "Improve",
            "detail": "改进了计算方式",
            "evidence": "证据文本",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_EquationParser",
        "entity_type": "Algorithm",
        "name": "Equation Parser",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "代数应用题解析",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming",
            "Local and Global Discriminative Models"
          ],
          "connections": [
            "Equation Tree Generation",
            "Likelihood Scoring"
          ],
          "mechanisms": [
            "ALGES System"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Text Feature Extraction",
          "Equation Tree Generation"
        ],
        "evolution_relations": [
          {
            "from_entity": "Hosseini2014_SimpleOperations",
            "to_entity": "Kushman2014_EquationParser",
            "relation_type": "Extend",
            "structure": "Architecture.Component",
            "detail": "扩展了解析范围至更复杂的方程",
            "evidence": "能够处理更复杂的方程问题",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_FineGrainedExpressions",
        "entity_type": "Algorithm",
        "name": "Fine-Grained Expressions",
        "title": "Learning Fine-Grained Expressions to Solve Math Word Problems",
        "year": 2016,
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.-Y.",
          "Yin, J."
        ],
        "task": "数学应用题求解",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree Generation",
            "Equation Normalization"
          ],
          "connections": [
            "Expression Tree",
            "Equation Normalization"
          ],
          "mechanisms": [
            "SEQ2SEQ Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Expression Tree Generation",
          "Equation Normalization"
        ],
        "evolution_relations": [
          {
            "from_entity": "Kushman2014_EquationParser",
            "to_entity": "Huang2016_FineGrainedExpressions",
            "relation_type": "Improve",
            "structure": "Architecture.Component",
            "detail": "引入细粒度表达式以提高解题准确性",
            "evidence": "通过引入细粒度表达式，提高了求解器的准确性",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_SolvingGeneralArithmetic",
        "entity_type": "Algorithm",
        "name": "Solving General Arithmetic Problems",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2015,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "一般算术应用题求解",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Constrained Inference Framework"
          ],
          "connections": [
            "Expression Tree Generation",
            "Constrained Inference"
          ],
          "mechanisms": [
            "Expression Tree Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Text Feature Extraction",
          "Expression Tree Generation"
        ],
        "evolution_relations": [
          {
            "from_entity": "Hosseini2014_SimpleOperations",
            "to_entity": "Roy2015_SolvingGeneralArithmetic",
            "relation_type": "Extend",
            "structure": "Architecture.Component",
            "detail": "扩展了解析范围至更复杂的算术问题",
            "evidence": "能够处理更复杂的多步算术问题",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ConstrainedLatentVariableModel",
        "entity_type": "Algorithm",
        "name": "Constrained Latent Variable Model (CL3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": 2013,
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ],
        "task": "指代消解",
        "dataset": [
          "ACE",
          "OntoNotes"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Latent Left Linking Model",
            "Knowledge-Based Constraints"
          ],
          "connections": [
            "Latent Variable Model",
            "Constraint Augmentation"
          ],
          "mechanisms": [
            "Stochastic Gradient Based Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Text Feature Extraction",
          "Constraint Integration"
        ],
        "evolution_relations": [
          {
            "from_entity": "Soon2001_PairwiseMentionModel",
            "to_entity": "Chang2013_ConstrainedLatentVariableModel",
            "relation_type": "Improve",
            "structure": "Architecture.Component",
            "detail": "引入约束以提高模型准确性",
            "evidence": "通过引入约束，显著提高了模型的准确性",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_MappingDeclarativeKnowledge",
        "entity_type": "Algorithm",
        "name": "Mapping to Declarative Knowledge",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": 2018,
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "数学应用题求解",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Semantic Representation",
            "Declarative Knowledge Integration"
          ],
          "connections": [
            "Semantic Parsing",
            "Equation Generation"
          ],
          "mechanisms": [
            "Latent Variable"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Text Feature Extraction",
          "Semantic Parsing"
        ],
        "evolution_relations": [
          {
            "from_entity": "Roy2015_SolvingGeneralArithmetic",
            "to_entity": "Roy2018_MappingDeclarativeKnowledge",
            "relation_type": "Improve",
            "structure": "Architecture.Component",
            "detail": "引入声明性知识映射以提高解题准确性",
            "evidence": "通过引入声明性知识映射，显著提高了求解器的性能",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2017_ProgramInduction",
        "entity_type": "Algorithm",
        "name": "Program Induction by Rationale Generation",
        "title": "Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems",
        "year": 2017,
        "authors": [
          "Ling, W.",
          "Yogatama, D.",
          "Dyer, C.",
          "Blunsom, P."
        ],
        "task": "代数应用题求解与解释",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ Model",
            "Rationale Generation"
          ],
          "connections": [
            "Expression Generation",
            "Rationale Explanation"
          ],
          "mechanisms": [
            "SEQ2SEQ Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Text Feature Extraction",
          "Expression Generation"
        ],
        "evolution_relations": [
          {
            "from_entity": "Kushman2014_EquationParser",
            "to_entity": "Chen2017_ProgramInduction",
            "relation_type": "Improve",
            "structure": "Architecture.Component",
            "detail": "引入理由生成以提高解题准确性",
            "evidence": "通过引入理由生成，显著提高了求解器的性能",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2018_SemanticallyAlignedEquation",
        "entity_type": "Algorithm",
        "name": "Semantically-Aligned Equation Generation",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": 2018,
        "authors": [
          "Chiang, T.-R.",
          "Chen, Y.-N."
        ],
        "task": "数学应用题求解",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ Model",
            "Equation Normalization"
          ],
          "connections": [
            "Expression Tree Generation",
            "Equation Normalization"
          ],
          "mechanisms": [
            "SEQ2SEQ Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Text Feature Extraction",
          "Expression Tree Generation"
        ],
        "evolution_relations": [
          {
            "from_entity": "Kushman2014_EquationParser",
            "to_entity": "Chiang2018_SemanticallyAlignedEquation",
            "relation_type": "Improve",
            "structure": "Architecture.Component",
            "detail": "引入语义对齐方程生成以提高解题准确性",
            "evidence": "通过引入语义对齐方程生成，显著提高了求解器的性能",
            "confidence": 0.95
          }
        ]
      }
    }
  ],
  "is_complete": true,
  "extraction_time": 1748094487.4134398
}