{
  "entities": [
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_LatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Latent Left Linking Model (L3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": [
          "Coreference Resolution"
        ],
        "datasets": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Left-Linking Model"
          ],
          "connections": [
            "Best-Left-Link"
          ],
          "mechanisms": [
            "Latent Structural SVM",
            "Stochastic Gradient Descent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Threshold Tuning",
            "Temperature Parameter Tuning"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Pairwise Compatibility Score"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ConstrainedLatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Constrained Latent Left Linking Model (CL3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": [
          "Coreference Resolution"
        ],
        "datasets": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Left-Linking Model",
            "Domain Knowledge-Based Constraints"
          ],
          "connections": [
            "Best-Left-Link"
          ],
          "mechanisms": [
            "Latent Structural SVM",
            "Stochastic Gradient Descent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Threshold Tuning",
            "Temperature Parameter Tuning"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Pairwise Compatibility Score"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ProbabilisticLatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Probabilistic Latent Left Linking Model (PL3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": [
          "Coreference Resolution"
        ],
        "datasets": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Left-Linking Model",
            "Probabilistic Model"
          ],
          "connections": [
            "Best-Left-Link"
          ],
          "mechanisms": [
            "Latent Structural SVM",
            "Stochastic Gradient Descent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Likelihood-Based Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Threshold Tuning",
            "Temperature Parameter Tuning"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Pairwise Compatibility Score"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004",
        "entity_type": "Dataset",
        "name": "ACE 2004",
        "description": "A dataset for coreference resolution containing 443 documents.",
        "domain": "Natural Language Processing",
        "size": 443,
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Ontonotes5_2012",
        "entity_type": "Dataset",
        "name": "Ontonotes-5.0",
        "description": "A large annotated corpus for coreference resolution containing 3,145 documents from various sources.",
        "domain": "Natural Language Processing",
        "size": 3145,
        "year": 2012,
        "creators": [
          "Pradhan et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_Coreference",
        "entity_type": "Metric",
        "name": "MUC",
        "description": "A metric for evaluating coreference resolution systems.",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "metric_entity": {
        "metric_id": "BCUB_Coreference",
        "entity_type": "Metric",
        "name": "BCUB",
        "description": "A metric for evaluating coreference resolution systems.",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "metric_entity": {
        "metric_id": "CEAF_EntityBased",
        "entity_type": "Metric",
        "name": "Entity-based CEAF",
        "description": "A metric for evaluating coreference resolution systems.",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_NeuralNetworkParser",
        "entity_type": "Algorithm",
        "name": "Neural Network Parser",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "English Penn Treebank",
          "Chinese Penn Treebank"
        ],
        "metrics": [
          "Unlabeled Attachment Score (UAS)",
          "Labeled Attachment Score (LAS)"
        ],
        "architecture": {
          "components": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Arc Label Embeddings",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Cube Activation Function"
          ],
          "mechanisms": [
            "Dense Representations",
            "Transition-based Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-Entropy Loss",
            "L2 Regularization",
            "Mini-batched AdaGrad",
            "Dropout"
          ],
          "parameter_tuning": [
            "Pre-trained Word Embeddings",
            "Random Initialization"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Arc Label Embeddings"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "English_Penn_Treebank_2014",
        "entity_type": "Dataset",
        "name": "English Penn Treebank",
        "description": "A dataset for English syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 39832,
        "year": 2014,
        "creators": [
          "Johansson and Nugues"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Chinese_Penn_Treebank_2014",
        "entity_type": "Dataset",
        "name": "Chinese Penn Treebank",
        "description": "A dataset for Chinese syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 16091,
        "year": 2014,
        "creators": [
          "Zhang and Clark"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "UAS_Parsing",
        "entity_type": "Metric",
        "name": "Unlabeled Attachment Score (UAS)",
        "description": "The proportion of words that are attached to their correct heads, ignoring labels",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly attached words / Total words"
      }
    },
    {
      "metric_entity": {
        "metric_id": "LAS_Parsing",
        "entity_type": "Metric",
        "name": "Labeled Attachment Score (LAS)",
        "description": "The proportion of words that are attached to their correct heads and have the correct label",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly attached and labeled words / Total words"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_MultiPassSieve",
        "entity_type": "Algorithm",
        "name": "Multi-Pass Sieve",
        "title": "A Multi-Pass Sieve for Coreference Resolution",
        "year": 2010,
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": [
          "Coreference Resolution"
        ],
        "datasets": [
          "ACE2004-ROTH-DEV2",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC",
          "B3"
        ],
        "architecture": {
          "components": [
            "Pass 1- Exact Match",
            "Pass 2- Precise Constructs",
            "Pass 3- Strict Head Matching",
            "Pass 4- Variants of Strict Head",
            "Pass 5- Variants of Strict Head",
            "Pass 6- Relaxed Head Matching",
            "Pass 7- Pronouns"
          ],
          "connections": [
            "Attribute Sharing",
            "Cluster Information Propagation"
          ],
          "mechanisms": [
            "Deterministic Models",
            "Tiered Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Information",
          "Attribute Detection",
          "Modifier Information",
          "Discourse Salience"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-ROTH-DEV2_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-ROTH-DEV2",
        "description": "Development split of Bengston and Roth(2008) from the 2004 Automatic Content Extraction (ACE) evaluation",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": 2004,
        "creators": [
          "Bengston and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-CULOTTA-TEST_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-CULOTTA-TEST",
        "description": "Partition of ACE 2004 corpus reserved for testing by several previous works",
        "domain": "Natural Language Processing",
        "size": 107,
        "year": 2004,
        "creators": [
          "Culotta et al.",
          "Bengston and Roth",
          "Haghighi and Klein"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-NWIRE_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-NWIRE",
        "description": "Newswire subset of the ACE 2004 corpus",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": 2004,
        "creators": [
          "Poon and Domingos",
          "Haghighi and Klein"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MUC6-TEST_1995",
        "entity_type": "Dataset",
        "name": "MUC6-TEST",
        "description": "Test corpus from the sixth Message Understanding Conference (MUC-6) evaluation",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": 1995,
        "creators": [
          "Vilain et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_F1_Coreference",
        "entity_type": "Metric",
        "name": "Pairwise F1",
        "description": "Computed over mention pairs in the same entity cluster",
        "category": "Coreference Resolution",
        "formula": "2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_Scoring",
        "entity_type": "Metric",
        "name": "MUC",
        "description": "Measures how many predicted clusters need to be merged to cover the gold clusters",
        "category": "Coreference Resolution",
        "formula": "Not specified in the paper"
      }
    },
    {
      "metric_entity": {
        "metric_id": "B3_Scoring",
        "entity_type": "Metric",
        "name": "B3",
        "description": "Uses the intersection between predicted and gold clusters for a given mention to mark correct mentions and the sizes of the predicted and gold clusters as denominators for precision and recall",
        "category": "Coreference Resolution",
        "formula": "Not specified in the paper"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
        "entity_type": "Algorithm",
        "name": "Structured Self-attentive Sentence Embedding",
        "title": "A Structured Self-attentive Sentence Embedding",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": [
          "Author Profiling",
          "Sentiment Classification",
          "Textual Entailment"
        ],
        "datasets": [
          "Age Dataset",
          "Yelp Dataset",
          "SNLI Corpus"
        ],
        "metrics": [
          "Classification Accuracy"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Self-attention Mechanism"
          ],
          "connections": [
            "Weighted Sum of Hidden States"
          ],
          "mechanisms": [
            "Softmax",
            "Tanh",
            "Penalization Term"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Dropout",
            "L2 Regularization",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Embeddings Initialization",
          "Tokenization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Age_Dataset_2017",
        "entity_type": "Dataset",
        "name": "Age Dataset",
        "description": "Twitter tweets in English, Spanish, and Dutch with age and gender labels",
        "domain": "Natural Language Processing",
        "size": 76485,
        "year": 2017,
        "creators": [
          "PAN Conference"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Yelp_Dataset_2017",
        "entity_type": "Dataset",
        "name": "Yelp Dataset",
        "description": "2.7M Yelp reviews with star ratings",
        "domain": "Natural Language Processing",
        "size": 2700000,
        "year": 2017,
        "creators": [
          "Yelp"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SNLI_Corpus_2015",
        "entity_type": "Dataset",
        "name": "SNLI Corpus",
        "description": "570k human-written English sentence pairs manually labeled for entailment, contradiction, and neutral",
        "domain": "Natural Language Processing",
        "size": 570000,
        "year": 2015,
        "creators": [
          "Bowman et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Classification",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Classification accuracy",
        "category": "Classification Evaluation",
        "formula": "Correct classifications / Total classifications"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_TagBasedSolver",
        "entity_type": "Algorithm",
        "name": "Tag-based English Math Word Problem Solver",
        "title": "A Tag-based English Math Word Problem Solver with Understanding, Reasoning and Explanation",
        "year": 2016,
        "authors": [
          "Chao-Chun Liang",
          "Kuang-Yi Hsu",
          "Chien-Tsung Huang",
          "Chung-Min Li",
          "Shen-Yu Miao",
          "Keh-Yih Su"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Solution_Type_Accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "Pipeline"
          ],
          "mechanisms": [
            "Tag-based annotation",
            "First-order logic predicates",
            "Logic inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning",
            "SVM with linear kernel"
          ],
          "parameter_tuning": [
            "Feature extraction",
            "Pattern matching"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "POS tagging",
          "Named entity recognition",
          "Dependency parsing",
          "Co-reference resolution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MA1_2014",
        "entity_type": "Dataset",
        "name": "MA1",
        "description": "Simple math word problems on addition and subtraction for third, fourth, and fifth graders",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MA2_2014",
        "entity_type": "Dataset",
        "name": "MA2",
        "description": "Math word problems with more irrelevant information",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IXL_2014",
        "entity_type": "Dataset",
        "name": "IXL",
        "description": "Math word problems with more information gaps",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Solution_Type_Accuracy",
        "entity_type": "Metric",
        "name": "Solution Type Accuracy",
        "description": "Accuracy of identifying the correct solution type",
        "category": "Classification evaluation",
        "formula": "Correctly identified solution types / Total solution types"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_EasyFirstNonDirectionalParser",
        "entity_type": "Algorithm",
        "name": "Easy-First Non-Directional Dependency Parsing",
        "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing",
        "year": 2010,
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "WSJ Treebank",
          "CoNLL 2007 English dataset"
        ],
        "metrics": [
          "Accuracy",
          "Root",
          "Complete"
        ],
        "architecture": {
          "components": [
            "ATTACHLEFT",
            "ATTACHRIGHT"
          ],
          "connections": [
            "Dependency Edges"
          ],
          "mechanisms": [
            "Score Function",
            "Feature Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "POS Tagging",
          "Feature Templates"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WSJ_Treebank_2010",
        "entity_type": "Dataset",
        "name": "WSJ Treebank",
        "description": "Wall Street Journal Treebank used for dependency parsing",
        "domain": "Natural Language Processing",
        "size": "Sections 2-21 for training, Section 22 for development, Section 23 for testing",
        "year": 2010,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL_2007_English_dataset_2010",
        "entity_type": "Dataset",
        "name": "CoNLL 2007 English dataset",
        "description": "English dataset from the CoNLL 2007 shared task",
        "domain": "Natural Language Processing",
        "size": "Smaller than WSJ Treebank, created using a different conversion procedure",
        "year": 2010,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Root_Prediction",
        "entity_type": "Metric",
        "name": "Root",
        "description": "Percentage of sentences in which the ROOT attachment is correct",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correct ROOT attachments / Total sentences"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Complete_Correct_Parse",
        "entity_type": "Metric",
        "name": "Complete",
        "description": "Percentage of sentences in which all tokens were assigned their correct parent",
        "category": "Dependency Parsing Evaluation",
        "formula": "Sentences with all correct token assignments / Total sentences"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Earley1970_EfficientParsingAlgorithm",
        "entity_type": "Algorithm",
        "name": "Efficient Context-Free Parsing Algorithm",
        "title": "An Efficient Context-Free Parsing Algorithm",
        "year": 1970,
        "authors": [
          "Jay Earley"
        ],
        "task": [
          "Syntax Analysis",
          "Parsing"
        ],
        "datasets": [],
        "metrics": [
          "Time Complexity",
          "Space Complexity"
        ],
        "architecture": {
          "components": [
            "Predictor",
            "Completer",
            "Scanner"
          ],
          "connections": [
            "State Sets",
            "Look-ahead"
          ],
          "mechanisms": [
            "LR(k) Parsing",
            "Top-down Parsing",
            "Bottom-up Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context-Free Grammars",
          "Derivation Trees"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "TimeComplexity_Parsing",
        "entity_type": "Metric",
        "name": "Time Complexity",
        "description": "The time required to parse a string using the algorithm",
        "category": "Algorithm Performance",
        "formula": "O(n^3) for general context-free grammars, O(n^2) for unambiguous grammars, O(n) for bounded state grammars"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpaceComplexity_Parsing",
        "entity_type": "Metric",
        "name": "Space Complexity",
        "description": "The memory required to parse a string using the algorithm",
        "category": "Algorithm Performance",
        "formula": "O(n^2)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2015_GeoTutor",
        "entity_type": "Algorithm",
        "name": "GeoTutor",
        "title": "Automatic Synthesis of Geometry Problems for an Intelligent Tutoring System",
        "year": 2015,
        "authors": [
          "Chris Alvin",
          "Sumit Gulwani",
          "Rupak Majumdar",
          "Supratik Mukhopadhyay"
        ],
        "task": [
          "Euclidean Geometry Problem Synthesis"
        ],
        "datasets": [
          "High School Geometry Problems"
        ],
        "metrics": [
          "Proof Width",
          "Proof Length",
          "Deductive Steps"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Pebbling Algorithm"
          ],
          "connections": [
            "Forward Edges",
            "Back-Edges"
          ],
          "mechanisms": [
            "Traversal Algorithm",
            "Coarse Problem Homomorphism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Breadth-First Pebbling",
            "Coordinate-Based Computation"
          ],
          "parameter_tuning": [
            "User Query Restrictions"
          ]
        },
        "feature_processing": [
          "Assumption Filtering",
          "Invariant Characteristics"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "HighSchoolGeometryProblems_2015",
        "entity_type": "Dataset",
        "name": "High School Geometry Problems",
        "description": "A corpus of high school geometry problems from standard geometry textbooks.",
        "domain": "Education",
        "size": 155,
        "year": 2015,
        "creators": [
          "Sinclair et al.",
          "Boyd et al.",
          "Larson et al.",
          "Jurgensen et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ProofWidth_Classification",
        "entity_type": "Metric",
        "name": "Proof Width",
        "description": "The width of the problem hypergraph.",
        "category": "Classification Assessment",
        "formula": "Width of the hypergraph"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ProofLength_Classification",
        "entity_type": "Metric",
        "name": "Proof Length",
        "description": "The diameter of the problem hypergraph.",
        "category": "Classification Assessment",
        "formula": "Diameter of the hypergraph"
      }
    },
    {
      "metric_entity": {
        "metric_id": "DeductiveSteps_Classification",
        "entity_type": "Metric",
        "name": "Deductive Steps",
        "description": "The number of hyperedges in the problem hypergraph.",
        "category": "Classification Assessment",
        "formula": "Number of hyperedges"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shi2015_SigmaDolphin",
        "entity_type": "Algorithm",
        "name": "SigmaDolphin",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": 2015,
        "authors": [
          "Shuming Shi",
          "Yuehui Wang",
          "Chin-Yew Lin",
          "Xiaojiang Liu",
          "Yong Rui"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Algebra.com",
          "Yahoo Answers"
        ],
        "metrics": [
          "Precision",
          "Recall",
          "F1"
        ],
        "architecture": {
          "components": [
            "CFG Parser",
            "Reasoning Module"
          ],
          "connections": [
            "Semantic Parsing",
            "Math Expression Derivation"
          ],
          "mechanisms": [
            "Context-Free Grammar",
            "Semantic Representation Language (DOL)"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Top-down Parsing",
            "Earley Algorithm"
          ],
          "parameter_tuning": [
            "Type Compatibility Checking"
          ]
        },
        "feature_processing": [
          "Lexical String Handling",
          "Entity Variable Assignment"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Algebra_com_2015",
        "entity_type": "Dataset",
        "name": "Algebra.com",
        "description": "A website for users to post math problems and get help from tutors",
        "domain": "Mathematics",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Various Contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Yahoo_Answers_2015",
        "entity_type": "Dataset",
        "name": "Yahoo Answers",
        "description": "A Q&A platform where users can post and answer questions",
        "domain": "Mathematics",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Various Contributors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Evaluation",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "The proportion of true positive results among the total predicted positives",
        "category": "Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Evaluation",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "The proportion of true positive results among the total actual positives",
        "category": "Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Evaluation",
        "entity_type": "Metric",
        "name": "F1",
        "description": "The harmonic mean of precision and recall",
        "category": "Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_KAZB",
        "entity_type": "Algorithm",
        "name": "KAZB",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "N. Kushman",
          "Y. Artzi",
          "L. Zettlemoyer",
          "R. Barzilay"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "LinearT2",
          "LinearT6"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Mapping to Templates"
          ],
          "connections": [
            "Training Data Equations"
          ],
          "mechanisms": [
            "Statistical Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "ALLEQ Version"
          ],
          "parameter_tuning": [
            "Linear Equations"
          ]
        },
        "feature_processing": [
          "Problem Similarity"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "BasicSim",
        "entity_type": "Algorithm",
        "name": "BasicSim",
        "title": "Simple Statistical Method for Math Word Problem Solving",
        "year": 2015,
        "authors": [
          "Not Explicitly Mentioned"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Linear",
          "Test Set All"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Similarity Calculation"
          ],
          "connections": [
            "Training Set Problems"
          ],
          "mechanisms": [
            "Statistical Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-Validation"
          ],
          "parameter_tuning": [
            "None Mentioned"
          ]
        },
        "feature_processing": [
          "Problem Similarity"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_Aristo",
        "entity_type": "Algorithm",
        "name": "Aristo",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": [
          "Elementary Science Question Answering"
        ],
        "datasets": [
          "NY Regents Science Exam"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "IR Solver",
            "PMI Solver",
            "SVM Solver",
            "RULE Solver",
            "ILP Solver"
          ],
          "connections": [
            "Logistic Regression Combiner"
          ],
          "mechanisms": [
            "Information Retrieval",
            "Pointwise Mutual Information",
            "Support Vector Machine",
            "Rule-based Reasoning",
            "Integer Linear Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Logistic Regression Calibration"
          ],
          "parameter_tuning": [
            "TF-IDF Scoring",
            "Window Size for PMI"
          ]
        },
        "feature_processing": [
          "Text Parsing",
          "N-gram Extraction",
          "Word Embeddings",
          "Lexical Entailment"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NY_Regents_Science_Exam_2016",
        "entity_type": "Dataset",
        "name": "NY Regents Science Exam",
        "description": "Multiple-choice science exam questions for 4th grade students",
        "domain": "Elementary Education",
        "size": 237,
        "year": 2016,
        "creators": [
          "New York State Education Department"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_IRSolver",
        "entity_type": "Algorithm",
        "name": "IR Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": [
          "Elementary Science Question Answering"
        ],
        "datasets": [
          "NY Regents Science Exam"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Lucene Search Engine"
          ],
          "connections": [],
          "mechanisms": [
            "Information Retrieval"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Query Construction",
          "Stopword Filtering"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_PMISolver",
        "entity_type": "Algorithm",
        "name": "PMI Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": [
          "Elementary Science Question Answering"
        ],
        "datasets": [
          "Web Corpus"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Pointwise Mutual Information Calculation"
          ],
          "connections": [],
          "mechanisms": [
            "Statistical Association"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Window Size for PMI"
          ]
        },
        "feature_processing": [
          "N-gram Extraction",
          "Stopword Filtering"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_SVMSolver",
        "entity_type": "Algorithm",
        "name": "SVM Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": [
          "Elementary Science Question Answering"
        ],
        "datasets": [
          "Elementary Science Corpus"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Support Vector Machine"
          ],
          "connections": [],
          "mechanisms": [
            "Word Embeddings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SVM Ranker"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Word Embedding Generation",
          "Cosine Similarity Calculation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_RULESolver",
        "entity_type": "Algorithm",
        "name": "RULE Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": [
          "Elementary Science Question Answering"
        ],
        "datasets": [
          "Elementary Science Corpus"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Probabilistic First-Order Logic Rules"
          ],
          "connections": [],
          "mechanisms": [
            "Rule-based Reasoning",
            "Lexical Entailment"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Text Parsing",
          "Syntactic Pattern Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_ILPSolver",
        "entity_type": "Algorithm",
        "name": "ILP Solver",
        "title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Peter Clark",
          "Oren Etzioni",
          "Tushar Khot",
          "Ashish Sabharwal",
          "Oyvind Tafjord",
          "Peter Turney",
          "Daniel Khashabi"
        ],
        "task": [
          "Elementary Science Question Answering"
        ],
        "datasets": [
          "Curated Tables"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming Model"
          ],
          "connections": [],
          "mechanisms": [
            "Structured Knowledge Representation",
            "Table Joins"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Table Construction",
          "Relation Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_BiLSTMClassifier",
        "entity_type": "Algorithm",
        "name": "BiLSTM Classifier",
        "title": "Data-Driven Methods for Solving Algebra Word Problems",
        "year": 2018,
        "authors": [
          "Robaidek, Benjamin",
          "Koncel-Kedziorski, Rik",
          "Hajishirzi, Hannaneh"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "DRAW",
          "MAWPS",
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "BiLSTM"
          ],
          "connections": [
            "Softmax"
          ],
          "mechanisms": [
            "Cross Entropy Loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_StructuredSelfAttention",
        "entity_type": "Algorithm",
        "name": "Structured Self-Attention",
        "title": "Data-Driven Methods for Solving Algebra Word Problems",
        "year": 2018,
        "authors": [
          "Robaidek, Benjamin",
          "Koncel-Kedziorski, Rik",
          "Hajishirzi, Hannaneh"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "DRAW",
          "MAWPS",
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "Multi-Hop Attention"
          ],
          "connections": [
            "Self-Attention"
          ],
          "mechanisms": [
            "Fixed Size Embedding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_Seq2Seq",
        "entity_type": "Algorithm",
        "name": "Seq2Seq Model",
        "title": "Data-Driven Methods for Solving Algebra Word Problems",
        "year": 2018,
        "authors": [
          "Robaidek, Benjamin",
          "Koncel-Kedziorski, Rik",
          "Hajishirzi, Hannaneh"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "DRAW",
          "MAWPS",
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "LSTM",
            "CNN"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DRAW_2015",
        "entity_type": "Dataset",
        "name": "DRAW",
        "description": "A diverse algebra word problem set",
        "domain": "Natural Language Processing",
        "size": 1000,
        "year": 2015,
        "creators": [
          "Upadhyay, Shyam",
          "Chang, Ming-Wei"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MAWPS_2016",
        "entity_type": "Dataset",
        "name": "MAWPS",
        "description": "Math Word Problem Repository",
        "domain": "Natural Language Processing",
        "size": 2373,
        "year": 2016,
        "creators": [
          "Koncel-Kedziorski, Rik",
          "Roy, Subhro",
          "Amini, Aida",
          "Kushman, Nate",
          "Hajishirzi, Hannaneh"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Math23K_2017",
        "entity_type": "Dataset",
        "name": "Math23K",
        "description": "Large dataset of Chinese algebra word problems",
        "domain": "Natural Language Processing",
        "size": 23164,
        "year": 2017,
        "creators": [
          "Wang, Yan",
          "Liu, Xiaojiang",
          "Shi, Shuming"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_RNNBasedSeq2SeqModel",
        "entity_type": "Algorithm",
        "name": "RNN-based Seq2Seq Model",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Yan",
          "Liu, Xiaojiang",
          "Shi, Shuming"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K",
          "Alg514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Word Embedding Layer",
            "GRU Encoder",
            "LSTM Decoder"
          ],
          "connections": [
            "GRU",
            "LSTM"
          ],
          "mechanisms": [
            "Gated Recurrent Unit",
            "Long Short-Term Memory"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_SignificantNumberIdentification",
        "entity_type": "Algorithm",
        "name": "Significant Number Identification (SNI)",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Yan",
          "Liu, Xiaojiang",
          "Shi, Shuming"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "LSTM"
          ],
          "connections": [
            "LSTM"
          ],
          "mechanisms": [
            "Long Short-Term Memory"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Binary Classification"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Context Window"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_HybridModel",
        "entity_type": "Algorithm",
        "name": "Hybrid Model",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Yan",
          "Liu, Xiaojiang",
          "Shi, Shuming"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K",
          "Alg514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Retrieval Model"
          ],
          "connections": [
            "Jaccard Similarity"
          ],
          "mechanisms": [
            "Threshold-based Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Tokenization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Alg514_2014",
        "entity_type": "Dataset",
        "name": "Alg514",
        "description": "A dataset of 514 linear algebra problems",
        "domain": "Natural Language Processing",
        "size": 514,
        "year": 2014,
        "creators": [
          "Kushman, Nate",
          "Artzi, Yoav",
          "Zettlemoyer, Luke",
          "Barzilay, Regina"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_G-ALIGNER",
        "entity_type": "Algorithm",
        "name": "G-ALIGNER",
        "title": "Diagram Understanding in Geometry Questions",
        "year": 2014,
        "authors": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ],
        "task": [
          "Diagram Understanding",
          "Geometry Question Solving"
        ],
        "datasets": [
          "Geometry Questions Dataset_2014"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Primitive Detection",
            "Alignment with Textual Mentions"
          ],
          "connections": [
            "Submodular Optimization",
            "Greedy Approximation"
          ],
          "mechanisms": [
            "Hough Transform",
            "Corner Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Submodular Function Maximization"
          ],
          "parameter_tuning": [
            "No Parameter Tuning Required"
          ]
        },
        "feature_processing": [
          "OCR for Label Positioning",
          "Textual Mention Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geometry_Questions_Dataset_2014",
        "entity_type": "Dataset",
        "name": "Geometry Questions Dataset",
        "description": "A dataset of high school plane geometry questions with textual descriptions and diagrams.",
        "domain": "Geometry",
        "size": 100,
        "year": 2014,
        "creators": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Identifying_Primitives",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Classification Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Aligning_Visual_Elements",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Alignment Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Watanabe1991_PBFDiagramUnderstandingFramework",
        "entity_type": "Algorithm",
        "name": "PBF Diagram Understanding Framework",
        "title": "Diagram Understanding Using Integration of Layout Information and Textual Information",
        "year": 1991,
        "authors": [
          "Yasuhiko Watanabe",
          "Makoto Nagao"
        ],
        "task": [
          "Diagram Understanding"
        ],
        "datasets": [
          "PBF Diagrams"
        ],
        "metrics": [
          "Accuracy",
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Layout Information Extraction",
            "Natural Language Information Extraction"
          ],
          "connections": [
            "Integration of Layout and Natural Language Information"
          ],
          "mechanisms": [
            "Semantic Interpretation Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pattern Matching",
            "Japanese Morphological Analysis"
          ],
          "parameter_tuning": [
            "Rule-based Classification"
          ]
        },
        "feature_processing": [
          "Symbol Detection",
          "Spatial Relationship Analysis",
          "Expression Pattern Matching"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PBF_Diagrams_1991",
        "entity_type": "Dataset",
        "name": "PBF Diagrams",
        "description": "Diagrams from Pictorial Books of Flora containing information about plant parts, types, properties, and species.",
        "domain": "Botany",
        "size": 31,
        "year": 1991,
        "creators": [
          "Yasuhiko Watanabe",
          "Makoto Nagao"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Success_Rate_Semantic_Analysis",
        "entity_type": "Metric",
        "name": "Success Rate",
        "description": "Rate of successful semantic interpretation of diagram elements.",
        "category": "Semantic Analysis Evaluation",
        "formula": "Successful Interpretations / Total Interpretations"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_DimensionallyGuidedSynthesis",
        "entity_type": "Algorithm",
        "name": "Dimensionally Guided Synthesis",
        "title": "Dimensionally Guided Synthesis of Mathematical Word Problems",
        "year": 2016,
        "authors": [
          "Ke Wang",
          "Zhendong Su"
        ],
        "task": [
          "Math Word Problem Generation"
        ],
        "datasets": [],
        "metrics": [
          "Statistical Indistinguishability",
          "Error Rate"
        ],
        "architecture": {
          "components": [
            "Equation Generator",
            "Narrative Generator"
          ],
          "connections": [
            "Binary Expression Tree",
            "Dimensional Units"
          ],
          "mechanisms": [
            "Dimensional Consistency",
            "Semantic Instantiation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Equation Synthesis",
            "Variable Unrolling"
          ],
          "parameter_tuning": [
            "SMT Solver",
            "Predefined Operational Rules"
          ]
        },
        "feature_processing": [
          "Keyword Assignment",
          "Numerical Value Generation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "StatisticalIndistinguishability_Authenticity",
        "entity_type": "Metric",
        "name": "Statistical Indistinguishability",
        "description": "Measure of whether generated problems are statistically indistinguishable from textbook problems",
        "category": "Authenticity Evaluation",
        "formula": "Paired t-test and Chi-square test of independence"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorRate_Difficulty",
        "entity_type": "Metric",
        "name": "Error Rate",
        "description": "Measure of the difficulty level of generated problems",
        "category": "Difficulty Evaluation",
        "formula": "Percentage of incorrect answers"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_SkipGram",
        "entity_type": "Algorithm",
        "name": "Skip-gram",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": [
          "Word Representation Learning",
          "Phrase Representation Learning"
        ],
        "datasets": [
          "News Articles Dataset"
        ],
        "metrics": [
          "Accuracy",
          "Syntactic Accuracy",
          "Semantic Accuracy"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Output Layer"
          ],
          "connections": [
            "Weight Matrices"
          ],
          "mechanisms": [
            "Negative Sampling",
            "Hierarchical Softmax"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of Frequent Words",
            "Negative Sampling",
            "Hierarchical Softmax"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Context Window Size",
            "Vector Dimensionality"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Subsampling of Frequent Words"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_HierarchicalSoftmax",
        "entity_type": "Algorithm",
        "name": "Hierarchical Softmax",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": [
          "Word Representation Learning"
        ],
        "datasets": [
          "News Articles Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary Tree",
            "Inner Nodes",
            "Leaf Nodes"
          ],
          "connections": [
            "Paths in Binary Tree"
          ],
          "mechanisms": [
            "Logarithmic Evaluation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Binary Huffman Tree"
          ],
          "parameter_tuning": [
            "Tree Structure"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_NegativeSampling",
        "entity_type": "Algorithm",
        "name": "Negative Sampling",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": [
          "Word Representation Learning"
        ],
        "datasets": [
          "News Articles Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Noise Distribution",
            "Target Word",
            "Negative Samples"
          ],
          "connections": [
            "Logistic Regression"
          ],
          "mechanisms": [
            "Log-Sigmoid Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Logistic Regression"
          ],
          "parameter_tuning": [
            "Number of Negative Samples"
          ]
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NewsArticlesDataset_2013",
        "entity_type": "Dataset",
        "name": "News Articles Dataset",
        "description": "A large dataset consisting of various news articles",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": 2013,
        "creators": [
          "Google Inc."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SyntacticAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Syntactic Accuracy",
        "description": "Accuracy on syntactic analogical reasoning",
        "category": "Classification Evaluation",
        "formula": "Correct Syntactic Analogies / Total Syntactic Analogies"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SemanticAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Semantic Accuracy",
        "description": "Accuracy on semantic analogical reasoning",
        "category": "Classification Evaluation",
        "formula": "Correct Semantic Analogies / Total Semantic Analogies"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_DEDUCOM",
        "entity_type": "Algorithm",
        "name": "DEDUCOM",
        "title": "Experiments with a Deductive Question-Answering Program",
        "year": 1965,
        "authors": [
          "James R. Slagle"
        ],
        "task": [
          "Deductive Question-Answering"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Fact Interpreter",
            "Question Reducer",
            "Search Procedure"
          ],
          "connections": [
            "Depth-First Search"
          ],
          "mechanisms": [
            "Predicate Calculus Deductions",
            "Logical Deductions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Heuristic Programming"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Fact Input Processing",
          "Question Parsing"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2016_ImplicitQuantityRelationExtractor",
        "entity_type": "Algorithm",
        "name": "Implicit Quantity Relation Extractor",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": 2016,
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Elementary school arithmetic application problem (People's Education Press, 2011)",
          "Suzhou Education Publishing House"
        ],
        "metrics": [
          "Classification Accuracy"
        ],
        "architecture": {
          "components": [
            "Chinese Phrase Parser",
            "SVM Classifier",
            "Instantiation Method"
          ],
          "connections": [
            "Semantic Models"
          ],
          "mechanisms": [
            "Sequence Alignment",
            "Map List Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SVM with Slack Variable",
            "Bag of Words"
          ],
          "parameter_tuning": [
            "Lagrange Multiplier",
            "Weight Number for Slack Variable"
          ]
        },
        "feature_processing": [
          "Chinese Phrase Parsing",
          "Normalization of Common Units"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ElementarySchoolArithmeticApplicationProblem_2011",
        "entity_type": "Dataset",
        "name": "Elementary school arithmetic application problem",
        "description": "Arithmetic word problems for elementary school students",
        "domain": "Education",
        "size": 627,
        "year": 2011,
        "creators": [
          "People's Education Press"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SuzhouEducationPublishingHouse_2016",
        "entity_type": "Dataset",
        "name": "Suzhou Education Publishing House",
        "description": "Arithmetic word problems for training",
        "domain": "Education",
        "year": 2016,
        "creators": [
          "Suzhou Education Publishing House"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_FrameBasedCalculus",
        "entity_type": "Algorithm",
        "name": "Frame-Based Calculus",
        "title": "Frame-Based Calculus of solving Arithmetic Multi-Step Addition and Subtraction word problems",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": [
          "Solving Multi-Step Addition and Subtraction Word Problems"
        ],
        "datasets": [
          "Chinese Elementary School Word Problems"
        ],
        "metrics": [
          "Correctness of Solution"
        ],
        "architecture": {
          "components": [
            "Problem Frames",
            "Production Rules"
          ],
          "connections": [
            "Means-end Analysis"
          ],
          "mechanisms": [
            "Frame Identification",
            "Working Memory",
            "Rule Base",
            "Executive Controlling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Means-end Analysis"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Natural Language Processing",
          "Semantic Frame Construction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ChineseElementarySchoolWordProblems_2010",
        "entity_type": "Dataset",
        "name": "Chinese Elementary School Word Problems",
        "description": "Word problems collected from Chinese elementary school textbooks",
        "domain": "Education",
        "size": "Not specified",
        "year": 2010,
        "creators": [
          "Peoples Education Press",
          "Beijing Normal University Press",
          "DONGBEI Normal University Press"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "CorrectnessOfSolution_ProblemSolving",
        "entity_type": "Metric",
        "name": "Correctness of Solution",
        "description": "Whether the multi-step addition and subtraction word problems are correctly solved",
        "category": "Problem Solving Evaluation",
        "formula": "Number of Correct Solutions / Total Number of Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "deMarneffe2006_TypedDependencyExtractor",
        "entity_type": "Algorithm",
        "name": "Typed Dependency Extractor",
        "title": "Generating Typed Dependency Parses from Phrase Structure Parses",
        "year": 2006,
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Dependency Extraction Rules"
          ],
          "connections": [
            "Head Identification Rules"
          ],
          "mechanisms": [
            "Collapsing Dependencies"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Statistical Parsing"
          ],
          "parameter_tuning": [
            "Collins Head Rules"
          ]
        },
        "feature_processing": [
          "Semantic Head Retrieval",
          "Dependency Typing"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreebank_1999",
        "entity_type": "Dataset",
        "name": "Penn Treebank",
        "description": "A widely used dataset for parsing English sentences.",
        "domain": "Natural Language Processing",
        "size": "Over 4.5 million words",
        "year": 1999,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "DependencyAccuracy_Classification",
        "entity_type": "Metric",
        "name": "Dependency Accuracy",
        "description": "Measures the accuracy of dependency relations in a parse.",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly parsed dependencies / Total dependencies"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collins1999_HeadDrivenStatisticalModel",
        "entity_type": "Algorithm",
        "name": "Head-Driven Statistical Model",
        "title": "Head-Driven Statistical Models for Natural Language Parsing",
        "year": 1999,
        "authors": [
          "Michael Collins"
        ],
        "task": [
          "Natural Language Parsing"
        ],
        "datasets": [
          "Penn Treebank"
        ],
        "metrics": [
          "Parsing Accuracy"
        ],
        "architecture": {
          "components": [
            "Statistical Models"
          ],
          "connections": [
            "Head Rules"
          ],
          "mechanisms": [
            "Probabilistic Context-Free Grammar"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Parameter Estimation"
          ]
        },
        "feature_processing": [
          "Syntactic Analysis"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Charniak2000_MaximumEntropyParser",
        "entity_type": "Algorithm",
        "name": "Maximum-Entropy Parser",
        "title": "A maximum-entropy-inspired parser",
        "year": 2000,
        "authors": [
          "Eugene Charniak"
        ],
        "task": [
          "Parsing"
        ],
        "datasets": [
          "Penn Treebank"
        ],
        "metrics": [
          "Parsing Accuracy"
        ],
        "architecture": {
          "components": [
            "Maximum Entropy Model"
          ],
          "connections": [
            "Feature Functions"
          ],
          "mechanisms": [
            "Log-linear Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Entropy Estimation"
          ],
          "parameter_tuning": [
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Feature Engineering"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin1998_MINIPAR",
        "entity_type": "Algorithm",
        "name": "MINIPAR",
        "title": "Dependency-based evaluation of MINIPAR",
        "year": 1998,
        "authors": [
          "Dekang Lin"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Dependency Parser"
          ],
          "connections": [
            "Dependency Relations"
          ],
          "mechanisms": [
            "Rule-Based Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based"
          ],
          "parameter_tuning": [
            "Dependency Rules"
          ]
        },
        "feature_processing": [
          "Dependency Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sleator1993_LinkParser",
        "entity_type": "Algorithm",
        "name": "Link Parser",
        "title": "Parsing English with a link grammar",
        "year": 1993,
        "authors": [
          "Daniel D. Sleator",
          "Davy Temperley"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Link Grammar"
          ],
          "connections": [
            "Link Relations"
          ],
          "mechanisms": [
            "Constraint-Based Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Constraint-Based"
          ],
          "parameter_tuning": [
            "Link Rules"
          ]
        },
        "feature_processing": [
          "Dependency Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Gelernter1959_GeometryMachine",
        "entity_type": "Algorithm",
        "name": "Geometry Machine",
        "year": 1959,
        "authors": [
          "Gelernter"
        ],
        "task": [
          "Geometry Theorem Proving"
        ],
        "methodology": {
          "training_strategy": [
            "Backward Chaining Search Strategy"
          ],
          "heuristic_knowledge": [
            "Use Diagram to Reject False Goal Statements"
          ]
        },
        "feature_processing": [
          "Specific Heuristic Knowledge about Geometry Domain"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "CeruttiDavis1969_FORMAC",
        "entity_type": "Algorithm",
        "name": "FORMAC",
        "year": 1969,
        "authors": [
          "Cerutti",
          "Davis"
        ],
        "task": [
          "Elementary Analytic Geometry Theorem Proving"
        ],
        "methodology": {
          "training_strategy": [
            "Symbolic Manipulation"
          ],
          "approach": [
            "Descartes' Method (Algebraic Approach)"
          ]
        },
        "feature_processing": [
          "Assign Coordinates to Points"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Efficiency_GeometryRuleApplications",
        "entity_type": "Metric",
        "name": "Efficiency",
        "description": "Efficiency of Geometry Rule Applications",
        "category": "Search Space Evaluation",
        "formula": "Number of Inferences per Layer"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1999_GeoRep",
        "entity_type": "Algorithm",
        "name": "GeoRep",
        "title": "GeoRep: A Flexible Tool for Spatial Representation of Line Drawings",
        "year": 1999,
        "authors": [
          "Ronald W. Ferguson",
          "Kenneth D. Forbus"
        ],
        "task": [
          "Spatial Representation",
          "Diagrammatic Reasoning"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Low-Level Relational Describer (LLRD)",
            "High-Level Relational Describer (HLRD)"
          ],
          "connections": [
            "Visual Operations Library",
            "Domain-Specific Rules"
          ],
          "mechanisms": [
            "Proximity Detection",
            "Reference Frame Relations",
            "Parallel Lines Detection",
            "Connectivity Detection",
            "Polygon and Polyline Detection",
            "Boundary Description",
            "Interval Relations",
            "Grouping"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Primitive Shape Detection",
          "Proximity Calculation",
          "Visual Relation Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1994_MAGI",
        "entity_type": "Algorithm",
        "name": "MAGI",
        "title": "MAGI: Analogy-based encoding using symmetry and regularity",
        "year": 1994,
        "authors": [
          "Ronald W. Ferguson"
        ],
        "task": [
          "Symmetry Detection",
          "Analogical Encoding"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Symmetry Detector",
            "Regular Pattern Recognizer"
          ],
          "connections": [
            "Visual Relation Integration"
          ],
          "mechanisms": [
            "Symmetry Judgment",
            "Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Shape Analysis",
          "Boundary Detection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1995_JUXTA",
        "entity_type": "Algorithm",
        "name": "JUXTA",
        "title": "Understanding illustrations of physical laws by integrating differences in visual and textual representations",
        "year": 1995,
        "authors": [
          "Ronald W. Ferguson",
          "Kenneth D. Forbus"
        ],
        "task": [
          "Diagram Understanding",
          "Critiquing Simplified Diagrams"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Visual Level Representation",
            "Physical Level Representation",
            "Process Level Representation"
          ],
          "connections": [
            "Visual Operation Library",
            "Domain-Specific Rules"
          ],
          "mechanisms": [
            "Difference Detection",
            "Caption Interpretation",
            "Contextual Analysis"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Visual Relation Detection",
          "Textual Analysis"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PolygonFigures_1996",
        "entity_type": "Dataset",
        "name": "Polygon Figures",
        "description": "Set of randomly-generated polygons used for symmetry detection experiments",
        "domain": "Symmetry Detection",
        "size": 240,
        "year": 1996,
        "creators": [
          "Ronald W. Ferguson",
          "Anna Aminoff",
          "Dedre Gentner"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_SymmetryJudgment",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of symmetry judgment in polygon figures",
        "category": "Symmetry Detection",
        "formula": "Correctly identified symmetric polygons / Total number of polygons"
      }
    },
    {
      "metric_entity": {
        "metric_id": "QualitativeFactors_SymmetryJudgment",
        "entity_type": "Metric",
        "name": "Qualitative Factors",
        "description": "Effect of qualitative visual structure on symmetry judgment",
        "category": "Symmetry Detection",
        "formula": "Significant effect of qualitative factors on accuracy"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_GloVe",
        "entity_type": "Algorithm",
        "name": "GloVe",
        "title": "GloVe: Global Vectors for Word Representation",
        "year": 2014,
        "authors": [
          "Jeffrey Pennington",
          "Richard Socher",
          "Christopher D. Manning"
        ],
        "task": [
          "Word Representation",
          "Word Analogy",
          "Word Similarity",
          "Named Entity Recognition"
        ],
        "datasets": [
          "Wikipedia 2010",
          "Wikipedia 2014",
          "Gigaword 5",
          "Gigaword 5 + Wikipedia 2014",
          "Common Crawl"
        ],
        "metrics": [
          "Accuracy",
          "Spearman Rank Correlation"
        ],
        "architecture": {
          "components": [
            "Global Log-Bilinear Regression Model",
            "Weighted Least Squares Model"
          ],
          "connections": [
            "Dot Product",
            "Bias Terms"
          ],
          "mechanisms": [
            "Co-occurrence Matrix Factorization",
            "Weighting Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "AdaGrad",
            "Stochastic Sampling"
          ],
          "parameter_tuning": [
            "xmax=100",
            "=3/4",
            "Initial Learning Rate=0.05"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Lowercasing",
          "Context Window Construction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Wikipedia_2010",
        "entity_type": "Dataset",
        "name": "Wikipedia 2010",
        "description": "A 2010 dump of Wikipedia with 1 billion tokens",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": 2010,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Wikipedia_2014",
        "entity_type": "Dataset",
        "name": "Wikipedia 2014",
        "description": "A 2014 dump of Wikipedia with 1.6 billion tokens",
        "domain": "Natural Language Processing",
        "size": 1600000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Gigaword_5",
        "entity_type": "Dataset",
        "name": "Gigaword 5",
        "description": "A dataset with 4.3 billion tokens",
        "domain": "Natural Language Processing",
        "size": 4300000000,
        "year": 2014,
        "creators": [
          "Various Sources"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Gigaword_5_Wikipedia_2014",
        "entity_type": "Dataset",
        "name": "Gigaword 5 + Wikipedia 2014",
        "description": "Combined dataset with 6 billion tokens",
        "domain": "Natural Language Processing",
        "size": 6000000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Common_Crawl",
        "entity_type": "Dataset",
        "name": "Common Crawl",
        "description": "Web data with 42 billion tokens",
        "domain": "Natural Language Processing",
        "size": 42000000000,
        "year": 2014,
        "creators": [
          "Common Crawl Foundation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_WordAnalogy",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy on the word analogy task",
        "category": "Word Analogy Evaluation",
        "formula": "Correct answers / Total questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpearmanRankCorrelation_WordSimilarity",
        "entity_type": "Metric",
        "name": "Spearman Rank Correlation",
        "description": "Spearman rank correlation on word similarity tasks",
        "category": "Word Similarity Evaluation",
        "formula": "Correlation between ranked word similarities and human judgments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_NER",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 score on the named entity recognition task",
        "category": "Named Entity Recognition Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_ZDC",
        "entity_type": "Algorithm",
        "name": "ZDC",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": 2015,
        "authors": [
          "Zhou",
          "Dai",
          "Chen"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Alg514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Improved Template-based Statistical Learning"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Reduced Search Space"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_SIM",
        "entity_type": "Algorithm",
        "name": "SIM",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": 2016,
        "authors": [
          "Huang",
          "Shi",
          "Lin",
          "Yin",
          "Ma"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Alg514",
          "SingleEQ",
          "Dolphin18K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Similarity-based Method"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Lexical Similarity Calculation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "TF-IDF",
          "Weighted Jaccard Similarity"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin1878_2015",
        "entity_type": "Dataset",
        "name": "Dolphin1878",
        "description": "A dataset of 1,878 number word problems",
        "domain": "Mathematics",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Shi",
          "Wang",
          "Lin",
          "Liu",
          "Rui"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SingleEQ_2015",
        "entity_type": "Dataset",
        "name": "SingleEQ",
        "description": "A dataset of 508 single equation problems",
        "domain": "Mathematics",
        "size": 508,
        "year": 2015,
        "creators": [
          "Koncel-Kedziorski",
          "Hajishirzi",
          "Sabharwal",
          "Etzioni",
          "Ang"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin18K_2016",
        "entity_type": "Dataset",
        "name": "Dolphin18K",
        "description": "A large-scale dataset of 18,460 annotated math word problems",
        "domain": "Mathematics",
        "size": 18460,
        "year": 2016,
        "creators": [
          "Huang",
          "Shi",
          "Lin",
          "Yin",
          "Ma"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ImageNet_2009",
        "entity_type": "Dataset",
        "name": "ImageNet",
        "description": "WordNet",
        "domain": "",
        "size": 3200000,
        "year": 2009,
        "creators": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Caltech101_2004",
        "entity_type": "Dataset",
        "name": "Caltech101",
        "description": "101",
        "domain": "",
        "size": 9146,
        "year": 2004,
        "creators": [
          "Fei-Fei, L.",
          "Fergus, R.",
          "Perona, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Caltech256_2007",
        "entity_type": "Dataset",
        "name": "Caltech256",
        "description": "256",
        "domain": "",
        "size": 30607,
        "year": 2007,
        "creators": [
          "Griffin, G.",
          "Holub, A.",
          "Perona, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MSRC_2006",
        "entity_type": "Dataset",
        "name": "MSRC",
        "description": "24",
        "domain": "",
        "size": 591,
        "year": 2006,
        "creators": [
          "Shotton, J.",
          "Winn, J.",
          "Rother, C.",
          "Criminisi, A."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PASCAL_2008",
        "entity_type": "Dataset",
        "name": "PASCAL",
        "description": "",
        "domain": "",
        "size": 2008,
        "year": 2008,
        "creators": [
          "Everingham, M.",
          "Van Gool, L.",
          "Williams, C. K. I.",
          "Winn, J.",
          "Zisserman, A."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "TinyImage_2008",
        "entity_type": "Dataset",
        "name": "TinyImage",
        "description": "8000",
        "domain": "",
        "size": 80000000,
        "year": 2008,
        "creators": [
          "Torralba, A.",
          "Fergus, R.",
          "Freeman, W."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ESP_2004",
        "entity_type": "Dataset",
        "name": "ESP",
        "description": "",
        "domain": "",
        "size": 60000,
        "year": 2004,
        "creators": [
          "von Ahn, L.",
          "Dabbish, L."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "LabelMe_2008",
        "entity_type": "Dataset",
        "name": "LabelMe",
        "description": "30000",
        "domain": "",
        "size": 30000,
        "year": 2008,
        "creators": [
          "Russell, B.",
          "Torralba, A.",
          "Murphy, K.",
          "Freeman, W."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "LotusHill_2007",
        "entity_type": "Dataset",
        "name": "Lotus Hill",
        "description": "50000",
        "domain": "",
        "size": 50000,
        "year": 2007,
        "creators": [
          "Yao, B.",
          "Yang, X.",
          "Zhu, S."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Classification",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "",
        "category": "",
        "formula": " /  + "
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Classification",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "",
        "category": "",
        "formula": " /  + "
      }
    },
    {
      "metric_entity": {
        "metric_id": "AUC_ROC",
        "entity_type": "Metric",
        "name": "AUC",
        "description": "ROC",
        "category": "",
        "formula": "ROC"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_TreeMaxClassifier",
        "entity_type": "Algorithm",
        "name": "Tree-Max Classifier",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": [
          "Object Classification"
        ],
        "datasets": [
          "ImageNet"
        ],
        "metrics": [
          "AUC"
        ],
        "architecture": {
          "components": [
            "AdaBoost-based Classifier"
          ],
          "connections": [
            "Hierarchical Structure"
          ],
          "mechanisms": [
            "Synset Nodes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Sampling"
          ],
          "parameter_tuning": [
            "AdaBoost"
          ]
        },
        "feature_processing": [
          "Image Descriptors"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_NonParametricObjectRecognition",
        "entity_type": "Algorithm",
        "name": "Non-Parametric Object Recognition",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": [
          "Object Recognition"
        ],
        "datasets": [
          "ImageNet",
          "Caltech256"
        ],
        "metrics": [
          "Accuracy",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Nearest Neighbor"
          ],
          "connections": [
            "Hierarchical Structure"
          ],
          "mechanisms": [
            "Synset Nodes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Sampling"
          ],
          "parameter_tuning": [
            "SSD Pixel Distance"
          ]
        },
        "feature_processing": [
          "Image Descriptors"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_AdaBoostBasedClassifier",
        "entity_type": "Algorithm",
        "name": "AdaBoost-based Classifier",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": 2009,
        "authors": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": [
          "Object Classification"
        ],
        "datasets": [
          "ImageNet"
        ],
        "metrics": [
          "AUC"
        ],
        "architecture": {
          "components": [
            "AdaBoost"
          ],
          "connections": [
            "Hierarchical Structure"
          ],
          "mechanisms": [
            "Synset Nodes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Sampling"
          ],
          "parameter_tuning": [
            "AdaBoost"
          ]
        },
        "feature_processing": [
          "Image Descriptors"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hajishirzi2013_NECO",
        "entity_type": "Algorithm",
        "name": "NECO",
        "title": "Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves",
        "year": 2013,
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": [
          "Coreference Resolution",
          "Named-Entity Linking"
        ],
        "datasets": [
          "ACE 2004 Newswire",
          "CoNLL 2011"
        ],
        "metrics": [
          "MUC",
          "B3",
          "Pairwise",
          "F1"
        ],
        "architecture": {
          "components": [
            "Sieve-based model",
            "NEL-informed sieves",
            "Mention detection",
            "Cluster merging"
          ],
          "connections": [
            "Coreference rules",
            "NEL constraints"
          ],
          "mechanisms": [
            "Automatic mention detection",
            "Entity link propagation",
            "Fine-grained attributes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic rules",
            "High precision sieves first"
          ],
          "parameter_tuning": [
            "Confidence thresholds for NEL systems"
          ]
        },
        "feature_processing": [
          "Mention pruning",
          "Attribute extraction from Freebase and Wikipedia"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004_NWIRE_2004",
        "entity_type": "Dataset",
        "name": "ACE 2004 Newswire",
        "description": "Newswire subset of the ACE 2004 corpus",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CONLL2011_2011",
        "entity_type": "Dataset",
        "name": "CoNLL 2011",
        "description": "Coreference dataset with text from five different domains",
        "domain": "Natural Language Processing",
        "size": 625,
        "year": 2011,
        "creators": [
          "Pradhan et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "B3_Coreference",
        "entity_type": "Metric",
        "name": "B3",
        "description": "Computes the proportion of intersection between predicted and gold clusters for every mention",
        "category": "Coreference evaluation",
        "formula": "Intersection over union of clusters"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_Coreference",
        "entity_type": "Metric",
        "name": "Pairwise",
        "description": "Measures the accuracy of predicting pairs of mentions as coreferent",
        "category": "Coreference evaluation",
        "formula": "Correctly predicted pairs / Total pairs"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_NEL",
        "entity_type": "Metric",
        "name": "F1",
        "description": "Harmonic mean of precision and recall",
        "category": "Named-entity linking evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_QuadraticProgrammingSolver",
        "entity_type": "Algorithm",
        "name": "Quadratic Programming Solver",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": [
          "Algebra Word Problem Solving"
        ],
        "datasets": [
          "Kushman2014_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Log-linear Model",
            "Quadratic Programming"
          ],
          "connections": [
            "Max-margin Objective"
          ],
          "mechanisms": [
            "Constraint Generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin Objective",
            "Quadratic Programming"
          ],
          "parameter_tuning": [
            "C Parameter"
          ]
        },
        "feature_processing": [
          "Single Slot Features",
          "Slot Pair Features",
          "Solution Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Kushman2014_Dataset_2014",
        "entity_type": "Dataset",
        "name": "Kushman2014 Dataset",
        "description": "Benchmark dataset for algebra word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_CombinedFeedbackPerceptron",
        "entity_type": "Algorithm",
        "name": "Combined Feedback Perceptron",
        "title": "Learning from Natural Instructions",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": [
          "Semantic Parsing",
          "Natural Language Instruction Interpretation"
        ],
        "datasets": [
          "Geoquery",
          "Solitaire Card Game Rules"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary Perceptron",
            "Structured Perceptron"
          ],
          "connections": [
            "Feature Function",
            "Weight Vector"
          ],
          "mechanisms": [
            "Loss Approximation",
            "Binary Update",
            "Structural Update"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-Driven Updates"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geoquery_1996",
        "entity_type": "Dataset",
        "name": "Geoquery",
        "description": "A dataset of geographical queries and their corresponding logical forms",
        "domain": "Natural Language Processing",
        "size": 500,
        "year": 1996,
        "creators": [
          "Zelle, J.",
          "Mooney, R."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SolitaireCardGameRules_2014",
        "entity_type": "Dataset",
        "name": "Solitaire Card Game Rules",
        "description": "Instructions and rules for various versions of the Solitaire card game",
        "domain": "Card Games",
        "size": "Varies",
        "year": 2014,
        "creators": [
          "Goldwasser, D.",
          "Roth, D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_StructuredPerceptron",
        "entity_type": "Algorithm",
        "name": "Structured Perceptron",
        "title": "Learning from Natural Instructions",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": [
          "Semantic Parsing"
        ],
        "datasets": [
          "Geoquery",
          "Solitaire Card Game Rules"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Feature Representation"
          ],
          "mechanisms": [
            "Structured Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-Driven Updates"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_BinaryPerceptron",
        "entity_type": "Algorithm",
        "name": "Binary Perceptron",
        "title": "Learning from Natural Instructions",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": [
          "Semantic Parsing"
        ],
        "datasets": [
          "Geoquery",
          "Solitaire Card Game Rules"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Feature Representation"
          ],
          "mechanisms": [
            "Binary Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-Driven Updates"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_LossApproximation",
        "entity_type": "Algorithm",
        "name": "Loss Approximation",
        "title": "Learning from Natural Instructions",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": [
          "Semantic Parsing"
        ],
        "datasets": [
          "Geoquery",
          "Solitaire Card Game Rules"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Feature Representation"
          ],
          "mechanisms": [
            "Loss Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-Driven Updates"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_RNNEncoderDecoder",
        "entity_type": "Algorithm",
        "name": "RNN EncoderDecoder",
        "title": "Learning Phrase Representations using RNN EncoderDecoder for Statistical Machine Translation",
        "year": 2014,
        "authors": [
          "Kyunghyun Cho",
          "Bart van Merrinboer",
          "Caglar Gulcehre",
          "Dzmitry Bahdanau",
          "Fethi Bougares",
          "Holger Schwenk",
          "Yoshua Bengio"
        ],
        "task": [
          "Statistical Machine Translation"
        ],
        "datasets": [
          "Europarl",
          "News Commentary",
          "UN",
          "Crawled Corpora"
        ],
        "metrics": [
          "BLEU"
        ],
        "architecture": {
          "components": [
            "Encoder RNN",
            "Decoder RNN"
          ],
          "connections": [
            "Conditional Probability"
          ],
          "mechanisms": [
            "Reset Gate",
            "Update Gate"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximize Conditional Log-Likelihood",
            "Gradient-Based Algorithm"
          ],
          "parameter_tuning": [
            "Adadelta",
            "Stochastic Gradient Descent"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Phrase Pair Scoring"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Europarl_2014",
        "entity_type": "Dataset",
        "name": "Europarl",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Natural Language Processing",
        "size": 61000000,
        "year": 2014,
        "creators": [
          "Philipp Koehn"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NewsCommentary_2014",
        "entity_type": "Dataset",
        "name": "News Commentary",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Natural Language Processing",
        "size": 5500000,
        "year": 2014,
        "creators": [
          "Philipp Koehn"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "UN_2014",
        "entity_type": "Dataset",
        "name": "UN",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Natural Language Processing",
        "size": 421000000,
        "year": 2014,
        "creators": [
          "Philipp Koehn"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CrawledCorpora_2014",
        "entity_type": "Dataset",
        "name": "Crawled Corpora",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Natural Language Processing",
        "size": 870000000,
        "year": 2014,
        "creators": [
          "Philipp Koehn"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_Translation",
        "entity_type": "Metric",
        "name": "BLEU",
        "description": "Bilingual Evaluation Understudy",
        "category": "Machine Translation Evaluation",
        "formula": "Exponential of the weighted sum of modified n-gram precision and brevity penalty"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_EquationSystemSolver",
        "entity_type": "Algorithm",
        "name": "Equation System Solver",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": [
          "Algebra Word Problem Solving"
        ],
        "datasets": [
          "Algebra.com Dataset"
        ],
        "metrics": [
          "Equation Accuracy",
          "Answer Accuracy"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Log-linear Distribution",
            "Beam Search"
          ],
          "connections": [
            "Alignment between Equations and Text"
          ],
          "mechanisms": [
            "Latent Variable Modeling",
            "Marginal Data Log-Likelihood Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Weak Supervision",
            "L-BFGS Optimization"
          ],
          "parameter_tuning": [
            "L2 Regularization"
          ]
        },
        "feature_processing": [
          "Part-of-Speech Tagging",
          "Lematization",
          "Dependency Parsing",
          "Canonicalization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Algebra.com_Dataset_2014",
        "entity_type": "Dataset",
        "name": "Algebra.com Dataset",
        "description": "A dataset of algebra word problems collected from Algebra.com",
        "domain": "Natural Language Processing, Algebra",
        "size": 514,
        "year": 2014,
        "creators": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Equation_Accuracy",
        "entity_type": "Metric",
        "name": "Equation Accuracy",
        "description": "Measures how often the system generates the correct equation system",
        "category": "Equation Generation",
        "formula": "Number of Correct Equation Systems / Total Number of Equation Systems"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Answer_Accuracy",
        "entity_type": "Metric",
        "name": "Answer Accuracy",
        "description": "Evaluates how often the generated numerical answer is correct",
        "category": "Numerical Answer Evaluation",
        "formula": "Number of Correct Answers / Total Number of Answers"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_ARIS",
        "entity_type": "Algorithm",
        "name": "ARIS",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": 2014,
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Entity Recognition",
            "Container Identification",
            "Verb Categorization",
            "State Transition Modeling",
            "Equation Formation"
          ],
          "connections": [
            "Dependency Parsing",
            "Coreference Resolution"
          ],
          "mechanisms": [
            "Support Vector Machines",
            "Circumscription Assumption"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-validation",
            "Feature Extraction"
          ],
          "parameter_tuning": [
            "Regularization",
            "Similarity-based Feature Selection"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Coreference Resolution",
          "Named Entity Recognition"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_FormulaBasedSolver",
        "entity_type": "Algorithm",
        "name": "Formula-Based Solver",
        "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
        "year": 2016,
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Variable Identification",
            "Formula Recognition",
            "Equation Generation"
          ],
          "connections": [
            "Part-Whole",
            "Change",
            "Comparison"
          ],
          "mechanisms": [
            "Log-linear Model",
            "Feature Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Parameter Vector "
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Machine Readable Dictionaries",
          "Semantic Relations Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AddSub_2014",
        "entity_type": "Dataset",
        "name": "AddSub",
        "description": "A dataset of simple addition-subtraction arithmetic problems for third, fourth, and fifth graders.",
        "domain": "Natural Language Processing",
        "size": 395,
        "year": 2014,
        "creators": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_LongShortTermMemory",
        "entity_type": "Algorithm",
        "name": "Long Short-Term Memory (LSTM)",
        "title": "Long Short-Term Memory",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jrgen Schmidhuber"
        ],
        "task": [
          "Sequence Modeling",
          "Long Time Lag Problems"
        ],
        "datasets": [],
        "metrics": [
          "Success Rate",
          "Training Time"
        ],
        "architecture": {
          "components": [
            "Memory Cells",
            "Input Gates",
            "Output Gates",
            "Constant Error Carousels (CECs)"
          ],
          "connections": [
            "Fully Connected Hidden Layer",
            "Self-Connections"
          ],
          "mechanisms": [
            "Multiplicative Gates",
            "Truncated Backpropagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated Backpropagation Through Time",
            "Real-Time Recurrent Learning (RTRL)"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Bias Initialization"
          ]
        },
        "feature_processing": [
          "Local Input/Output Representations",
          "Distributed Representations"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_ConstantErrorFlow",
        "entity_type": "Algorithm",
        "name": "Constant Error Flow",
        "title": "Long Short-Term Memory",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jrgen Schmidhuber"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Error Signal Stability"
        ],
        "architecture": {
          "components": [
            "Single Unit with Self-Connection"
          ],
          "connections": [
            "Self-Connection"
          ],
          "mechanisms": [
            "Fixed Time Constants"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Naive Approach"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_RecurrentCascadeCorrelation",
        "entity_type": "Algorithm",
        "name": "Recurrent Cascade-Correlation",
        "title": "Long Short-Term Memory",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jrgen Schmidhuber"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Hidden Units",
            "Output Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Incremental Network Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Sequential Network Construction"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_BackPropagationThroughTime",
        "entity_type": "Algorithm",
        "name": "Back-Propagation Through Time (BPTT)",
        "title": "Long Short-Term Memory",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jrgen Schmidhuber"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Error Signal Stability"
        ],
        "architecture": {
          "components": [
            "Hidden Units",
            "Output Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Gradient-Based Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Full Backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_RealTimeRecurrentLearning",
        "entity_type": "Algorithm",
        "name": "Real-Time Recurrent Learning (RTRL)",
        "title": "Long Short-Term Memory",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jrgen Schmidhuber"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Error Signal Stability"
        ],
        "architecture": {
          "components": [
            "Hidden Units",
            "Output Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Gradient-Based Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_ElmanNets",
        "entity_type": "Algorithm",
        "name": "Elman Nets",
        "title": "Long Short-Term Memory",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jrgen Schmidhuber"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Hidden Units",
            "Output Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Gradient-Based Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Elman's Training Procedure"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_NeuralSequenceChunker",
        "entity_type": "Algorithm",
        "name": "Neural Sequence Chunker",
        "title": "Long Short-Term Memory",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jrgen Schmidhuber"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Two Networks"
          ],
          "connections": [
            "Inter-Network Connections"
          ],
          "mechanisms": [
            "Chunking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Chunking"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "EmbeddedReberGrammar_1997",
        "entity_type": "Dataset",
        "name": "Embedded Reber Grammar",
        "description": "A synthetic dataset for evaluating sequence modeling algorithms.",
        "domain": "Natural Language Processing",
        "size": 512,
        "year": 1997,
        "creators": [
          "Sepp Hochreiter",
          "Jrgen Schmidhuber"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SuccessRate_Classification",
        "entity_type": "Metric",
        "name": "Success Rate",
        "description": "Percentage of successful trials in classification tasks.",
        "category": "Classification Evaluation",
        "formula": "Number of successful trials / Total number of trials"
      }
    },
    {
      "metric_entity": {
        "metric_id": "TrainingTime_Performance",
        "entity_type": "Metric",
        "name": "Training Time",
        "description": "Time required to train the model successfully.",
        "category": "Performance Evaluation",
        "formula": "Total time taken to achieve stopping criterion"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorSignalStability_ErrorFlow",
        "entity_type": "Metric",
        "name": "Error Signal Stability",
        "description": "Stability of error signals over time.",
        "category": "Error Flow Evaluation",
        "formula": "Magnitude of error signals over time"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goyal2016_DeepLSTM",
        "entity_type": "Algorithm",
        "name": "Deeper LSTM Question + norm Image",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": 2016,
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "Visual Question Answering",
        "datasets": [
          "VQA v2.0"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "CNN embedding",
            "LSTM embedding",
            "Point-wise multiplication",
            "Multi-layer perceptron classifier"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lu2016_HierarchicalCoAttention",
        "entity_type": "Algorithm",
        "name": "Hierarchical Co-attention",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": 2016,
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "Visual Question Answering",
        "datasets": [
          "VQA v2.0"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Word-level attention",
            "Phrase-level attention",
            "Entire question-level attention"
          ],
          "connections": [
            "Co-attention mechanism"
          ],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fukui2016_MultimodalCompactBilinearPooling",
        "entity_type": "Algorithm",
        "name": "Multimodal Compact Bilinear Pooling",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": 2016,
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "Visual Question Answering",
        "datasets": [
          "VQA v2.0"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Multimodal compact bilinear pooling"
          ],
          "connections": [
            "Image features",
            "Language features"
          ],
          "mechanisms": [
            "Fully-connected layer"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "VQA_v2.0_2016",
        "entity_type": "Dataset",
        "name": "VQA v2.0",
        "description": "Balanced Visual Question Answering dataset with complementary images",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 1100000,
        "year": 2016,
        "creators": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "COCO_2014",
        "entity_type": "Dataset",
        "name": "COCO",
        "description": "Common Objects in Context dataset",
        "domain": "Computer Vision",
        "size": 204000,
        "year": 2014,
        "creators": [
          "T.-Y. Lin",
          "M. Maire",
          "S. Belongie",
          "J. Hays",
          "P. Perona",
          "D. Ramanan",
          "P. Dollar",
          "C. L. Zitnick"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_VQA",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correctly answered questions",
        "category": "Classification",
        "formula": "Correctly classified samples / Total samples"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Entropy_AnswerDistribution",
        "entity_type": "Metric",
        "name": "Entropy",
        "description": "Measure of uncertainty in the answer distribution",
        "category": "Distribution Analysis",
        "formula": "-sum(p(x) * log(p(x)))"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_KNOWLEDGE",
        "entity_type": "Algorithm",
        "name": "KNOWLEDGE",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": 2018,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl",
          "Perturb",
          "Aggregate"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Concept Selection",
            "Declarative Rule Selection"
          ],
          "connections": [
            "Latent Variable Modeling"
          ],
          "mechanisms": [
            "Transfer",
            "Dimensional Analysis",
            "Part-Whole Relation",
            "Explicit Math"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Structured SVM",
            "Two Stage Learning"
          ],
          "parameter_tuning": [
            "Beam Search"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Coreference Resolution",
          "Verb Classification",
          "Rate Component Detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArith_2018",
        "entity_type": "Dataset",
        "name": "AllArith",
        "description": "Arithmetic word problem dataset",
        "domain": "Mathematics",
        "size": 831,
        "year": 2018,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithLex_2018",
        "entity_type": "Dataset",
        "name": "AllArithLex",
        "description": "Subset of AllArith for testing robustness to new vocabulary",
        "domain": "Mathematics",
        "size": 831,
        "year": 2018,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithTmpl_2018",
        "entity_type": "Dataset",
        "name": "AllArithTmpl",
        "description": "Subset of AllArith for testing robustness to new equation forms",
        "domain": "Mathematics",
        "size": 831,
        "year": 2018,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Perturb_2018",
        "entity_type": "Dataset",
        "name": "Perturb",
        "description": "New word problems created by perturbing original problems",
        "domain": "Mathematics",
        "size": 661,
        "year": 2018,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Aggregate_2018",
        "entity_type": "Dataset",
        "name": "Aggregate",
        "description": "Combined dataset of AllArith and Perturb",
        "domain": "Mathematics",
        "size": 1492,
        "year": 2018,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_MathDQN",
        "entity_type": "Algorithm",
        "name": "MathDQN",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "AI2",
          "IL",
          "CC",
          "ArithS",
          "ArithM"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Deep Q-Network",
            "Feed-Forward Neural Network"
          ],
          "connections": [
            "Two-layer Feed-Forward Neural Network"
          ],
          "mechanisms": [
            "Reinforcement Learning",
            "Deep Q-Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "-greedy Strategy",
            "Mini-Batch Gradient Descent",
            "Experience Replay"
          ],
          "parameter_tuning": [
            "Discount Factor =0.9",
            "Learning Rate 0.0001",
            "Replay Memory Size 15,000"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Feature Concatenation",
          "Re-order Mechanism"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AI2_2014",
        "entity_type": "Dataset",
        "name": "AI2",
        "description": "Single-step and multi-step arithmetic word problems involving addition and subtraction",
        "domain": "Arithmetic Word Problems",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IL_2015",
        "entity_type": "Dataset",
        "name": "IL",
        "description": "Single-step word problems with one operator (addition, subtraction, multiplication, division)",
        "domain": "Arithmetic Word Problems",
        "size": 562,
        "year": 2015,
        "creators": [
          "Roy, Vieira, and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CC_2015",
        "entity_type": "Dataset",
        "name": "CC",
        "description": "Multi-step problems without irrelevant quantities, involving combinations of four types of operators",
        "domain": "Arithmetic Word Problems",
        "size": 600,
        "year": 2015,
        "creators": [
          "Roy and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ArithS_2018",
        "entity_type": "Dataset",
        "name": "ArithS",
        "description": "Subset of single-step arithmetic problems involving only one operator",
        "domain": "Arithmetic Word Problems",
        "size": 890,
        "year": 2018,
        "creators": [
          "Wang et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ArithM_2018",
        "entity_type": "Dataset",
        "name": "ArithM",
        "description": "Subset of multi-step arithmetic problems involving at least two operators",
        "domain": "Arithmetic Word Problems",
        "size": 667,
        "year": 2018,
        "creators": [
          "Wang et al."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2016_MultiTaskSeq2Seq",
        "entity_type": "Algorithm",
        "name": "Multi-task Sequence to Sequence Learning",
        "title": "MULTI-TASK SEQUENCE TO SEQUENCE LEARNING",
        "year": 2016,
        "authors": [
          "Minh-Thang Luong",
          "Quoc V. Le",
          "Ilya Sutskever",
          "Oriol Vinyals",
          "Lukasz Kaiser"
        ],
        "task": [
          "Machine Translation",
          "Constituency Parsing",
          "Image Caption Generation"
        ],
        "datasets": [
          "WMT'15 English-German Translation",
          "Penn Tree Bank Parsing",
          "High-Confidence Corpus Parsing",
          "Image Captioning Dataset"
        ],
        "metrics": [
          "BLEU",
          "F1 Score",
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "One-to-Many",
            "Many-to-One",
            "Many-to-Many"
          ],
          "mechanisms": [
            "Recurrent Neural Networks",
            "Long Short-Term Memory (LSTM)",
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Parameter Updates Allocation"
          ],
          "parameter_tuning": [
            "SGD",
            "Learning Rate Adjustment"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Embeddings Initialization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT15_EnglishGermanTranslation_2015",
        "entity_type": "Dataset",
        "name": "WMT'15 English-German Translation",
        "description": "Parallel corpus for English-German translation",
        "domain": "Machine Translation",
        "size": 4500000,
        "year": 2015,
        "creators": [
          "Bojar et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreeBankParsing_1993",
        "entity_type": "Dataset",
        "name": "Penn Tree Bank Parsing",
        "description": "Corpus for syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 40000,
        "year": 1993,
        "creators": [
          "Marcus et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "HighConfidenceCorpusParsing_2015",
        "entity_type": "Dataset",
        "name": "High-Confidence Corpus Parsing",
        "description": "Large corpus for syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 11000000,
        "year": 2015,
        "creators": [
          "Vinyals et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ImageCaptioningDataset_2015",
        "entity_type": "Dataset",
        "name": "Image Captioning Dataset",
        "description": "Dataset of image-caption pairs",
        "domain": "Computer Vision",
        "size": 596000,
        "year": 2015,
        "creators": [
          "Vinyals et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1Score_Parsing",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Parsing Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Perplexity_LanguageModeling",
        "entity_type": "Metric",
        "name": "Perplexity",
        "description": "Measure of how well a probability distribution predicts a sample",
        "category": "Language Modeling Evaluation",
        "formula": "exp(-1/N * sum(log p(x_i))"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sundaram2015_WordProblemSolver",
        "entity_type": "Algorithm",
        "name": "Word Problem Solver",
        "title": "Natural Language Processing for Solving Simple Word Problems",
        "year": 2015,
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Hosseini2014_DS1",
          "Hosseini2014_DS2",
          "Hosseini2014_DS3"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Simplification Phase",
            "Analysis Phase",
            "Knowledge Representation",
            "Temporal Schemas"
          ],
          "connections": [
            "Dependency Parsing",
            "Co-reference Resolution",
            "Conjunction Resolution"
          ],
          "mechanisms": [
            "Stanford CoreNLP Suite",
            "Common Sense Law of Inertia"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Conjunction Resolution",
          "Co-reference Resolution",
          "Entity Resolution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Hosseini2014_DS1",
        "entity_type": "Dataset",
        "name": "DS1",
        "description": "Dataset with simple word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Hosseini2014_DS2",
        "entity_type": "Dataset",
        "name": "DS2",
        "description": "Dataset with moderate complexity word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Hosseini2014_DS3",
        "entity_type": "Dataset",
        "name": "DS3",
        "description": "Dataset with complex word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2018_CASS",
        "entity_type": "Algorithm",
        "name": "CASS (Copy and Alignment Sequence-to-Sequence)",
        "title": "Neural Math Word Problem Solver with Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Danqing Huang",
          "Jing Liu",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Copy Mechanism",
            "Alignment Mechanism"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "Gated Recurrent Unit (GRU)",
            "Policy Gradient"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning",
            "Policy Gradient",
            "Pre-training with Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "SGD Optimizer",
            "Decaying Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Tokenization",
          "Post-processing for Number Recovery"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NumWord_2015",
        "entity_type": "Dataset",
        "name": "NumWord",
        "description": "Contains 2,871 number word problems with 1,183 templates",
        "domain": "Mathematics",
        "size": 2871,
        "year": 2015,
        "creators": [
          "Shi et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Solution_Accuracy",
        "entity_type": "Metric",
        "name": "Solution Accuracy",
        "description": "Accuracy of the final solution to the math word problem",
        "category": "Math Word Problem Solving Evaluation",
        "formula": "Number of correctly solved problems / Total number of problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_Seq2SeqAttn",
        "entity_type": "Algorithm",
        "name": "Seq2SeqAttn",
        "title": "Deep Neural Model for Math Word Problem Solving",
        "year": 2017,
        "authors": [
          "Yan Wang",
          "Xiaojiang Liu",
          "Shuming Shi"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "Gated Recurrent Unit (GRU)"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "SGD Optimizer"
          ]
        },
        "feature_processing": [
          "Number Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2017_FeatureBasedModel",
        "entity_type": "Algorithm",
        "name": "Feature-Based Model",
        "title": "Learning Fine-Grained Expressions to Solve Math Word Problems",
        "year": 2017,
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Retrieval",
            "Equation Ranking"
          ],
          "connections": [
            "Feature Vectors"
          ],
          "mechanisms": [
            "Ranking Algorithms"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Engineering"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_ALGES",
        "entity_type": "Algorithm",
        "name": "ALGES",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": [
          "Algebraic Word Problem Solving"
        ],
        "datasets": [
          "SINGLEEQ"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming (ILP)",
            "Local Discriminative Models",
            "Global Discriminative Models"
          ],
          "connections": [
            "Equation Tree Generation",
            "Bottom-Up Scoring"
          ],
          "mechanisms": [
            "Quantified Sets (Qsets)",
            "Reordering Rules",
            "Feature Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision",
            "Discriminative Models"
          ],
          "parameter_tuning": [
            "LIBSVM with RBF Kernel"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Qset Reordering",
          "Semantic Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SINGLEEQ_2015",
        "entity_type": "Dataset",
        "name": "SINGLEEQ",
        "description": "Grade-school algebra word problems that map to single equations",
        "domain": "Natural Language Processing",
        "size": 508,
        "year": 2015,
        "creators": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_VerbCategorization",
        "entity_type": "Algorithm",
        "name": "Verb Categorization",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": 2014,
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "ADDSUB"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Verb Categories",
            "Semantic Parsing"
          ],
          "connections": [
            "Rule-Based Filtering"
          ],
          "mechanisms": [
            "Dependency Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dependency Parsing",
          "Rule-Based Filtering"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ADDSUB_2014",
        "entity_type": "Dataset",
        "name": "ADDSUB",
        "description": "Addition and subtraction word problems with irrelevant distractor quantities",
        "domain": "Natural Language Processing",
        "size": "Not specified",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TemplateBased",
        "entity_type": "Algorithm",
        "name": "Template-Based Method",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": [
          "Algebraic Word Problem Solving"
        ],
        "datasets": [
          "SINGLEEQ"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Global and Local Features"
          ],
          "connections": [
            "Template Matching"
          ],
          "mechanisms": [
            "Dependency Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Fully Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dependency Parsing",
          "Template Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_CompositionalVectorGrammar",
        "entity_type": "Algorithm",
        "name": "Compositional Vector Grammar (CVG)",
        "title": "Parsing with Compositional Vector Grammars",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": [
          "Syntactic Parsing"
        ],
        "datasets": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "Labeled F1 Score"
        ],
        "architecture": {
          "components": [
            "Probabilistic Context-Free Grammar (PCFG)",
            "Recursive Neural Network (RNN)",
            "Syntactically Untied Recursive Neural Network (SU-RNN)"
          ],
          "connections": [
            "Composition Function",
            "Parent-Child Relationships"
          ],
          "mechanisms": [
            "Continuous Vector Representations",
            "Syntactic Categories"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Training Objective",
            "Backpropagation Through Structure (BTS)",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Regularization",
            "Mini-batch Size",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreebank_WSJ_2013",
        "entity_type": "Dataset",
        "name": "Penn Treebank WSJ",
        "description": "Wall Street Journal section of the Penn Treebank",
        "domain": "Natural Language Processing",
        "size": "Varies by section",
        "year": 2013,
        "creators": [
          "Various contributors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Labeled_F1_Score_Parsing",
        "entity_type": "Metric",
        "name": "Labeled F1 Score",
        "description": "F1 score for labeled syntactic parsing",
        "category": "Syntactic Parsing Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_StandardRecursiveNeuralNetwork",
        "entity_type": "Algorithm",
        "name": "Standard Recursive Neural Network (RNN)",
        "title": "Parsing with Compositional Vector Grammars",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": [
          "Syntactic Parsing"
        ],
        "datasets": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "Labeled F1 Score"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Composition Function"
          ],
          "connections": [
            "Parent-Child Relationships"
          ],
          "mechanisms": [
            "Continuous Vector Representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Training Objective"
          ],
          "parameter_tuning": [
            "Regularization"
          ]
        },
        "feature_processing": [
          "Word Vector Representations"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_SyntacticallyUntiedRecursiveNeuralNetwork",
        "entity_type": "Algorithm",
        "name": "Syntactically Untied Recursive Neural Network (SU-RNN)",
        "title": "Parsing with Compositional Vector Grammars",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": [
          "Syntactic Parsing"
        ],
        "datasets": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "Labeled F1 Score"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Composition Function"
          ],
          "connections": [
            "Parent-Child Relationships"
          ],
          "mechanisms": [
            "Continuous Vector Representations",
            "Syntactic Categories"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Training Objective",
            "Backpropagation Through Structure (BTS)",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Regularization",
            "Mini-batch Size",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_QuantityExtraction",
        "entity_type": "Algorithm",
        "name": "QuantityExtraction",
        "title": "Reasoning about Quantities in Natural Language",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": [
          "Quantity Recognition",
          "Quantity Standardization"
        ],
        "datasets": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Segmentation",
            "Standardization"
          ],
          "connections": [
            "Semi-CRF",
            "Bank of Classifiers"
          ],
          "mechanisms": [
            "Parameter Averaging",
            "Perceptron Algorithm"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "Semi-CRF",
            "Bank of Classifiers"
          ]
        },
        "feature_processing": [
          "Word Class Features",
          "Character-based Features",
          "Part of Speech Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_QuantityEntailment",
        "entity_type": "Algorithm",
        "name": "QuantityEntailment",
        "title": "Reasoning about Quantities in Natural Language",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": [
          "Quantity Entailment"
        ],
        "datasets": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Extraction Phase",
            "Reasoning Phase"
          ],
          "connections": [
            "Implicit Quantity Productions",
            "Quantity Comparisons"
          ],
          "mechanisms": [
            "Monotonicity Verification",
            "Coreference Resolution",
            "Semantic Role Labeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based Standardization",
            "Coreference Resolution",
            "Semantic Role Labeling"
          ],
          "parameter_tuning": [
            "Monotonicity Verification",
            "Coreference Resolution",
            "Semantic Role Labeling"
          ]
        },
        "feature_processing": [
          "WordNet Synsets",
          "POS Tags",
          "Contextual Cues"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_MathWordProblemSolver",
        "entity_type": "Algorithm",
        "name": "MathWordProblemSolver",
        "title": "Reasoning about Quantities in Natural Language",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Elementary Math Word Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quantity Pair Classifier",
            "Operation Classifier",
            "Order Classifier"
          ],
          "connections": [
            "Cascade of Classifiers"
          ],
          "mechanisms": [
            "Sparse Averaged Perceptron"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gold Annotations"
          ],
          "parameter_tuning": [
            "Feature Engineering"
          ]
        },
        "feature_processing": [
          "Unigrams and Bigrams",
          "POS Tags",
          "Quantity Units Matching"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "RTE_Datasets_2006",
        "entity_type": "Dataset",
        "name": "RTE Datasets",
        "description": "Textual Entailment datasets from RTE2 to RTE4",
        "domain": "Natural Language Processing",
        "size": 384,
        "year": 2006,
        "creators": [
          "Dagan, I.",
          "Glickman, O.",
          "Magnini, B."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Newswire_Text_2015",
        "entity_type": "Dataset",
        "name": "Newswire Text",
        "description": "600 sentences of newswire text containing quantity mentions",
        "domain": "Natural Language Processing",
        "size": 600,
        "year": 2015,
        "creators": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Elementary_Math_Word_Problems_2015",
        "entity_type": "Dataset",
        "name": "Elementary Math Word Problems",
        "description": "Elementary school math word problems",
        "domain": "Education",
        "size": 500,
        "year": 2015,
        "creators": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Quantitative_Reasoning",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Quantitative Reasoning",
        "formula": "2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Quantitative_Reasoning",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Proportion of true positive predictions",
        "category": "Quantitative Reasoning",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Quantitative_Reasoning",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Proportion of actual positives that are correctly identified",
        "category": "Quantitative Reasoning",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Math_Word_Problems",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correct answers",
        "category": "Math Word Problem Solving",
        "formula": "Correct Answers / Total Questions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jung2004_WindowedHoughTransform",
        "entity_type": "Algorithm",
        "name": "Windowed Hough Transform",
        "title": "Rectangle Detection based on a Windowed Hough Transform",
        "year": 2004,
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": [
          "Rectangle Detection"
        ],
        "datasets": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Sliding Window",
            "Hough Transform",
            "Peak Detection"
          ],
          "connections": [
            "Geometric Constraints"
          ],
          "mechanisms": [
            "Butterfly Pattern Analysis"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "T",
            "T",
            "TL",
            "T"
          ]
        },
        "feature_processing": [
          "Edge Detection",
          "Canny Operator"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhu2003_RectangularHoughTransform",
        "entity_type": "Algorithm",
        "name": "Rectangular Hough Transform (RHT)",
        "title": "Automatic Particle Detection through Efficient Hough Transforms",
        "year": 2003,
        "authors": [
          "Y. Zhu",
          "B. Carragher",
          "F. Mouche",
          "C. Potter"
        ],
        "task": [
          "Particle Detection"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "2D Accumulator Array"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lagunovsky1999_StraightLineExtraction",
        "entity_type": "Algorithm",
        "name": "Straight-line-based Primitive Extraction",
        "title": "Straight-line-based Primitive Extraction in Grey-scale Object Recognition",
        "year": 1999,
        "authors": [
          "D. Lagunovsky",
          "S. Ablameyko"
        ],
        "task": [
          "Primitive Extraction"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Linear Primitives",
            "Grouping"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin1998_BuildingDetection",
        "entity_type": "Algorithm",
        "name": "Building Detection and Description",
        "title": "Building Detection and Description from a Single Intensity Image",
        "year": 1998,
        "authors": [
          "C. Lin",
          "R. Nevatia"
        ],
        "task": [
          "Building Detection"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Line Detection",
            "Anti-parallel Lines"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Tao2002_RectangleBuildingExtraction",
        "entity_type": "Algorithm",
        "name": "Rectangle Building Extraction",
        "title": "A New Approach to Extract Rectangle Building from Aerial Urban Images",
        "year": 2002,
        "authors": [
          "W.-B. Tao",
          "J.-W. Tian",
          "J. Liu"
        ],
        "task": [
          "Building Extraction"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Edge Elements",
            "Linear Elements"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Detection",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Detection accuracy",
        "category": "Detection Evaluation",
        "formula": "Correct detections / Total detections"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_ROBUST",
        "entity_type": "Algorithm",
        "name": "ROBUST",
        "title": "ROBUST UNDERSTANDING OF WORD PROBLEMS WITH EXTRANEOUS INFORMATION",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": [
          "Understanding Arithmetic Word Problems with Extraneous Information"
        ],
        "datasets": [
          "Custom Word Problems"
        ],
        "metrics": [
          "Correct Solution Rate"
        ],
        "architecture": {
          "components": [
            "Change Schema Recognition",
            "Formula Instantiation",
            "Schema Instantiation"
          ],
          "connections": [
            "Change Verbs Categorization",
            "Natural Language Parsing"
          ],
          "mechanisms": [
            "Cautious Strategy for Schema Instantiation Creation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None (Rule-Based System)"
          ],
          "parameter_tuning": [
            "None (Rule-Based System)"
          ]
        },
        "feature_processing": [
          "Parsing Natural Language Sentences",
          "Identifying Change Verbs"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Custom_Word_Problems_2023",
        "entity_type": "Dataset",
        "name": "Custom Word Problems",
        "description": "A collection of multi-step arithmetic word problems with extraneous information.",
        "domain": "Arithmetic Problem Solving",
        "size": "Not specified",
        "year": 2023,
        "creators": [
          "Bakman, Y."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Correct_Solution_Rate_Understanding",
        "entity_type": "Metric",
        "name": "Correct Solution Rate",
        "description": "The proportion of correctly solved word problems.",
        "category": "Problem Solving Performance",
        "formula": "Number of Correct Solutions / Total Number of Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_SemanticParser",
        "entity_type": "Algorithm",
        "name": "Semantic Parser with On-the-fly Ontology Matching",
        "title": "Scaling Semantic Parsers with On-the-fly Ontology Matching",
        "year": 2013,
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": [
          "Question Answering",
          "Semantic Parsing"
        ],
        "datasets": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall",
          "Precision",
          "F1"
        ],
        "architecture": {
          "components": [
            "Probabilistic CCG",
            "Ontology Matching Model"
          ],
          "connections": [
            "CCG Parsing",
            "Logical Form Transformation"
          ],
          "mechanisms": [
            "Domain-independent Parsing",
            "Structure Matching",
            "Constant Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Perceptron",
            "Latent Variable Learning"
          ],
          "parameter_tuning": [
            "Feature Weights"
          ]
        },
        "feature_processing": [
          "CCG Lexical Categories",
          "Wiktionary Definitions",
          "Knowledge Base Constraints"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "GeoQuery_1996",
        "entity_type": "Dataset",
        "name": "GeoQuery",
        "description": "Geography database with a small ontology and questions with relatively complex, compositional structure.",
        "domain": "Geography",
        "size": "Not specified",
        "year": 1996,
        "creators": [
          "Zelle, J.",
          "Mooney, R."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "FreebaseQA_2013",
        "entity_type": "Dataset",
        "name": "Freebase QA",
        "description": "Questions to Freebase, a large community-authored database that spans many sub-domains.",
        "domain": "Open-domain Question Answering",
        "size": "917 questions",
        "year": 2013,
        "creators": [
          "Cai, Q.",
          "Yates, A."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_QA",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Percentage of total questions answered correctly.",
        "category": "Question Answering Evaluation",
        "formula": "Correctly answered questions / Total questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_QA",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Percentage of produced queries with correct answers.",
        "category": "Question Answering Evaluation",
        "formula": "Correctly answered queries / Produced queries"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_QA",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall.",
        "category": "Question Answering Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2019_SemanticallyAlignedEquationGenerator",
        "entity_type": "Algorithm",
        "name": "Semantically-Aligned Equation Generator",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": 2019,
        "authors": [
          "Ting-Rui Chiang",
          "Yun-Nung Chen"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "BLSTM",
            "LSTM",
            "Gated Mechanisms"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Semantic Representation Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Knuth1968_ContextFreeSemanticsAlgorithm",
        "entity_type": "Algorithm",
        "name": "Context-Free Semantics Algorithm",
        "title": "Semantics of Context-Free Languages",
        "year": 1968,
        "authors": [
          "Donald E. Knuth"
        ],
        "task": [
          "Semantic Analysis of Context-Free Grammars"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Directed Graph Construction"
          ],
          "connections": [
            "Graph Pasting"
          ],
          "mechanisms": [
            "Cycle Detection"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_SequenceToSequenceLearning",
        "entity_type": "Algorithm",
        "name": "Sequence to Sequence Learning with Neural Networks",
        "title": "Sequence to Sequence Learning with Neural Networks",
        "year": 2014,
        "authors": [
          "Ilya Sutskever",
          "Oriol Vinyals",
          "Quoc V. Le"
        ],
        "task": [
          "Machine Translation"
        ],
        "datasets": [
          "WMT'14 English to French"
        ],
        "metrics": [
          "BLEU score"
        ],
        "architecture": {
          "components": [
            "Multilayered LSTM",
            "Deep LSTM"
          ],
          "connections": [
            "Input Sequence Encoder",
            "Output Sequence Decoder"
          ],
          "mechanisms": [
            "Long Short-Term Memory (LSTM)",
            "Reversed Input Sentences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Backpropagation",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Fixed Learning Rate",
            "Gradient Clipping"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Reversed Source Sentences"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT14_English_to_French",
        "entity_type": "Dataset",
        "name": "WMT'14 English to French",
        "description": "A dataset for English to French translation used in the WMT'14 evaluation campaign.",
        "domain": "Natural Language Processing",
        "size": 12000000,
        "year": 2014,
        "creators": [
          "WMT'14"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wiseman2016_BeamSearchOptimization",
        "entity_type": "Algorithm",
        "name": "Beam Search Optimization (BSO)",
        "title": "Sequence-to-Sequence Learning as Beam-Search Optimization",
        "year": 2016,
        "authors": [
          "Sam Wiseman",
          "Alexander M. Rush"
        ],
        "task": [
          "Word Ordering",
          "Dependency Parsing",
          "Machine Translation"
        ],
        "datasets": [
          "PTB",
          "Penn Treebank",
          "IWSLT 2014 German-to-English"
        ],
        "metrics": [
          "BLEU",
          "UAS",
          "LAS"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder",
            "Global Attention Model"
          ],
          "connections": [
            "Attention Mechanism",
            "Input Feeding"
          ],
          "mechanisms": [
            "Beam Search",
            "LaSO Framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Training",
            "Curriculum Beam Strategy",
            "Pre-training with Cross-Entropy Loss"
          ],
          "parameter_tuning": [
            "Adagrad",
            "Gradient Clipping",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embeddings Initialization",
          "Singleton Words Replacement",
          "Digit Normalization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PTB_2016",
        "entity_type": "Dataset",
        "name": "PTB",
        "description": "Penn Treebank dataset for word ordering and dependency parsing tasks",
        "domain": "Natural Language Processing",
        "size": "Varies",
        "year": 2016,
        "creators": [
          "Zhang, Y.",
          "Clark, S."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IWSLT2014_German_to_English_2016",
        "entity_type": "Dataset",
        "name": "IWSLT 2014 German-to-English",
        "description": "Dataset from the IWSLT 2014 machine translation evaluation campaign",
        "domain": "Machine Translation",
        "size": "153K training sentences, 7K development sentences, 7K test sentences",
        "year": 2016,
        "creators": [
          "Cettolo, M.",
          "Niehues, J.",
          "Stker, S.",
          "Bentivogli, L.",
          "Federico, M."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_SimpleCoreferenceResolution",
        "entity_type": "Algorithm",
        "name": "Simple Coreference Resolution",
        "title": "Simple Coreference Resolution with Rich Syntactic and Semantic Features",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": [
          "Coreference Resolution"
        ],
        "datasets": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module",
            "Selection Module"
          ],
          "connections": [
            "Syntactic Paths",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Syntactic Constraints",
            "Semantic Compatibility",
            "Tree Distance"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning",
            "Treebank Parsing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining",
          "Appositive Annotation",
          "Predicate Nominative Annotation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-ROTH-DEV_2009",
        "entity_type": "Dataset",
        "name": "ACE2004-ROTH-DEV",
        "description": "Development set split of the ACE 2004 training set",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": 2009,
        "creators": [
          "Bengston",
          "Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-CULOTTA-TEST_2009",
        "entity_type": "Dataset",
        "name": "ACE2004-CULOTTA-TEST",
        "description": "Test set split of the ACE 2004 training set",
        "domain": "Natural Language Processing",
        "size": 107,
        "year": 2009,
        "creators": [
          "Culotta",
          "Bengston",
          "Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-NWIRE_2009",
        "entity_type": "Dataset",
        "name": "ACE2004-NWIRE",
        "description": "ACE 2004 Newswire set",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": 2009,
        "creators": [
          "Poon",
          "Domingos"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MUC-6-TEST_2009",
        "entity_type": "Dataset",
        "name": "MUC-6-TEST",
        "description": "MUC6 formal evaluation set",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": 2009,
        "creators": []
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "BLIPP_2009",
        "entity_type": "Dataset",
        "name": "BLIPP",
        "description": "1.8 million sentences of newswire parsed with the Charniak parser",
        "domain": "Natural Language Processing",
        "size": 1800000,
        "year": 2009,
        "creators": [
          "Charniak"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WIKI_2009",
        "entity_type": "Dataset",
        "name": "WIKI",
        "description": "25k articles of English Wikipedia abstracts parsed by the Klein and Manning parser",
        "domain": "Natural Language Processing",
        "size": 25000,
        "year": 2009,
        "creators": [
          "Klein",
          "Manning"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "b3_Coreference",
        "entity_type": "Metric",
        "name": "b3",
        "description": "For each mention, form the intersection between the predicted cluster and the true cluster for that mention",
        "category": "Coreference Evaluation",
        "formula": "F1 = 2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "CEAF_Coreference",
        "entity_type": "Metric",
        "name": "CEAF",
        "description": "Scores the best match between true and predicted clusters using a similarity function",
        "category": "Coreference Evaluation",
        "formula": "Best match using 3 similarity function"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2016_ExpressionTreeBasedSolver",
        "entity_type": "Algorithm",
        "name": "Expression Tree Based Solver",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2016,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "AI2 Dataset",
          "IL Dataset",
          "Commoncore Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Monotonic Expression Tree",
            "Quantity Schema"
          ],
          "connections": [
            "LCA Operation Prediction",
            "Relevance Classification"
          ],
          "mechanisms": [
            "Constrained Inference Framework",
            "Multiclass Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search",
            "Pairwise Conjunction of Features"
          ],
          "parameter_tuning": [
            "wIRR"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Shallow Parsing",
          "Unit Extraction",
          "Noun Phrase Extraction",
          "Rate Detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AI2_Dataset_2014",
        "entity_type": "Dataset",
        "name": "AI2 Dataset",
        "description": "A collection of 395 addition and subtraction problems",
        "domain": "Arithmetic Word Problems",
        "size": 395,
        "year": 2014,
        "creators": [
          "M. J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IL_Dataset_2015",
        "entity_type": "Dataset",
        "name": "IL Dataset",
        "description": "A collection of arithmetic problems, each solvable by performing one operation",
        "domain": "Arithmetic Word Problems",
        "size": 562,
        "year": 2015,
        "creators": [
          "S. Roy",
          "T. Vieira",
          "D. Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Commoncore_Dataset_2016",
        "entity_type": "Dataset",
        "name": "Commoncore Dataset",
        "description": "A new dataset of multi-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 600,
        "year": 2016,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Relax_Accuracy",
        "entity_type": "Metric",
        "name": "Relax Accuracy",
        "description": "Fraction of quantities or quantity pairs correctly predicted",
        "category": "Partial Evaluation",
        "formula": "Correct Predictions / Total Predictions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Strict_Accuracy",
        "entity_type": "Metric",
        "name": "Strict Accuracy",
        "description": "Fraction of problems where all quantities or quantity pairs were correctly classified",
        "category": "Complete Evaluation",
        "formula": "Fully Correct Problems / Total Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2015_GEOS",
        "entity_type": "Algorithm",
        "name": "GEOS",
        "title": "Solving Geometry Problems: Combining Text and Diagram Interpretation",
        "year": 2015,
        "authors": [
          "Minjoon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni",
          "Clint Malcolm"
        ],
        "task": [
          "Geometry Problem Solving"
        ],
        "datasets": [
          "SAT Geometry Questions"
        ],
        "metrics": [
          "SAT Score"
        ],
        "architecture": {
          "components": [
            "Text Parser",
            "Diagram Parser",
            "Optimization Module",
            "Solver"
          ],
          "connections": [
            "Text-Diagram Integration"
          ],
          "mechanisms": [
            "Submodular Optimization",
            "Greedy Algorithm"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Log-linear Model"
          ],
          "parameter_tuning": [
            "Trade-off Parameter "
          ]
        },
        "feature_processing": [
          "Concept Identification",
          "Relation Identification",
          "Relation Completion"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SAT_Geometry_Questions_2015",
        "entity_type": "Dataset",
        "name": "SAT Geometry Questions",
        "description": "A dataset of SAT plane geometry questions with textual descriptions, diagrams, and multiple-choice answers.",
        "domain": "Educational Testing",
        "size": 186,
        "year": 2015,
        "creators": [
          "College Board",
          "Allen Institute for AI"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "SAT_Score_Geometry",
        "entity_type": "Metric",
        "name": "SAT Score",
        "description": "Score achieved on SAT geometry questions, penalized for wrong answers.",
        "category": "Test Performance",
        "formula": "Correctly answered questions - 0.25 * Incorrectly answered questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Text_Interpretation",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Precision of text interpretation in deriving literals for geometry question texts.",
        "category": "Text Interpretation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Text_Interpretation",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Recall of text interpretation in deriving literals for geometry question texts.",
        "category": "Text Interpretation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Text_Interpretation",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 score of text interpretation in deriving literals for geometry question texts.",
        "category": "Text Interpretation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Dependency_Parsing",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of dependency parsing in matching dependency parse structures to ground truth annotations.",
        "category": "Dependency Parsing",
        "formula": "Number of Correct Structures / Total Number of Structures"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_RelationKnowledgePoweredModel",
        "entity_type": "Algorithm",
        "name": "Relation Knowledge Powered Model (RK)",
        "title": "Solving Verbal Questions in IQ Test by Knowledge-Powered Word Embedding",
        "year": 2016,
        "authors": [
          "Huazheng Wang",
          "Fei Tian",
          "Bin Gao",
          "Chengjieren Zhu",
          "Jiang Bian",
          "Tie-Yan Liu"
        ],
        "task": [
          "Verbal Comprehension Questions Solving"
        ],
        "datasets": [
          "wiki2014",
          "IQ Test Set"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Question Classifier",
            "Word-Sense Pair Embedding",
            "Relation Embedding"
          ],
          "connections": [
            "Co-learning of Word-Sense Pairs and Relations"
          ],
          "mechanisms": [
            "Multi-Sense Clustering",
            "Relational Knowledge Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Skip-gram",
            "Negative Sampling",
            "Back Propagation"
          ],
          "parameter_tuning": [
            "Window Size",
            "Embedding Dimension",
            "Epoch Number"
          ]
        },
        "feature_processing": [
          "TF-IDF",
          "Context Window Representation",
          "Spherical k-means Clustering"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "wiki2014_2016",
        "entity_type": "Dataset",
        "name": "wiki2014",
        "description": "Large text snapshot from Wikipedia",
        "domain": "Natural Language Processing",
        "size": 3400000000,
        "year": 2016,
        "creators": [
          "Wikipedia Contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IQTestSet_2016",
        "entity_type": "Dataset",
        "name": "IQ Test Set",
        "description": "Verbal comprehension questions from published IQ test books",
        "domain": "Intelligence Testing",
        "size": 232,
        "year": 2016,
        "creators": [
          "Various Authors of IQ Test Books"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengio2003_NeuralProbabilisticLanguageModel",
        "entity_type": "Algorithm",
        "name": "Neural Probabilistic Language Model",
        "title": "A Neural Probabilistic Language Model",
        "year": 2003,
        "authors": [
          "Yoshua Bengio",
          "Rejean Ducharme",
          "Pascal Vincent",
          "Christian Jauvin"
        ],
        "task": [
          "Language Modeling"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Blei2003_LatentDirichletAllocation",
        "entity_type": "Algorithm",
        "name": "Latent Dirichlet Allocation (LDA)",
        "title": "Latent Dirichlet Allocation",
        "year": 2003,
        "authors": [
          "David M Blei",
          "Andrew Y Ng",
          "Michael I Jordan"
        ],
        "task": [
          "Topic Modeling"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collobert2008_UnifiedArchitectureForNLP",
        "entity_type": "Algorithm",
        "name": "Unified Architecture for Natural Language Processing",
        "title": "A Unified Architecture for Natural Language Processing",
        "year": 2008,
        "authors": [
          "Ronan Collobert",
          "Jason Weston"
        ],
        "task": [
          "Natural Language Processing"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2012_MultiSenseWordEmbedding",
        "entity_type": "Algorithm",
        "name": "Multi-Sense Word Embedding",
        "title": "Improving Word Representations via Global Context and Multiple Word Prototypes",
        "year": 2012,
        "authors": [
          "Eric H Huang",
          "Richard Socher",
          "Christopher D Manning",
          "Andrew Y Ng"
        ],
        "task": [
          "Word Representation"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2014_ProblemGenerationAlgorithm",
        "entity_type": "Algorithm",
        "name": "Problem Generation Algorithm",
        "title": "Synthesis of Geometry Proof Problems",
        "year": 2014,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": [
          "Geometry Proof Problem Generation"
        ],
        "datasets": [
          "Figures from Geometry Textbooks"
        ],
        "metrics": [
          "Number of Generated Problems",
          "Time Taken to Generate Problems"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Minimal Assumption Generation",
            "Strictly Interesting Problem Synthesis"
          ],
          "connections": [
            "Derive Function",
            "Choose Operator"
          ],
          "mechanisms": [
            "First-order Logic",
            "Horn Clauses"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Hypergraph Reachability",
            "Fixed-point Procedure"
          ],
          "parameter_tuning": [
            "Minimal Sets Enumeration",
            "Strictly Interesting Problem Synthesis"
          ]
        },
        "feature_processing": [
          "Implicit Facts Extraction",
          "Explicit Facts Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "FiguresFromGeometryTextbooks_2014",
        "entity_type": "Dataset",
        "name": "Figures from Geometry Textbooks",
        "description": "A collection of 110 geometric figures taken from standard mathematics textbooks in India and the United States.",
        "domain": "High School Geometry",
        "size": 110,
        "year": 2014,
        "creators": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "NumberOfGeneratedProblems_Generation",
        "entity_type": "Metric",
        "name": "Number of Generated Problems",
        "description": "The number of geometry proof problems generated per figure.",
        "category": "Problem Generation Evaluation",
        "formula": "Total number of problems / Number of figures"
      }
    },
    {
      "metric_entity": {
        "metric_id": "TimeTakenToGenerateProblems_Efficiency",
        "entity_type": "Metric",
        "name": "Time Taken to Generate Problems",
        "description": "The average time taken to generate problems per figure.",
        "category": "Efficiency Evaluation",
        "formula": "Total time / Number of figures"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2019_TemplateBasedSolver",
        "entity_type": "Algorithm",
        "name": "Template-Based Math Word Problem Solver",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": 2019,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K",
          "MAWPS"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Bi-LSTM",
            "Self Attention",
            "Recursive Neural Network"
          ],
          "connections": [
            "Attention Layer",
            "Recursive Connections"
          ],
          "mechanisms": [
            "Operator Encapsulation",
            "Equation Normalization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Adam Optimizer",
            "SGD Optimizer"
          ],
          "parameter_tuning": [
            "Dropout",
            "Batch Size",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Quantity Embedding",
          "Suffix Expression Serialization"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_MathProblemSolving",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correctly solved math word problems",
        "category": "Math Word Problem Solving",
        "formula": "Number of Correct Solutions / Total Number of Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_EquationNormalization",
        "entity_type": "Algorithm",
        "name": "Equation Normalization",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree"
          ],
          "connections": [
            "Normalization Rules"
          ],
          "mechanisms": [
            "Order Duplication Handling",
            "Bracket Duplication Handling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Tokenization",
          "Equation Template Transformation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_BiLSTM",
        "entity_type": "Algorithm",
        "name": "BiLSTM",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM"
          ],
          "connections": [
            "Global Attention Mechanism"
          ],
          "mechanisms": [
            "LSTM Cells"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adam Optimizer",
            "Beam Search"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Tokenization",
          "Equation Template Transformation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_ConvS2S",
        "entity_type": "Algorithm",
        "name": "ConvS2S",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Convolutional Layers"
          ],
          "connections": [
            "Gate Linear Units"
          ],
          "mechanisms": [
            "Convolutional Architecture"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Early Stopping",
            "Learning Rate Annealing"
          ],
          "parameter_tuning": [
            "Max-Epochs",
            "Hidden Size"
          ]
        },
        "feature_processing": [
          "Number Tokenization",
          "Equation Template Transformation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_Transformer",
        "entity_type": "Algorithm",
        "name": "Transformer",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Multi-Head Self-Attention Module",
            "Position-Wise Fully-Connected Feed-Forward Network"
          ],
          "connections": [
            "Self-Attention"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adam Optimizer",
            "Dropout"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Number of Heads",
            "Dimension of Keys",
            "Dimension of Values",
            "Output Dimension"
          ]
        },
        "feature_processing": [
          "Number Tokenization",
          "Equation Template Transformation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_EnsembleModel",
        "entity_type": "Algorithm",
        "name": "Ensemble Model",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "ConvS2S",
            "Transformer"
          ],
          "connections": [
            "Generation Probability Selection"
          ],
          "mechanisms": [
            "Model Combination"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Tokenization",
          "Equation Template Transformation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fletcher1985_WORDPRO",
        "entity_type": "Algorithm",
        "name": "WORDPRO",
        "title": "Understanding and solving arithmetic word problems: A computer simulation",
        "year": 1985,
        "authors": [
          "Fletcher, C. R."
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [],
        "metrics": [
          "Run-Time Statistics"
        ],
        "architecture": {
          "components": [
            "Production Rules",
            "Set Schema",
            "Transfer Schema",
            "Superset Schema",
            "More-Than/Less-Than Schema"
          ],
          "connections": [
            "Short-Term Memory (STM)",
            "Long-Term Memory (LTM)"
          ],
          "mechanisms": [
            "Meaning Postulates",
            "Arithmetic Strategies",
            "Problem-Solving Procedures"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Production System"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Propositional Representation",
          "Bilevel Representation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "RunTimeStatistics_ProblemSolving",
        "entity_type": "Metric",
        "name": "Run-Time Statistics",
        "description": "Statistics collected during the execution of the program, including number of production rules fired, number of conversions, number of LTM searches, and maximum number of chunks held over.",
        "category": "Program Performance Evaluation",
        "formula": "Not explicitly defined, but includes counts of various operations"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_BEATRIX",
        "entity_type": "Algorithm",
        "name": "BEATRIX",
        "title": "Understanding Natural Language with Diagrams",
        "year": 1990,
        "authors": [
          "Novak, G. S.",
          "Bulko, W."
        ],
        "task": [
          "Physics Problem Solving"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "English Parser",
            "Diagram Parser",
            "Coreference Resolver"
          ],
          "connections": [
            "Blackboard Architecture"
          ],
          "mechanisms": [
            "Opportunistic Co-parsers",
            "ATN Parser",
            "Knowledge Sources"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Text Parsing",
          "Diagram Parsing",
          "Coreference Resolution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PhysicsProblems_1990",
        "entity_type": "Dataset",
        "name": "Physics Problems",
        "description": "Textbook physics problems with accompanying diagrams",
        "domain": "Physics Education",
        "size": null,
        "year": 1990,
        "creators": [
          "Novak, G. S.",
          "Bulko, W."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "UnifiedModel_Accuracy",
        "entity_type": "Metric",
        "name": "Unified Model Accuracy",
        "description": "Accuracy of the unified model that combines information from both text and diagram",
        "category": "Model Evaluation",
        "formula": null
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bulko1988_BEATRIX",
        "entity_type": "Algorithm",
        "name": "BEATRIX",
        "title": "Understanding Text With an Accompanying Diagram",
        "year": 1988,
        "authors": [
          "William C. Bulko"
        ],
        "task": [
          "Physics Problem Solving"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Graphic Interface",
            "Blackboard System",
            "Knowledge Sources"
          ],
          "connections": [
            "Coreference Resolution",
            "Parsing"
          ],
          "mechanisms": [
            "Blackboard Control Structure",
            "Opportunistic Control"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Text Parsing",
          "Picture Element Identification",
          "Touch Relation Analysis"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CollegeLevelPhysicsTextbooks_1988",
        "entity_type": "Dataset",
        "name": "College-Level Physics Textbooks",
        "description": "Collections of ready-made test cases in the form of college-level textbooks",
        "domain": "Physics",
        "size": null,
        "year": 1988,
        "creators": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Correctness_Completeness",
        "entity_type": "Metric",
        "name": "Correctness and Completeness",
        "description": "Validation of the model's correctness and completeness when supplied as input to a physics problem-solving program",
        "category": "Model Validation",
        "formula": null
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_PairwiseCoreferenceModel",
        "entity_type": "Algorithm",
        "name": "Pairwise Coreference Model",
        "title": "Understanding the Value of Features for Coreference Resolution",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": [
          "Coreference Resolution"
        ],
        "datasets": [
          "ACE 2004 English training data"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function",
            "Document-Level Decision Model"
          ],
          "connections": [
            "Best-Link decision model",
            "Pairwise coreference function"
          ],
          "mechanisms": [
            "Averaged Perceptron Learning Algorithm"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Regularized Average Perceptron",
            "Threshold Optimization"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Mention Types",
          "String Relation Features",
          "Semantic Features",
          "Relative Location Features",
          "Learned Features",
          "Aligned Modifiers",
          "Memorization Features",
          "Predicted Entity Types"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004_2004",
        "entity_type": "Dataset",
        "name": "ACE 2004 English training data",
        "description": "A dataset used for coreference resolution tasks",
        "domain": "Natural Language Processing",
        "size": 336,
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "B-Cubed_F-Score_Coreference",
        "entity_type": "Metric",
        "name": "B-Cubed F-Score",
        "description": "A measure of the overlap of predicted clusters and true clusters",
        "category": "Coreference Evaluation",
        "formula": "Harmonic mean of precision and recall"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_F-Score_Coreference",
        "entity_type": "Metric",
        "name": "MUC F-Score",
        "description": "Official MUC scoring algorithm",
        "category": "Coreference Evaluation",
        "formula": "Harmonic mean of precision and recall, counting precision errors by computing the minimum number of links that must be added and recall errors by the number of links that must be removed"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_UNITDEP",
        "entity_type": "Algorithm",
        "name": "UNITDEP",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Vertex Classifier",
            "Edge Classifier",
            "Constrained Inference Module"
          ],
          "connections": [
            "Joint Inference with Arithmetic Solver"
          ],
          "mechanisms": [
            "Decomposed Model",
            "Monotonic Expression Tree"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search",
            "Scaling Parameters Tuning"
          ],
          "parameter_tuning": [
            "IRR",
            "VERTEX",
            "EDGE"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-based Extraction Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArith_2017",
        "entity_type": "Dataset",
        "name": "AllArith",
        "description": "A comprehensive dataset of arithmetic word problems",
        "domain": "Mathematics",
        "size": 831,
        "year": 2017,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithLex_2017",
        "entity_type": "Dataset",
        "name": "AllArithLex",
        "description": "Subset of AllArith with low lexical overlap",
        "domain": "Mathematics",
        "size": 415,
        "year": 2017,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithTmpl_2017",
        "entity_type": "Dataset",
        "name": "AllArithTmpl",
        "description": "Subset of AllArith with low template overlap",
        "domain": "Mathematics",
        "size": 415,
        "year": 2017,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_LCA++",
        "entity_type": "Algorithm",
        "name": "LCA++",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Irrelevance Classifier",
            "LCA Operation Classifier"
          ],
          "connections": [
            "Monotonic Expression Tree"
          ],
          "mechanisms": [
            "Feature Augmentation",
            "Positive Answer Constraint"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TEMPLATE",
        "entity_type": "Algorithm",
        "name": "TEMPLATE",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Nathan Kushman",
          "Luke Zettlemoyer",
          "Regina Barzilay",
          "Yoav Artzi"
        ],
        "task": [
          "Algebra Word Problem Solving"
        ],
        "datasets": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Template-based Solver"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_SINGLEEQ",
        "entity_type": "Algorithm",
        "name": "SINGLEEQ",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": 2015,
        "authors": [
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi",
          "Ashish Sabharwal",
          "Oren Etzioni",
          "Siena Ang"
        ],
        "task": [
          "Single Equation Word Problem Solving"
        ],
        "datasets": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Single Equation Solver"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_HoughTransformation",
        "entity_type": "Algorithm",
        "name": "Hough Transformation",
        "title": "Use of the Hough Transformation To Detect Lines and Curves in Pictures",
        "year": 1972,
        "authors": [
          "Richard O. Duda",
          "Peter E. Hart"
        ],
        "task": [
          "Line Detection",
          "Curve Detection"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Point-Line Transformation",
            "Parameter Space"
          ],
          "connections": [
            "Normal Parameterization"
          ],
          "mechanisms": [
            "Accumulator Array"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Quantization",
          "Thresholding"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Count_ColinearPoints",
        "entity_type": "Metric",
        "name": "Count of Colinear Points",
        "description": "Number of colinear points detected by the Hough Transformation",
        "category": "Line Detection",
        "formula": "k figure points lie along the line whose normal parameters are (, p)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Antol2015_VQA",
        "entity_type": "Algorithm",
        "name": "VQA",
        "title": "VQA: Visual Question Answering",
        "year": 2015,
        "authors": [
          "Stanislaw Antol",
          "Aishwarya Agrawal",
          "Jiasen Lu",
          "Margaret Mitchell",
          "Dhruv Batra",
          "C. Lawrence Zitnick",
          "Devi Parikh"
        ],
        "task": [
          "Visual Question Answering"
        ],
        "datasets": [
          "MS COCO_2014",
          "Abstract Scenes_2015"
        ],
        "metrics": [
          "Accuracy_Open-Answer",
          "Accuracy_Multiple-Choice"
        ],
        "architecture": {
          "components": [
            "Multi-Layer Perceptron",
            "LSTM"
          ],
          "connections": [
            "Element-wise Multiplication"
          ],
          "mechanisms": [
            "Dropout",
            "Softmax"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Bag-of-Words",
            "Image Features"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Bag-of-Words",
          "Image Feature Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MS_COCO_2014",
        "entity_type": "Dataset",
        "name": "MS COCO",
        "description": "Microsoft Common Objects in Context dataset",
        "domain": "Computer Vision",
        "size": 204721,
        "year": 2014,
        "creators": [
          "T.-Y. Lin",
          "M. Maire",
          "S. Belongie",
          "J. Hays",
          "P. Perona",
          "D. Ramanan",
          "P. Dollar",
          "C. L. Zitnick"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Abstract_Scenes_2015",
        "entity_type": "Dataset",
        "name": "Abstract Scenes",
        "description": "Dataset of abstract scenes for VQA",
        "domain": "Computer Vision",
        "size": 50000,
        "year": 2015,
        "creators": [
          "Stanislaw Antol",
          "Aishwarya Agrawal",
          "Jiasen Lu",
          "Margaret Mitchell",
          "Dhruv Batra",
          "C. Lawrence Zitnick",
          "Devi Parikh"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Open-Answer",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for open-answer task",
        "category": "Classification Evaluation",
        "formula": "min(# humans that provided that answer / 3, 1)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Multiple-Choice",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for multiple-choice task",
        "category": "Classification Evaluation",
        "formula": "Number of correct answers / Total number of questions"
      }
    }
  ],
  "is_complete": true,
  "extraction_time": 1749233835.277125
}