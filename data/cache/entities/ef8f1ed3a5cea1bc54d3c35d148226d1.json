{
  "entities": [
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_LatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Latent Left Linking Model (L3M)",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "datasets": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Left-Linking Model"
          ],
          "connections": [
            "Best-Left-Link Inference"
          ],
          "mechanisms": [
            "Latent Structural SVM",
            "Stochastic Gradient Descent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Regularization Parameter λ",
            "Threshold t"
          ]
        },
        "feature_processing": [
          "Feature Extraction for Pairwise Scoring"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ConstrainedLatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Constrained Latent Left Linking Model (CL3M)",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "datasets": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Left-Linking Model",
            "Constraint Injection"
          ],
          "connections": [
            "Best-Left-Link Inference"
          ],
          "mechanisms": [
            "Latent Structural SVM",
            "Stochastic Gradient Descent",
            "Domain Knowledge-Based Constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Regularization Parameter λ",
            "Threshold t",
            "Constraint Scores ρ"
          ]
        },
        "feature_processing": [
          "Feature Extraction for Pairwise Scoring",
          "Constraint Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chang2013_ProbabilisticLatentLeftLinkingModel",
        "entity_type": "Algorithm",
        "name": "Probabilistic Latent Left Linking Model (PL3M)",
        "year": 2013,
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "Coreference Resolution",
        "datasets": [
          "ACE 2004",
          "Ontonotes-5.0"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Probabilistic Left-Linking Model"
          ],
          "connections": [
            "Best-Left-Link Inference"
          ],
          "mechanisms": [
            "Latent Structural SVM",
            "Stochastic Gradient Descent",
            "Temperature Parameter γ"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Likelihood-Based Approach",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Regularization Parameter λ",
            "Temperature Parameter γ"
          ]
        },
        "feature_processing": [
          "Feature Extraction for Pairwise Scoring"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004",
        "entity_type": "Dataset",
        "name": "ACE 2004",
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Ontonotes2012",
        "entity_type": "Dataset",
        "name": "Ontonotes-5.0",
        "year": 2012,
        "creators": [
          "Pradhan et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_Coreference",
        "entity_type": "Metric",
        "name": "MUC",
        "category": "Coreference Evaluation"
      }
    },
    {
      "metric_entity": {
        "metric_id": "BCUB_Coreference",
        "entity_type": "Metric",
        "name": "BCUB",
        "category": "Coreference Evaluation"
      }
    },
    {
      "metric_entity": {
        "metric_id": "CEAF_Coreference",
        "entity_type": "Metric",
        "name": "CEAF",
        "category": "Coreference Evaluation"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chen2014_NeuralNetworkParser",
        "entity_type": "Algorithm",
        "name": "Neural Network Parser",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": 2014,
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "English Penn Treebank",
          "Chinese Penn Treebank"
        ],
        "metrics": [
          "Unlabeled Attachment Score (UAS)",
          "Labeled Attachment Score (LAS)"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Dense Embeddings",
            "Cube Activation Function"
          ],
          "mechanisms": [
            "Neural Network Classifier",
            "Arc-Standard System"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-Entropy Loss",
            "L2 Regularization",
            "Mini-Batched AdaGrad",
            "Dropout"
          ],
          "parameter_tuning": [
            "Pre-trained Word Embeddings",
            "Random Initialization"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Arc Label Embeddings"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "English_Penn_Treebank_2014",
        "entity_type": "Dataset",
        "name": "English Penn Treebank",
        "description": "A dataset for English syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 39832,
        "year": 2014,
        "creators": [
          "Johansson, R.",
          "Nugues, P."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Chinese_Penn_Treebank_2014",
        "entity_type": "Dataset",
        "name": "Chinese Penn Treebank",
        "description": "A dataset for Chinese syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 16091,
        "year": 2014,
        "creators": [
          "Zhang, Y.",
          "Clark, S."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Unlabeled_Attachment_Score_Parsing",
        "entity_type": "Metric",
        "name": "Unlabeled Attachment Score (UAS)",
        "description": "The proportion of words that have the correct head",
        "category": "Dependency Parsing Evaluation",
        "formula": "Number of correct heads / Total number of words"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Labeled_Attachment_Score_Parsing",
        "entity_type": "Metric",
        "name": "Labeled Attachment Score (LAS)",
        "description": "The proportion of words that have the correct head and label",
        "category": "Dependency Parsing Evaluation",
        "formula": "Number of correct heads and labels / Total number of words"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Raghunathan2010_MultiPassSieve",
        "entity_type": "Algorithm",
        "name": "Multi-Pass Sieve",
        "title": "A Multi-Pass Sieve for Coreference Resolution",
        "year": 2010,
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": [
          "Coreference Resolution"
        ],
        "datasets": [
          "ACE2004-ROTH-DEV2",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC",
          "B3"
        ],
        "architecture": {
          "components": [
            "Pass 1- Exact Match",
            "Pass 2- Precise Constructs",
            "Pass 3- Strict Head Matching",
            "Pass 4- Variants of Strict Head",
            "Pass 5- Variants of Strict Head",
            "Pass 6- Relaxed Head Matching",
            "Pass 7- Pronouns"
          ],
          "connections": [
            "Attribute Sharing",
            "Cluster Information Sharing"
          ],
          "mechanisms": [
            "Deterministic Models",
            "Tiered Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Information",
          "Attribute Detection",
          "Modifier Information"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-ROTH-DEV2_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-ROTH-DEV2",
        "description": "Development split of Bengston and Roth(2008) from the 2004 Automatic Content Extraction (ACE) evaluation.",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": 2004,
        "creators": [
          "Bengston and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-CULOTTA-TEST_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-CULOTTA-TEST",
        "description": "Partition of ACE 2004 corpus reserved for testing by several previous works.",
        "domain": "Natural Language Processing",
        "size": 107,
        "year": 2004,
        "creators": [
          "Culotta et al.",
          "Bengston and Roth",
          "Haghighi and Klein"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-NWIRE_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-NWIRE",
        "description": "Newswire subset of the ACE 2004 corpus utilized by Poon and Domingos(2008) and Haghighi and Klein (2009) for testing.",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": 2004,
        "creators": [
          "Poon and Domingos",
          "Haghighi and Klein"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MUC6-TEST_1995",
        "entity_type": "Dataset",
        "name": "MUC6-TEST",
        "description": "Test corpus from the sixth Message Understanding Conference (MUC-6) evaluation.",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": 1995,
        "creators": [
          "Vilain et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_F1",
        "entity_type": "Metric",
        "name": "Pairwise F1",
        "description": "Computed over mention pairs in the same entity cluster.",
        "category": "Coreference Resolution",
        "formula": "2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_Scoring",
        "entity_type": "Metric",
        "name": "MUC",
        "description": "Measures how many predicted clusters need to be merged to cover the gold clusters.",
        "category": "Coreference Resolution",
        "formula": "Not specified in the paper"
      }
    },
    {
      "metric_entity": {
        "metric_id": "B3_Scoring",
        "entity_type": "Metric",
        "name": "B3",
        "description": "Uses the intersection between predicted and gold clusters for a given mention to mark correct mentions and the sizes of the predicted and gold clusters as denominators for precision and recall.",
        "category": "Coreference Resolution",
        "formula": "Not specified in the paper"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
        "entity_type": "Algorithm",
        "name": "Structured Self-attentive Sentence Embedding",
        "year": 2017,
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": [
          "Author Profiling",
          "Sentiment Classification",
          "Textual Entailment"
        ],
        "datasets": [
          "Age Dataset",
          "Yelp Dataset",
          "SNLI Corpus"
        ],
        "metrics": [
          "Classification Accuracy"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Self-attention Mechanism",
            "Fully Connected Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Attention Weights",
            "Weighted Sum of Hidden States"
          ],
          "mechanisms": [
            "Self-attention",
            "Penalization Term"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Dropout",
            "L2 Regularization",
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Tokenization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Age_Dataset_2017",
        "entity_type": "Dataset",
        "name": "Age Dataset",
        "year": 2017,
        "creators": [
          "PAN Conference on Authorship Analysis"
        ],
        "domain": "Natural Language Processing",
        "size": 76485,
        "description": "Twitter tweets in English, Spanish, and Dutch with age and gender information"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Yelp_Dataset_2017",
        "entity_type": "Dataset",
        "name": "Yelp Dataset",
        "year": 2017,
        "creators": [
          "Yelp"
        ],
        "domain": "Natural Language Processing",
        "size": 2700000,
        "description": "Yelp reviews with star ratings"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SNLI_Corpus_2015",
        "entity_type": "Dataset",
        "name": "SNLI Corpus",
        "year": 2015,
        "creators": [
          "Bowman et al."
        ],
        "domain": "Natural Language Processing",
        "size": 570000,
        "description": "Human-written English sentence pairs manually labeled for entailment, contradiction, and neutral"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Classification",
        "entity_type": "Metric",
        "name": "Accuracy",
        "category": "Classification",
        "description": "Proportion of correctly classified instances"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Liang2016_TagBasedSolver",
        "entity_type": "Algorithm",
        "name": "Tag-based statistical MWP solver",
        "title": "A Tag-based English Math Word Problem Solver with Understanding, Reasoning and Explanation",
        "year": 2016,
        "authors": [
          "Chao-Chun Liang",
          "Kuang-Yi Hsu",
          "Chien-Tsung Huang",
          "Chung-Min Li",
          "Shen-Yu Miao",
          "Keh-Yih Su"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "MA1",
          "MA2",
          "IXL"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "Pipeline processing"
          ],
          "mechanisms": [
            "Tag-based annotation",
            "First-order logic predicates",
            "Logic inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SVM classifier with linear kernel"
          ],
          "parameter_tuning": [
            "Feature sets: verb category related features, keyword indicators, pattern-matching indicators"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Sentence splitting",
          "POS tagging",
          "Lemmatization",
          "Named entity recognition",
          "Parsing",
          "Co-reference resolution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MA1_2014",
        "entity_type": "Dataset",
        "name": "MA1",
        "description": "Simple MWPs on addition and subtraction for third, fourth, and fifth graders",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MA2_2014",
        "entity_type": "Dataset",
        "name": "MA2",
        "description": "MWPs with more irrelevant information",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IXL_2014",
        "entity_type": "Dataset",
        "name": "IXL",
        "description": "MWPs with more information gaps",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldberg2010_EasyFirstNonDirectionalParser",
        "entity_type": "Algorithm",
        "name": "Easy-First Non-Directional Dependency Parsing",
        "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing",
        "year": 2010,
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "WSJ Treebank",
          "CoNLL 2007 English dataset"
        ],
        "metrics": [
          "Accuracy",
          "Root",
          "Complete"
        ],
        "architecture": {
          "components": [
            "ATTACHLEFT",
            "ATTACHRIGHT"
          ],
          "connections": [
            "Dependency edges"
          ],
          "mechanisms": [
            "Non-directional parsing",
            "Best-first parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron"
          ],
          "parameter_tuning": [
            "Parameter averaging"
          ]
        },
        "feature_processing": [
          "Binary valued features",
          "POS tagging",
          "Feature templates"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WSJ_Treebank_2010",
        "entity_type": "Dataset",
        "name": "WSJ Treebank",
        "description": "Wall Street Journal Treebank used for dependency parsing experiments",
        "domain": "Natural Language Processing",
        "size": "Sections 2-21 for training, Section 22 for development, Section 23 for testing",
        "year": 2010,
        "creators": [
          "Penn Treebank"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CoNLL_2007_2010",
        "entity_type": "Dataset",
        "name": "CoNLL 2007 English dataset",
        "description": "English dataset from the CoNLL 2007 shared task on dependency parsing",
        "domain": "Natural Language Processing",
        "size": "Smaller than WSJ Treebank, created using a different conversion procedure",
        "year": 2010,
        "creators": [
          "CoNLL 2007 organizers"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Root_Classification",
        "entity_type": "Metric",
        "name": "Root",
        "description": "Percentage of sentences in which the ROOT attachment is correct",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correct ROOT attachments / Total sentences"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Complete_Classification",
        "entity_type": "Metric",
        "name": "Complete",
        "description": "Percentage of sentences in which all tokens were assigned their correct parent",
        "category": "Dependency Parsing Evaluation",
        "formula": "Sentences with all correct attachments / Total sentences"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Earley1970_EfficientParsingAlgorithm",
        "entity_type": "Algorithm",
        "name": "Efficient Context-Free Parsing Algorithm",
        "year": 1970,
        "authors": [
          "Earley, J."
        ],
        "task": [
          "Parsing"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Predictor",
            "Completer",
            "Scanner"
          ],
          "connections": [
            "State Sets",
            "Look-ahead"
          ],
          "mechanisms": [
            "LR(k) Parsing",
            "Top-down Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context-Free Grammars",
          "Derivation Trees"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "TimeComplexity_Parsing",
        "entity_type": "Metric",
        "name": "Time Complexity",
        "description": "Time complexity of parsing algorithms",
        "category": "Algorithm Performance",
        "formula": "O(n^3) for general context-free grammars, O(n^2) for unambiguous grammars, O(n) for bounded state grammars"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpaceComplexity_Parsing",
        "entity_type": "Metric",
        "name": "Space Complexity",
        "description": "Space complexity of parsing algorithms",
        "category": "Algorithm Performance",
        "formula": "O(n^2)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Knuth1965_LRkAlgorithm",
        "entity_type": "Algorithm",
        "name": "LR(k) Algorithm",
        "year": 1965,
        "authors": [
          "Knuth, D.E."
        ],
        "task": [
          "Parsing"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Stack",
            "State Sets"
          ],
          "connections": [
            "Look-ahead"
          ],
          "mechanisms": [
            "Bottom-up Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context-Free Grammars"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cocke1969_CockeAlgorithm",
        "entity_type": "Algorithm",
        "name": "Cocke's Algorithm",
        "year": 1969,
        "authors": [
          "Cocke"
        ],
        "task": [
          "Parsing"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": [
            "Context-Free Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kasami1969_KasamiAlgorithm",
        "entity_type": "Algorithm",
        "name": "Kasami's Algorithm",
        "year": 1969,
        "authors": [
          "Kasami, T.",
          "Torii, K."
        ],
        "task": [
          "Parsing"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": [
            "Unambiguous Context-Free Grammars"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Younger1967_RecognitionAndParsing",
        "entity_type": "Algorithm",
        "name": "Recognition and Parsing of Context-Free Languages",
        "year": 1967,
        "authors": [
          "Younger, D.H."
        ],
        "task": [
          "Parsing"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": [
            "Context-Free Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2015_GeoTutor",
        "entity_type": "Algorithm",
        "name": "GeoTutor",
        "title": "Automatic Synthesis of Geometry Problems for an Intelligent Tutoring System",
        "year": 2015,
        "authors": [
          "Chris Alvin",
          "Sumit Gulwani",
          "Rupak Majumdar",
          "Supratik Mukhopadhyay"
        ],
        "task": [
          "Euclidean Geometry Problem Synthesis"
        ],
        "datasets": [
          "High School Geometry Problems"
        ],
        "metrics": [
          "Proof Width",
          "Proof Length",
          "Deductive Steps"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Pebbling Algorithm"
          ],
          "connections": [
            "Forward Edges",
            "Back-Edges"
          ],
          "mechanisms": [
            "Traversal Algorithm",
            "Coarse Problem Homomorphism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Breadth-First Pebbling"
          ],
          "parameter_tuning": [
            "User Query Restrictions"
          ]
        },
        "feature_processing": [
          "Coordinate-Based Computation",
          "Assumption Filtering"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "HighSchoolGeometryProblems_2015",
        "entity_type": "Dataset",
        "name": "High School Geometry Problems",
        "description": "A collection of geometry problems from standard high school textbooks",
        "domain": "Education",
        "size": 110,
        "year": 2015,
        "creators": [
          "Sinclair",
          "Dikshit",
          "Boyd",
          "Larson",
          "Jurgensen",
          "Brown"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "ProofWidth_Classification",
        "entity_type": "Metric",
        "name": "Proof Width",
        "description": "The width of the problem hypergraph",
        "category": "Classification",
        "formula": "Width of the hypergraph"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ProofLength_Classification",
        "entity_type": "Metric",
        "name": "Proof Length",
        "description": "The diameter of the problem hypergraph",
        "category": "Classification",
        "formula": "Diameter of the hypergraph"
      }
    },
    {
      "metric_entity": {
        "metric_id": "DeductiveSteps_Classification",
        "entity_type": "Metric",
        "name": "Deductive Steps",
        "description": "The number of hyperedges in the problem hypergraph",
        "category": "Classification",
        "formula": "Number of hyperedges"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Shi2015_SigmaDolphin",
        "entity_type": "Algorithm",
        "name": "SigmaDolphin",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": 2015,
        "authors": [
          "Shuming Shi",
          "Yuehui Wang",
          "Chin-Yew Lin",
          "Xiaojiang Liu",
          "Yong Rui"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Algebra.com_2015",
          "YahooAnswers_2015"
        ],
        "metrics": [
          "Precision",
          "Recall",
          "F1"
        ],
        "architecture": {
          "components": [
            "Semantic Parser",
            "Reasoning Module"
          ],
          "connections": [
            "CFG Parser",
            "DOL Trees"
          ],
          "mechanisms": [
            "Context-Free Grammar",
            "Semantic Interpretation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CFG Rules Creation",
            "Type Compatibility Checking"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing",
          "Mathematical Expression Derivation"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Algebra.com_2015",
        "entity_type": "Dataset",
        "name": "Algebra.com",
        "description": "A website for users to post math problems and get help from tutors",
        "domain": "Mathematics",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Various Contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "YahooAnswers_2015",
        "entity_type": "Dataset",
        "name": "Yahoo Answers",
        "description": "A question-and-answer website",
        "domain": "Mathematics",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Various Contributors"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Classification",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "The proportion of true positive results among the total predicted positives",
        "category": "Classification Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Classification",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "The proportion of true positive results among the total actual positives",
        "category": "Classification Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Classification",
        "entity_type": "Metric",
        "name": "F1",
        "description": "The harmonic mean of precision and recall",
        "category": "Classification Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_KAZB",
        "entity_type": "Algorithm",
        "name": "KAZB",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "N. Kushman",
          "Y. Artzi",
          "L. Zettlemoyer",
          "R. Barzilay"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "LinearT2_2015",
          "LinearT6_2015"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Mapping"
          ],
          "connections": [
            "Training Data Equations"
          ],
          "mechanisms": [
            "Learning-Based Statistical Method"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Equation Templates Determination"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_BasicSim",
        "entity_type": "Algorithm",
        "name": "BasicSim",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": 2014,
        "authors": [
          "M.J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "LinearT2_2015",
          "LinearT6_2015"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Similarity Calculation"
          ],
          "connections": [
            "Training Set Problems"
          ],
          "mechanisms": [
            "Statistical Method"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Similarity Computation"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Feature Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_Aristo",
        "entity_type": "Algorithm",
        "name": "Aristo",
        "title": "Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P.",
          "Khashabi, D."
        ],
        "task": [
          "Elementary Science Question Answering"
        ],
        "datasets": [
          "NY Regents Science Exam"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "IR Solver",
            "PMI Solver",
            "SVM Solver",
            "RULE Solver",
            "ILP Solver"
          ],
          "connections": [
            "Logistic Regression Combiner"
          ],
          "mechanisms": [
            "Information Retrieval",
            "Pointwise Mutual Information",
            "Support Vector Machine",
            "Rule-based Reasoning",
            "Integer Linear Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Logistic Regression Calibration"
          ],
          "parameter_tuning": [
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "Text Parsing",
          "N-gram Extraction",
          "Word Embeddings",
          "Lexical Semantics"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_IRSolver",
        "entity_type": "Algorithm",
        "name": "IR Solver",
        "title": "Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P.",
          "Khashabi, D."
        ],
        "task": [
          "Information Retrieval"
        ],
        "datasets": [
          "NY Regents Science Exam"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Search Engine"
          ],
          "connections": [],
          "mechanisms": [
            "Lucene Search"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Query Construction",
          "Non-stopword Overlap"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_PMISolver",
        "entity_type": "Algorithm",
        "name": "PMI Solver",
        "title": "Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P.",
          "Khashabi, D."
        ],
        "task": [
          "Statistical Association"
        ],
        "datasets": [
          "NY Regents Science Exam"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Pointwise Mutual Information"
          ],
          "connections": [],
          "mechanisms": [
            "N-gram Extraction",
            "PMI Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "N-gram Extraction",
          "Stopword Filtering"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_SVMSolver",
        "entity_type": "Algorithm",
        "name": "SVM Solver",
        "title": "Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P.",
          "Khashabi, D."
        ],
        "task": [
          "Word Similarity"
        ],
        "datasets": [
          "NY Regents Science Exam"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Support Vector Machine"
          ],
          "connections": [],
          "mechanisms": [
            "Word Embeddings",
            "Cosine Similarity"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SVM Ranker"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Word Embedding Generation",
          "Vector Summation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_RULESolver",
        "entity_type": "Algorithm",
        "name": "RULE Solver",
        "title": "Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P.",
          "Khashabi, D."
        ],
        "task": [
          "Rule-based Reasoning"
        ],
        "datasets": [
          "NY Regents Science Exam"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Probabilistic First-Order Logic Rules"
          ],
          "connections": [],
          "mechanisms": [
            "Rule Extraction",
            "Logical Implication"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Text Parsing",
          "Implication Pattern Matching"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Clark2016_ILPSolver",
        "entity_type": "Algorithm",
        "name": "ILP Solver",
        "title": "Retrieval, Statistics, and Inference to Answer Elementary Science Questions",
        "year": 2016,
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P.",
          "Khashabi, D."
        ],
        "task": [
          "Structured Knowledge Reasoning"
        ],
        "datasets": [
          "NY Regents Science Exam"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Knowledge Tables"
          ],
          "connections": [],
          "mechanisms": [
            "Integer Linear Programming",
            "Table Joining"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Table Construction",
          "Relation Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NY_Regents_Science_Exam_2016",
        "entity_type": "Dataset",
        "name": "NY Regents Science Exam",
        "description": "Elementary Science Exam Questions",
        "domain": "Elementary Education",
        "size": 237,
        "year": 2016,
        "creators": [
          "New York State Education Department"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Elementary_Science_Corpus_2016",
        "entity_type": "Dataset",
        "name": "Elementary Science Corpus",
        "description": "80k sentences about elementary science",
        "domain": "Elementary Education",
        "size": 80000,
        "year": 2016,
        "creators": [
          "Allen Institute for Artificial Intelligence"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Web_Corpus_2016",
        "entity_type": "Dataset",
        "name": "Web Corpus",
        "description": "5 × 10^10 tokens (280 GB of plain text)",
        "domain": "General",
        "size": 50000000000,
        "year": 2016,
        "creators": [
          "Web Pages"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_BiLSTMClassifier",
        "entity_type": "Algorithm",
        "name": "BiLSTM Classifier",
        "year": 2018,
        "authors": [
          "Robaidek, Benjamin",
          "Koncel-Kedziorski, Rik",
          "Hajishirzi, Hannaneh"
        ],
        "task": "Math Word Problem Solving",
        "datasets": [
          "DRAW",
          "MAWPS",
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "Softmax"
          ],
          "connections": [
            "Bidirectional LSTM"
          ],
          "mechanisms": [
            "Cross Entropy Loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training",
            "Cross Entropy Loss"
          ],
          "parameter_tuning": [
            "Learning Rate Tuning",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin2017_StructuredSelfAttention",
        "entity_type": "Algorithm",
        "name": "Structured Self-Attention",
        "year": 2017,
        "authors": [
          "Lin, Zhouhan",
          "Feng, Minwei",
          "Santos, Cicero Nogueira dos",
          "Yu, Mo",
          "Xiang, Bing",
          "Zhou, Bowen",
          "Bengio, Yoshua"
        ],
        "task": "Math Word Problem Solving",
        "datasets": [
          "DRAW",
          "MAWPS",
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "Self-Attention"
          ],
          "connections": [
            "Multi-Hop Attention"
          ],
          "mechanisms": [
            "Fixed Size Embedding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Learning Rate Tuning",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_Seq2Seq",
        "entity_type": "Algorithm",
        "name": "Seq2Seq Model",
        "year": 2014,
        "authors": [
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Le, Quoc V"
        ],
        "task": "Math Word Problem Solving",
        "datasets": [
          "DRAW",
          "MAWPS",
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Attention Mechanism"
          ],
          "mechanisms": [
            "LSTM"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Sequence Prediction"
          ],
          "parameter_tuning": [
            "Learning Rate Tuning",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Tokenization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "DRAW_2015",
        "entity_type": "Dataset",
        "name": "DRAW",
        "year": 2015,
        "creators": [
          "Upadhyay, Shyam",
          "Chang, Ming-Wei"
        ],
        "domain": "Math Word Problem Solving",
        "size": 2373,
        "description": "A challenging and diverse algebra word problem set"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MAWPS_2016",
        "entity_type": "Dataset",
        "name": "MAWPS",
        "year": 2016,
        "creators": [
          "Koncel-Kedziorski, Rik",
          "Roy, Subhro",
          "Amini, Aida",
          "Kushman, Nate",
          "Hajishirzi, Hannaneh"
        ],
        "domain": "Math Word Problem Solving",
        "size": 2373,
        "description": "A math word problem repository"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Math23K_2017",
        "entity_type": "Dataset",
        "name": "Math23K",
        "year": 2017,
        "creators": [
          "Wang, Yan",
          "Liu, Xiaojiang",
          "Shi, Shuming"
        ],
        "domain": "Math Word Problem Solving",
        "size": 23164,
        "description": "A large dataset of Chinese algebra word problems"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Oracle_Accuracy",
        "entity_type": "Metric",
        "name": "Oracle Accuracy",
        "category": "Upper Bound Evaluation",
        "description": "The number of test equation templates which appear in the training data"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_DeepNeuralSolver",
        "entity_type": "Algorithm",
        "name": "Deep Neural Solver",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Yan",
          "Liu, Xiaojiang",
          "Shi, Shuming"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K",
          "Alg514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "GRU",
            "LSTM"
          ],
          "mechanisms": [
            "Gated Recurrent Unit",
            "Long Short-Term Memory"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_Seq2SeqModel",
        "entity_type": "Algorithm",
        "name": "Seq2Seq Model",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Yan",
          "Liu, Xiaojiang",
          "Shi, Shuming"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K",
          "Alg514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "GRU",
            "LSTM"
          ],
          "mechanisms": [
            "Gated Recurrent Unit",
            "Long Short-Term Memory"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_HybridModel",
        "entity_type": "Algorithm",
        "name": "Hybrid Model",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Yan",
          "Liu, Xiaojiang",
          "Shi, Shuming"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K",
          "Alg514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Retrieval Model"
          ],
          "connections": [
            "Threshold-based Switching"
          ],
          "mechanisms": [
            "Jaccard Similarity"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2017_RetrievalModel",
        "entity_type": "Algorithm",
        "name": "Retrieval Model",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": 2017,
        "authors": [
          "Wang, Yan",
          "Liu, Xiaojiang",
          "Shi, Shuming"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K",
          "Alg514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "TF-IDF Vectorizer"
          ],
          "connections": [
            "Jaccard Similarity"
          ],
          "mechanisms": [
            "Lexical Similarity Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Alg514_2014",
        "entity_type": "Dataset",
        "name": "Alg514",
        "description": "A dataset of linear algebra problems",
        "domain": "Natural Language Processing",
        "size": 514,
        "year": 2014,
        "creators": [
          "Kushman, Nate",
          "Artzi, Yoav",
          "Zettlemoyer, Luke",
          "Barzilay, Regina"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2014_G-ALIGNER",
        "entity_type": "Algorithm",
        "name": "G-ALIGNER",
        "title": "Diagram Understanding in Geometry Questions",
        "year": 2014,
        "authors": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ],
        "task": [
          "Diagram Understanding",
          "Geometry Question Solving"
        ],
        "datasets": [
          "Geometry Questions Dataset_2014"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Primitive Detector",
            "Alignment Module"
          ],
          "connections": [
            "Visual and Textual Coupling"
          ],
          "mechanisms": [
            "Submodular Optimization",
            "Greedy Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Submodular Function Maximization"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Hough Transform",
          "Gaussian Blur",
          "Binarization",
          "Corner Detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geometry_Questions_Dataset_2014",
        "entity_type": "Dataset",
        "name": "Geometry Questions Dataset",
        "description": "A dataset of high school plane geometry questions with textual descriptions and diagrams.",
        "domain": "Geometry",
        "size": 100,
        "year": 2014,
        "creators": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Identifying_Primitives",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Identifying Primitives",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Aligning_Visual_Elements",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Aligning Visual Elements",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Watanabe1991_PBFDiagramUnderstandingFramework",
        "entity_type": "Algorithm",
        "name": "PBF Diagram Understanding Framework",
        "title": "Diagram Understanding Using Integration of Layout Information and Textual Information",
        "year": 1991,
        "authors": [
          "Watanabe, Yasuhiko",
          "Nagao, Makoto"
        ],
        "task": [
          "Diagram Understanding"
        ],
        "datasets": [
          "PBF Diagrams"
        ],
        "metrics": [
          "Semantic Analysis Accuracy"
        ],
        "architecture": {
          "components": [
            "Layout Information Extraction",
            "Natural Language Information Extraction"
          ],
          "connections": [
            "Integration of Layout and Natural Language Information"
          ],
          "mechanisms": [
            "Symbol Connection",
            "Spatial Relationship Detection",
            "Expression Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Annotation of Diagram Elements"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Japanese Morphological Analysis",
          "Pattern Matching"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PBF_Diagrams_1991",
        "entity_type": "Dataset",
        "name": "PBF Diagrams",
        "description": "Diagrams from Pictorial Books of Flora containing information about plant parts, shapes, and relationships.",
        "domain": "Botanical Illustration",
        "size": 31,
        "year": 1991,
        "creators": [
          "Watanabe, Yasuhiko",
          "Nagao, Makoto"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Semantic_Analysis_Accuracy_Classification",
        "entity_type": "Metric",
        "name": "Semantic Analysis Accuracy",
        "description": "Accuracy of correctly classifying words in PBF diagrams into predefined categories.",
        "category": "Classification Evaluation",
        "formula": "Correctly Classified Words / Total Words"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_DimensionallyGuidedSynthesis",
        "entity_type": "Algorithm",
        "name": "Dimensionally Guided Synthesis",
        "title": "Dimensionally Guided Synthesis of Mathematical Word Problems",
        "year": 2016,
        "authors": [
          "Ke Wang",
          "Zhendong Su"
        ],
        "task": [
          "Math Word Problem Generation"
        ],
        "datasets": [],
        "metrics": [
          "Statistical Indistinguishability",
          "Error Rate"
        ],
        "architecture": {
          "components": [
            "Equation Generator",
            "Narrative Generator"
          ],
          "connections": [
            "Binary Expression Tree",
            "Dimensional Units"
          ],
          "mechanisms": [
            "Dimensional Consistency",
            "Recursive Narrative Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Equation Generation",
            "Variable Unrolling"
          ],
          "parameter_tuning": [
            "Dimensional Unit Assignment",
            "Keyword Selection"
          ]
        },
        "feature_processing": [
          "Dimensional Unit Classification",
          "Sub-story Theme Association"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "StatisticalIndistinguishability_Authenticity",
        "entity_type": "Metric",
        "name": "Statistical Indistinguishability",
        "description": "Measure of whether generated problems are statistically indistinguishable from textbook problems",
        "category": "Authenticity Evaluation",
        "formula": "Paired t-test and Chi-square test of independence"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorRate_Difficulty",
        "entity_type": "Metric",
        "name": "Error Rate",
        "description": "Measure of the difficulty level of problems based on student error rates",
        "category": "Difficulty Evaluation",
        "formula": "Percentage of incorrect answers"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_SkipGram",
        "entity_type": "Algorithm",
        "name": "Skip-gram",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": [
          "Word Representation Learning",
          "Phrase Representation Learning"
        ],
        "datasets": [
          "Internal Google News Dataset"
        ],
        "metrics": [
          "Accuracy",
          "Syntactic Accuracy",
          "Semantic Accuracy"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Output Layer"
          ],
          "connections": [
            "Weight Matrices"
          ],
          "mechanisms": [
            "Negative Sampling",
            "Hierarchical Softmax",
            "Subsampling of Frequent Words"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Negative Sampling",
            "Hierarchical Softmax",
            "Subsampling of Frequent Words"
          ],
          "parameter_tuning": [
            "Dimensionality",
            "Context Size",
            "Subsampling Rate"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Subsampling of Frequent Words"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Internal_Google_News_Dataset_2013",
        "entity_type": "Dataset",
        "name": "Internal Google News Dataset",
        "description": "A large dataset consisting of various news articles with one billion words.",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": 2013,
        "creators": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Analogical_Reasoning",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of solving analogical reasoning tasks.",
        "category": "Analogical Reasoning",
        "formula": "Number of correct answers / Total number of questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Syntactic_Accuracy_Analogical_Reasoning",
        "entity_type": "Metric",
        "name": "Syntactic Accuracy",
        "description": "Accuracy of solving syntactic analogical reasoning tasks.",
        "category": "Analogical Reasoning",
        "formula": "Number of correct syntactic analogies / Total number of syntactic analogies"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Semantic_Accuracy_Analogical_Reasoning",
        "entity_type": "Metric",
        "name": "Semantic Accuracy",
        "description": "Accuracy of solving semantic analogical reasoning tasks.",
        "category": "Analogical Reasoning",
        "formula": "Number of correct semantic analogies / Total number of semantic analogies"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_HierarchicalSoftmax",
        "entity_type": "Algorithm",
        "name": "Hierarchical Softmax",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": [
          "Word Representation Learning"
        ],
        "datasets": [
          "Internal Google News Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary Tree",
            "Inner Nodes",
            "Leaf Nodes"
          ],
          "connections": [
            "Paths in Binary Tree"
          ],
          "mechanisms": [
            "Logarithmic Probability Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Hierarchical Softmax"
          ],
          "parameter_tuning": [
            "Tree Structure"
          ]
        },
        "feature_processing": [
          "Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_NegativeSampling",
        "entity_type": "Algorithm",
        "name": "Negative Sampling",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": [
          "Word Representation Learning"
        ],
        "datasets": [
          "Internal Google News Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Output Layer"
          ],
          "connections": [
            "Weight Matrices"
          ],
          "mechanisms": [
            "Logistic Regression"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Negative Sampling"
          ],
          "parameter_tuning": [
            "Number of Negative Samples"
          ]
        },
        "feature_processing": [
          "Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mikolov2013_PhraseSkipGram",
        "entity_type": "Algorithm",
        "name": "Phrase Skip-gram",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": 2013,
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": [
          "Phrase Representation Learning"
        ],
        "datasets": [
          "Internal Google News Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Output Layer"
          ],
          "connections": [
            "Weight Matrices"
          ],
          "mechanisms": [
            "Phrase Identification",
            "Subsampling of Frequent Words"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Phrase Identification",
            "Subsampling of Frequent Words"
          ],
          "parameter_tuning": [
            "Dimensionality",
            "Context Size",
            "Subsampling Rate"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Phrase Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Slagle1965_DEDUCOM",
        "entity_type": "Algorithm",
        "name": "DEDUCOM",
        "title": "Experiments with a Deductive Question-Answering Program",
        "year": 1965,
        "authors": [
          "James R. Slagle"
        ],
        "task": [
          "Question Answering",
          "Deductive Reasoning"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Fact Interpreter",
            "Depth-First Search Procedure"
          ],
          "connections": [
            "Logical Deductions",
            "Predicate Calculus"
          ],
          "mechanisms": [
            "Heuristic Programming",
            "Recursive Question Reduction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Providing Facts",
            "Adjusting Fact Order"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Fact Representation",
          "Logical Equivalence Transformation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Time_Efficiency",
        "entity_type": "Metric",
        "name": "Time Efficiency",
        "description": "Time taken by DEDUCOM to answer each question",
        "category": "Performance Evaluation",
        "formula": "Time taken to answer a question"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Yu2016_ImplicitQuantityRelationsExtractor",
        "entity_type": "Algorithm",
        "name": "Implicit Quantity Relations Extractor",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": 2016,
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Elementary school arithmetic application problem (People's Education Press, 2011)",
          "Suzhou Education Publishing House"
        ],
        "metrics": [
          "Classification Accuracy"
        ],
        "architecture": {
          "components": [
            "Chinese Phrase Parse",
            "SVM Classification",
            "Instantiation Method"
          ],
          "connections": [
            "Semantic Models"
          ],
          "mechanisms": [
            "Sequence Alignment",
            "Equation Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SVM with Slack Variable"
          ],
          "parameter_tuning": [
            "Lagrange Multiplier",
            "Weight Number for Slack Variable"
          ]
        },
        "feature_processing": [
          "Bag of Words",
          "Chinese Lexical Analysis System (ICTCLAS)"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ElementarySchoolArithmeticApplicationProblem_2011",
        "entity_type": "Dataset",
        "name": "Elementary school arithmetic application problem",
        "description": "Arithmetic word problems for elementary school students",
        "domain": "Education",
        "size": 627,
        "year": 2011,
        "creators": [
          "People's Education Press"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SuzhouEducationPublishingHouse_2016",
        "entity_type": "Dataset",
        "name": "Suzhou Education Publishing House",
        "description": "Arithmetic word problems for training",
        "domain": "Education",
        "size": 283,
        "year": 2016,
        "creators": [
          "Suzhou Education Publishing House"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ma2010_FrameBasedCalculus",
        "entity_type": "Algorithm",
        "name": "Frame-Based Calculus",
        "title": "Frame-Based Calculus of solving Arithmetic Multi-Step Addition and Subtraction word problems",
        "year": 2010,
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [],
        "metrics": [
          "Effectiveness"
        ],
        "architecture": {
          "components": [
            "MSWPAS-NP",
            "MSWPAS-CP"
          ],
          "connections": [
            "Natural Language Processing",
            "Frame-Based Calculus"
          ],
          "mechanisms": [
            "Means-end Analysis"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Problem Representation",
            "Planning",
            "Trying to Solve and Assessment"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Comprehension and Representation",
          "Frame Identification"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ChineseElementarySchoolProblems_2010",
        "entity_type": "Dataset",
        "name": "Chinese Elementary School Word Problems",
        "description": "Word problems gathered from four publishers in China",
        "domain": "Education",
        "size": "Not specified",
        "year": 2010,
        "creators": [
          "People’s Education Press",
          "Beijing Normal University Press",
          "DONGBEI Normal University Press"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Effectiveness_Solving",
        "entity_type": "Metric",
        "name": "Effectiveness",
        "description": "Effectiveness of solving multi-step addition and subtraction word problems",
        "category": "Problem Solving",
        "formula": "Not specified"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "deMarneffe2006_TypedDependencyExtraction",
        "entity_type": "Algorithm",
        "name": "Typed Dependency Extraction",
        "title": "Generating Typed Dependency Parses from Phrase Structure Parses",
        "year": 2006,
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Dependency Extractor"
          ],
          "connections": [
            "Rule-based Patterns"
          ],
          "mechanisms": [
            "Collins Head Rules",
            "Semantic Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Statistical Parsing"
          ],
          "parameter_tuning": [
            "Rule Definitions",
            "Pattern Matching"
          ]
        },
        "feature_processing": [
          "Head Identification",
          "Dependency Labeling"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreebank_1999",
        "entity_type": "Dataset",
        "name": "Penn Treebank",
        "description": "A widely used dataset for parsing English sentences.",
        "domain": "Natural Language Processing",
        "size": "Over 4 million words",
        "year": 1999,
        "creators": [
          "Mitchell Marcus",
          "Beatrice Santorini",
          "Mary Ann Marcinkiewicz"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "DependencyAccuracy_Parsing",
        "entity_type": "Metric",
        "name": "Dependency Accuracy",
        "description": "Measures the accuracy of dependency relations extracted from sentences.",
        "category": "Parsing Evaluation",
        "formula": "Correctly labeled dependencies / Total dependencies"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collins1999_HeadDrivenStatisticalModel",
        "entity_type": "Algorithm",
        "name": "Head-Driven Statistical Model",
        "title": "Head-Driven Statistical Models for Natural Language Parsing",
        "year": 1999,
        "authors": [
          "Michael Collins"
        ],
        "task": [
          "Natural Language Parsing"
        ],
        "datasets": [
          "Penn Treebank"
        ],
        "metrics": [
          "Parsing Accuracy"
        ],
        "architecture": {
          "components": [
            "Statistical Parser"
          ],
          "connections": [
            "Head Rules"
          ],
          "mechanisms": [
            "Probabilistic Context-Free Grammar"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Parameter Estimation"
          ]
        },
        "feature_processing": [
          "Syntactic Analysis"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lin1998_MINIPAR",
        "entity_type": "Algorithm",
        "name": "MINIPAR",
        "title": "Dependency-based evaluation of MINIPAR",
        "year": 1998,
        "authors": [
          "Dekang Lin"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "Various Corpora"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Dependency Parser"
          ],
          "connections": [
            "Rule-based Patterns"
          ],
          "mechanisms": [
            "Dependency Relations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based Parsing"
          ],
          "parameter_tuning": [
            "Rule Definitions"
          ]
        },
        "feature_processing": [
          "Dependency Labeling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sleator1993_LinkParser",
        "entity_type": "Algorithm",
        "name": "Link Parser",
        "title": "Parsing English with a link grammar",
        "year": 1993,
        "authors": [
          "Daniel D. Sleator",
          "Davy Temperley"
        ],
        "task": [
          "Dependency Parsing"
        ],
        "datasets": [
          "Various Corpora"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Link Grammar Parser"
          ],
          "connections": [
            "Link Relations"
          ],
          "mechanisms": [
            "Link Grammar"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based Parsing"
          ],
          "parameter_tuning": [
            "Rule Definitions"
          ]
        },
        "feature_processing": [
          "Dependency Labeling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Gelernter1959_GeometryMachine",
        "entity_type": "Algorithm",
        "name": "Geometry Machine",
        "year": 1959,
        "authors": [
          "Gelernter"
        ],
        "task": [
          "Geometry Theorem Proving"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Heuristic Knowledge",
            "Backward Chaining Search Strategy"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Diagram Analysis"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "CeruttiDavis1969_FORMAC",
        "entity_type": "Algorithm",
        "name": "FORMAC",
        "year": 1969,
        "authors": [
          "Cerutti",
          "Davis"
        ],
        "task": [
          "Elementary Analytic Geometry Theorem Proving"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Symbolic Manipulation"
          ],
          "connections": [],
          "mechanisms": [
            "Descartes' Method"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Efficiency_GeometryTheoremProving",
        "entity_type": "Metric",
        "name": "Efficiency",
        "description": "Efficiency of geometry theorem proving algorithms",
        "category": "Algorithm Performance",
        "formula": "Not explicitly defined"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Ferguson1999_GeoRep",
        "entity_type": "Algorithm",
        "name": "GeoRep",
        "title": "GeoRep: A Flexible Tool for Spatial Representation of Line Drawings",
        "year": 1999,
        "authors": [
          "Ronald W. Ferguson",
          "Kenneth D. Forbus"
        ],
        "task": [
          "Spatial Representation",
          "Diagrammatic Reasoning"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Low-Level Relational Describer (LLRD)",
            "High-Level Relational Describer (HLRD)"
          ],
          "connections": [
            "Visual Operations Library",
            "Reference Frames"
          ],
          "mechanisms": [
            "Proximity Detection",
            "Parallel Lines Detection",
            "Polygon and Polyline Detection",
            "Boundary Description",
            "Interval Relations"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Proximity Calculation",
          "Grouping Rules"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SymmetryStudy_1996",
        "entity_type": "Dataset",
        "name": "Symmetry Study",
        "description": "A dataset of randomly-generated polygons used for symmetry detection experiments.",
        "domain": "Perception and Symmetry Detection",
        "size": 240,
        "year": 1996,
        "creators": [
          "Ferguson, R. W.",
          "Aminoff, A.",
          "Gentner, D."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_SymmetryJudgment",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy of symmetry judgment in polygon perception.",
        "category": "Perception Evaluation",
        "formula": "Correct judgments / Total judgments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "QualitativeFactors_SymmetryJudgment",
        "entity_type": "Metric",
        "name": "Qualitative Factors",
        "description": "Effect of qualitative visual structure on symmetry judgment.",
        "category": "Perception Evaluation",
        "formula": "Significant effect on accuracy even after accounting for metric measures of asymmetry"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_GloVe",
        "entity_type": "Algorithm",
        "name": "GloVe",
        "title": "GloVe: Global Vectors for Word Representation",
        "year": 2014,
        "authors": [
          "Jeffrey Pennington",
          "Richard Socher",
          "Christopher D. Manning"
        ],
        "task": [
          "Word Representation",
          "Word Analogy",
          "Word Similarity",
          "Named Entity Recognition"
        ],
        "datasets": [
          "Wikipedia 2010",
          "Wikipedia 2014",
          "Gigaword 5",
          "Gigaword 5 + Wikipedia 2014",
          "Common Crawl"
        ],
        "metrics": [
          "Accuracy",
          "Spearman Rank Correlation"
        ],
        "architecture": {
          "components": [
            "Word Vectors",
            "Context Vectors",
            "Weighting Function"
          ],
          "connections": [
            "Dot Product"
          ],
          "mechanisms": [
            "Global Log-Bilinear Regression",
            "Weighted Least Squares"
          ]
        },
        "methodology": {
          "training_strategy": [
            "AdaGrad",
            "Stochastic Sampling"
          ],
          "parameter_tuning": [
            "xmax=100",
            "α=3/4",
            "Initial Learning Rate=0.05"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Lowercasing",
          "Co-occurrence Counting"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Wikipedia_2010",
        "entity_type": "Dataset",
        "name": "Wikipedia 2010",
        "description": "A 2010 dump of Wikipedia with 1 billion tokens",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": 2010,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Wikipedia_2014",
        "entity_type": "Dataset",
        "name": "Wikipedia 2014",
        "description": "A 2014 dump of Wikipedia with 1.6 billion tokens",
        "domain": "Natural Language Processing",
        "size": 1600000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Gigaword_5",
        "entity_type": "Dataset",
        "name": "Gigaword 5",
        "description": "A dataset with 4.3 billion tokens",
        "domain": "Natural Language Processing",
        "size": 4300000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Gigaword_5_Wikipedia_2014",
        "entity_type": "Dataset",
        "name": "Gigaword 5 + Wikipedia 2014",
        "description": "A combined dataset with 6 billion tokens",
        "domain": "Natural Language Processing",
        "size": 6000000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Common_Crawl",
        "entity_type": "Dataset",
        "name": "Common Crawl",
        "description": "A dataset with 42 billion tokens of web data",
        "domain": "Natural Language Processing",
        "size": 42000000000,
        "year": 2014,
        "creators": [
          "Stanford University"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_WordAnalogy",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy on the word analogy task",
        "category": "Word Analogy Evaluation",
        "formula": "Correct answers / Total questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpearmanRankCorrelation_WordSimilarity",
        "entity_type": "Metric",
        "name": "Spearman Rank Correlation",
        "description": "Spearman rank correlation on word similarity tasks",
        "category": "Word Similarity Evaluation",
        "formula": "Correlation between ranked word similarities and human judgments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_NER",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "F1 score on the Named Entity Recognition task",
        "category": "Named Entity Recognition Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_ZDC",
        "entity_type": "Algorithm",
        "name": "ZDC",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": 2015,
        "authors": [
          "Zhou",
          "Dai",
          "Chen"
        ],
        "task": "Math Word Problem Solving",
        "datasets": [
          "Alg514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quadratic Programming",
            "Equation Template Selection"
          ],
          "connections": [
            "Problem Sentence Mapping"
          ],
          "mechanisms": [
            "Reduced Search Space"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-Validation"
          ],
          "parameter_tuning": [
            "Template Definition"
          ]
        },
        "feature_processing": [
          "Lexical Similarity Calculation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2016_SIM",
        "entity_type": "Algorithm",
        "name": "SIM",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": 2016,
        "authors": [
          "Huang",
          "Shi",
          "Lin",
          "Yin",
          "Ma"
        ],
        "task": "Math Word Problem Solving",
        "datasets": [
          "Alg514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Similarity-Based Method"
          ],
          "connections": [
            "Template Selection",
            "Template Slot Filling"
          ],
          "mechanisms": [
            "Weighted Jaccard Similarity",
            "Word-Level Edit-Distance"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-Validation"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "TF-IDF Vectorization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin1878_2015",
        "entity_type": "Dataset",
        "name": "Dolphin1878",
        "description": "A dataset of 1,878 number word problems",
        "domain": "Mathematics",
        "size": 1878,
        "year": 2015,
        "creators": [
          "Shi",
          "Wang",
          "Lin",
          "Liu",
          "Rui"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Dolphin18K_2016",
        "entity_type": "Dataset",
        "name": "Dolphin18K",
        "description": "A large-scale dataset of 18,460 annotated math word problems",
        "domain": "Mathematics",
        "size": 18460,
        "year": 2016,
        "creators": [
          "Huang",
          "Shi",
          "Lin",
          "Yin",
          "Ma"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Verb395_2014",
        "entity_type": "Dataset",
        "name": "Verb395",
        "description": "A collection of addition/subtraction problems",
        "domain": "Mathematics",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini",
          "Hajishirzi",
          "Etzioni",
          "Kushman"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SingleEQ_2015",
        "entity_type": "Dataset",
        "name": "SingleEQ",
        "description": "A dataset of 508 single-equation problems",
        "domain": "Mathematics",
        "size": 508,
        "year": 2015,
        "creators": [
          "Koncel-Kedziorski",
          "Hajishirzi",
          "Sabharwal",
          "Etzioni",
          "Ang"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Deng2009_ImageNetConstruction",
        "entity_type": "Algorithm",
        "name": "ImageNet Construction",
        "year": 2009,
        "authors": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ],
        "task": [
          "Image Database Construction"
        ],
        "datasets": [
          "ImageNet"
        ],
        "metrics": [
          "Precision",
          "Coverage",
          "Diversity"
        ],
        "architecture": {
          "components": [
            "WordNet Structure",
            "Amazon Mechanical Turk"
          ],
          "connections": [
            "Synset Linking"
          ],
          "mechanisms": [
            "Candidate Image Collection",
            "Image Verification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Crowdsourcing",
            "Duplicate Removal"
          ],
          "parameter_tuning": [
            "Multiple User Voting",
            "Confidence Score Threshold"
          ]
        },
        "feature_processing": [
          "Image Query Expansion",
          "Translation into Multiple Languages"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ImageNet_2009",
        "entity_type": "Dataset",
        "name": "ImageNet",
        "description": "A large-scale hierarchical image database built upon the WordNet structure",
        "domain": "Computer Vision",
        "size": 3200000,
        "year": 2009,
        "creators": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Coverage_Diversity",
        "entity_type": "Metric",
        "name": "Coverage and Diversity",
        "description": "Measures the comprehensiveness and variety of images within the dataset",
        "category": "Dataset Evaluation",
        "formula": "Number of Categories * Number of Images per Category"
      }
    },
    {
      "metric_entity": {
        "metric_id": "AUC_Classification",
        "entity_type": "Metric",
        "name": "AUC",
        "description": "Area Under the ROC Curve",
        "category": "Classification Evaluation",
        "formula": "Integral of True Positive Rate over False Positive Rate"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collins2008_ActiveLearning",
        "entity_type": "Algorithm",
        "name": "Active Learning Approach",
        "year": 2008,
        "authors": [
          "B. Collins",
          "J. Deng",
          "K. Li",
          "L. Fei-Fei"
        ],
        "task": [
          "Dataset Construction"
        ],
        "datasets": [
          "ImageNet"
        ],
        "metrics": [
          "Precision",
          "Coverage"
        ],
        "architecture": {
          "components": [
            "Active Learning Framework"
          ],
          "connections": [
            "User Interaction"
          ],
          "mechanisms": [
            "Query Selection",
            "Label Propagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Uncertainty Sampling",
            "Query-by-Committee"
          ],
          "parameter_tuning": [
            "Batch Size",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Data Augmentation"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Boiman2008_NBNN",
        "entity_type": "Algorithm",
        "name": "Naive Bayesian Nearest Neighbor (NBNN)",
        "year": 2008,
        "authors": [
          "O. Boiman",
          "E. Shechtman",
          "M. Irani"
        ],
        "task": [
          "Object Recognition"
        ],
        "datasets": [
          "ImageNet"
        ],
        "metrics": [
          "AUC",
          "Precision"
        ],
        "architecture": {
          "components": [
            "Bag-of-Features Representation"
          ],
          "connections": [
            "SIFT Descriptors"
          ],
          "mechanisms": [
            "Nearest Neighbor Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "AdaBoost"
          ],
          "parameter_tuning": [
            "Threshold Setting"
          ]
        },
        "feature_processing": [
          "Feature Normalization",
          "Descriptor Extraction"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hajishirzi2013_NECO",
        "entity_type": "Algorithm",
        "name": "NECO",
        "title": "Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves",
        "year": 2013,
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": [
          "Coreference Resolution",
          "Named-Entity Linking"
        ],
        "datasets": [
          "ACE2004-NWIRE",
          "CONLL2011"
        ],
        "metrics": [
          "MUC",
          "B3",
          "Pairwise",
          "F1"
        ],
        "architecture": {
          "components": [
            "Multi-pass Sieves",
            "NEL-informed Mention-Merging Sieves"
          ],
          "connections": [
            "Coreference Clusters",
            "NEL Constraints"
          ],
          "mechanisms": [
            "Automatic Mention Detection",
            "Entity Link Propagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic Rules",
            "High Precision Sieves First"
          ],
          "parameter_tuning": [
            "Confidence Thresholds for NEL Systems"
          ]
        },
        "feature_processing": [
          "Mention Detection",
          "Entity Linking",
          "Attribute Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CONLL2011_2011",
        "entity_type": "Dataset",
        "name": "CONLL2011",
        "description": "Coreference dataset from five different domains",
        "domain": "Natural Language Processing",
        "size": 625,
        "year": 2011,
        "creators": [
          "Pradhan et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "B3_Coreference",
        "entity_type": "Metric",
        "name": "B3",
        "description": "Computes the proportion of intersection between predicted and gold clusters for every mention",
        "category": "Coreference Evaluation",
        "formula": "Intersection proportion between predicted and gold clusters"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_Coreference",
        "entity_type": "Metric",
        "name": "Pairwise",
        "description": "Measures the accuracy of pairwise coreference decisions",
        "category": "Coreference Evaluation",
        "formula": "Correct pairwise decisions / Total pairwise decisions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_NEL",
        "entity_type": "Metric",
        "name": "F1",
        "description": "Harmonic mean of precision and recall",
        "category": "Named-Entity Linking Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_QuadraticProgrammingSolver",
        "entity_type": "Algorithm",
        "name": "Quadratic Programming Solver",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": 2015,
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": [
          "Algebra Word Problem Solving"
        ],
        "datasets": [
          "Kushman2014_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Log-linear Model",
            "Quadratic Programming"
          ],
          "connections": [
            "Max-margin Objective"
          ],
          "mechanisms": [
            "Constraint Generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin Objective",
            "Quadratic Programming"
          ],
          "parameter_tuning": [
            "C Parameter"
          ]
        },
        "feature_processing": [
          "Single Slot Features",
          "Slot Pair Features",
          "Solution Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Kushman2014_Dataset_2014",
        "entity_type": "Dataset",
        "name": "Kushman2014_Dataset",
        "description": "Benchmark dataset for algebra word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_CombinedFeedbackPerceptron",
        "entity_type": "Algorithm",
        "name": "Combined Feedback Perceptron",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "datasets": [
          "Geoquery_2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary Perceptron",
            "Structured Perceptron"
          ],
          "connections": [
            "Feature Function",
            "Weight Vector"
          ],
          "mechanisms": [
            "Loss Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-driven Updates"
          ],
          "parameter_tuning": [
            "Weight Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geoquery_2014",
        "entity_type": "Dataset",
        "name": "Geoquery",
        "description": "A dataset containing 250 queries for training and 250 for testing.",
        "domain": "Natural Language Processing",
        "size": 500,
        "year": 2014,
        "creators": [
          "Zelle, J.",
          "Mooney, R."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_StructuredPerceptron",
        "entity_type": "Algorithm",
        "name": "Structured Perceptron",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "datasets": [
          "Geoquery_2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Feature Extraction"
          ],
          "mechanisms": [
            "Structured Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Weight Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_BinaryPerceptron",
        "entity_type": "Algorithm",
        "name": "Binary Perceptron",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "datasets": [
          "Geoquery_2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Feature Extraction"
          ],
          "mechanisms": [
            "Binary Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Weight Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_LearningFromNaturalInstructions",
        "entity_type": "Algorithm",
        "name": "Learning from Natural Instructions",
        "year": 2014,
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "Semantic Parsing",
        "datasets": [
          "Solitaire Card Game Rules",
          "Geoquery_2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Semantic Interpreter",
            "Feedback Mechanism"
          ],
          "connections": [
            "Natural Language Instructions",
            "Logical Form"
          ],
          "mechanisms": [
            "Behavioral Feedback",
            "Response-driven Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-driven Updates"
          ],
          "parameter_tuning": [
            "Weight Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_RNNEncoderDecoder",
        "entity_type": "Algorithm",
        "name": "RNN Encoder–Decoder",
        "title": "Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation",
        "year": 2014,
        "authors": [
          "Kyunghyun Cho",
          "Bart van Merriënboer",
          "Caglar Gulcehre",
          "Dzmitry Bahdanau",
          "Fethi Bougares",
          "Holger Schwenk",
          "Yoshua Bengio"
        ],
        "task": [
          "Statistical Machine Translation"
        ],
        "datasets": [
          "Europarl",
          "News Commentary",
          "UN",
          "Crawled Corpora"
        ],
        "metrics": [
          "BLEU Score"
        ],
        "architecture": {
          "components": [
            "Encoder RNN",
            "Decoder RNN"
          ],
          "connections": [
            "Conditional Probability"
          ],
          "mechanisms": [
            "Reset Gate",
            "Update Gate",
            "Hidden Unit"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based Algorithm",
            "Joint Training"
          ],
          "parameter_tuning": [
            "Adadelta",
            "Stochastic Gradient Descent"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Phrase Pair Scoring"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Europarl_2014",
        "entity_type": "Dataset",
        "name": "Europarl",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 61000000,
        "year": 2014,
        "creators": [
          "Philipp Koehn"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NewsCommentary_2014",
        "entity_type": "Dataset",
        "name": "News Commentary",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 5500000,
        "year": 2014,
        "creators": [
          "Philipp Koehn"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "UN_2014",
        "entity_type": "Dataset",
        "name": "UN",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 421000000,
        "year": 2014,
        "creators": [
          "Philipp Koehn"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CrawledCorpora_2014",
        "entity_type": "Dataset",
        "name": "Crawled Corpora",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 870000000,
        "year": 2014,
        "creators": [
          "Philipp Koehn"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEUScore_Translation",
        "entity_type": "Metric",
        "name": "BLEU Score",
        "description": "Evaluation metric for machine translation",
        "category": "Translation Evaluation",
        "formula": "Exponential average of precision scores"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Schwenk2012-CSLM",
        "entity_type": "Algorithm",
        "name": "Continuous Space Language Model (CSLM)",
        "title": "Continuous space language models",
        "year": 2012,
        "authors": [
          "Holger Schwenk"
        ],
        "task": [
          "Language Modeling"
        ],
        "datasets": [
          "Target Corpus"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Embedding Layer",
            "Rectified Layers",
            "Softmax Layer"
          ],
          "connections": [
            "Feedforward"
          ],
          "mechanisms": [
            "Rectified Linear Units"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Uniform Initialization"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Perplexity_LanguageModeling",
        "entity_type": "Metric",
        "name": "Perplexity",
        "description": "Evaluation metric for language modeling",
        "category": "Language Modeling Evaluation",
        "formula": "Inverse of the geometric mean per-word likelihood"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_EquationSolver",
        "entity_type": "Algorithm",
        "name": "EquationSolver",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": [
          "Algebra Word Problem Solving"
        ],
        "datasets": [
          "Algebra.com Dataset_2014"
        ],
        "metrics": [
          "Equation Accuracy",
          "Answer Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Selection",
            "Alignment",
            "Equation Instantiation"
          ],
          "connections": [
            "Log-linear Distribution",
            "Beam Search"
          ],
          "mechanisms": [
            "Latent Variables",
            "Marginal Data Log-likelihood"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Semi-supervised Learning"
          ],
          "parameter_tuning": [
            "L-BFGS",
            "L2-norm Regularization"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Part-of-Speech Tagging",
          "Lematization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Algebra.com_Dataset_2014",
        "entity_type": "Dataset",
        "name": "Algebra.com Dataset",
        "description": "A dataset of algebra word problems collected from Algebra.com",
        "domain": "Natural Language Processing",
        "size": 514,
        "year": 2014,
        "creators": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Equation_Accuracy",
        "entity_type": "Metric",
        "name": "Equation Accuracy",
        "description": "Measures how often the system generates the correct equation system",
        "category": "Equation Generation",
        "formula": "Number of correct equation systems / Total number of equation systems"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Answer_Accuracy",
        "entity_type": "Metric",
        "name": "Answer Accuracy",
        "description": "Measures how often the generated numerical answer is correct",
        "category": "Answer Generation",
        "formula": "Number of correct numerical answers / Total number of numerical answers"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_ARIS",
        "entity_type": "Algorithm",
        "name": "ARIS",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": 2014,
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "MA1_2014",
          "IXL_2014",
          "MA2_2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Entity Recognition",
            "Container Identification",
            "Verb Categorization",
            "State Transition Modeling"
          ],
          "connections": [
            "Dependency Parsing",
            "Coreference Resolution"
          ],
          "mechanisms": [
            "Support Vector Machines",
            "Circumscription Assumption"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-validation",
            "Feature Extraction"
          ],
          "parameter_tuning": [
            "Regularization",
            "Similarity-based Feature Selection"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Named Entity Recognition",
          "Coreference Resolution",
          "Attribute Assignment"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Mitra2016_FormulaBasedSolver",
        "entity_type": "Algorithm",
        "name": "Formula-Based Solver",
        "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
        "year": 2016,
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Variable Identification",
            "Formula Recognition",
            "Equation Generation"
          ],
          "connections": [
            "Part-Whole",
            "Change",
            "Comparison"
          ],
          "mechanisms": [
            "Log-linear Model",
            "Feature Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Parameter Vector θ"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Semantic Relations Extraction",
          "Contextual Information Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AddSub_2014",
        "entity_type": "Dataset",
        "name": "AddSub",
        "description": "A dataset of simple addition-subtraction arithmetic problems for third, fourth, and fifth graders.",
        "domain": "Natural Language Processing",
        "size": 395,
        "year": 2014,
        "creators": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1997_LongShortTermMemory",
        "entity_type": "Algorithm",
        "name": "Long Short-Term Memory (LSTM)",
        "title": "Long Short-Term Memory",
        "year": 1997,
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": [
          "Sequence Modeling",
          "Long Time Lag Problems"
        ],
        "datasets": [],
        "metrics": [
          "Success Rate",
          "Number of Training Sequences"
        ],
        "architecture": {
          "components": [
            "Memory Cells",
            "Input Gates",
            "Output Gates",
            "Constant Error Carousels (CECs)"
          ],
          "connections": [
            "Fully Connected Hidden Layer",
            "Fixed Self-Connections"
          ],
          "mechanisms": [
            "Multiplicative Gates",
            "Truncated Backpropagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated Backpropagation Through Time",
            "Real-Time Recurrent Learning (RTTL)"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Initial Bias Values"
          ]
        },
        "feature_processing": [
          "Local Input/Output Representations",
          "Distributed Representations"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hochreiter1991_ConstantErrorBackprop",
        "entity_type": "Algorithm",
        "name": "Constant Error Backpropagation",
        "title": "Long Short-Term Memory",
        "year": 1991,
        "authors": [
          "Sepp Hochreiter"
        ],
        "task": [
          "Long Time Lag Problems"
        ],
        "datasets": [],
        "metrics": [
          "Error Signal Scaling"
        ],
        "architecture": {
          "components": [
            "Single Unit",
            "Self-Connection"
          ],
          "connections": [
            "Fixed Self-Connection"
          ],
          "mechanisms": [
            "Linear Activation Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated Backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Schmidhuber1992_NeuralSequenceChunker",
        "entity_type": "Algorithm",
        "name": "Neural Sequence Chunker",
        "title": "Long Short-Term Memory",
        "year": 1992,
        "authors": [
          "Jürgen Schmidhuber"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Two Nets"
          ],
          "connections": [
            "Additional Output for Predicting Hidden Unit"
          ],
          "mechanisms": [
            "Hierarchical Chunking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robinson1987_BackPropagationThroughTime",
        "entity_type": "Algorithm",
        "name": "Back-Propagation Through Time (BPTT)",
        "title": "Long Short-Term Memory",
        "year": 1987,
        "authors": [
          "A. J. Robinson",
          "F. Fallside"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Error Signal Scaling"
        ],
        "architecture": {
          "components": [
            "Recurrent Units"
          ],
          "connections": [
            "Temporal Connections"
          ],
          "mechanisms": [
            "Gradient-Based Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robinson1987_RealTimeRecurrentLearning",
        "entity_type": "Algorithm",
        "name": "Real-Time Recurrent Learning (RTRL)",
        "title": "Long Short-Term Memory",
        "year": 1987,
        "authors": [
          "A. J. Robinson",
          "F. Fallside"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Error Signal Scaling"
        ],
        "architecture": {
          "components": [
            "Recurrent Units"
          ],
          "connections": [
            "Temporal Connections"
          ],
          "mechanisms": [
            "Gradient-Based Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Real-Time Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Elman1988_RecurrentCascadeCorrelation",
        "entity_type": "Algorithm",
        "name": "Recurrent Cascade-Correlation (RCC)",
        "title": "Long Short-Term Memory",
        "year": 1988,
        "authors": [
          "Jeffrey Elman"
        ],
        "task": [
          "Sequence Modeling"
        ],
        "datasets": [],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Hidden Units"
          ],
          "connections": [
            "Forward Connections"
          ],
          "mechanisms": [
            "Cascade-Correlation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "SuccessRate_Classification",
        "entity_type": "Metric",
        "name": "Success Rate",
        "description": "Percentage of successful trials",
        "category": "Classification Evaluation",
        "formula": "Number of successful trials / Total number of trials"
      }
    },
    {
      "metric_entity": {
        "metric_id": "TrainingSequences_Number",
        "entity_type": "Metric",
        "name": "Number of Training Sequences",
        "description": "Number of training sequences required to achieve success",
        "category": "Training Efficiency",
        "formula": "Total number of training sequences"
      }
    },
    {
      "metric_entity": {
        "metric_id": "ErrorSignalScaling_ErrorFlow",
        "entity_type": "Metric",
        "name": "Error Signal Scaling",
        "description": "Scaling of error signals during backpropagation",
        "category": "Error Flow Analysis",
        "formula": "Scaling factor applied to error signals"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Antol2015_VQA",
        "entity_type": "Algorithm",
        "name": "VQA",
        "title": "VQA: Visual Question Answering",
        "year": 2015,
        "authors": [
          "Antol, S.",
          "Agrawal, A.",
          "Lu, J.",
          "Mitchell, M.",
          "Batra, D.",
          "Zitnick, C. L.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "datasets": [
          "VQA_2015"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "CNN",
            "LSTM"
          ],
          "connections": [
            "Point-wise Multiplication"
          ],
          "mechanisms": [
            "Multi-layer Perceptron Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": [
            "Adam"
          ]
        },
        "feature_processing": [
          "Image Embedding",
          "Question Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goyal2016_BalancedVQA",
        "entity_type": "Algorithm",
        "name": "Balanced VQA",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": 2016,
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "datasets": [
          "VQA_2015",
          "VQA_v2.0_2016"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "CNN",
            "LSTM",
            "Attention Mechanism"
          ],
          "connections": [
            "Point-wise Multiplication"
          ],
          "mechanisms": [
            "Hierarchical Co-attention",
            "Multimodal Compact Bilinear Pooling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Pairwise Hinge Ranking Loss"
          ],
          "parameter_tuning": [
            "Adam",
            "Normalization"
          ]
        },
        "feature_processing": [
          "Image Embedding",
          "Question Embedding",
          "Counter-example Selection"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fukui2016_MCB",
        "entity_type": "Algorithm",
        "name": "Multimodal Compact Bilinear Pooling (MCB)",
        "title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
        "year": 2016,
        "authors": [
          "Fukui, A.",
          "Park, D. H.",
          "Yang, D.",
          "Rohrbach, A.",
          "Darrell, T.",
          "Rohrbach, M."
        ],
        "task": "Visual Question Answering",
        "datasets": [
          "VQA_2015"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "CNN",
            "LSTM"
          ],
          "connections": [
            "Multimodal Compact Bilinear Pooling"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": [
            "Adam"
          ]
        },
        "feature_processing": [
          "Image Embedding",
          "Question Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Lu2016_HieCoAtt",
        "entity_type": "Algorithm",
        "name": "Hierarchical Co-attention (HieCoAtt)",
        "title": "Hierarchical Question-Image Co-Attention for Visual Question Answering",
        "year": 2016,
        "authors": [
          "Lu, J.",
          "Yang, J.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "Visual Question Answering",
        "datasets": [
          "VQA_2015"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "CNN",
            "LSTM"
          ],
          "connections": [
            "Hierarchical Co-attention"
          ],
          "mechanisms": [
            "Word-level Attention",
            "Phrase-level Attention",
            "Entire Question-level Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": [
            "Adam"
          ]
        },
        "feature_processing": [
          "Image Embedding",
          "Question Embedding"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "VQA_2015",
        "entity_type": "Dataset",
        "name": "VQA",
        "description": "Visual Question Answering dataset with real images and free-form questions",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 614000,
        "year": 2015,
        "creators": [
          "Antol, S.",
          "Agrawal, A.",
          "Lu, J.",
          "Mitchell, M.",
          "Batra, D.",
          "Zitnick, C. L.",
          "Parikh, D."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "VQA_v2.0_2016",
        "entity_type": "Dataset",
        "name": "VQA v2.0",
        "description": "Balanced Visual Question Answering dataset with complementary images",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 1100000,
        "year": 2016,
        "creators": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2018_KNOWLEDGE",
        "entity_type": "Algorithm",
        "name": "KNOWLEDGE",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": 2018,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl",
          "Perturb",
          "Aggregate"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Transfer",
            "Dimensional Analysis",
            "Part-Whole Relation",
            "Explicit Math"
          ],
          "connections": [
            "Declarative Rules"
          ],
          "mechanisms": [
            "Latent Variable Modeling",
            "Concept Selection",
            "Rule Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two Stage Learning",
            "Latent Structured SVM"
          ],
          "parameter_tuning": [
            "Beam Search",
            "Feature Extraction"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Coreference Resolution",
          "Verb Classification",
          "Rate Component Detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArith_2017",
        "entity_type": "Dataset",
        "name": "AllArith",
        "description": "A dataset of arithmetic word problems",
        "domain": "Mathematics",
        "size": 831,
        "year": 2017,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithLex_2017",
        "entity_type": "Dataset",
        "name": "AllArithLex",
        "description": "Subset of AllArith to test robustness to new vocabulary",
        "domain": "Mathematics",
        "size": 831,
        "year": 2017,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AllArithTmpl_2017",
        "entity_type": "Dataset",
        "name": "AllArithTmpl",
        "description": "Subset of AllArith to test robustness to new equation forms",
        "domain": "Mathematics",
        "size": 831,
        "year": 2017,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Perturb_2018",
        "entity_type": "Dataset",
        "name": "Perturb",
        "description": "New dataset created by perturbing AllArith problems",
        "domain": "Mathematics",
        "size": 661,
        "year": 2018,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Aggregate_2018",
        "entity_type": "Dataset",
        "name": "Aggregate",
        "description": "Combined dataset of AllArith and Perturb",
        "domain": "Mathematics",
        "size": 1492,
        "year": 2018,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_MathDQN",
        "entity_type": "Algorithm",
        "name": "MathDQN",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "AI2",
          "IL",
          "CC",
          "ArithS",
          "ArithM"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Deep Q-Network",
            "Feed-forward Neural Network"
          ],
          "connections": [
            "Two-layer Feed-forward Neural Network"
          ],
          "mechanisms": [
            "Reinforcement Learning",
            "Experience Replay Memory",
            "Epsilon-Greedy Strategy"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient Descent",
            "Mini-batch Gradient Update",
            "Experience Replay"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Discount Factor",
            "Replay Memory Size"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Feature Vector Construction",
          "Re-order Mechanism"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AI2_2014",
        "entity_type": "Dataset",
        "name": "AI2",
        "description": "Contains 395 single-step or multi-step arithmetic word problems involving only addition and subtraction.",
        "domain": "Arithmetic Word Problems",
        "size": 395,
        "year": 2014,
        "creators": [
          "Hosseini et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IL_2015",
        "entity_type": "Dataset",
        "name": "IL",
        "description": "Contains 562 single-step word problems with one operator, including addition, subtraction, multiplication, and division.",
        "domain": "Arithmetic Word Problems",
        "size": 562,
        "year": 2015,
        "creators": [
          "Roy, Vieira, and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CC_2015",
        "entity_type": "Dataset",
        "name": "CC",
        "description": "Contains 600 multi-step problems without irrelevant quantities, harvested from commoncoresheets.",
        "domain": "Arithmetic Word Problems",
        "size": 600,
        "year": 2015,
        "creators": [
          "Roy and Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ArithS_2018",
        "entity_type": "Dataset",
        "name": "ArithS",
        "description": "Subset of the union of AI2, IL and CC, contains 890 single-step arithmetic problems that involve only one operator.",
        "domain": "Arithmetic Word Problems",
        "size": 890,
        "year": 2018,
        "creators": [
          "Wang et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ArithM_2018",
        "entity_type": "Dataset",
        "name": "ArithM",
        "description": "Collected from AI2⋃ IL⋃ CC, contains 667 multi-step arithmetic problems that involve at least two operators.",
        "domain": "Arithmetic Word Problems",
        "size": 667,
        "year": 2018,
        "creators": [
          "Wang et al."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Luong2016_MultiTaskSeq2Seq",
        "entity_type": "Algorithm",
        "name": "Multi-task Sequence to Sequence Learning",
        "title": "Multi-task Sequence to Sequence Learning",
        "year": 2016,
        "authors": [
          "Minh-Thang Luong",
          "Quoc V. Le",
          "Ilya Sutskever",
          "Oriol Vinyals",
          "Lukasz Kaiser"
        ],
        "task": [
          "Machine Translation",
          "Constituency Parsing",
          "Image Caption Generation"
        ],
        "datasets": [
          "WMT'15",
          "Penn Tree Bank",
          "High-Confidence Corpus",
          "Image Caption Dataset"
        ],
        "metrics": [
          "BLEU",
          "F1 Score",
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks",
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Long Short-Term Memory (LSTM)",
            "Gated Recurrent Unit (GRU)"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Parameter Updates Allocation"
          ],
          "parameter_tuning": [
            "SGD",
            "Learning Rate Adjustment"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Embeddings"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT_2015",
        "entity_type": "Dataset",
        "name": "WMT'15",
        "description": "Parallel corpus for English-German translation",
        "domain": "Natural Language Processing",
        "size": 4500000,
        "year": 2015,
        "creators": [
          "Bojar et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreeBank_1993",
        "entity_type": "Dataset",
        "name": "Penn Tree Bank",
        "description": "Corpus for syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 40000,
        "year": 1993,
        "creators": [
          "Marcus et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "HighConfidenceCorpus_2015",
        "entity_type": "Dataset",
        "name": "High-Confidence Corpus",
        "description": "Large corpus for syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 11000000,
        "year": 2015,
        "creators": [
          "Vinyals et al."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ImageCaptionDataset_2015",
        "entity_type": "Dataset",
        "name": "Image Caption Dataset",
        "description": "Dataset of image-caption pairs",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 596000,
        "year": 2015,
        "creators": [
          "Vinyals et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_Translation",
        "entity_type": "Metric",
        "name": "BLEU",
        "description": "Evaluation metric for machine translation",
        "category": "Translation Evaluation",
        "formula": "Exponential averaging of modified n-gram precision"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Parsing",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Evaluation metric for parsing",
        "category": "Parsing Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sundaram2015_WordProblemSolver",
        "entity_type": "Algorithm",
        "name": "Word Problem Solver",
        "title": "Natural Language Processing for Solving Simple Word Problems",
        "year": 2015,
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Hosseini2014_DS1",
          "Hosseini2014_DS2",
          "Hosseini2014_DS3"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Simplification Module",
            "Analysis Module",
            "Knowledge Representation Module",
            "Temporal Schemas"
          ],
          "connections": [
            "Dependency Parsing",
            "Stanford CoreNLP Suite"
          ],
          "mechanisms": [
            "Schema Matching",
            "Temporal Ordering",
            "Common Sense Law of Inertia"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Conjunction Resolution",
          "Currency Preprocessing",
          "Co-reference Resolution",
          "Sentence Preprocessing",
          "Entity Resolution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Hosseini2014_DS1",
        "entity_type": "Dataset",
        "name": "DS1",
        "description": "Dataset with simple word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Hosseini2014_DS2",
        "entity_type": "Dataset",
        "name": "DS2",
        "description": "Dataset with moderate complexity word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Hosseini2014_DS3",
        "entity_type": "Dataset",
        "name": "DS3",
        "description": "Dataset with complex word problems",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2018_CASS",
        "entity_type": "Algorithm",
        "name": "CASS",
        "title": "Neural Math Word Problem Solver with Reinforcement Learning",
        "year": 2018,
        "authors": [
          "Danqing Huang",
          "Jing Liu",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Copy Mechanism",
            "Alignment Mechanism"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "Gated Recurrent Unit",
            "Policy Gradient"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning",
            "Policy Gradient",
            "Pre-training with Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "SGD Optimizer",
            "Decaying Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Tokenization",
          "Equation Normalization"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NumWord_2015",
        "entity_type": "Dataset",
        "name": "NumWord",
        "description": "Contains 2,871 number word problems with 1,183 templates",
        "domain": "Mathematics",
        "size": 2871,
        "year": 2015,
        "creators": [
          "Shi et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Solution_Accuracy",
        "entity_type": "Metric",
        "name": "Solution Accuracy",
        "description": "The proportion of correctly solved math word problems",
        "category": "Math Word Problem Solving Evaluation",
        "formula": "Number of Correct Solutions / Total Number of Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Koncel-Kedziorski2015_ALGES",
        "entity_type": "Algorithm",
        "name": "ALGES",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": 2015,
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": [
          "Algebraic Word Problem Solving"
        ],
        "datasets": [
          "SINGLEEQ"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming (ILP)",
            "Local Model",
            "Global Model"
          ],
          "connections": [
            "Equation Tree Generation",
            "Feature Extraction"
          ],
          "mechanisms": [
            "Quantified Sets (Qsets)",
            "Reordering Rules",
            "Bottom-Up Scoring"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision",
            "Discriminative Models"
          ],
          "parameter_tuning": [
            "LIBSVM with RBF Kernel"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Semantic Features",
          "Lexical Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SINGLEEQ_2015",
        "entity_type": "Dataset",
        "name": "SINGLEEQ",
        "description": "Grade-school algebra word problems that map to single equations",
        "domain": "Natural Language Processing",
        "size": 508,
        "year": 2015,
        "creators": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Hosseini2014_VerbCategorization",
        "entity_type": "Algorithm",
        "name": "Verb-Categorization",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": 2014,
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "ADDSUB"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Verb Categories",
            "Semantic Parsing"
          ],
          "connections": [
            "Rule-Based Filtering"
          ],
          "mechanisms": [
            "Dependency Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Rule-Based"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Lexical Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ADDSUB_2014",
        "entity_type": "Dataset",
        "name": "ADDSUB",
        "description": "Addition and subtraction word problems with irrelevant distractor quantities",
        "domain": "Natural Language Processing",
        "year": 2014,
        "creators": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_TemplateBased",
        "entity_type": "Algorithm",
        "name": "Template-Based",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": 2014,
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": [
          "Algebraic Word Problem Solving"
        ],
        "datasets": [
          "SINGLEEQ"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Global and Local Features"
          ],
          "connections": [
            "Template Matching"
          ],
          "mechanisms": [
            "Dependency Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Fully Supervised Learning"
          ],
          "parameter_tuning": [
            "Template Matching"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Lexical Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_CompositionalVectorGrammar",
        "entity_type": "Algorithm",
        "name": "Compositional Vector Grammar (CVG)",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "Syntactic Parsing",
        "datasets": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Probabilistic Context-Free Grammar (PCFG)",
            "Recursive Neural Network (RNN)"
          ],
          "connections": [
            "Syntactically Untied Weights"
          ],
          "mechanisms": [
            "Max-Margin Training Objective",
            "Bottom-Up Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CKY Dynamic Programming",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Regularization",
            "Mini-batch Size",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PennTreebankWSJ_2013",
        "entity_type": "Dataset",
        "name": "Penn Treebank WSJ",
        "year": 2013,
        "creators": [
          "Various contributors"
        ],
        "domain": "Natural Language Processing",
        "size": "Varies by section",
        "description": "Wall Street Journal section of the Penn Treebank"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Parsing",
        "entity_type": "Metric",
        "name": "F1 Score",
        "category": "Parsing Evaluation",
        "description": "Harmonic mean of precision and recall",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_SyntacticallyUntiedRecursiveNeuralNetwork",
        "entity_type": "Algorithm",
        "name": "Syntactically Untied Recursive Neural Network (SU-RNN)",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "Syntactic Parsing",
        "datasets": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Recursive Neural Network (RNN)"
          ],
          "connections": [
            "Syntactically Untied Weights"
          ],
          "mechanisms": [
            "Max-Margin Training Objective",
            "Bottom-Up Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CKY Dynamic Programming",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Regularization",
            "Mini-batch Size",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Socher2013_StandardRecursiveNeuralNetwork",
        "entity_type": "Algorithm",
        "name": "Standard Recursive Neural Network (RNN)",
        "year": 2013,
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "Syntactic Parsing",
        "datasets": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Recursive Neural Network (RNN)"
          ],
          "connections": [
            "Fully Tied Weights"
          ],
          "mechanisms": [
            "Max-Margin Training Objective",
            "Bottom-Up Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CKY Dynamic Programming",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Regularization",
            "Mini-batch Size",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Stanford2013_FactoredParser",
        "entity_type": "Algorithm",
        "name": "Stanford Factored Parser",
        "year": 2013,
        "authors": [
          "Christopher D. Manning",
          "Dan Klein"
        ],
        "task": "Syntactic Parsing",
        "datasets": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Factored Model"
          ],
          "connections": [
            "Standard PCFG"
          ],
          "mechanisms": [
            "Max-Margin Training Objective"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CKY Dynamic Programming"
          ],
          "parameter_tuning": [
            "Regularization"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Berkeley2007_Parser",
        "entity_type": "Algorithm",
        "name": "Berkeley Parser",
        "year": 2007,
        "authors": [
          "Sergey Petrov",
          "Dan Klein"
        ],
        "task": "Syntactic Parsing",
        "datasets": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Probabilistic CFG"
          ],
          "connections": [
            "Latent Annotations"
          ],
          "mechanisms": [
            "Max-Margin Training Objective"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CKY Dynamic Programming"
          ],
          "parameter_tuning": [
            "Regularization"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Charniak2000_MaximumEntropyParser",
        "entity_type": "Algorithm",
        "name": "Maximum-Entropy-Inspired Parser",
        "year": 2000,
        "authors": [
          "Eugene Charniak"
        ],
        "task": "Syntactic Parsing",
        "datasets": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Maximum Entropy Model"
          ],
          "connections": [
            "Standard PCFG"
          ],
          "mechanisms": [
            "Max-Margin Training Objective"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CKY Dynamic Programming"
          ],
          "parameter_tuning": [
            "Regularization"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_QuantityExtraction",
        "entity_type": "Algorithm",
        "name": "QuantityExtraction",
        "title": "Reasoning about Quantities in Natural Language",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": [
          "Quantity Recognition",
          "Quantity Standardization"
        ],
        "datasets": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Segmentation",
            "Standardization"
          ],
          "connections": [
            "Semi-CRF",
            "Bank of Classifiers"
          ],
          "mechanisms": [
            "Parameter Averaging",
            "Perceptron"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "Semi-CRF",
            "Bank of Classifiers"
          ]
        },
        "feature_processing": [
          "Word Class Features",
          "Character-based Features",
          "Part of Speech Tags"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_QuantityEntailment",
        "entity_type": "Algorithm",
        "name": "QuantityEntailment",
        "title": "Reasoning about Quantities in Natural Language",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": [
          "Quantity Entailment"
        ],
        "datasets": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Extraction Phase",
            "Reasoning Phase"
          ],
          "connections": [
            "Implicit Quantity Productions",
            "Quantity Comparisons"
          ],
          "mechanisms": [
            "Monotonicity Verification",
            "Coreference Resolution",
            "Semantic Role Labeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based Standardization",
            "Implicit Quantity Production Rules"
          ],
          "parameter_tuning": [
            "Monotonicity Verification",
            "Coreference Resolution",
            "Semantic Role Labeling"
          ]
        },
        "feature_processing": [
          "WordNet Synsets",
          "Coreference Resolution",
          "Semantic Role Labeling"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2015_MathWordProblemSolver",
        "entity_type": "Algorithm",
        "name": "MathWordProblemSolver",
        "title": "Reasoning about Quantities in Natural Language",
        "year": 2015,
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Elementary Math Word Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quantity Pair Classifier",
            "Operation Classifier",
            "Order Classifier"
          ],
          "connections": [
            "Cascade of Classifiers"
          ],
          "mechanisms": [
            "Sparse Averaged Perceptron"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gold Annotations",
            "SNOW Framework"
          ],
          "parameter_tuning": [
            "Feature Functions",
            "Learned Weight Vectors"
          ]
        },
        "feature_processing": [
          "Unigrams and Bigrams",
          "POS Tags",
          "Relevant Pair of Quantities"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "RTE_Datasets_2006",
        "entity_type": "Dataset",
        "name": "RTE Datasets",
        "description": "Textual Entailment datasets used for evaluating entailment decisions",
        "domain": "Natural Language Processing",
        "size": 384,
        "year": 2006,
        "creators": [
          "Dagan, I.",
          "Glickman, O.",
          "Magnini, B."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Newswire_Text_2015",
        "entity_type": "Dataset",
        "name": "Newswire Text",
        "description": "Sentences from news articles containing quantity mentions",
        "domain": "Natural Language Processing",
        "size": 600,
        "year": 2015,
        "creators": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Elementary_Math_Word_Problems_2015",
        "entity_type": "Dataset",
        "name": "Elementary Math Word Problems",
        "description": "Math word problems collected from educational websites",
        "domain": "Mathematics Education",
        "size": 750,
        "year": 2015,
        "creators": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1_Score_Quantitative_Inference",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Quantitative Inference Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_Quantitative_Inference",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Proportion of true positive predictions among all positive predictions",
        "category": "Quantitative Inference Evaluation",
        "formula": "True Positives / (True Positives + False Positives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_Quantitative_Inference",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Proportion of true positive predictions among all actual positives",
        "category": "Quantitative Inference Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Math_Word_Problems",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Proportion of correctly solved math word problems",
        "category": "Math Word Problem Solving Evaluation",
        "formula": "Correct Answers / Total Problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Jung2004_WindowedHoughTransform",
        "entity_type": "Algorithm",
        "name": "Windowed Hough Transform",
        "title": "Rectangle detection based on a windowed Hough transform",
        "year": 2004,
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": [
          "Rectangle Detection"
        ],
        "datasets": [
          "Synthetic images",
          "Natural images"
        ],
        "metrics": [
          "Detection accuracy"
        ],
        "architecture": {
          "components": [
            "Sliding window",
            "Hough Transform",
            "Peak extraction"
          ],
          "connections": [
            "Geometric constraints"
          ],
          "mechanisms": [
            "Local maxima detection",
            "Butterfly pattern analysis"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter tuning for thresholds"
          ],
          "parameter_tuning": [
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge detection",
          "Canny's operator"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SyntheticImages_2004",
        "entity_type": "Dataset",
        "name": "Synthetic images",
        "description": "Images containing geometric objects for testing rectangle detection algorithms",
        "domain": "Computer Vision",
        "year": 2004,
        "creators": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NaturalImages_2004",
        "entity_type": "Dataset",
        "name": "Natural images",
        "description": "Real-world images for testing rectangle detection algorithms",
        "domain": "Computer Vision",
        "year": 2004,
        "creators": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "DetectionAccuracy_RectangleDetection",
        "entity_type": "Metric",
        "name": "Detection accuracy",
        "description": "Accuracy of detecting rectangles in images",
        "category": "Object Detection",
        "formula": "Number of correctly detected rectangles / Total number of rectangles"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Zhu2003_RectangularHoughTransform",
        "entity_type": "Algorithm",
        "name": "Rectangular Hough Transform (RHT)",
        "title": "Automatic particle detection through efficient hough transforms",
        "year": 2003,
        "authors": [
          "Y. Zhu",
          "B. Carragher",
          "F. Mouche",
          "C. Potter"
        ],
        "task": [
          "Particle detection"
        ],
        "datasets": [
          "Cryo-electron microscopy images"
        ],
        "metrics": [
          "Detection accuracy"
        ],
        "architecture": {
          "components": [
            "2-D accumulator array"
          ],
          "connections": [
            "Center and orientation detection"
          ],
          "mechanisms": [
            "Fast detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter tuning for dimensions"
          ],
          "parameter_tuning": [
            "Known dimensions"
          ]
        },
        "feature_processing": [
          "Edge detection"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CryoElectronMicroscopyImages_2003",
        "entity_type": "Dataset",
        "name": "Cryo-electron microscopy images",
        "description": "Images used for detecting particles in cryo-electron microscopy",
        "domain": "Biomedical Imaging",
        "year": 2003,
        "creators": [
          "Y. Zhu",
          "B. Carragher",
          "F. Mouche",
          "C. Potter"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bakman2023_ROBUST",
        "entity_type": "Algorithm",
        "name": "ROBUST",
        "title": "ROBUST UNDERSTANDING OF WORD PROBLEMS WITH EXTRANEOUS INFORMATION",
        "year": 2023,
        "authors": [
          "Bakman, Y."
        ],
        "task": [
          "Word Problem Solving"
        ],
        "datasets": [
          "Custom Word Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Parser",
            "Schema Instantiation Creator",
            "Change Formula Matcher"
          ],
          "connections": [
            "Schema Instantiation to Proposition Matching"
          ],
          "mechanisms": [
            "Change Verb Categorization",
            "Cautious Strategy"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Natural Language Parsing",
            "Schema Matching"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Sentence Splitting",
          "Variable Substitution"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Custom_Word_Problems_2023",
        "entity_type": "Dataset",
        "name": "Custom Word Problems",
        "description": "A collection of multi-step arithmetic word problems with extraneous information.",
        "domain": "Education",
        "size": "Not specified",
        "year": 2023,
        "creators": [
          "Bakman, Y."
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kwiatkowski2013_SemanticParser",
        "entity_type": "Algorithm",
        "name": "Semantic Parser with On-the-fly Ontology Matching",
        "title": "Scaling Semantic Parsers with On-the-fly Ontology Matching",
        "year": 2013,
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": [
          "Question Answering",
          "Semantic Parsing"
        ],
        "datasets": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall",
          "Precision",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Probabilistic CCG",
            "Ontology Matching Model"
          ],
          "connections": [
            "CCG Parsing",
            "Logical Form Transformation"
          ],
          "mechanisms": [
            "Domain-independent Parsing",
            "Structure Matching",
            "Constant Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Perceptron",
            "Latent Variable Learning"
          ],
          "parameter_tuning": [
            "Feature Weights"
          ]
        },
        "feature_processing": [
          "Word Class Information from Wiktionary",
          "Lexical Features",
          "Structural Features",
          "Knowledge Base Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "GeoQuery_1996",
        "entity_type": "Dataset",
        "name": "GeoQuery",
        "description": "Geography database with a small ontology and questions with relatively complex, compositional structure.",
        "domain": "Geography",
        "size": null,
        "year": 1996,
        "creators": [
          "Zelle, J.",
          "Mooney, R."
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "FreebaseQA_2013",
        "entity_type": "Dataset",
        "name": "Freebase QA",
        "description": "Questions to Freebase, a large community-authored database that spans many sub-domains.",
        "domain": "Open-domain Question Answering",
        "size": 917,
        "year": 2013,
        "creators": [
          "Cai, Q.",
          "Yates, A."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Recall_QA",
        "entity_type": "Metric",
        "name": "Recall",
        "description": "Percentage of total questions answered correctly.",
        "category": "Question Answering Evaluation",
        "formula": "Number of Correct Answers / Total Number of Questions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Precision_QA",
        "entity_type": "Metric",
        "name": "Precision",
        "description": "Percentage of produced queries with correct answers.",
        "category": "Question Answering Evaluation",
        "formula": "Number of Correct Queries / Total Number of Produced Queries"
      }
    },
    {
      "metric_entity": {
        "metric_id": "F1Score_QA",
        "entity_type": "Metric",
        "name": "F1 Score",
        "description": "Harmonic mean of Precision and Recall.",
        "category": "Question Answering Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Chiang2019_SemanticallyAlignedEquationGenerator",
        "entity_type": "Algorithm",
        "name": "Semantically-Aligned Equation Generator",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": 2019,
        "authors": [
          "Ting-Rui Chiang",
          "Yun-Nung Chen"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "BLSTM",
            "LSTM",
            "Gated Mechanisms"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Semantic Representation Extraction",
          "External Constant Leveraging"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Knuth1968_ContextFreeSemanticsAlgorithm",
        "entity_type": "Algorithm",
        "name": "Context-Free Semantics Algorithm",
        "year": 1968,
        "authors": [
          "Donald E. Knuth"
        ],
        "task": [
          "Semantic Analysis of Context-Free Languages"
        ],
        "architecture": {
          "components": [
            "Directed Graph Construction"
          ],
          "connections": [
            "Graph Inclusion Rules"
          ],
          "mechanisms": [
            "Cycle Detection"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Sutskever2014_SequenceToSequenceLearning",
        "entity_type": "Algorithm",
        "name": "Sequence to Sequence Learning with Neural Networks",
        "year": 2014,
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q. V."
        ],
        "task": [
          "Machine Translation"
        ],
        "datasets": [
          "WMT'14 English to French"
        ],
        "metrics": [
          "BLEU"
        ],
        "architecture": {
          "components": [
            "Multilayered LSTM",
            "Deep LSTM"
          ],
          "connections": [
            "Fixed-dimensional vector representation"
          ],
          "mechanisms": [
            "Long Short-Term Memory"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised backpropagation",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning rate decay",
            "Gradient clipping"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Reversing source sentences"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WMT14_EnglishToFrench",
        "entity_type": "Dataset",
        "name": "WMT'14 English to French",
        "description": "A large-scale dataset for English to French translation",
        "domain": "Natural Language Processing",
        "size": 12000000,
        "year": 2014,
        "creators": [
          "WMT"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_TranslationQuality",
        "entity_type": "Metric",
        "name": "BLEU",
        "description": "Bilingual Evaluation Understudy",
        "category": "Translation Quality",
        "formula": "Exponential averaging of modified n-gram precision"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wiseman2016_BSO",
        "entity_type": "Algorithm",
        "name": "Beam Search Optimization (BSO)",
        "title": "Sequence-to-Sequence Learning as Beam-Search Optimization",
        "year": 2016,
        "authors": [
          "Sam Wiseman",
          "Alexander M. Rush"
        ],
        "task": [
          "Word Ordering",
          "Dependency Parsing",
          "Machine Translation"
        ],
        "datasets": [
          "PTB",
          "Penn Treebank",
          "IWSLT 2014 German-to-English"
        ],
        "metrics": [
          "BLEU",
          "UAS",
          "LAS"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Global Attention Model"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "LSTM",
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Optimization",
            "LaSO Framework",
            "Curriculum Beam"
          ],
          "parameter_tuning": [
            "Adagrad",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Input Feeding",
          "Word Embeddings"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PTB_2016",
        "entity_type": "Dataset",
        "name": "PTB",
        "description": "Penn Treebank dataset for word ordering and dependency parsing",
        "domain": "Natural Language Processing",
        "size": "Varies",
        "year": 2016,
        "creators": [
          "Zhang and Clark"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IWSLT2014_German_to_English_2016",
        "entity_type": "Dataset",
        "name": "IWSLT 2014 German-to-English",
        "description": "Dataset for machine translation from German to English",
        "domain": "Machine Translation",
        "size": "153K training sentences, 7K development sentences, 7K test sentences",
        "year": 2016,
        "creators": [
          "Cettolo et al."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "UAS_Parsing",
        "entity_type": "Metric",
        "name": "UAS",
        "description": "Unlabeled Attachment Score for evaluating dependency parsing",
        "category": "Dependency Parsing Evaluation",
        "formula": "Percentage of correct head-word attachments"
      }
    },
    {
      "metric_entity": {
        "metric_id": "LAS_Parsing",
        "entity_type": "Metric",
        "name": "LAS",
        "description": "Labeled Attachment Score for evaluating dependency parsing",
        "category": "Dependency Parsing Evaluation",
        "formula": "Percentage of correct head-word attachments with correct labels"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Haghighi2009_SimpleCoreferenceResolution",
        "entity_type": "Algorithm",
        "name": "Simple Coreference Resolution",
        "title": "Simple Coreference Resolution with Rich Syntactic and Semantic Features",
        "year": 2009,
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": [
          "Coreference Resolution"
        ],
        "datasets": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST",
          "BLIPP",
          "WIKI"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module",
            "Selection Module"
          ],
          "connections": [
            "Syntactic Paths",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Syntactic Constraints",
            "Semantic Compatibility",
            "Tree Distance"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning",
            "Deterministic Rules"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Parsing",
          "NER Tagging",
          "Headword Extraction"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004-ROTH-DEV_2004",
        "entity_type": "Dataset",
        "name": "ACE2004-ROTH-DEV",
        "description": "Development set split of the ACE 2004 training set",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": 2004,
        "creators": [
          "Bengston",
          "Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MUC-6-TEST_1995",
        "entity_type": "Dataset",
        "name": "MUC-6-TEST",
        "description": "MUC6 formal evaluation set",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": 1995,
        "creators": [
          "Vilain",
          "Burger",
          "Aberdeen",
          "Connolly",
          "Hirschman"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "BLIPP_2000",
        "entity_type": "Dataset",
        "name": "BLIPP",
        "description": "1.8 million sentences of newswire parsed with the Charniak parser",
        "domain": "Natural Language Processing",
        "size": 1800000,
        "year": 2000,
        "creators": [
          "Charniak"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "WIKI_2003",
        "entity_type": "Dataset",
        "name": "WIKI",
        "description": "25k articles of English Wikipedia abstracts parsed by the Klein and Manning parser",
        "domain": "Natural Language Processing",
        "size": 25000,
        "year": 2003,
        "creators": [
          "Klein",
          "Manning"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Pairwise_F1_Coreference",
        "entity_type": "Metric",
        "name": "Pairwise F1",
        "description": "Precision, recall, and F1 over all pairs of mentions in the same entity cluster",
        "category": "Coreference Evaluation",
        "formula": "F1 = 2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "b3_Coreference",
        "entity_type": "Metric",
        "name": "b3",
        "description": "For each mention, form the intersection between the predicted cluster and the true cluster for that mention",
        "category": "Coreference Evaluation",
        "formula": "F1 = 2 * (precision * recall) / (precision + recall)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2016_ExpressionTreeBasedSolver",
        "entity_type": "Algorithm",
        "name": "Expression Tree Based Solver",
        "title": "Solving General Arithmetic Word Problems",
        "year": 2016,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "AI2 Dataset",
          "IL Dataset",
          "Commoncore Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Monotonic Expression Tree",
            "Quantity Schema"
          ],
          "connections": [
            "LCA Operations",
            "Relevance Classification"
          ],
          "mechanisms": [
            "Constrained Inference Framework",
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Multiclass SVM",
            "Binary SVM"
          ],
          "parameter_tuning": [
            "wIRR"
          ]
        },
        "feature_processing": [
          "Unit Features",
          "Related NP Features",
          "Miscellaneous Features",
          "Question Features"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "AI2_Dataset_2014",
        "entity_type": "Dataset",
        "name": "AI2 Dataset",
        "description": "A collection of 395 addition and subtraction problems",
        "domain": "Arithmetic Word Problems",
        "size": 395,
        "year": 2014,
        "creators": [
          "M. J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "IL_Dataset_2015",
        "entity_type": "Dataset",
        "name": "IL Dataset",
        "description": "A collection of arithmetic problems that can be solved by performing one operation",
        "domain": "Arithmetic Word Problems",
        "size": 562,
        "year": 2015,
        "creators": [
          "S. Roy",
          "T. Vieira",
          "D. Roth"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Commoncore_Dataset_2016",
        "entity_type": "Dataset",
        "name": "Commoncore Dataset",
        "description": "A new dataset of multi-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 600,
        "year": 2016,
        "creators": [
          "Subhro Roy",
          "Dan Roth"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Relax_Accuracy",
        "entity_type": "Metric",
        "name": "Relax Accuracy",
        "description": "Fraction of quantities or quantity pairs which the classifier got correct",
        "category": "Partial Evaluation",
        "formula": "Correct predictions / Total predictions"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Strict_Accuracy",
        "entity_type": "Metric",
        "name": "Strict Accuracy",
        "description": "Fraction of math problems for which all quantities or quantity pairs were correctly classified",
        "category": "Complete Evaluation",
        "formula": "Perfectly correct problems / Total problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Seo2015_GEOS",
        "entity_type": "Algorithm",
        "name": "GEOS",
        "title": "Solving Geometry Problems: Combining Text and Diagram Interpretation",
        "year": 2015,
        "authors": [
          "Minjoon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni",
          "Clint Malcolm"
        ],
        "task": [
          "Geometry Problem Solving"
        ],
        "datasets": [
          "SAT Geometry Questions"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Text Parser",
            "Diagram Parser",
            "Optimization Module",
            "Solver"
          ],
          "connections": [
            "Submodular Optimization",
            "Greedy Algorithm"
          ],
          "mechanisms": [
            "Hypergraph Representation",
            "Log-linear Model",
            "Bridging Relations",
            "Coordinating Conjunctions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "L2 Regularization",
            "Trade-off Parameter λ"
          ]
        },
        "feature_processing": [
          "Concept Identification",
          "Relation Identification",
          "Relation Completion",
          "Equation Analyzer"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "SAT_Geometry_Questions_2015",
        "entity_type": "Dataset",
        "name": "SAT Geometry Questions",
        "description": "A dataset of SAT plane geometry questions with textual descriptions, diagrams, and multiple-choice answers.",
        "domain": "Natural Language Processing and Geometry",
        "size": 186,
        "year": 2015,
        "creators": [
          "Minjoon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni",
          "Clint Malcolm"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_SAT",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Percentage of correctly answered questions penalized by the wrong answers.",
        "category": "Classification Evaluation",
        "formula": "Correctly Answered Questions - (0.25 * Incorrectly Answered Questions)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2016_RelationKnowledgePoweredModel",
        "entity_type": "Algorithm",
        "name": "Relation Knowledge Powered Model (RK)",
        "title": "Solving Verbal Questions in IQ Test by Knowledge-Powered Word Embedding",
        "year": 2016,
        "authors": [
          "Huazheng Wang",
          "Fei Tian",
          "Bin Gao",
          "Chengjieren Zhu",
          "Jiang Bian",
          "Tie-Yan Liu"
        ],
        "task": [
          "Verbal Comprehension Questions in IQ Tests"
        ],
        "datasets": [
          "wiki2014",
          "VerbalQuestions"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Question Classifier",
            "Word-Sense Pair Embeddings",
            "Relation Embeddings"
          ],
          "connections": [
            "Co-learning of Word-Sense Pairs and Relations"
          ],
          "mechanisms": [
            "Multi-Sense Identification",
            "Relational Knowledge Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Back Propagation Neural Networks",
            "Margin-Based Regularization"
          ],
          "parameter_tuning": [
            "Embedding Dimension",
            "Negative Sampling Count",
            "Epoch Number"
          ]
        },
        "feature_processing": [
          "TF-IDF",
          "Context Window Clustering",
          "Spherical k-means"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "wiki2014_2016",
        "entity_type": "Dataset",
        "name": "wiki2014",
        "description": "A large text snapshot from Wikipedia",
        "domain": "Natural Language Processing",
        "size": 3400000000,
        "year": 2016,
        "creators": [
          "Wikipedia Contributors"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "VerbalQuestions_2016",
        "entity_type": "Dataset",
        "name": "VerbalQuestions",
        "description": "A collection of verbal comprehension questions from published IQ test books",
        "domain": "Intelligence Testing",
        "size": 232,
        "year": 2016,
        "creators": [
          "Philip Carter",
          "Dan Pape",
          "Ken Russell"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengio2003_NeuralProbabilisticLanguageModel",
        "entity_type": "Algorithm",
        "name": "Neural Probabilistic Language Model",
        "title": "A Neural Probabilistic Language Model",
        "year": 2003,
        "authors": [
          "Yoshua Bengio",
          "Rejean Ducharme",
          "Pascal Vincent",
          "Christian Jauvin"
        ],
        "task": [
          "Language Modeling"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Blei2003_LatentDirichletAllocation",
        "entity_type": "Algorithm",
        "name": "Latent Dirichlet Allocation (LDA)",
        "title": "Latent Dirichlet Allocation",
        "year": 2003,
        "authors": [
          "David M Blei",
          "Andrew Y Ng",
          "Michael I Jordan"
        ],
        "task": [
          "Topic Modeling"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Collobert2008_UnifiedArchitectureForNLP",
        "entity_type": "Algorithm",
        "name": "Unified Architecture for Natural Language Processing",
        "title": "A Unified Architecture for Natural Language Processing",
        "year": 2008,
        "authors": [
          "Ronan Collobert",
          "Jason Weston"
        ],
        "task": [
          "Natural Language Processing"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Huang2012_MultiSenseWordEmbedding",
        "entity_type": "Algorithm",
        "name": "Multi-Sense Word Embedding",
        "title": "Improving Word Representations via Global Context and Multiple Word Prototypes",
        "year": 2012,
        "authors": [
          "Eric H Huang",
          "Richard Socher",
          "Christopher D Manning",
          "Andrew Y Ng"
        ],
        "task": [
          "Word Embedding"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Neelakantan2014_EfficientNonParametricEstimation",
        "entity_type": "Algorithm",
        "name": "Efficient Non-Parametric Estimation of Multiple Embeddings per Word",
        "title": "Efficient Non-Parametric Estimation of Multiple Embeddings per Word in Vector Space",
        "year": 2014,
        "authors": [
          "Arvind Neelakantan",
          "Jeevan Shankar",
          "Alexandre Passos",
          "Andrew McCallum"
        ],
        "task": [
          "Word Embedding"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {},
        "methodology": {},
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Alvin2014_ProblemGenerationAlgorithm",
        "entity_type": "Algorithm",
        "name": "Problem Generation Algorithm",
        "title": "Synthesis of Geometry Proof Problems",
        "year": 2014,
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": [
          "Geometry Proof Problem Generation"
        ],
        "datasets": [
          "Figures from Geometry Textbooks"
        ],
        "metrics": [
          "Number of Generated Problems",
          "Time Taken to Generate Problems"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Minimal Assumption Generation",
            "Strictly Interesting Problem Synthesis"
          ],
          "connections": [
            "Derive Function",
            "AllMinimalSets Algorithm",
            "GenProblem Algorithm"
          ],
          "mechanisms": [
            "Hypergraph Reachability",
            "Fixed-point Procedure",
            "Non-deterministic Choices"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Semi-automated Methodology"
          ],
          "parameter_tuning": [
            "Axioms Selection",
            "Figure Input"
          ]
        },
        "feature_processing": [
          "Implicit and Explicit Facts Extraction",
          "Predicate Enumeration"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Figures_from_Geometry_Textbooks_2014",
        "entity_type": "Dataset",
        "name": "Figures from Geometry Textbooks",
        "description": "A collection of 110 geometric figures taken from standard mathematics textbooks in India and the United States.",
        "domain": "High School Geometry",
        "size": 110,
        "year": 2014,
        "creators": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Number_of_Generated_Problems_2014",
        "entity_type": "Metric",
        "name": "Number of Generated Problems",
        "description": "The number of geometry proof problems generated per figure.",
        "category": "Problem Generation Evaluation",
        "formula": "Total number of problems generated / Number of figures"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Time_Taken_to_Generate_Problems_2014",
        "entity_type": "Metric",
        "name": "Time Taken to Generate Problems",
        "description": "The average time taken to generate problems per figure.",
        "category": "Efficiency Evaluation",
        "formula": "Total time taken / Number of figures"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2019_TemplateBasedSolver",
        "entity_type": "Algorithm",
        "name": "Template-Based Solver with Recursive Neural Networks",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": 2019,
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K",
          "MAWPS"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Bi-LSTM",
            "Self Attention",
            "Recursive Neural Network"
          ],
          "connections": [
            "Attention Layer",
            "Recursive Connections"
          ],
          "mechanisms": [
            "Operator Encapsulation",
            "Equation Normalization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adam Optimizer",
            "SGD Optimizer",
            "Cross-Entropy Loss"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Quantity Extraction",
          "Suffix Expression Serialization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Robaidek2018_DataDrivenMethods",
        "entity_type": "Algorithm",
        "name": "Data-Driven Methods",
        "title": "Data-Driven Methods for Solving Algebra Word Problems",
        "year": 2018,
        "authors": [
          "B. Robaidek",
          "R. Koncel-Kedziorski",
          "H. Hajishirzi"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "MAWPS",
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "CNN"
          ],
          "connections": [
            "Self Attention"
          ],
          "mechanisms": [
            "Softmax Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": [
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_EquationNormalization",
        "entity_type": "Algorithm",
        "name": "Equation Normalization",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Rule-Based Normalization"
          ],
          "connections": [
            "Order Normalization",
            "Bracket Normalization"
          ],
          "mechanisms": [
            "Rule 1",
            "Rule 2"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_BiLSTM",
        "entity_type": "Algorithm",
        "name": "BiLSTM",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM"
          ],
          "connections": [
            "Global Attention"
          ],
          "mechanisms": [
            "LSTM Cells"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adam Optimizer",
            "Beam Search"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_ConvS2S",
        "entity_type": "Algorithm",
        "name": "ConvS2S",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Convolutional Layers"
          ],
          "connections": [
            "Gate Linear Units"
          ],
          "mechanisms": [
            "Convolutional Architecture"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Early Stopping",
            "Learning Rate Annealing"
          ],
          "parameter_tuning": [
            "Max-Epochs",
            "Hidden Size"
          ]
        },
        "feature_processing": [
          "Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_Transformer",
        "entity_type": "Algorithm",
        "name": "Transformer",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Multi-Head Self-Attention",
            "Position-Wise Feed-Forward Network"
          ],
          "connections": [
            "Self-Attention"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adam Optimizer",
            "Dropout"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Number of Heads"
          ]
        },
        "feature_processing": [
          "Tokenization"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Wang2018_EnsembleModel",
        "entity_type": "Algorithm",
        "name": "Ensemble Model",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": 2018,
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": [
          "Math Word Problem Solving"
        ],
        "datasets": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "ConvS2S",
            "Transformer"
          ],
          "connections": [
            "Generation Probability"
          ],
          "mechanisms": [
            "Model Combination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Model Selection"
          ],
          "parameter_tuning": []
        },
        "feature_processing": []
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Fletcher1985_WORDPRO",
        "entity_type": "Algorithm",
        "name": "WORDPRO",
        "title": "Understanding and solving arithmetic word problems: A computer simulation",
        "year": 1985,
        "authors": [
          "Fletcher, C. R."
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [],
        "metrics": [
          "Run-Time Statistics"
        ],
        "architecture": {
          "components": [
            "Production Rules",
            "Set Schema",
            "Transfer Schema",
            "Superset Schema",
            "More-Than/Less-Than Schema"
          ],
          "connections": [
            "Meaning Postulates",
            "Arithmetic Strategies",
            "Problem-Solving Procedures"
          ],
          "mechanisms": [
            "Short-Term Memory (STM)",
            "Long-Term Memory (LTM)"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Read-Purge Loop"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Propositional Representation",
          "Bilevel Representation"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "RunTimeStatistics_ProblemSolving",
        "entity_type": "Metric",
        "name": "Run-Time Statistics",
        "description": "Statistics collected during the runtime of the program, including number of production rules fired, number of conversions, number of LTM searches, and maximum number of chunks held over.",
        "category": "Problem Solving Performance",
        "formula": "Not explicitly defined"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Novak1990_BEATRIX",
        "entity_type": "Algorithm",
        "name": "BEATRIX",
        "title": "Understanding Natural Language with Diagrams",
        "year": 1990,
        "authors": [
          "Novak, G. S.",
          "Bulko, W."
        ],
        "task": [
          "Physics Problem Solving"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "English Parser",
            "Diagram Parser",
            "Coreference Resolver"
          ],
          "connections": [
            "Blackboard Architecture"
          ],
          "mechanisms": [
            "Opportunistic Co-parsing",
            "Constraint Satisfaction"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Recognition",
          "Semantic Inference"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "PhysicsProblems_1990",
        "entity_type": "Dataset",
        "name": "Physics Problems",
        "description": "Textbook physics problems with accompanying diagrams",
        "domain": "Physics Education",
        "size": null,
        "year": 1990,
        "creators": [
          "Novak, G. S.",
          "Bulko, W."
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "UnifiedModel_Quality",
        "entity_type": "Metric",
        "name": "Unified Model Quality",
        "description": "Quality of the unified internal model representing the problem",
        "category": "Problem Representation",
        "formula": null
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bulko1988_BEATRIX",
        "entity_type": "Algorithm",
        "name": "BEATRIX",
        "title": "Understanding Text With an Accompanying Diagram",
        "year": 1988,
        "authors": [
          "William C. Bulko"
        ],
        "task": [
          "Physics Problem Solving"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Graphic Interface",
            "Blackboard System",
            "Understanding Module",
            "Picture Parsing",
            "Text Parsing"
          ],
          "connections": [
            "Coreference Resolution",
            "Semantic Network Model"
          ],
          "mechanisms": [
            "Blackboard Control Structure",
            "Knowledge Sources",
            "ATN Parser"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Text Editing",
          "Picture Drawing",
          "Correction Facility"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CollegeLevelPhysicsTextbooks_1988",
        "entity_type": "Dataset",
        "name": "College-Level Physics Textbooks",
        "description": "Collections of ready-made test cases in the form of college-level textbooks",
        "domain": "Physics Education",
        "size": null,
        "year": 1988,
        "creators": []
      }
    },
    {
      "metric_entity": {
        "metric_id": "Correctness_Completeness",
        "entity_type": "Metric",
        "name": "Correctness and Completeness",
        "description": "Validation of the model's correctness and completeness when supplied as input to a physics problem-solving program",
        "category": "Model Validation",
        "formula": null
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Bengtson2008_PairwiseCoreferenceModel",
        "entity_type": "Algorithm",
        "name": "Pairwise Coreference Model",
        "title": "Understanding the Value of Features for Coreference Resolution",
        "year": 2008,
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": [
          "Coreference Resolution"
        ],
        "datasets": [
          "ACE 2004 English Training Data"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function",
            "Document-Level Decision Model"
          ],
          "connections": [
            "Best-Link Decision Model",
            "Pairwise Coreference Scoring"
          ],
          "mechanisms": [
            "Averaged Perceptron Learning Algorithm"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Regularized Average Perceptron",
            "Threshold Optimization"
          ],
          "parameter_tuning": [
            "Learning Rate = 0.1",
            "Regularization Parameter = 3.5"
          ]
        },
        "feature_processing": [
          "Mention Types",
          "String Relation Features",
          "Semantic Features",
          "Relative Location Features",
          "Learned Features",
          "Aligned Modifiers",
          "Memorization Features",
          "Predicted Entity Types"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ACE2004_2004",
        "entity_type": "Dataset",
        "name": "ACE 2004 English Training Data",
        "description": "A dataset for coreference resolution provided by NIST",
        "domain": "Natural Language Processing",
        "size": 336,
        "year": 2004,
        "creators": [
          "NIST"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "B-Cubed_F-Score_Coreference",
        "entity_type": "Metric",
        "name": "B-Cubed F-Score",
        "description": "A measure of the overlap of predicted clusters and true clusters",
        "category": "Coreference Evaluation",
        "formula": "Harmonic mean of precision and recall"
      }
    },
    {
      "metric_entity": {
        "metric_id": "MUC_F-Score_Coreference",
        "entity_type": "Metric",
        "name": "MUC F-Score",
        "description": "Official MUC scoring algorithm for coreference evaluation",
        "category": "Coreference Evaluation",
        "formula": "Harmonic mean of precision and recall, counting precision and recall errors differently"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Roy2017_UNITDEP",
        "entity_type": "Algorithm",
        "name": "UNITDEP",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": 2017,
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": [
          "Arithmetic Word Problem Solving"
        ],
        "datasets": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Vertex Classifier",
            "Edge Classifier",
            "Constrained Inference Module"
          ],
          "connections": [
            "Joint Inference with Arithmetic Solver"
          ],
          "mechanisms": [
            "Decomposed Model",
            "Rule-based Extraction Features",
            "Context Features"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search",
            "Scaling Parameters Tuning"
          ],
          "parameter_tuning": [
            "λIRR",
            "λVERTEX",
            "λEDGE"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-based Extraction Features"
        ]
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Duda1972_HoughTransformation",
        "entity_type": "Algorithm",
        "name": "Hough Transformation",
        "title": "Use of the Hough Transformation To Detect Lines and Curves in Pictures",
        "year": 1972,
        "authors": [
          "Richard O. Duda",
          "Peter E. Hart"
        ],
        "task": [
          "Line Detection",
          "Curve Detection"
        ],
        "datasets": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Point-Line Transformation",
            "Parameter Space"
          ],
          "connections": [
            "Normal Parameterization"
          ],
          "mechanisms": [
            "Accumulator Array"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Quantization",
          "Projection"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Count_ColinearPoints",
        "entity_type": "Metric",
        "name": "Count of Colinear Points",
        "description": "Number of colinear points detected by the Hough Transformation",
        "category": "Line Detection",
        "formula": "k figure points lie along the line whose normal parameters are (θ, p)"
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "MS_COCO_2014",
        "entity_type": "Dataset",
        "name": "MS COCO",
        "description": "Microsoft Common Objects in Context dataset",
        "domain": "Computer Vision",
        "size": 204721,
        "year": 2014,
        "creators": [
          "T.-Y. Lin",
          "M. Maire",
          "S. Belongie",
          "J. Hays",
          "P. Perona",
          "D. Ramanan",
          "P. Dollar",
          "C. L. Zitnick"
        ]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Abstract_Scenes_2015",
        "entity_type": "Dataset",
        "name": "Abstract Scenes",
        "description": "Dataset of abstract scenes for VQA",
        "domain": "Computer Vision",
        "size": 50000,
        "year": 2015,
        "creators": [
          "Stanislaw Antol",
          "Aishwarya Agrawal",
          "Jiasen Lu",
          "Margaret Mitchell",
          "Dhruv Batra",
          "C. Lawrence Zitnick",
          "Devi Parikh"
        ]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Open-Answer",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for open-answer task",
        "category": "Classification Evaluation",
        "formula": "min(# humans that provided that answer / 3, 1)"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_Multiple-Choice",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "Accuracy for multiple-choice task",
        "category": "Classification Evaluation",
        "formula": "Number of correct answers / Total number of questions"
      }
    }
  ],
  "is_complete": true,
  "extraction_time": 1748863873.662668
}