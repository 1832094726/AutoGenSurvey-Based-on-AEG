[
  {
    "from_entity": "Roy2015_ExpressionTree",
    "to_entity": "Wang2018_TranslationModel",
    "relation_type": "Extend",
    "structure": "Expression Tree -> Translation Model",
    "detail": "Translation Model扩展了Expression Tree的思想，使用表达式树作为输出序列。",
    "evidence": "Seq2SeqET[15] extended the idea of DNS by using expression tree as the output sequence.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Koncel-Kedziorski2015_ALGES",
    "to_entity": "Wang2018_TranslationModel",
    "relation_type": "Optimize",
    "structure": "ALGES -> Translation Model",
    "detail": "Translation Model通过引入seq2seq模型优化了ALGES的表达式树生成过程。",
    "evidence": "Seq2SeqET[15] extended the idea of DNS by using expression tree as the output sequence. It applied seq2seq model to convert the problem text into an expression tree.",
    "confidence": 0.85,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Wang2018_MathDQN",
    "to_entity": "Zhang2019_DeepNeuralSolver",
    "relation_type": "Improve",
    "structure": "MathDQN -> Deep Neural Solver",
    "detail": "Deep Neural Solver在MathDQN的基础上进一步改进，使用了更复杂的深度学习模型和双向LSTM。",
    "evidence": "Following DNS, there have emerged multiple DL-based solvers for arithmetic word problems. Deep Neural Solver(DNS)[14] is a pioneering work designed for equation set problems. T-RNN can be viewed as an improvement of Seq2SeqET, in terms of quantity encoding, template representation and tree construction.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Roy2015_ExpressionTree",
    "to_entity": "Wang2018_MathDQN",
    "relation_type": "Replace",
    "structure": "Expression Tree -> MathDQN",
    "detail": "MathDQN用强化学习方法替换了Expression Tree的Beam Search方法，以更好地处理多步问题。",
    "evidence": "MathDQN models the tree construction as Markov Decision Process and leverage the strengths of deep Q-network (DQN). By using a two-layer feed-forward neural network as the deep Q-network to approximate the Q-value function, the framework learns model parameters from the reward feedback of the environment.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Koncel-Kedziorski2015_ALGES",
    "to_entity": "Wang2018_MathDQN",
    "relation_type": "Optimize",
    "structure": "ALGES -> MathDQN",
    "detail": "MathDQN通过引入强化学习优化了ALGES的表达式树生成过程。",
    "evidence": "MathDQN iteratively picks the best operator for two selected quantities. This procedure can be viewed as beam search with k=1 when exploiting candidate expression trees. Its deep Q-network acts as the operator classifier and guides the model to select the most promising operator for tree construction.",
    "confidence": 0.85,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Roy2015_ExpressionTree",
    "to_entity": "Wang2019_T-RNN",
    "relation_type": "Improve",
    "structure": "Expression Tree -> T-RNN",
    "detail": "T-RNN在Expression Tree的基础上进行了改进，特别是在数量编码、模板表示和树构造方面。",
    "evidence": "T-RNN can be viewed as an improvement of Seq2SeqET, in terms of quantity encoding, template representation and tree construction.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Koncel-Kedziorski2015_ALGES",
    "to_entity": "Huang2017_FG_Expression",
    "relation_type": "Extend",
    "structure": "ALGES -> FG-Expression",
    "detail": "FG-Expression扩展了ALGES的方法，通过细粒度单元解析方程模板。",
    "evidence": "FG-Expression parses an equation template into fine-grained units, called template fragment. Each template is represented in a tree structure as in Figure 3 and each fragment represents a sub-tree rooted at an internal node.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Huang2017_FG_Expression",
    "to_entity": "Huang2018_FG-Expression",
    "relation_type": "Optimize",
    "structure": "FG-Expression -> FG-Expression",
    "detail": "FG-Expression在2018年的版本中优化了特征选择和模板片段的应用。",
    "evidence": "FG-Expression also significantly reduces the search space because only top-k templates are examined whereas previous methods align numbers for all the templates in the training dataset.",
    "confidence": 0.85,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Wang2018_TranslationModel",
    "to_entity": "Wang2019_T-RNN",
    "relation_type": "Improve",
    "structure": "Translation Model -> T-RNN",
    "detail": "T-RNN在Translation Model的基础上进行了改进，特别是在递归神经网络和自注意力机制方面。",
    "evidence": "T-RNN can be viewed as an improvement of Seq2SeqET, in terms of quantity encoding, template representation and tree construction. First, an effective embedding network with Bi-LSTM and self attention is used to vectorize the quantities.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Wang2018_MathDQN",
    "to_entity": "Wang2019_T-RNN",
    "relation_type": "Optimize",
    "structure": "MathDQN -> T-RNN",
    "detail": "T-RNN通过引入Bi-LSTM和自注意力机制优化了MathDQN的数量编码和模板表示。",
    "evidence": "T-RNN can be viewed as an improvement of Seq2SeqET, in terms of quantity encoding, template representation and tree construction. First, an effective embedding network with Bi-LSTM and self attention is used to vectorize the quantities.",
    "confidence": 0.85,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Roy2015_ExpressionTree",
    "to_entity": "Chiang2018_StackDecoder",
    "relation_type": "Optimize",
    "structure": "Expression Tree -> StackDecoder",
    "detail": "StackDecoder通过引入栈机制优化了Expression Tree的语义跟踪。",
    "evidence": "StackDecoder is also based on seq2seq model. Its encoder extracts semantic meanings of quantities in the question text and the decoder is equipped with a stack to facilitate tracking the semantic meanings of operands.",
    "confidence": 0.85,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Koncel-Kedziorski2015_ALGES",
    "to_entity": "Chiang2018_StackDecoder",
    "relation_type": "Optimize",
    "structure": "ALGES -> StackDecoder",
    "detail": "StackDecoder通过引入栈机制优化了ALGES的表达式树生成过程。",
    "evidence": "StackDecoder is also based on seq2seq model. Its encoder extracts semantic meanings of quantities in the question text and the decoder is equipped with a stack to facilitate tracking the semantic meanings of operands.",
    "confidence": 0.85,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Roy2015_ExpressionTree",
    "to_entity": "Zhang2019_DeepNeuralSolver",
    "relation_type": "Replace",
    "structure": "Expression Tree -> Deep Neural Solver",
    "detail": "Deep Neural Solver用深度学习模型替换了Expression Tree的手工特征工程方法。",
    "evidence": "Deep Neural Solver(DNS)[14] is the first deep learning based algorithm that does not rely on hand-crafted features. This is a milestone contribution because all the previous methods (including MathDQN) require human intelligence to help extract features that are effective.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Koncel-Kedziorski2015_ALGES",
    "to_entity": "Zhang2019_DeepNeuralSolver",
    "relation_type": "Replace",
    "structure": "ALGES -> Deep Neural Solver",
    "detail": "Deep Neural Solver用深度学习模型替换了ALGES的手工特征工程方法。",
    "evidence": "Deep Neural Solver(DNS)[14] is the first deep learning based algorithm that does not rely on hand-crafted features. This is a milestone contribution because all the previous methods (including MathDQN) require human intelligence to help extract features that are effective.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Wang2018_MathDQN",
    "to_entity": "Zhang2019_DeepNeuralSolver",
    "relation_type": "Improve",
    "structure": "MathDQN -> Deep Neural Solver",
    "detail": "Deep Neural Solver在MathDQN的基础上进一步改进，使用了更复杂的深度学习模型和双向LSTM。",
    "evidence": "Deep Neural Solver(DNS)[14] is the first deep learning based algorithm that does not rely on hand-crafted features. This is a milestone contribution because all the previous methods (including MathDQN) require human intelligence to help extract features that are effective.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Roy2015_ExpressionTree",
    "to_entity": "Huang2017_FG_Expression",
    "relation_type": "Extend",
    "structure": "Expression Tree -> FG-Expression",
    "detail": "FG-Expression扩展了Expression Tree的方法，通过细粒度单元解析方程模板。",
    "evidence": "FG-Expression parses an equation template into fine-grained units, called template fragment. Each template is represented in a tree structure as in Figure 3 and each fragment represents a sub-tree rooted at an internal node.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Koncel-Kedziorski2015_ALGES",
    "to_entity": "Huang2017_FG_Expression",
    "relation_type": "Extend",
    "structure": "ALGES -> FG-Expression",
    "detail": "FG-Expression扩展了ALGES的方法，通过细粒度单元解析方程模板。",
    "evidence": "FG-Expression parses an equation template into fine-grained units, called template fragment. Each template is represented in a tree structure as in Figure 3 and each fragment represents a sub-tree rooted at an internal node.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  },
  {
    "from_entity": "Wang2018_TranslationModel",
    "to_entity": "Zhang2019_DeepNeuralSolver",
    "relation_type": "Replace",
    "structure": "Translation Model -> Deep Neural Solver",
    "detail": "Deep Neural Solver用深度学习模型替换了Translation Model的手工特征工程方法。",
    "evidence": "Deep Neural Solver(DNS)[14] is the first deep learning based algorithm that does not rely on hand-crafted features. This is a milestone contribution because all the previous methods (including MathDQN) require human intelligence to help extract features that are effective.",
    "confidence": 0.9,
    "from_entity_type": "Algorithm",
    "to_entity_type": "Algorithm",
    "extraction_complete": true
  }
]