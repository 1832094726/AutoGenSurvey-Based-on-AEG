[
  {
    "algorithm_entity": {
      "algorithm_id": "Cho2014_DeepNeuralNetwork",
      "entity_type": "Algorithm",
      "name": "Deep Neural Network",
      "year": 2014,
      "authors": ["Kyunghyun Cho", "Bart van MerriÃ«nboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"],
      "task": "Statistical Machine Translation",
      "dataset": ["WMT14_EnglishFrench_2014"],
      "metrics": ["BLEU_Translation"],
      "architecture": {
        "components": ["Encoder", "Decoder"],
        "connections": ["Recurrent connections"],
        "mechanisms": ["Reset gate", "Update gate"]
      },
      "methodology": {
        "training_strategy": ["Gradient-based optimization", "Joint training"],
        "parameter_tuning": ["Learning rate", "Batch size"]
      },
      "feature_processing": ["Word embeddings", "Phrase pairs scoring"]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "TestSet_newstest2012_2014",
      "entity_type": "Dataset",
      "name": "newstest2012",
      "year": 2014,
      "domain": "Machine Translation",
      "size": 70000,
      "creators": ["WMT'14 workshop"]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "TestSet_newstest2013_2014",
      "entity_type": "Dataset",
      "name": "newstest2013",
      "year": 2014,
      "domain": "Machine Translation",
      "size": 70000,
      "creators": ["WMT'14 workshop"]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "TestSet_newstest2014_2014",
      "entity_type": "Dataset",
      "name": "newstest2014",
      "year": 2014,
      "domain": "Machine Translation",
      "size": 70000,
      "creators": ["WMT'14 workshop"]
    }
  },
  {
    "metric_entity": {
      "metric_id": "ValidationPerplexity_LanguageModel",
      "entity_type": "Metric",
      "name": "Validation Perplexity",
      "category": "Language Modeling",
      "formula": "exp(-average_log_probability)"
    }
  },
  {
    "algorithm_entity": {
      "algorithm_id": "Schwenk2007_ContinuousSpaceLanguageModel",
      "entity_type": "Algorithm",
      "name": "Continuous Space Language Model",
      "year": 2007,
      "authors": ["Holger Schwenk"],
      "task": "Language Modeling",
      "dataset": ["Target corpus"],
      "metrics": ["Perplexity_LanguageModel"],
      "architecture": {
        "components": ["Embedding layer", "Rectified layers", "Softmax output"],
        "connections": ["Fully connected"],
        "mechanisms": ["Word embeddings"]
      },
      "methodology": {
        "training_strategy": ["Stochastic gradient descent"],
        "parameter_tuning": ["Embedding dimension", "Layer sizes"]
      },
      "feature_processing": ["Word embeddings"]
    }
  }
]