[
  {
    "algorithm_entity": {
      "algorithm_id": "Robaidek2018_Seq2SeqModelWithAttention",
      "entity_type": "Algorithm",
      "name": "Seq2Seq Model with Attention",
      "year": 2018,
      "authors": ["Benjamin Robaidek", "Rik Koncel-Kedziorski", "Hannaneh Hajishirzi"],
      "task": "Algebra Word Problem Solving",
      "dataset": ["Math23K_2017", "DRAW_2016", "MAWPS_2016"],
      "metrics": ["Accuracy_Classification", "F1_Score"],
      "architecture": {
        "components": ["Encoder", "Decoder", "Attention Mechanism"],
        "connections": ["LSTM", "CNN"],
        "mechanisms": ["Attention"]
      },
      "methodology": {
        "training_strategy": ["Cross Entropy Loss", "SGD"],
        "parameter_tuning": ["Learning Rate", "Dropout Rate"]
      },
      "feature_processing": ["Significant Number Identifier"]
    }
  },
  {
    "algorithm_entity": {
      "algorithm_id": "Robaidek2018_BiLSTMClassifier",
      "entity_type": "Algorithm",
      "name": "BiLSTM Classifier",
      "year": 2018,
      "authors": ["Benjamin Robaidek", "Rik Koncel-Kedziorski", "Hannaneh Hajishirzi"],
      "task": "Algebra Word Problem Solving",
      "dataset": ["Math23K_2017", "DRAW_2016", "MAWPS_2016"],
      "metrics": ["Accuracy_Classification", "F1_Score"],
      "architecture": {
        "components": ["BiLSTM", "Softmax"],
        "connections": ["Bidirectional LSTM"],
        "mechanisms": ["Hidden State Scaling"]
      },
      "methodology": {
        "training_strategy": ["Cross Entropy Loss", "SGD"],
        "parameter_tuning": ["Learning Rate", "Dropout Rate"]
      },
      "feature_processing": ["Significant Number Identifier"]
    }
  },
  {
    "algorithm_entity": {
      "algorithm_id": "Robaidek2018_StructuredSelfAttention",
      "entity_type": "Algorithm",
      "name": "Structured Self-Attention",
      "year": 2018,
      "authors": ["Benjamin Robaidek", "Rik Koncel-Kedziorski", "Hannaneh Hajishirzi"],
      "task": "Algebra Word Problem Solving",
      "dataset": ["Math23K_2017", "DRAW_2016", "MAWPS_2016"],
      "metrics": ["Accuracy_Classification", "F1_Score"],
      "architecture": {
        "components": ["BiLSTM", "Self-Attention"],
        "connections": ["Multi-Hop Self-Attention"],
        "mechanisms": ["Attention"]
      },
      "methodology": {
        "training_strategy": ["Cross Entropy Loss", "SGD"],
        "parameter_tuning": ["Learning Rate", "Dropout Rate"]
      },
      "feature_processing": ["Significant Number Identifier"]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "Math23K_2017",
      "entity_type": "Dataset",
      "name": "Math23K",
      "description": "Large-scale dataset of Chinese algebra word problems",
      "domain": "Mathematics",
      "size": 23164,
      "year": 2017,
      "creators": ["Wang, Y.", "Zhang, D.", "Gao, L.", "Song, J.", "Guo, L.", "Shen, H.T."]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "DRAW_2016",
      "entity_type": "Dataset",
      "name": "DRAW",
      "description": "Dataset of algebra word problems",
      "domain": "Mathematics",
      "size": 1000,
      "year": 2016,
      "creators": ["Upadhyay, S.", "Chang, M."]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "MAWPS_2016",
      "entity_type": "Dataset",
      "name": "MAWPS",
      "description": "Math Word Problem Repository",
      "domain": "Mathematics",
      "size": 2373,
      "year": 2016,
      "creators": ["Koncel-Kedziorski, R.", "Roy, S.", "Amini, A.", "Kushman, N.", "Hajishirzi, H."]
    }
  },
  {
    "metric_entity": {
      "metric_id": "Accuracy_Classification",
      "entity_type": "Metric",
      "name": "Accuracy",
      "description": "分类准确率",
      "category": "分类评估",
      "formula": "正确分类样本数/总样本数"
    }
  },
  {
    "metric_entity": {
      "metric_id": "F1_Score",
      "entity_type": "Metric",
      "name": "F1 Score",
      "description": "F1得分",
      "category": "分类评估",
      "formula": "2 * (Precision * Recall) / (Precision + Recall)"
    }
  }
]