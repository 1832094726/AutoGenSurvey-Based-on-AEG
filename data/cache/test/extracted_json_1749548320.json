[
  {
    "algorithm_entity": {
      "algorithm_id": "Wang2018_EquationNormalization",
      "entity_type": "Algorithm",
      "name": "Equation Normalization Method",
      "year": 2018,
      "authors": ["Lei Wang", "Yan Wang", "Deng Cai", "Dongxiang Zhang", "Xiaojiang Liu"],
      "task": "Math Word Problem Solving",
      "dataset": ["Math23K_2017"],
      "metrics": ["Accuracy_Classification"],
      "architecture": {
        "components": ["Expression Tree"],
        "connections": [],
        "mechanisms": []
      },
      "methodology": {
        "training_strategy": ["Sequence-to-sequence (SEQ2SEQ) models"],
        "parameter_tuning": ["Rule 1 (shorter equation)", "Rule 2 (ordered number tokens)", "Eliminating brackets"]
      },
      "feature_processing": ["Order-duplicated templates", "Bracket-duplicated templates"]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "Math23K_2017",
      "entity_type": "Dataset",
      "name": "Math23K",
      "description": "A dataset of 23,162 labeled math word problems",
      "domain": "Automatic Math Word Problem Solving",
      "size": 23162,
      "year": 2017,
      "creators": ["Wang et al."]
    }
  },
  {
    "metric_entity": {
      "metric_id": "Accuracy_Classification",
      "entity_type": "Metric",
      "name": "Accuracy",
      "description": "Classification accuracy",
      "category": "Classification assessment",
      "formula": "Correct classifications / Total classifications"
    }
  },
  {
    "algorithm_entity": {
      "algorithm_id": "Wang2017_SEQ2SEQModel",
      "entity_type": "Algorithm",
      "name": "SEQ2SEQ Model",
      "year": 2017,
      "authors": ["Lei Wang", "Yan Wang", "Deng Cai", "Dongxiang Zhang", "Xiaojiang Liu"],
      "task": "Math Word Problem Solving",
      "dataset": ["Math23K_2017"],
      "metrics": ["Accuracy_Classification"],
      "architecture": {
        "components": ["Bidirectional Long Short-Term Memory network"],
        "connections": ["Global attention mechanism"],
        "mechanisms": ["Two-layer Bi-LSTM encoder", "Two-layer LSTM decoder"]
      },
      "methodology": {
        "training_strategy": ["Sequence-to-sequence (SEQ2SEQ) models"],
        "parameter_tuning": ["Adam optimizer", "Learning rate 1e-3", "β1=0.9", "β2=0.99", "Dropout rate 0.5"]
      },
      "feature_processing": ["Number mapping", "Equation templates"]
    }
  },
  {
    "algorithm_entity": {
      "algorithm_id": "Gehring2017_ConvolutionalSEQ2SEQ",
      "entity_type": "Algorithm",
      "name": "ConvS2S",
      "year": 2017,
      "authors": ["Jonas Gehring", "Michael Auli", "David Grangier", "Denis Yarats", "Yann N Dauphin"],
      "task": "Math Word Problem Solving",
      "dataset": ["Math23K_2017"],
      "metrics": ["Accuracy_Classification"],
      "architecture": {
        "components": ["Convolutional architecture"],
        "connections": ["Shared convolutional structure"],
        "mechanisms": ["Gate linear units as non-linearity activations"]
      },
      "methodology": {
        "training_strategy": ["Sequence-to-sequence (SEQ2SEQ) models"],
        "parameter_tuning": ["Early stopping", "Learning rate annealing", "Max-epochs 100"]
      },
      "feature_processing": ["Number mapping", "Equation templates"]
    }
  },
  {
    "algorithm_entity": {
      "algorithm_id": "Vaswani2017_Transformer",
      "entity_type": "Algorithm",
      "name": "Transformer",
      "year": 2017,
      "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Łukasz Kaiser", "Illia Polosukhin"],
      "task": "Math Word Problem Solving",
      "dataset": ["Math23K_2017"],
      "metrics": ["Accuracy_Classification"],
      "architecture": {
        "components": ["Multi-head self-attention module", "Position-wise fully-connected feed-forward network"],
        "connections": ["Stack of identical layers"],
        "mechanisms": ["Self-attention", "Feed-forward networks"]
      },
      "methodology": {
        "training_strategy": ["Sequence-to-sequence (SEQ2SEQ) models"],
        "parameter_tuning": ["Adam optimizer", "Learning rate 1e-3", "β1=0.9", "β2=0.99", "Dropout rate 0.3"]
      },
      "feature_processing": ["Number mapping", "Equation templates"]
    }
  },
  {
    "algorithm_entity": {
      "algorithm_id": "Wang2018_EnsembleModel",
      "entity_type": "Algorithm",
      "name": "Ensemble Model",
      "year": 2018,
      "authors": ["Lei Wang", "Yan Wang", "Deng Cai", "Dongxiang Zhang", "Xiaojiang Liu"],
      "task": "Math Word Problem Solving",
      "dataset": ["Math23K_2017"],
      "metrics": ["Accuracy_Classification"],
      "architecture": {
        "components": ["Combination of BiLSTM, ConvS2S, Transformer"],
        "connections": [],
        "mechanisms": []
      },
      "methodology": {
        "training_strategy": ["Combining multiple SEQ2SEQ models"],
        "parameter_tuning": ["Generation probability selection"]
      },
      "feature_processing": ["Same as individual models"]
    }
  }
]