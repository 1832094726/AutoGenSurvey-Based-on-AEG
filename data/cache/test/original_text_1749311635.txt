### 提取章节：4 Experiments

#### 已提取实体：
- Cho2014_RNNEncoderDecoder
- WMT14_EnglishFrench_2014
- BLEU_Translation
- Cho2014_RecurrentNeuralNetwork
- Hochreiter1997_LongShortTermMemory
- Cho2014_AdaptiveHiddenUnit
- ConditionalLogLikelihood_Translation
- Schwenk2012_FeedforwardNeuralNetwork
- Devlin2014_NeuralNetworkJointModel
- Zou2013_BilingualEmbedding
- Chandar2014_BagOfWordsMapping
- Europarl_2005
- NewsCommentary_2014
- UNCorpus_2014
- CrawledCorpora_2014
- Perplexity_LanguageModel

#### 新提取实体：

```json
[
  {
    "algorithm_entity": {
      "algorithm_id": "Cho2014_DeepNeuralNetwork",
      "entity_type": "Algorithm",
      "name": "Deep Neural Network",
      "year": 2014,
      "authors": ["Kyunghyun Cho", "Bart van Merriënboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"],
      "task": "Statistical Machine Translation",
      "dataset": ["WMT14_EnglishFrench_2014"],
      "metrics": ["BLEU_Translation"],
      "architecture": {
        "components": ["Encoder", "Decoder"],
        "connections": ["Recurrent connections"],
        "mechanisms": ["Reset gate", "Update gate"]
      },
      "methodology": {
        "training_strategy": ["Gradient-based optimization", "Joint training"],
        "parameter_tuning": ["Learning rate", "Batch size"]
      },
      "feature_processing": ["Word embeddings", "Phrase pairs scoring"]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "TestSet_newstest2012_2014",
      "entity_type": "Dataset",
      "name": "newstest2012",
      "year": 2014,
      "domain": "Machine Translation",
      "size": 70000,
      "creators": ["WMT'14 workshop"]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "TestSet_newstest2013_2014",
      "entity_type": "Dataset",
      "name": "newstest2013",
      "year": 2014,
      "domain": "Machine Translation",
      "size": 70000,
      "creators": ["WMT'14 workshop"]
    }
  },
  {
    "dataset_entity": {
      "dataset_id": "TestSet_newstest2014_2014",
      "entity_type": "Dataset",
      "name": "newstest2014",
      "year": 2014,
      "domain": "Machine Translation",
      "size": 70000,
      "creators": ["WMT'14 workshop"]
    }
  },
  {
    "metric_entity": {
      "metric_id": "ValidationPerplexity_LanguageModel",
      "entity_type": "Metric",
      "name": "Validation Perplexity",
      "category": "Language Modeling",
      "formula": "exp(-average_log_probability)"
    }
  },
  {
    "algorithm_entity": {
      "algorithm_id": "Schwenk2007_ContinuousSpaceLanguageModel",
      "entity_type": "Algorithm",
      "name": "Continuous Space Language Model",
      "year": 2007,
      "authors": ["Holger Schwenk"],
      "task": "Language Modeling",
      "dataset": ["Target corpus"],
      "metrics": ["Perplexity_LanguageModel"],
      "architecture": {
        "components": ["Embedding layer", "Rectified layers", "Softmax output"],
        "connections": ["Fully connected"],
        "mechanisms": ["Word embeddings"]
      },
      "methodology": {
        "training_strategy": ["Stochastic gradient descent"],
        "parameter_tuning": ["Embedding dimension", "Layer sizes"]
      },
      "feature_processing": ["Word embeddings"]
    }
  }
]
```

### 提取总结：
1. 刚刚提取的是 **4 Experiments** 小节。
2. 论文中还有其他小节未被提取。
3. 下一个要提取的小节是 **4.1 Data and Baseline System**。

EXTRACTION_COMPLETE: false, CURRENT_SECTION: 4 Experiments, NEXT_SECTION: 4.1 Data and Baseline System