[
  {
    "from_entity": "Earley1970_EfficientContextFreeParsingAlgorithm",
    "to_entity": "Shi2015_SigmaDolphin",
    "relation_type": "Use",
    "structure": "Architecture.Component",
    "detail": "SigmaDolphin uses Earley's context-free parsing algorithm as part of its CFG parser",
    "problem_addressed": "Parsing natural language sentences into structured representations",
    "evidence": "We implement a top-down parser for our new CFG of Section 3.2.1, following the Earley algorithm(Earley, 1970).",
    "confidence": 0.95
  },
  {
    "from_entity": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
    "to_entity": "Chen2014_NeuralNetworkDependencyParser",
    "relation_type": "Optimize",
    "structure": "Architecture.Mechanism",
    "detail": "Chen's Neural Network Dependency Parser optimizes dependency parsing by using neural networks",
    "problem_addressed": "Inefficiency and locality issues in traditional parsing algorithms",
    "evidence": "Current dependency parsers can be categorized into three families: local-and-greedy transition-based parsers, globally optimized graph-based parsers, and hybrid systems. Our work aims to improve upon these.",
    "confidence": 0.88
  },
  {
    "from_entity": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
    "to_entity": "WSJ_Treebank_2010",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Goldberg's algorithm is evaluated on the WSJ Treebank",
    "problem_addressed": "Evaluation of parsing accuracy on a standard dataset",
    "evidence": "We evaluate the parser using the WSJ Treebank. The trees were converted to dependency structures with the Penn2Malt conversion program.",
    "confidence": 0.92
  },
  {
    "from_entity": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
    "to_entity": "CoNLL_2007_English_dataset_2007",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Goldberg's algorithm is evaluated on the CoNLL 2007 English dataset",
    "problem_addressed": "Evaluation of parsing accuracy on a linguistically adequate dataset",
    "evidence": "We evaluated the parsers also on the English dataset from the CoNLL 2007 shared task.",
    "confidence": 0.92
  },
  {
    "from_entity": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
    "to_entity": "Accuracy_Classification",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Goldberg's algorithm uses Accuracy as an evaluation metric",
    "problem_addressed": "Measuring the correctness of parsing results",
    "evidence": "We evaluate the parsers using three common measures: (unlabeled) Accuracy: percentage of tokens which got assigned their correct parent.",
    "confidence": 0.9
  },
  {
    "from_entity": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
    "to_entity": "Root_Classification",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Goldberg's algorithm uses Root as an evaluation metric",
    "problem_addressed": "Measuring the correctness of root attachment",
    "evidence": "Root: The percentage of sentences in which the ROOT attachment is correct.",
    "confidence": 0.9
  },
  {
    "from_entity": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
    "to_entity": "Complete_Classification",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Goldberg's algorithm uses Complete as an evaluation metric",
    "problem_addressed": "Measuring the correctness of complete parses",
    "evidence": "Complete: the percentage of sentences in which all tokens were assigned their correct parent.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "ACE_2004",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chang's CL3M algorithm is evaluated on the ACE 2004 dataset",
    "problem_addressed": "Evaluation of coreference resolution performance",
    "evidence": "We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Ontonotes_5.0",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chang's CL3M algorithm is evaluated on the Ontonotes 5.0 dataset",
    "problem_addressed": "Evaluation of coreference resolution performance",
    "evidence": "We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "MUC",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses MUC as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "BCUB",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses BCUB as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "CEAFe",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses CEAFe as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_ConstrainedProbabilisticLatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CPL3M algorithm optimizes CL3M by adding a temperature parameter",
    "problem_addressed": "Improving the robustness and adaptability of coreference resolution",
    "evidence": "The Constrained Probabilistic Latent Left-Linking Model (CPL3M) extends CL3M with a temperature parameter.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_LatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes L3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Latent Left-Linking Model (CL3M) extends L3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chen2014_NeuralNetworkDependencyParser",
    "to_entity": "English_Penn_Treebank_2014",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chen's Neural Network Dependency Parser is evaluated on the English Penn Treebank",
    "problem_addressed": "Evaluation of parsing accuracy on a standard dataset",
    "evidence": "We evaluate the parser using the WSJ Treebank. The trees were converted to dependency structures with the Penn2Malt conversion program.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chen2014_NeuralNetworkDependencyParser",
    "to_entity": "Chinese_Penn_Treebank_2014",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chen's Neural Network Dependency Parser is evaluated on the Chinese Penn Treebank",
    "problem_addressed": "Evaluation of parsing accuracy on a standard dataset",
    "evidence": "We evaluate the parser using the WSJ Treebank. The trees were converted to dependency structures with the Penn2Malt conversion program.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chen2014_NeuralNetworkDependencyParser",
    "to_entity": "UAS",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chen's Neural Network Dependency Parser uses UAS as an evaluation metric",
    "problem_addressed": "Measuring the accuracy of unlabeled dependencies",
    "evidence": "We evaluate the parser using three common measures: (unlabeled) Accuracy: percentage of tokens which got assigned their correct parent.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chen2014_NeuralNetworkDependencyParser",
    "to_entity": "LAS",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chen's Neural Network Dependency Parser uses LAS as an evaluation metric",
    "problem_addressed": "Measuring the accuracy of labeled dependencies",
    "evidence": "We evaluate the parser using three common measures: (unlabeled) Accuracy: percentage of tokens which got assigned their correct parent.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chen2014_NeuralNetworkDependencyParser",
    "to_entity": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
    "relation_type": "Optimize",
    "structure": "Architecture.Mechanism",
    "detail": "Chen's Neural Network Dependency Parser optimizes Goldberg's algorithm by using neural networks",
    "problem_addressed": "Inefficiency and locality issues in traditional parsing algorithms",
    "evidence": "Current dependency parsers can be categorized into three families: local-and-greedy transition-based parsers, globally optimized graph-based parsers, and hybrid systems. Our work aims to improve upon these.",
    "confidence": 0.88
  },
  {
    "from_entity": "Shi2015_SigmaDolphin",
    "to_entity": "Dolphin18K_2016",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "SigmaDolphin is evaluated on the Dolphin18K dataset",
    "problem_addressed": "Evaluation of solving number word problems",
    "evidence": "We build a test set of over 1,500 problems and make a quantitative comparison with state-of-the-art statistical methods.",
    "confidence": 0.9
  },
  {
    "from_entity": "Shi2015_SigmaDolphin",
    "to_entity": "Precision_Classification",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "SigmaDolphin uses Precision as an evaluation metric",
    "problem_addressed": "Measuring the correctness of generated solutions",
    "evidence": "We achieve a high precision and a reasonable recall on our test set of over 1,500 problems.",
    "confidence": 0.85
  },
  {
    "from_entity": "Shi2015_SigmaDolphin",
    "to_entity": "Recall_Classification",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "SigmaDolphin uses Recall as an evaluation metric",
    "problem_addressed": "Measuring the completeness of generated solutions",
    "evidence": "We achieve a high precision and a reasonable recall on our test set of over 1,500 problems.",
    "confidence": 0.85
  },
  {
    "from_entity": "Shi2015_SigmaDolphin",
    "to_entity": "F1_Classification",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "SigmaDolphin uses F1 as an evaluation metric",
    "problem_addressed": "Balancing precision and recall in generated solutions",
    "evidence": "We achieve a high precision and a reasonable recall on our test set of over 1,500 problems.",
    "confidence": 0.85
  },
  {
    "from_entity": "Clark2016_Aristo",
    "to_entity": "NY_Regents_Science_Exam_2016",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Aristo is evaluated on the NY Regents Science Exam",
    "problem_addressed": "Evaluation of answering elementary science questions",
    "evidence": "We use real exam questions, exactly as written, from the NY Regents 4th Grade Science exams.",
    "confidence": 0.9
  },
  {
    "from_entity": "Clark2016_Aristo",
    "to_entity": "Accuracy_Classification",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Aristo uses Accuracy as an evaluation metric",
    "problem_addressed": "Measuring the correctness of generated answers",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.85
  },
  {
    "from_entity": "Alvin2015_GeoTutor",
    "to_entity": "High_School_Geometry_Problems_2015",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "GeoTutor is evaluated on the High School Geometry Problems dataset",
    "problem_addressed": "Evaluation of synthesizing geometry problems",
    "evidence": "We evaluated GeoTutor on a corpus of high school geometry problems from standard geometry text books.",
    "confidence": 0.9
  },
  {
    "from_entity": "Alvin2015_GeoTutor",
    "to_entity": "Number_of_synthesized_problems",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "GeoTutor uses Number of synthesized problems as an evaluation metric",
    "problem_addressed": "Measuring the productivity of problem synthesis",
    "evidence": "Evaluation results show that our approach significantly outperforms base-line methods on our test set.",
    "confidence": 0.85
  },
  {
    "from_entity": "Alvin2015_GeoTutor",
    "to_entity": "Difficulty_level",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "GeoTutor uses Difficulty level as an evaluation metric",
    "problem_addressed": "Measuring the complexity of generated problems",
    "evidence": "Evaluation results show that our approach significantly outperforms base-line methods on our test set.",
    "confidence": 0.85
  },
  {
    "from_entity": "Alvin2015_GeoTutor",
    "to_entity": "Proof_Width",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "GeoTutor uses Proof Width as an evaluation metric",
    "problem_addressed": "Measuring the width of the problem hypergraph",
    "evidence": "Evaluation results show that our approach significantly outperforms base-line methods on our test set.",
    "confidence": 0.85
  },
  {
    "from_entity": "Alvin2015_GeoTutor",
    "to_entity": "Proof_Length",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "GeoTutor uses Proof Length as an evaluation metric",
    "problem_addressed": "Measuring the length of the problem hypergraph",
    "evidence": "Evaluation results show that our approach significantly outperforms base-line methods on our test set.",
    "confidence": 0.85
  },
  {
    "from_entity": "Alvin2015_GeoTutor",
    "to_entity": "Deductive_Steps",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "GeoTutor uses Deductive Steps as an evaluation metric",
    "problem_addressed": "Measuring the number of deductive steps in the problem hypergraph",
    "evidence": "Evaluation results show that our approach significantly outperforms base-line methods on our test set.",
    "confidence": 0.85
  },
  {
    "from_entity": "Alvin2015_GeoTutor",
    "to_entity": "Coverage_of_Givens",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "GeoTutor uses Coverage of Givens as an evaluation metric",
    "problem_addressed": "Measuring the usage of given assumptions in the problem",
    "evidence": "Evaluation results show that our approach significantly outperforms base-line methods on our test set.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_LatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes L3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Latent Left-Linking Model (CL3M) extends L3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_ProbabilisticLatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes PL3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Latent Left-Linking Model (CL3M) extends PL3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_ConstrainedProbabilisticLatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes CPL3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Probabilistic Latent Left-Linking Model (CPL3M) extends CL3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "MUC",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses MUC as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "BCUB",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses BCUB as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "CEAFe",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses CEAFe as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_LatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes L3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Latent Left-Linking Model (CL3M) extends L3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_ProbabilisticLatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes PL3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Latent Left-Linking Model (CL3M) extends PL3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_ConstrainedProbabilisticLatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes CPL3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Probabilistic Latent Left-Linking Model (CPL3M) extends CL3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "ACE_2004",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chang's CL3M algorithm is evaluated on the ACE 2004 dataset",
    "problem_addressed": "Evaluation of coreference resolution performance",
    "evidence": "We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Ontonotes_5.0",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chang's CL3M algorithm is evaluated on the Ontonotes 5.0 dataset",
    "problem_addressed": "Evaluation of coreference resolution performance",
    "evidence": "We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "MUC",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses MUC as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "BCUB",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses BCUB as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "CEAFe",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses CEAFe as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_LatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes L3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Latent Left-Linking Model (CL3M) extends L3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_ProbabilisticLatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes PL3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Latent Left-Linking Model (CL3M) extends PL3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_ConstrainedProbabilisticLatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes CPL3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Probabilistic Latent Left-Linking Model (CPL3M) extends CL3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "ACE_2004",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chang's CL3M algorithm is evaluated on the ACE 2004 dataset",
    "problem_addressed": "Evaluation of coreference resolution performance",
    "evidence": "We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Ontonotes_5.0",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chang's CL3M algorithm is evaluated on the Ontonotes 5.0 dataset",
    "problem_addressed": "Evaluation of coreference resolution performance",
    "evidence": "We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "MUC",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses MUC as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "BCUB",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses BCUB as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "CEAFe",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses CEAFe as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_LatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes L3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Latent Left-Linking Model (CL3M) extends L3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_ProbabilisticLatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes PL3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Latent Left-Linking Model (CL3M) extends PL3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_ConstrainedProbabilisticLatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Chang's CL3M algorithm optimizes CPL3M by adding a constraint module",
    "problem_addressed": "Improving the robustness and accuracy of coreference resolution",
    "evidence": "The Constrained Probabilistic Latent Left-Linking Model (CPL3M) extends CL3M with a constraint module.",
    "confidence": 0.9
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "ACE_2004",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chang's CL3M algorithm is evaluated on the ACE 2004 dataset",
    "problem_addressed": "Evaluation of coreference resolution performance",
    "evidence": "We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Ontonotes_5.0",
    "relation_type": "Use",
    "structure": "Dataset.Evaluation",
    "detail": "Chang's CL3M algorithm is evaluated on the Ontonotes 5.0 dataset",
    "problem_addressed": "Evaluation of coreference resolution performance",
    "evidence": "We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam.",
    "confidence": 0.85
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "MUC",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses MUC as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "BCUB",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses BCUB as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "CEAFe",
    "relation_type": "Use",
    "structure": "Metric.Evaluation",
    "detail": "Chang's CL3M algorithm uses CEAFe as an evaluation metric",
    "problem_addressed": "Measuring the quality of coreference clusters",
    "evidence": "Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.",
    "confidence": 0.8
  },
  {
    "from_entity": "Chang2013_ConstrainedLatentLeftLinkingModel",
    "to_entity": "Chang2013_LatentLeftLinkingModel",
    "relation_type": "Optimize",
    "structure": "Architecture.Component",
    "detail": "Ch