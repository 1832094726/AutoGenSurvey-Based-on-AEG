```json
{
  "entities": [
    {
      "algorithm_entity": {
        "algorithm_id": "Zhou2015_QuadraticProgrammingApproach",
        "entity_type": "Algorithm",
        "name": "Quadratic Programming Approach",
        "year": 2015,
        "authors": ["Zhou, L.", "Dai, S.", "Chen, L."],
        "task": "Algebra Word Problem Solving",
        "dataset": ["ALG514_2014"],
        "metrics": ["Accuracy_AlgebraWordProblems"],
        "architecture": {
          "components": ["Log-linear model", "Integer Linear Programming"],
          "connections": ["Feature function", "Weight vector"],
          "mechanisms": ["Max-margin objective", "Constraint generation"]
        },
        "methodology": {
          "training_strategy": ["Max-margin objective", "Constraint generation"],
          "parameter_tuning": ["Weight vector"]
        },
        "feature_processing": ["Lexical features", "Syntactic features", "Semantic features"]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "ALG514_2014",
        "entity_type": "Dataset",
        "name": "ALG514",
        "description": "A dataset of algebra word problems",
        "domain": "Natural Language Processing",
        "size": 514,
        "year": 2014,
        "creators": ["Kushman, N.", "Artzi, Y.", "Zettlemoyer, L.", "Barzilay, R."]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_AlgebraWordProblems",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "The proportion of correctly solved algebra word problems",
        "category": "Algebra Word Problem Solving",
        "formula": "Correctly solved problems / Total problems"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Cho2014_RecurrentNeuralNetworkEncoderDecoder",
        "entity_type": "Algorithm",
        "name": "Recurrent Neural Network Encoder-Decoder",
        "year": 2014,
        "authors": ["Cho, K.", "van MerriÃ«nboer, B.", "Gulcehre, C.", "Bahdanau, D.", "Bougares, F.", "Schwenk, H.", "Bengio, Y."],
        "task": "Phrase-based Statistical Machine Translation",
        "dataset": ["Europarl_2014", "NewsCommentary_2014", "UN_2014"],
        "metrics": ["BLEU_Score_Translation", "Perplexity_LanguageModel"],
        "architecture": {
          "components": ["Encoder RNN", "Decoder RNN"],
          "connections": ["Hidden state", "Reset gate", "Update gate"],
          "mechanisms": ["Adaptive remembering and forgetting", "Continuous space representation"]
        },
        "methodology": {
          "training_strategy": ["Maximize conditional log-likelihood", "Beam search"],
          "parameter_tuning": ["L-BFGS", "Adadelta", "Stochastic gradient descent"]
        },
        "feature_processing": ["Word embeddings", "Dependency parsing", "Part-of-speech tagging"]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Europarl_2014",
        "entity_type": "Dataset",
        "name": "Europarl",
        "description": "A parallel corpus for statistical machine translation",
        "domain": "Statistical Machine Translation",
        "size": 61000000,
        "year": 2014,
        "creators": ["Koehn, P."]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "NewsCommentary_2014",
        "entity_type": "Dataset",
        "name": "News Commentary",
        "description": "A dataset of news commentary for statistical machine translation",
        "domain": "Statistical Machine Translation",
        "size": 5500000,
        "year": 2014,
        "creators": ["Koehn, P."]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "UN_2014",
        "entity_type": "Dataset",
        "name": "UN",
        "description": "A dataset of United Nations documents for statistical machine translation",
        "domain": "Statistical Machine Translation",
        "size": 421000000,
        "year": 2014,
        "creators": ["Koehn, P."]
      }
    },
    {
      "metric_entity": {
        "metric_id": "BLEU_Score_Translation",
        "entity_type": "Metric",
        "name": "BLEU",
        "description": "A score for evaluating the quality of statistical machine translation",
        "category": "Translation Performance",
        "formula": "Exponential average of n-gram precision scores"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Perplexity_LanguageModel",
        "entity_type": "Metric",
        "name": "Perplexity",
        "description": "A measure of how well a language model predicts a sample",
        "category": "Language Model Performance",
        "formula": "2^(-log2 probability of the sample)"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Kushman2014_EquationTemplate",
        "entity_type": "Algorithm",
        "name": "Equation Template",
        "year": 2014,
        "authors": ["Kushman, N.", "Artzi, Y.", "Zettlemoyer, L.", "Barzilay, R."],
        "task": "Algebra Word Problem Solving",
        "dataset": ["ALG514_2014"],
        "metrics": ["Equation_Accuracy", "Answer_Accuracy"],
        "architecture": {
          "components": ["Template induction", "Slot filling", "Equation solving"],
          "connections": ["Unknown slots", "Number slots"],
          "mechanisms": ["Canonicalization", "Dependency parsing"]
        },
        "methodology": {
          "training_strategy": ["Maximize conditional log-likelihood", "Beam search"],
          "parameter_tuning": ["L-BFGS", "L2 regularization"]
        },
        "feature_processing": ["Part-of-speech tagging", "Lematization", "Dependency parsing"]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Equation_Accuracy",
        "entity_type": "Metric",
        "name": "Equation Accuracy",
        "description": "The proportion of correctly generated equation systems",
        "category": "Algebra Word Problem Solving",
        "formula": "Correctly generated equation systems / Total equation systems"
      }
    },
    {
      "metric_entity": {
        "metric_id": "Answer_Accuracy",
        "entity_type": "Metric",
        "name": "Answer Accuracy",
        "description": "The proportion of correctly generated numerical answers",
        "category": "Algebra Word Problem Solving",
        "formula": "Correctly generated numerical answers / Total numerical answers"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Goldwasser2014_CombinedFeedbackPerceptron",
        "entity_type": "Algorithm",
        "name": "Combined Feedback Perceptron",
        "year": 2014,
        "authors": ["Goldwasser, D.", "Roth, D."],
        "task": "Semantic Interpretation",
        "dataset": ["Geoquery_2014"],
        "metrics": ["Accuracy_SemanticInterpretation"],
        "architecture": {
          "components": ["Binary perceptron", "Structured perceptron"],
          "connections": ["Feature function", "Weight vector"],
          "mechanisms": ["Binary updates", "Structural updates"]
        },
        "methodology": {
          "training_strategy": ["Online learning", "Error-driven updates"],
          "parameter_tuning": ["Weight vector"]
        },
        "feature_processing": ["Lexical features", "Syntactic features"]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Geoquery_2014",
        "entity_type": "Dataset",
        "name": "Geoquery",
        "description": "A dataset of geographical queries and their corresponding logical forms",
        "domain": "Natural Language Processing",
        "size": 500,
        "year": 2014,
        "creators": ["Zelle, J.", "Mooney, R."]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_SemanticInterpretation",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "The proportion of correctly interpreted natural language instructions",
        "category": "Semantic Interpretation",
        "formula": "Correctly interpreted instructions / Total instructions"
      }
    },
    {
      "algorithm_entity": {
        "algorithm_id": "Pennington2014_GloVe",
        "entity_type": "Algorithm",
        "name": "GloVe",
        "year": 2014,
        "authors": ["Pennington, J.", "Socher, R.", "Manning, C.D."],
        "task": "Word Representation",
        "dataset": ["Wikipedia_2014", "Gigaword_2014", "CommonCrawl_2014"],
        "metrics": ["Accuracy_WordAnalogy", "SpearmanRankCorrelation_WordSimilarity"],
        "architecture": {
          "components": ["Log-bilinear regression model", "Weighted least squares"],
          "connections": ["Word vectors", "Context word vectors"],
          "mechanisms": ["Global co-occurrence counts", "Bias terms"]
        },
        "methodology": {
          "training_strategy": ["Optimize weighted least squares objective"],
          "parameter_tuning": ["Weighting function", "Bias terms"]
        },
        "feature_processing": ["Word co-occurrence statistics", "Context window"]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Wikipedia_2014",
        "entity_type": "Dataset",
        "name": "Wikipedia",
        "description": "A large-scale text corpus",
        "domain": "Natural Language Processing",
        "size": 1600000000,
        "year": 2014,
        "creators": ["Wikipedia contributors"]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "Gigaword_2014",
        "entity_type": "Dataset",
        "name": "Gigaword",
        "description": "A large-scale text corpus",
        "domain": "Natural Language Processing",
        "size": 4300000000,
        "year": 2014,
        "creators": ["Gigaword contributors"]
      }
    },
    {
      "dataset_entity": {
        "dataset_id": "CommonCrawl_2014",
        "entity_type": "Dataset",
        "name": "Common Crawl",
        "description": "A large-scale web corpus",
        "domain": "Natural Language Processing",
        "size": 42000000000,
        "year": 2014,
        "creators": ["Common Crawl contributors"]
      }
    },
    {
      "metric_entity": {
        "metric_id": "Accuracy_WordAnalogy",
        "entity_type": "Metric",
        "name": "Accuracy",
        "description": "The proportion of correctly solved word analogies",
        "category": "Word Analogy",
        "formula": "Correctly solved word analogies / Total word analogies"
      }
    },
    {
      "metric_entity": {
        "metric_id": "SpearmanRankCorrelation_WordSimilarity",
        "entity_type": "Metric",
        "name": "Spearman Rank Correlation",
        "description": "A measure of how well word similarity scores match human judgments",
        "category": "Word Similarity",
        "formula": "Rank correlation between predicted and human similarity scores"
      }
    }
  ],
  "extraction_info": {
    "is_complete": false,
    "current_section": "EXPERIMENTAL SETUP",
    "next_section": "RESULTS"
  }
}
```