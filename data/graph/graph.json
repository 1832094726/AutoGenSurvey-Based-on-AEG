{
  "nodes": [
    {
      "id": "Ahmed2013_NaturalDeductionProblemGenerator",
      "label": "Natural Deduction Problem Generator",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ahmed2013_NaturalDeductionProblemGenerator",
        "entity_id": "Ahmed2013_NaturalDeductionProblemGenerator",
        "name": "Natural Deduction Problem Generator",
        "title": "",
        "year": "2013",
        "authors": [
          "Ahmed, U. Z.",
          "Gulwani, S.",
          "Karkare, A."
        ],
        "task": "[\"Natural Deduction Problem Generation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "ALGES2015_EquationTree",
      "label": "Equation Tree",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "ALGES2015_EquationTree",
        "entity_id": "ALGES2015_EquationTree",
        "name": "Equation Tree",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Equation Tree",
            "Integer Linear Programming"
          ],
          "connections": [
            "Bottom-up Tree Construction"
          ],
          "mechanisms": [
            "Syntactic Validity",
            "Type Consistency"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "ILP Constraints"
          ]
        },
        "feature_processing": [
          "Quantity Extraction",
          "Operator Selection"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Allen1983_IntervalRelations",
      "label": "Interval Relations",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Allen1983_IntervalRelations",
        "entity_id": "Allen1983_IntervalRelations",
        "name": "Interval Relations",
        "title": "",
        "year": "1983",
        "authors": [
          "Allen, J. F."
        ],
        "task": "[\"Temporal and Spatial Reasoning\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Temporal intervals",
            "Spatial intervals"
          ],
          "connections": [],
          "mechanisms": [
            "Representation of temporal and spatial intervals",
            "Calculation of interval relations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None (not a learning algorithm)"
          ],
          "parameter_tuning": [
            "None (not a learning algorithm)"
          ]
        },
        "feature_processing": [
          "Temporal and spatial interval detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2014_GenProblem",
      "label": "GenProblem",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2014_GenProblem",
        "entity_id": "Alvin2014_GenProblem",
        "name": "GenProblem",
        "title": "Synthesis of Geometry Proof Problems",
        "year": "2014",
        "authors": [
          "Chris Alvin",
          "Sumit Gulwani",
          "Rupak Majumdar",
          "Supratik Mukhopadhyay"
        ],
        "task": "[\"Geometry Proof Problem Generation\"]",
        "dataset": [
          "Figures from geometry textbooks"
        ],
        "metrics": [
          "Number of generated problems",
          "Time taken to generate problems"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Minimal Assumption Generation",
            "Strictly Interesting Problem Synthesis"
          ],
          "connections": [
            "Hypergraph nodes and edges",
            "Derive function",
            "Minimal set enumeration"
          ],
          "mechanisms": [
            "Hypergraph reachability",
            "Fixed-point procedure",
            "Non-deterministic choices"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Semi-automated methodology"
          ],
          "parameter_tuning": [
            "Axioms selection",
            "Figure input"
          ]
        },
        "feature_processing": [
          "Implicit and explicit facts extraction",
          "Predicate derivation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2014_HypergraphConstruction",
      "label": "Hypergraph Construction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2014_HypergraphConstruction",
        "entity_id": "Alvin2014_HypergraphConstruction",
        "name": "Hypergraph Construction",
        "title": "",
        "year": "2014",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Geometry Proof Problem Generation\"]",
        "dataset": [
          "Figures_from_geometry_textbooks_2014"
        ],
        "metrics": [
          "Number_of_generated_problems_Generation",
          "Time_taken_to_generate_problems_Generation"
        ],
        "architecture": {
          "components": [
            "Nodes",
            "Edges",
            "Predicates"
          ],
          "connections": [
            "Directed Hyperedges"
          ],
          "mechanisms": [
            "Derivation of Predicates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Enumerating all facts",
            "Connecting source facts to target facts using axioms"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Analyzing pictorial representations",
          "Enumerating implicit and explicit facts"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2014_MinimalAssumptionGeneration",
      "label": "Minimal Assumption Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2014_MinimalAssumptionGeneration",
        "entity_id": "Alvin2014_MinimalAssumptionGeneration",
        "name": "Minimal Assumption Generation",
        "title": "",
        "year": "2014",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Geometry Proof Problem Generation\"]",
        "dataset": [
          "Figures_from_geometry_textbooks_2014"
        ],
        "metrics": [
          "Number_of_generated_problems_Generation",
          "Time_taken_to_generate_problems_Generation"
        ],
        "architecture": {
          "components": [
            "Minimal Sets",
            "Fixed-point Procedure"
          ],
          "connections": [
            "Iterative Enumeration"
          ],
          "mechanisms": [
            "Checking minimality of assumption sets"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Systematic enumeration of minimal sets"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Ensuring minimality of assumption sets"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2014_ProblemGenerationAlgorithm",
      "label": "Problem Generation Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2014_ProblemGenerationAlgorithm",
        "entity_id": "Alvin2014_ProblemGenerationAlgorithm",
        "name": "Problem Generation Algorithm",
        "title": "Synthesis of Geometry Proof Problems",
        "year": "2014",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Geometry Proof Problem Generation\"]",
        "dataset": [],
        "metrics": [
          "Number of Generated Problems",
          "Time Taken to Generate Problems"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Minimal Assumption Generation",
            "Strictly Interesting Problem Synthesis"
          ],
          "connections": [
            "Derive Function",
            "Choose Operator"
          ],
          "mechanisms": [
            "First-order Logic",
            "Horn Clauses"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Hypergraph Reachability",
            "Fixed-point Procedure"
          ],
          "parameter_tuning": [
            "Minimal Sets Enumeration",
            "Strictly Interesting Problem Synthesis"
          ]
        },
        "feature_processing": [
          "Implicit Facts Extraction",
          "Explicit Facts Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2014_QueryInterface",
      "label": "Query Interface for Problem Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2014_QueryInterface",
        "entity_id": "Alvin2014_QueryInterface",
        "name": "Query Interface for Problem Generation",
        "title": "",
        "year": "2014",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Geometry Proof Problem Generation\"]",
        "dataset": [
          "Figures_from_geometry_textbooks_2014"
        ],
        "metrics": [
          "Number_of_generated_problems_Generation",
          "Time_taken_to_generate_problems_Generation"
        ],
        "architecture": {
          "components": [
            "Relational Database",
            "Query Engine"
          ],
          "connections": [
            "User Input -> Query Engine -> Relational Database -> Generated Problems"
          ],
          "mechanisms": [
            "Relational Query Processing",
            "Feature Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Input of (Fig, Axm) Pairs"
          ],
          "parameter_tuning": [
            "Feature Specification Parameters"
          ]
        },
        "feature_processing": [
          "Feature Extraction from Problem Characteristics"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2014_StrictlyInterestingProblemSynthesis",
      "label": "Strictly Interesting Problem Synthesis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2014_StrictlyInterestingProblemSynthesis",
        "entity_id": "Alvin2014_StrictlyInterestingProblemSynthesis",
        "name": "Strictly Interesting Problem Synthesis",
        "title": "",
        "year": "2014",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Geometry Proof Problem Generation\"]",
        "dataset": [
          "Figures_from_geometry_textbooks_2014"
        ],
        "metrics": [
          "Number_of_generated_problems_Generation",
          "Time_taken_to_generate_problems_Generation"
        ],
        "architecture": {
          "components": [
            "Goal Sets",
            "Non-deterministic Choices"
          ],
          "connections": [
            "Growing Goal Sets"
          ],
          "mechanisms": [
            "Ensuring strict interestingness"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Generating strictly interesting problems"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Choosing new goals based on existing assumptions"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2015_CoordinateBasedComputation",
      "label": "Coordinate-Based Computation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2015_CoordinateBasedComputation",
        "entity_id": "Alvin2015_CoordinateBasedComputation",
        "name": "Coordinate-Based Computation",
        "title": "",
        "year": "2015",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Euclidean Geometry Problem Synthesis\"]",
        "dataset": [
          "HighSchoolGeometryProblems_2015"
        ],
        "metrics": [
          "ProofWidth_Classification",
          "ProofLength_Classification",
          "DeductiveSteps_Classification"
        ],
        "architecture": {
          "components": [
            "Coordinate Calculation",
            "Figure Strengthening"
          ],
          "connections": [
            "Input Figure -> Coordinate Calculation -> Figure Strengthening"
          ],
          "mechanisms": [
            "Midpoint Detection",
            "Triangle Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Coordinate Processing",
          "Geometric Property Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2015_GeoTutor",
      "label": "GeoTutor",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2015_GeoTutor",
        "entity_id": "Alvin2015_GeoTutor",
        "name": "GeoTutor",
        "title": "Automatic Synthesis of Geometry Problems for an Intelligent Tutoring System",
        "year": "2015",
        "authors": [
          "Chris Alvin",
          "Sumit Gulwani",
          "Rupak Majumdar",
          "Supratik Mukhopadhyay"
        ],
        "task": "[\"Euclidean Geometry Problem Synthesis\"]",
        "dataset": [
          "High School Geometry Problems"
        ],
        "metrics": [
          "Proof Width",
          "Proof Length",
          "Deductive Steps"
        ],
        "architecture": {
          "components": [
            "Hypergraph Construction",
            "Pebbling Algorithm",
            "Problem Synthesis"
          ],
          "connections": [
            "Forward Edges",
            "Back-Edges"
          ],
          "mechanisms": [
            "Traversal Algorithm",
            "Coarse Problem Homomorphism",
            "Goal Analogous Problems"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Breadth-First Pebbling",
            "Coordinate-Based Computation"
          ],
          "parameter_tuning": [
            "User Query Restrictions"
          ]
        },
        "feature_processing": [
          "Invariant Characteristics Extraction",
          "Student Knowledge Base Integration"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2015_HypergraphTraversal",
      "label": "Hypergraph Traversal",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2015_HypergraphTraversal",
        "entity_id": "Alvin2015_HypergraphTraversal",
        "name": "Hypergraph Traversal",
        "title": "",
        "year": "2015",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Problem Synthesis\"]",
        "dataset": [
          "HighSchoolGeometryProblems_2015"
        ],
        "metrics": [
          "ProofWidth_Classification",
          "ProofLength_Classification",
          "DeductiveSteps_Classification"
        ],
        "architecture": {
          "components": [
            "Nodes",
            "Hyperedges"
          ],
          "connections": [
            "Forward Edges",
            "Back-Edges"
          ],
          "mechanisms": [
            "Pebbling Technique",
            "Breadth-First Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Exploration of Hypergraph"
          ],
          "parameter_tuning": [
            "User Query Restrictions"
          ]
        },
        "feature_processing": [
          "Coordinate-Based Computation",
          "Assumption Filtering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2015_PebblingAlgorithm",
      "label": "Pebbling Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2015_PebblingAlgorithm",
        "entity_id": "Alvin2015_PebblingAlgorithm",
        "name": "Pebbling Algorithm",
        "title": "",
        "year": "2015",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Problem Synthesis\"]",
        "dataset": [
          "HighSchoolGeometryProblems_2015"
        ],
        "metrics": [
          "ProofWidth_Classification",
          "ProofLength_Classification",
          "DeductiveSteps_Classification"
        ],
        "architecture": {
          "components": [
            "Forward Edges",
            "Back-Edges"
          ],
          "connections": [
            "Hypergraph Traversal",
            "Breadth-First Search"
          ],
          "mechanisms": [
            "Deduction",
            "Axiom Application"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Breadth-First Pebbling"
          ],
          "parameter_tuning": [
            "User Query Restrictions"
          ]
        },
        "feature_processing": [
          "Coordinate-Based Computation",
          "Assumption Filtering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Alvin2017_GeoShader",
      "label": "GeoShader",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2017_GeoShader",
        "entity_id": "Alvin2017_GeoShader",
        "name": "GeoShader",
        "title": "",
        "year": "2017",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Solving geometry problems with shaded areas\"]",
        "dataset": [
          "AI2_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Analysis hypergraph",
            "Intermediate facts",
            "Deduction relationships"
          ],
          "connections": [
            "Fact extraction",
            "Deduction path finding"
          ],
          "mechanisms": [
            "Hypergraph traversal"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning"
          ],
          "parameter_tuning": [
            "Hyperparameters for deduction rules"
          ]
        },
        "feature_processing": [
          "Diagram feature extraction",
          "Fact extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Alvin2017_ShadedAreaGeometryReasoning",
      "label": "Shaded Area Geometry Reasoning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Alvin2017_ShadedAreaGeometryReasoning",
        "entity_id": "Alvin2017_ShadedAreaGeometryReasoning",
        "name": "Shaded Area Geometry Reasoning",
        "title": "",
        "year": "2017",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Solving geometry problems with shaded areas\"]",
        "dataset": [
          "Geometry problems with shaded areas"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Hypergraph analysis",
            "Intermediate fact extraction"
          ],
          "connections": [
            "Directed edges indicating deductibility"
          ],
          "mechanisms": [
            "Path finding in hypergraph"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Visual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Andersen2013_TraceBasedFramework",
      "label": "Trace-Based Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Andersen2013_TraceBasedFramework",
        "entity_id": "Andersen2013_TraceBasedFramework",
        "name": "Trace-Based Framework",
        "title": "",
        "year": "2013",
        "authors": [
          "Andersen, E.",
          "Gulwani, S.",
          "Popovic, Z."
        ],
        "task": "[\"Analyzing and Synthesizing Educational Progressions\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Antol2015_LSTM_VQA",
      "label": "LSTM VQA",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Antol2015_LSTM_VQA",
        "entity_id": "Antol2015_LSTM_VQA",
        "name": "LSTM VQA",
        "title": "",
        "year": "2015",
        "authors": [
          "Antol, S.",
          "Agrawal, A.",
          "Lu, J.",
          "Mitchell, M.",
          "Batra, D.",
          "Zitnick, C. L.",
          "Parikh, D."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "MS_COCO_2014"
        ],
        "metrics": [
          "Accuracy_Open-Answer",
          "Accuracy_Multiple-Choice"
        ],
        "architecture": {
          "components": [
            "Long Short-Term Memory",
            "Softmax Layer"
          ],
          "connections": [
            "Recurrent Connections"
          ],
          "mechanisms": [
            "Gated Recurrent Units"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Embedding Size"
          ]
        },
        "feature_processing": [
          "One-Hot Encoding",
          "Image Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Antol2015_MLP_VQA",
      "label": "MLP VQA",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Antol2015_MLP_VQA",
        "entity_id": "Antol2015_MLP_VQA",
        "name": "MLP VQA",
        "title": "",
        "year": "2015",
        "authors": [
          "Antol, S.",
          "Agrawal, A.",
          "Lu, J.",
          "Mitchell, M.",
          "Batra, D.",
          "Zitnick, C. L.",
          "Parikh, D."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "MS_COCO_2014"
        ],
        "metrics": [
          "Accuracy_Open-Answer",
          "Accuracy_Multiple-Choice"
        ],
        "architecture": {
          "components": [
            "Multi-layer Perceptron",
            "Hidden Layers",
            "Dropout",
            "Tanh Activation"
          ],
          "connections": [
            "Fully Connected Layers"
          ],
          "mechanisms": [
            "Dropout Regularization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Bag-of-Words",
          "Image Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Antol2015_VQA",
      "label": "VQA",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Antol2015_VQA",
        "entity_id": "Antol2015_VQA",
        "name": "VQA",
        "title": "",
        "year": "2015",
        "authors": [
          "Stanislaw Antol",
          "Aishwarya Agrawal",
          "Jiasen Lu",
          "Margaret Mitchell",
          "Dhruv Batra",
          "C. Lawrence Zitnick",
          "Devi Parikh"
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "MS COCO_2014",
          "Abstract Scenes_2015"
        ],
        "metrics": [
          "Accuracy_OpenAnswer",
          "Accuracy_MultipleChoice"
        ],
        "architecture": {
          "components": [
            "Multi-Layer Perceptron (MLP)",
            "Long Short-Term Memory (LSTM)"
          ],
          "connections": [
            "Question to Answer",
            "Image to Answer",
            "Caption to Answer"
          ],
          "mechanisms": [
            "Element-wise Multiplication",
            "Linear Transformation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Concatenation of Features"
          ],
          "parameter_tuning": [
            "Dropout",
            "Hidden Units"
          ]
        },
        "feature_processing": [
          "Bag-of-Words",
          "One-Hot Encoding",
          "Image Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Auli2013_JointLanguageAndTranslationModeling",
      "label": "Joint Language and Translation Modeling with Recurrent Neural Networks",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Auli2013_JointLanguageAndTranslationModeling",
        "entity_id": "Auli2013_JointLanguageAndTranslationModeling",
        "name": "Joint Language and Translation Modeling with Recurrent Neural Networks",
        "title": "",
        "year": "2013",
        "authors": [
          "M. Auli",
          "M. Galley",
          "C. Quirk",
          "G. Zweig"
        ],
        "task": "[\"Statistical Machine Translation\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Networks",
            "Topic Model"
          ],
          "connections": [
            "Input Sentence to Topic Model",
            "Topic Model to Neural Network"
          ],
          "mechanisms": [
            "Joint Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rescoring n-best Lists"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Topic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bahdanau2014_NeuralMachineTranslation",
      "label": "Neural Machine Translation with Attention Mechanism",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bahdanau2014_NeuralMachineTranslation",
        "entity_id": "Bahdanau2014_NeuralMachineTranslation",
        "name": "Neural Machine Translation with Attention Mechanism",
        "title": "",
        "year": "2014",
        "authors": [
          "Bahdanau, D.",
          "Cho, K.",
          "Bengio, Y."
        ],
        "task": "[\"Machine Translation\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Attention Mechanism",
            "Recurrent Neural Networks"
          ],
          "connections": [
            "Input to Attention",
            "Attention to Output"
          ],
          "mechanisms": [
            "Jointly learning to align and translate"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training"
          ],
          "parameter_tuning": [
            "Hyperparameters tuning"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bahdanau2015_AttentionMechanism",
      "label": "Attention Mechanism",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bahdanau2015_AttentionMechanism",
        "entity_id": "Bahdanau2015_AttentionMechanism",
        "name": "Attention Mechanism",
        "title": "",
        "year": "2015",
        "authors": [
          "Bahdanau, Dzmitry",
          "Cho, Kyunghyun",
          "Bengio, Yoshua"
        ],
        "task": "[\"Sequence Modeling\"]",
        "dataset": [
          "WMT'15 English-German Translation",
          "Penn Tree Bank Parsing"
        ],
        "metrics": [
          "BLEU",
          "F1",
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Attention Layer"
          ],
          "connections": [
            "Encoder Hidden States",
            "Decoder Attention Weights"
          ],
          "mechanisms": [
            "Alignment Weights Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Mini-Batch Size"
          ]
        },
        "feature_processing": [
          "Context Vector Computation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bahdanau2015_Seq2SeqWithAttention",
      "label": "Seq2Seq with Attention",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bahdanau2015_Seq2SeqWithAttention",
        "entity_id": "Bahdanau2015_Seq2SeqWithAttention",
        "name": "Seq2Seq with Attention",
        "title": "",
        "year": "2015",
        "authors": [
          "Bahdanau, D.",
          "Cho, K.",
          "Bengio, Y."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Attention Mechanism"
          ],
          "connections": [
            "Bidirectional GRU",
            "Context Vector"
          ],
          "mechanisms": [
            "Attention Scores",
            "Softmax"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Number Tokenization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2007_ROBUST",
      "label": "ROBUST",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2007_ROBUST",
        "entity_id": "Bakman2007_ROBUST",
        "name": "ROBUST",
        "title": "",
        "year": "2007",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [
          "Not specified"
        ],
        "metrics": [
          "Not specified"
        ],
        "architecture": {
          "components": [
            "Schemas",
            "Temporal reasoning"
          ],
          "connections": [
            "Keyword matching",
            "Schema application"
          ],
          "mechanisms": [
            "Transfer-In-Ownership",
            "Change-Out"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge-based"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Keyword extraction",
          "Sentence parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2013_ROBUST",
      "label": "ROBUST",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2013_ROBUST",
        "entity_id": "Bakman2013_ROBUST",
        "name": "ROBUST",
        "title": "ROBUST UNDERSTANDING OF WORD PROBLEMS WITH EXTRANEOUS INFORMATION",
        "year": "2013",
        "authors": [
          "Yefim Bakman"
        ],
        "task": "[\"多步骤算术文字题理解\"]",
        "dataset": [
          "多步骤算术文字题数据集"
        ],
        "metrics": [
          "正确率",
          "解决时间"
        ],
        "architecture": {
          "components": [
            "模式识别",
            "句子转置",
            "无关信息添加"
          ],
          "connections": [
            "模式识别与句子转置结合",
            "句子转置与无关信息添加结合"
          ],
          "mechanisms": [
            "模式匹配",
            "谨慎策略"
          ]
        },
        "methodology": {
          "training_strategy": [
            "基于问题答案对的学习"
          ],
          "parameter_tuning": [
            "阈值调整"
          ]
        },
        "feature_processing": [
          "句子解析",
          "模式实例化"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_CautiousStrategy",
      "label": "Cautious Strategy",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_CautiousStrategy",
        "entity_id": "Bakman2023_CautiousStrategy",
        "name": "Cautious Strategy",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Word Problem Solving\"]",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Schema Instantiation Creation",
            "Formula Matching"
          ],
          "connections": [
            "Problem Propositions -> Schema Instantiations"
          ],
          "mechanisms": [
            "Relevance Checking",
            "Elementary Change Verb Splitting"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Heuristic Method for Schema Relevancy Estimation"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_ChangeFormula",
      "label": "Change Formula",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_ChangeFormula",
        "entity_id": "Bakman2023_ChangeFormula",
        "name": "Change Formula",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Formula Variables"
          ],
          "connections": [
            "Correspondence between sentence members and formula variables"
          ],
          "mechanisms": [
            "Instantiation of change schema"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parsing natural language",
            "Matching propositions to schema instantiations"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Parsing problem sentences",
          "Identifying change verbs"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_Creation",
      "label": "Creation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_Creation",
        "entity_id": "Bakman2023_Creation",
        "name": "Creation",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Word Problem Solving\"]",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Created Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Place/Owner"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_ROBUST",
      "label": "ROBUST",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_ROBUST",
        "entity_id": "Bakman2023_ROBUST",
        "name": "ROBUST",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Understanding arithmetic word problems with extraneous information\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Change formulas",
            "Schema instantiation",
            "Natural language parser"
          ],
          "connections": [
            "Change verbs to schema mapping",
            "Formula instantiation to problem propositions"
          ],
          "mechanisms": [
            "Cautious strategy for schema instantiation",
            "Complex change verb splitting"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Parsing natural language",
          "Identifying change verbs",
          "Splitting complex sentences"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_ROBUSTSimulation",
      "label": "ROBUST Simulation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_ROBUSTSimulation",
        "entity_id": "Bakman2023_ROBUSTSimulation",
        "name": "ROBUST Simulation",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Understanding Arithmetic Word Problems\"]",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Parser",
            "Schema Instantiation Creator",
            "Change Formula Recognizer"
          ],
          "connections": [
            "Parser -> Schema Instantiation Creator",
            "Schema Instantiation Creator -> Change Formula Recognizer"
          ],
          "mechanisms": [
            "Natural Language Parsing",
            "Schema Matching",
            "Formula Instantiation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None - Rule-Based System"
          ],
          "parameter_tuning": [
            "None - Rule-Based System"
          ]
        },
        "feature_processing": [
          "Natural Language Processing",
          "Sentence Splitting",
          "Variable Substitution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_Termination",
      "label": "Termination",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_Termination",
        "entity_id": "Bakman2023_Termination",
        "name": "Termination",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Word Problem Solving\"]",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Terminated Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Place/Owner"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_TransferInOwnership",
      "label": "Transfer-In-Ownership",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_TransferInOwnership",
        "entity_id": "Bakman2023_TransferInOwnership",
        "name": "Transfer-In-Ownership",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Word Problem Solving\"]",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Additional Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Owner"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_TransferInPlace",
      "label": "Transfer-In-Place",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_TransferInPlace",
        "entity_id": "Bakman2023_TransferInPlace",
        "name": "Transfer-In-Place",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Word Problem Solving\"]",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Additional Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Place"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_TransferOutOwnership",
      "label": "Transfer-Out-Ownership",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_TransferOutOwnership",
        "entity_id": "Bakman2023_TransferOutOwnership",
        "name": "Transfer-Out-Ownership",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Word Problem Solving\"]",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Additional Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Owner"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bakman2023_TransferOutPlace",
      "label": "Transfer-Out-Place",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bakman2023_TransferOutPlace",
        "entity_id": "Bakman2023_TransferOutPlace",
        "name": "Transfer-Out-Place",
        "title": "",
        "year": "2023",
        "authors": [
          "Bakman, Y."
        ],
        "task": "[\"Word Problem Solving\"]",
        "dataset": [
          "WordProblems_2023"
        ],
        "metrics": [
          "SolutionCorrectness_ProblemSolving"
        ],
        "architecture": {
          "components": [
            "Initial Number",
            "Additional Number",
            "Final Number"
          ],
          "connections": [
            "Objects -> Place"
          ],
          "mechanisms": [
            "Change Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Natural Language Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ballard1981_GeneralizedHoughTransform",
      "label": "Generalized Hough Transform (GHT)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ballard1981_GeneralizedHoughTransform",
        "entity_id": "Ballard1981_GeneralizedHoughTransform",
        "name": "Generalized Hough Transform (GHT)",
        "title": "Generalizing the Hough Transform to detect arbitrary shapes",
        "year": "1981",
        "authors": [
          "D. Ballard"
        ],
        "task": "[\"Arbitrary Shape Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Accumulator Array",
            "Shape Templates"
          ],
          "connections": [
            "Edge Points -> Accumulator Array"
          ],
          "mechanisms": [
            "Peak Detection",
            "Template Matching"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "BasicSim",
      "label": "BasicSim",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "BasicSim",
        "entity_id": "BasicSim",
        "name": "BasicSim",
        "title": "Simple Statistical Method for Math Word Problem Solving",
        "year": "2015",
        "authors": [
          "Not Explicitly Mentioned"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Similarity Calculation"
          ],
          "connections": [
            "Training Set Problems"
          ],
          "mechanisms": [
            "Statistical Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-Validation"
          ],
          "parameter_tuning": [
            "None Mentioned"
          ]
        },
        "feature_processing": [
          "Problem Similarity"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "BasicSim_2015",
      "label": "BasicSim",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "BasicSim_2015",
        "entity_id": "BasicSim_2015",
        "name": "BasicSim",
        "title": "",
        "year": "2015",
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "[\"自动求解数学文字题\"]",
        "dataset": [
          "LinearT2_2015",
          "LinearT6_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "相似性计算",
            "最相似问题应用"
          ],
          "connections": [
            "测试问题与训练集问题的相似性计算"
          ],
          "mechanisms": [
            "基于相似性的方程应用"
          ]
        },
        "methodology": {
          "training_strategy": [
            "基于训练集的问题相似性计算"
          ],
          "parameter_tuning": [
            "相似性阈值"
          ]
        },
        "feature_processing": [
          "问题相似性特征提取"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengio2003_NeuralLM",
      "label": "Neural Probabilistic Language Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengio2003_NeuralLM",
        "entity_id": "Bengio2003_NeuralLM",
        "name": "Neural Probabilistic Language Model",
        "title": "",
        "year": "2003",
        "authors": [
          "Bengio, Y.",
          "Ducharme, R.",
          "Vincent, P.",
          "Janvin, C."
        ],
        "task": "[\"Language Modeling\"]",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Log Probability"
        ],
        "architecture": {
          "components": [
            "Simple Neural Network Architecture"
          ],
          "connections": [
            "Word Vector Representations"
          ],
          "mechanisms": [
            "Language Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Training"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengio2003_NeuralProbabilisticLanguageModel",
      "label": "Neural Probabilistic Language Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengio2003_NeuralProbabilisticLanguageModel",
        "entity_id": "Bengio2003_NeuralProbabilisticLanguageModel",
        "name": "Neural Probabilistic Language Model",
        "title": "",
        "year": "2003",
        "authors": [
          "Bengio, Y.",
          "Ducharme, R.",
          "Vincent, P.",
          "Jauvin, C."
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Neural Network"
          ],
          "connections": [
            "Feedforward"
          ],
          "mechanisms": [
            "Probabilistic Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengston2008_SupervisedModel",
      "label": "Supervised Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengston2008_SupervisedModel",
        "entity_id": "Bengston2008_SupervisedModel",
        "name": "Supervised Model",
        "title": "",
        "year": "2008",
        "authors": [
          "Bengston, E.",
          "Roth, D."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-CULOTTA-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Feature-rich Models"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengtson2008_AlignedModifiers",
      "label": "Aligned Modifiers",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengtson2008_AlignedModifiers",
        "entity_id": "Bengtson2008_AlignedModifiers",
        "name": "Aligned Modifiers",
        "title": "",
        "year": "2008",
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Modifier Relationship Determination"
          ],
          "connections": [
            "Modifier Alignment"
          ],
          "mechanisms": [
            "Hypernym Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Modifier Lists"
          ]
        },
        "feature_processing": [
          "Modifier Comparison"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengtson2008_AnaphoricityClassifier",
      "label": "Anaphoricity Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengtson2008_AnaphoricityClassifier",
        "entity_id": "Bengtson2008_AnaphoricityClassifier",
        "name": "Anaphoricity Classifier",
        "title": "",
        "year": "2008",
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Anaphoricity Detection"
          ],
          "connections": [
            "Anaphoricity Matching"
          ],
          "mechanisms": [
            "Feature Conjunctions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Anaphoricity Features"
          ]
        },
        "feature_processing": [
          "Mention Type, Quotation Detection, Extent Text"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengtson2008_GenderMatch",
      "label": "Gender Match",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengtson2008_GenderMatch",
        "entity_id": "Bengtson2008_GenderMatch",
        "name": "Gender Match",
        "title": "",
        "year": "2008",
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Gender Determination"
          ],
          "connections": [
            "Gender Matching"
          ],
          "mechanisms": [
            "Gender Lookup Tables"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Gender Lists"
          ]
        },
        "feature_processing": [
          "Proper Name Gender Determination",
          "Common Noun Phrase Gender Determination"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengtson2008_MemorizationFeatures",
      "label": "Memorization Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengtson2008_MemorizationFeatures",
        "entity_id": "Bengtson2008_MemorizationFeatures",
        "name": "Memorization Features",
        "title": "",
        "year": "2008",
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Noun Pair Memorization"
          ],
          "connections": [
            "Noun Pair Matching"
          ],
          "mechanisms": [
            "Pattern Recognition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Noun Pair Lists"
          ]
        },
        "feature_processing": [
          "Final Head Noun Comparison"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengtson2008_NumberMatch",
      "label": "Number Match",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengtson2008_NumberMatch",
        "entity_id": "Bengtson2008_NumberMatch",
        "name": "Number Match",
        "title": "",
        "year": "2008",
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Number Determination"
          ],
          "connections": [
            "Number Matching"
          ],
          "mechanisms": [
            "Singular and Plural Lists"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Number Lists"
          ]
        },
        "feature_processing": [
          "Phrase Number Determination"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengtson2008_PairwiseCoreferenceModel",
      "label": "Pairwise Coreference Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengtson2008_PairwiseCoreferenceModel",
        "entity_id": "Bengtson2008_PairwiseCoreferenceModel",
        "name": "Pairwise Coreference Model",
        "title": "Understanding the Value of Features for Coreference Resolution",
        "year": "2008",
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE 2004 English training data"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function",
            "Document-Level Decision Model",
            "Best-Link decision model"
          ],
          "connections": [
            "Pairwise coreference function connects mentions in a graph"
          ],
          "mechanisms": [
            "Pairwise coreference scoring",
            "Graph construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Averaged perceptron learning algorithm",
            "Regularized version in Learning Based Java"
          ],
          "parameter_tuning": [
            "Learning rate: 0.1",
            "Regularization parameter: 3.5",
            "Threshold optimization"
          ]
        },
        "feature_processing": [
          "Mention Types",
          "String Relation Features",
          "Semantic Features",
          "Relative Location Features",
          "Learned Features",
          "Aligned Modifiers",
          "Memorization Features",
          "Predicted Entity Types"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengtson2008_PredictedEntityType",
      "label": "Predicted Entity Type",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengtson2008_PredictedEntityType",
        "entity_id": "Bengtson2008_PredictedEntityType",
        "name": "Predicted Entity Type",
        "title": "",
        "year": "2008",
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Entity Type Prediction"
          ],
          "connections": [
            "Type Matching"
          ],
          "mechanisms": [
            "List Lookup"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Entity Type Lists"
          ]
        },
        "feature_processing": [
          "Entity Type Comparison"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengtson2008_RegularizedAveragedPerceptron",
      "label": "Regularized Averaged Perceptron",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengtson2008_RegularizedAveragedPerceptron",
        "entity_id": "Bengtson2008_RegularizedAveragedPerceptron",
        "name": "Regularized Averaged Perceptron",
        "title": "",
        "year": "2008",
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference",
          "MUC_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Perceptron",
            "Regularization"
          ],
          "connections": [
            "Input Layer -> Output Layer"
          ],
          "mechanisms": [
            "Weight Updates",
            "Regularization Parameter"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Threshold Optimization"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Feature Selection",
          "Threshold Application"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bengtson2008_WordNetFeatures",
      "label": "WordNet Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bengtson2008_WordNetFeatures",
        "entity_id": "Bengtson2008_WordNetFeatures",
        "name": "WordNet Features",
        "title": "",
        "year": "2008",
        "authors": [
          "Eric Bengtson",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004"
        ],
        "metrics": [
          "B-Cubed F-Score",
          "MUC F-Score"
        ],
        "architecture": {
          "components": [
            "Synonym Check",
            "Antonym Check",
            "Hypernym Check"
          ],
          "connections": [
            "WordNet Tree Traversal"
          ],
          "mechanisms": [
            "Hypernym Tree Filtering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "WordNet Database"
          ]
        },
        "feature_processing": [
          "Head Noun Phrase Comparison"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Berant2013_SemanticParsingOnFreebase",
      "label": "SemanticParsingOnFreebase",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Berant2013_SemanticParsingOnFreebase",
        "entity_id": "Berant2013_SemanticParsingOnFreebase",
        "name": "SemanticParsingOnFreebase",
        "title": "",
        "year": "2013",
        "authors": [
          "Berant, J.",
          "Chou, A.",
          "Frostig, R.",
          "Liang, P."
        ],
        "task": "[\"Semantic parsing on Freebase\"]",
        "dataset": [
          "Question-answer pairs"
        ],
        "metrics": [
          "None specified"
        ],
        "architecture": {
          "components": [
            "None specified"
          ],
          "connections": [
            "None specified"
          ],
          "mechanisms": [
            "None specified"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None specified"
          ],
          "parameter_tuning": [
            "None specified"
          ]
        },
        "feature_processing": [
          "None specified"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Blei2003_LatentDirichletAllocation",
      "label": "Latent Dirichlet Allocation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Blei2003_LatentDirichletAllocation",
        "entity_id": "Blei2003_LatentDirichletAllocation",
        "name": "Latent Dirichlet Allocation",
        "title": "",
        "year": "2003",
        "authors": [
          "Blei, D.M.",
          "Ng, A.Y.",
          "Jordan, M.I."
        ],
        "task": "[\"Topic Modeling\"]",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Generative Model"
          ],
          "connections": [
            "Bayesian Inference"
          ],
          "mechanisms": [
            "Dirichlet Distribution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Variational Inference"
          ],
          "parameter_tuning": [
            "Number of Topics"
          ]
        },
        "feature_processing": [
          "Bag-of-Words"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Blei2003_LatentDirichletAllocationModel",
      "label": "Latent Dirichlet Allocation Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Blei2003_LatentDirichletAllocationModel",
        "entity_id": "Blei2003_LatentDirichletAllocationModel",
        "name": "Latent Dirichlet Allocation Model",
        "title": "",
        "year": "2003",
        "authors": [
          "Blei, D.M.",
          "Ng, A.Y.",
          "Jordan, M.I."
        ],
        "task": "[\"Verbal Comprehension Questions\"]",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bobrow1964_STUDENT",
      "label": "STUDENT",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bobrow1964_STUDENT",
        "entity_id": "Bobrow1964_STUDENT",
        "name": "STUDENT",
        "title": "",
        "year": "1964",
        "authors": [
          "Bobrow, D.G."
        ],
        "task": "[\"Solving algebraic word problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Transformation patterns",
            "Kernel sentences"
          ],
          "connections": [],
          "mechanisms": [
            "Pattern matching",
            "Verb categorization"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Boiman2008_Nearest_Neighbor_Based_Classification",
      "label": "Nearest Neighbor Based Classification",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Boiman2008_Nearest_Neighbor_Based_Classification",
        "entity_id": "Boiman2008_Nearest_Neighbor_Based_Classification",
        "name": "Nearest Neighbor Based Classification",
        "title": "",
        "year": "2008",
        "authors": [
          "Boiman, O.",
          "Shechtman, E.",
          "Irani, M."
        ],
        "task": "[\"Image Classification\"]",
        "dataset": [
          "Caltech101_2004",
          "Caltech256_2007"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Precision_Classification",
          "Recall_Classification"
        ],
        "architecture": {
          "components": [
            "Nearest Neighbor Classifier",
            "Bag-of-Features Representation"
          ],
          "connections": [
            "Feature Matching",
            "Distance Calculation"
          ],
          "mechanisms": [
            "Voting Scheme",
            "Feature Aggregation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "K Value",
            "Distance Metric"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Normalization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bowman2016_300DLSTMEncoders",
      "label": "300D LSTM encoders",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bowman2016_300DLSTMEncoders",
        "entity_id": "Bowman2016_300DLSTMEncoders",
        "name": "300D LSTM encoders",
        "title": "",
        "year": "2016",
        "authors": [
          "Bowman, S.R.",
          "Gauthier, J.",
          "Rastogi, A.",
          "Gupta, R.",
          "Manning, C.D.",
          "Potts, C."
        ],
        "task": "[\"Textual Entailment\"]",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "LSTM"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bowman2016_300DSPINNPIEncoders",
      "label": "300D SPINN-PI encoders",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bowman2016_300DSPINNPIEncoders",
        "entity_id": "Bowman2016_300DSPINNPIEncoders",
        "name": "300D SPINN-PI encoders",
        "title": "",
        "year": "2016",
        "authors": [
          "Bowman, S.R.",
          "Gauthier, J.",
          "Rastogi, A.",
          "Gupta, R.",
          "Manning, C.D.",
          "Potts, C."
        ],
        "task": "[\"Textual Entailment\"]",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "SPINN-PI"
          ],
          "connections": [
            "Recursive"
          ],
          "mechanisms": [
            "Tree-based"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Branavan2009_ReinforcementLearningMapping",
      "label": "Reinforcement Learning for Mapping Instructions to Actions",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Branavan2009_ReinforcementLearningMapping",
        "entity_id": "Branavan2009_ReinforcementLearningMapping",
        "name": "Reinforcement Learning for Mapping Instructions to Actions",
        "title": "",
        "year": "2009",
        "authors": [
          "Branavan, S.",
          "Chen, H.",
          "Zettlemoyer, L.S.",
          "Barzilay, R."
        ],
        "task": "[\"Instruction Mapping\"]",
        "dataset": [
          "ACL_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Reinforcement Learning",
            "Instruction Mapping"
          ],
          "connections": [
            "Instructions",
            "Actions"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Instruction Mapping"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Branavan2011_LearningToWin",
      "label": "Learning to Win by Reading Manuals",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Branavan2011_LearningToWin",
        "entity_id": "Branavan2011_LearningToWin",
        "name": "Learning to Win by Reading Manuals",
        "title": "",
        "year": "2011",
        "authors": [
          "Branavan, S.",
          "Silver, D.",
          "Barzilay, R."
        ],
        "task": "[\"Game Playing\"]",
        "dataset": [
          "Monte-Carlo Framework"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Monte-Carlo Framework",
            "Manual Reading"
          ],
          "connections": [
            "Reading Manuals",
            "Game Playing"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Monte-Carlo Framework"
          ],
          "parameter_tuning": [
            "Manual Reading"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Briars1984_CHIPS",
      "label": "CHIPS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Briars1984_CHIPS",
        "entity_id": "Briars1984_CHIPS",
        "name": "CHIPS",
        "title": "",
        "year": "1984",
        "authors": [
          "Briars, D.L.",
          "Larkin, J.H."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "One-step Arithmetic Word Problems"
        ],
        "metrics": [
          "Solution Correctness"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bulko1988_BEATRIX",
      "label": "BEATRIX",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bulko1988_BEATRIX",
        "entity_id": "Bulko1988_BEATRIX",
        "name": "BEATRIX",
        "title": "Understanding Text With an Accompanying Diagram",
        "year": "1988",
        "authors": [
          "William C. Bulko"
        ],
        "task": "[\"Physics Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Graphic Interface",
            "Blackboard System",
            "Knowledge Sources"
          ],
          "connections": [
            "TEXT level to TEXT-MODEL level",
            "PICTURE level to PICTURE-MODEL level",
            "PROBLEM-MODEL level"
          ],
          "mechanisms": [
            "Coreference Resolution",
            "Parsing English Text",
            "Parsing Diagrams"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Correction Facility",
          "Automatic Correction of Drawing Errors"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bulko1988_BlackboardControlStructure",
      "label": "Blackboard Control Structure",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bulko1988_BlackboardControlStructure",
        "entity_id": "Bulko1988_BlackboardControlStructure",
        "name": "Blackboard Control Structure",
        "title": "",
        "year": "1988",
        "authors": [
          "William C. Bulko"
        ],
        "task": "[\"Physics Problem Solving\"]",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correctness and Completeness of Problem Model"
        ],
        "architecture": {
          "components": [
            "Knowledge Sources",
            "Blackboard Levels"
          ],
          "connections": [
            "PICTURE level",
            "TEXT level",
            "PICTURE-MODEL level",
            "TEXT-MODEL level",
            "PROBLEM-MODEL level"
          ],
          "mechanisms": [
            "Coreference Resolution",
            "Object Identification",
            "Semantic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Pixel-Level Analysis",
          "Touch Relation Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bulko1988_IdentifyClassKS",
      "label": "Identify Class Knowledge Source",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bulko1988_IdentifyClassKS",
        "entity_id": "Bulko1988_IdentifyClassKS",
        "name": "Identify Class Knowledge Source",
        "title": "",
        "year": "1988",
        "authors": [
          "William C. Bulko"
        ],
        "task": "[\"Object Identification\"]",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correct Object Identification"
        ],
        "architecture": {
          "components": [
            "Identify-Class KSes"
          ],
          "connections": [
            "PICTURE level",
            "PICTURE-MODEL level"
          ],
          "mechanisms": [
            "Hypothesis Generation",
            "Abstract Object Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Object Shape Analysis",
          "Special Point Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bulko1988_MatchClassKS",
      "label": "Match Class Knowledge Source",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bulko1988_MatchClassKS",
        "entity_id": "Bulko1988_MatchClassKS",
        "name": "Match Class Knowledge Source",
        "title": "",
        "year": "1988",
        "authors": [
          "William C. Bulko"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correct Coreference Resolution"
        ],
        "architecture": {
          "components": [
            "Match-Class KSes"
          ],
          "connections": [
            "PICTURE-MODEL level",
            "TEXT-MODEL level",
            "PROBLEM-MODEL level"
          ],
          "mechanisms": [
            "Object Matching",
            "Ambiguity Resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Object Property Comparison",
          "Best Fit Calculation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bulko1988_ParseClassKS",
      "label": "Parse Class Knowledge Source",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bulko1988_ParseClassKS",
        "entity_id": "Bulko1988_ParseClassKS",
        "name": "Parse Class Knowledge Source",
        "title": "",
        "year": "1988",
        "authors": [
          "William C. Bulko"
        ],
        "task": "[\"Text Parsing\"]",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correct Sentence Parsing"
        ],
        "architecture": {
          "components": [
            "Parse-Class KSes"
          ],
          "connections": [
            "TEXT level",
            "TEXT-MODEL level"
          ],
          "mechanisms": [
            "Syntax Parsing",
            "Semantic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Sentence Structure Analysis",
          "Modifier Handling"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Bulko1988_PictureGrammarApproach",
      "label": "Picture Grammar Approach",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Bulko1988_PictureGrammarApproach",
        "entity_id": "Bulko1988_PictureGrammarApproach",
        "name": "Picture Grammar Approach",
        "title": "",
        "year": "1988",
        "authors": [
          "William C. Bulko"
        ],
        "task": "[\"Picture Parsing\"]",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "CorrectnessAndCompletenessOfProblemModel_Physics"
        ],
        "architecture": {
          "components": [
            "Parse Tree",
            "Hierarchical Structure"
          ],
          "connections": [
            "Object Relationships"
          ],
          "mechanisms": [
            "Syntax Rules for Picture Elements"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stepwise Refinement"
          ],
          "parameter_tuning": [
            "Heuristic Analysis"
          ]
        },
        "feature_processing": [
          "Object Classification",
          "Spatial Relationship Identification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "CASS2018_NeuralMathWordProblemSolver",
      "label": "Neural Math Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "CASS2018_NeuralMathWordProblemSolver",
        "entity_id": "CASS2018_NeuralMathWordProblemSolver",
        "name": "Neural Math Word Problem Solver",
        "title": "",
        "year": "2018",
        "authors": [
          "Huang, D.",
          "Liu, J.",
          "Lin, C.",
          "Yin, J."
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Copy and Alignment Mechanism"
          ],
          "connections": [
            "Sequence Translation",
            "Policy Gradient"
          ],
          "mechanisms": [
            "Reinforcement Learning",
            "Policy Gradient"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Policy Gradient Training",
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Policy Gradient"
          ]
        },
        "feature_processing": [
          "Word Embedding Features",
          "Unsupervised Word-Embedding Features"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "CASS2018_ReinforcementLearningSolver",
      "label": "CASS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "CASS2018_ReinforcementLearningSolver",
        "entity_id": "CASS2018_ReinforcementLearningSolver",
        "name": "CASS",
        "title": "Neural Math Word Problem Solver with Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Huang",
          "Liu",
          "Lin",
          "Yin"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Copy Mechanism",
            "Alignment Mechanism"
          ],
          "connections": [
            "Policy Gradient"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Policy Gradient"
          ],
          "parameter_tuning": [
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Quantity Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "CeruttiDavis1969_FORMAC",
      "label": "FORMAC",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "CeruttiDavis1969_FORMAC",
        "entity_id": "CeruttiDavis1969_FORMAC",
        "name": "FORMAC",
        "title": "",
        "year": "1969",
        "authors": [
          "Cerutti",
          "Davis"
        ],
        "task": "[\"Elementary Analytic Geometry Theorem Proving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Symbolic Manipulation",
            "Descartes' Method"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Coordinate Assignment"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chandar2014_BagOfWordsMapping",
      "label": "Bag-of-Words Mapping",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chandar2014_BagOfWordsMapping",
        "entity_id": "Chandar2014_BagOfWordsMapping",
        "name": "Bag-of-Words Mapping",
        "title": "",
        "year": "2014",
        "authors": [
          "Chandar, S.",
          "Lauly, S.",
          "Larochelle, H.",
          "Khapra, M.",
          "Ravindran, B.",
          "Raykar, V.",
          "Saha, A."
        ],
        "task": "[\"Phrase Pair Scoring\"]",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layers",
            "Output Layer"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Bag-of-Words Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2010b_StructuredOutputLearning",
      "label": "Structured Output Learning with Indirect Supervision",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2010b_StructuredOutputLearning",
        "entity_id": "Chang2010b_StructuredOutputLearning",
        "name": "Structured Output Learning with Indirect Supervision",
        "title": "",
        "year": "2010",
        "authors": [
          "Chang, M.",
          "Goldwasser, D.",
          "Roth, D.",
          "Srikumar, V."
        ],
        "task": "[\"Structured Prediction\"]",
        "dataset": [
          "ICML_2010"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Structured Output Learning",
            "Indirect Supervision"
          ],
          "connections": [
            "Indirect Supervision",
            "Structured Prediction"
          ],
          "mechanisms": [
            "Indirect Supervision"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Indirect Supervision"
          ],
          "parameter_tuning": [
            "Structured Output Learning"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_BestLeftLink",
      "label": "Best-Left-Link",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_BestLeftLink",
        "entity_id": "Chang2013_BestLeftLink",
        "name": "Best-Left-Link",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": "2013",
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE_2004",
          "Ontonotes-5.0_2012"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Left-Linking Model"
          ],
          "connections": [
            "Pairwise Compatibility Score",
            "Left-Linking Inference"
          ],
          "mechanisms": [
            "Efficient Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Regularization parameter λ",
            "Threshold t"
          ]
        },
        "feature_processing": [
          "Pairwise Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_CL3M",
      "label": "Constrained Latent Left Linking model (CL3M)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_CL3M",
        "entity_id": "Chang2013_CL3M",
        "name": "Constrained Latent Left Linking model (CL3M)",
        "title": "",
        "year": "2013",
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "Ontonotes_2013",
          "ACE_2013"
        ],
        "metrics": [
          "Accuracy_Classification",
          "F1_Score_Classification"
        ],
        "architecture": {
          "components": [
            "Latent structured prediction",
            "Knowledge-based constraints"
          ],
          "connections": [
            "Stochastic gradient-based learning"
          ],
          "mechanisms": [
            "Efficient inference",
            "Constraint augmentation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic gradient descent"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "label": "Constrained Latent Left-Linking Model (CL3M)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_ConstrainedLatentLeftLinkingModel",
        "entity_id": "Chang2013_ConstrainedLatentLeftLinkingModel",
        "name": "Constrained Latent Left-Linking Model (CL3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": "2013",
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE_2004",
          "Ontonotes-5.0_2012"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Left-Linking Model",
            "Latent Structural SVM"
          ],
          "connections": [
            "Pairwise Compatibility Score",
            "Left-Linking Inference"
          ],
          "mechanisms": [
            "Efficient Inference",
            "Constraint-Augmented Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Regularization parameter λ",
            "Threshold t",
            "Constraint Scores ρ"
          ]
        },
        "feature_processing": [
          "Pairwise Features",
          "Domain-Specific Constraints"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_ConstrainedLatentLeftLinkingModelWithDomainKnowledge",
      "label": "Constrained Latent Left-Linking Model with Domain Knowledge",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_ConstrainedLatentLeftLinkingModelWithDomainKnowledge",
        "entity_id": "Chang2013_ConstrainedLatentLeftLinkingModelWithDomainKnowledge",
        "name": "Constrained Latent Left-Linking Model with Domain Knowledge",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": "2013",
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "Ontonotes-5.0",
          "ACE 2004"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Latent Left-Linking Model",
            "Domain Knowledge Constraints"
          ],
          "connections": [
            "Pairwise Scoring",
            "Constraint Augmentation"
          ],
          "mechanisms": [
            "Efficient Inference",
            "Constraint Injection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Temperature Parameter γ",
            "Regularization Parameter λ"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Scores",
          "Domain Specific Constraints"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_ConstrainedProbabilisticLatentLeftLinkingModel",
      "label": "Constrained Probabilistic Latent Left-Linking Model (CPL3M)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_ConstrainedProbabilisticLatentLeftLinkingModel",
        "entity_id": "Chang2013_ConstrainedProbabilisticLatentLeftLinkingModel",
        "name": "Constrained Probabilistic Latent Left-Linking Model (CPL3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": "2013",
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE_2004",
          "Ontonotes-5.0_2012"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Left-Linking Model",
            "Latent Structural SVM"
          ],
          "connections": [
            "Pairwise Compatibility Score",
            "Left-Linking Inference"
          ],
          "mechanisms": [
            "Probabilistic Generalization",
            "Temperature-like Parameter",
            "Constraint-Augmented Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Likelihood-based Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Regularization parameter λ",
            "Temperature parameter γ",
            "Constraint Scores ρ"
          ]
        },
        "feature_processing": [
          "Pairwise Features",
          "Domain-Specific Constraints"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_ConstraintAugmentedScoring",
      "label": "Constraint-Augmented Scoring Function",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_ConstraintAugmentedScoring",
        "entity_id": "Chang2013_ConstraintAugmentedScoring",
        "name": "Constraint-Augmented Scoring Function",
        "title": "",
        "year": "2013",
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE_2004",
          "Ontonotes_2012"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_EntityBased",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Latent Left-Linking Model",
            "Domain-Specific Constraints"
          ],
          "connections": [
            "Latent Left-Linking Model -> Domain-Specific Constraints"
          ],
          "mechanisms": [
            "Constraint Injection",
            "Weighted Sum of Constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Constraint Scores ρ"
          ]
        },
        "feature_processing": [
          "Pairwise Features Extraction",
          "Constraint Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_L3M",
      "label": "Latent Left Linking model (L3M)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_L3M",
        "entity_id": "Chang2013_L3M",
        "name": "Latent Left Linking model (L3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": "2013",
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE",
          "Ontonotes"
        ],
        "metrics": [
          "Accuracy",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Latent Variables",
            "Constraints"
          ],
          "connections": [
            "Pairwise Scoring",
            "Decoding Algorithm"
          ],
          "mechanisms": [
            "Stochastic Gradient Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Hyperparameters"
          ]
        },
        "feature_processing": [
          "Knowledge-based Constraints"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_LatentLeftLinkingModel",
      "label": "Latent Left Linking Model (L3M)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_LatentLeftLinkingModel",
        "entity_id": "Chang2013_LatentLeftLinkingModel",
        "name": "Latent Left Linking Model (L3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": "2013",
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE_2013",
          "Ontonotes_2013"
        ],
        "metrics": [
          "Accuracy_Classification",
          "F1_Score_Classification"
        ],
        "architecture": {
          "components": [
            "Latent Variables",
            "Structured Prediction"
          ],
          "connections": [
            "Knowledge-based Constraints",
            "Stochastic Gradient Learning"
          ],
          "mechanisms": [
            "Efficient Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Hyperparameters for Constraints"
          ]
        },
        "feature_processing": [
          "Feature Extraction for Coreference Clustering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_LatentLeftLinkingModelWithConstraints",
      "label": "Latent Left-Linking Model with Constraints (L3M with Constraints)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_LatentLeftLinkingModelWithConstraints",
        "entity_id": "Chang2013_LatentLeftLinkingModelWithConstraints",
        "name": "Latent Left-Linking Model with Constraints (L3M with Constraints)",
        "title": "",
        "year": "2013",
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "Ontonotes-5.0_2012",
          "ACE_2004"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_Coreference",
          "F1Score_Average"
        ],
        "architecture": {
          "components": [
            "Latent Left-Linking Model",
            "Constraints"
          ],
          "connections": [
            "Pairwise Scoring",
            "Constraint Augmentation"
          ],
          "mechanisms": [
            "Efficient Inference",
            "Domain Knowledge Injection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Temperature Parameter γ"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Score",
          "Domain Specific Constraints"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_MaxMarginApproach",
      "label": "Max-Margin Approach",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_MaxMarginApproach",
        "entity_id": "Chang2013_MaxMarginApproach",
        "name": "Max-Margin Approach",
        "title": "",
        "year": "2013",
        "authors": [
          "Chang, K.-W.",
          "Samdani, R.",
          "Roth, D."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE_2004",
          "Ontonotes_2012"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_EntityBased",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Pairwise Scorer",
            "Latent Left-Linking Model"
          ],
          "connections": [
            "Pairwise Scorer -> Latent Left-Linking Model"
          ],
          "mechanisms": [
            "Max-Margin Optimization",
            "Loss Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "Concave Convex Procedure"
          ],
          "parameter_tuning": [
            "Regularization Parameter λ",
            "Threshold t"
          ]
        },
        "feature_processing": [
          "Pairwise Features Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "label": "Probabilistic Latent Left-Linking Model (PL3M)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_ProbabilisticLatentLeftLinkingModel",
        "entity_id": "Chang2013_ProbabilisticLatentLeftLinkingModel",
        "name": "Probabilistic Latent Left-Linking Model (PL3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": "2013",
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE_2004",
          "Ontonotes-5.0_2012"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Pairwise Mention Scorer",
            "Left-Linking Model",
            "Latent Structural SVM"
          ],
          "connections": [
            "Pairwise Compatibility Score",
            "Left-Linking Inference"
          ],
          "mechanisms": [
            "Probabilistic Generalization",
            "Temperature-like Parameter"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Likelihood-based Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Regularization parameter λ",
            "Temperature parameter γ"
          ]
        },
        "feature_processing": [
          "Pairwise Features",
          "Domain-Specific Constraints"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Charniak1968_CalculusWordProblems",
      "label": "Calculus Word Problems",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Charniak1968_CalculusWordProblems",
        "entity_id": "Charniak1968_CalculusWordProblems",
        "name": "Calculus Word Problems",
        "title": "",
        "year": "1968",
        "authors": [
          "Charniak, E."
        ],
        "task": "[\"Calculus Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Pattern Matching"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Charniak1968_CARPS",
      "label": "CARPS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Charniak1968_CARPS",
        "entity_id": "Charniak1968_CARPS",
        "name": "CARPS",
        "title": "",
        "year": "1968",
        "authors": [
          "Charniak, E."
        ],
        "task": "[\"Solving English rate problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Tree structure"
          ],
          "connections": [],
          "mechanisms": [
            "Information gathering"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Charniak2000_MaximumEntropyParser",
      "label": "Maximum-Entropy Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Charniak2000_MaximumEntropyParser",
        "entity_id": "Charniak2000_MaximumEntropyParser",
        "name": "Maximum-Entropy Parser",
        "title": "A maximum-entropy-inspired parser",
        "year": "2000",
        "authors": [
          "Eugene Charniak"
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [
          "Parsing Accuracy"
        ],
        "architecture": {
          "components": [
            "Maximum Entropy Model"
          ],
          "connections": [
            "Feature Functions"
          ],
          "mechanisms": [
            "Log-linear Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Entropy Estimation"
          ],
          "parameter_tuning": [
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Feature Engineering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2008_LearningToSportscast",
      "label": "Learning to Sportscast",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2008_LearningToSportscast",
        "entity_id": "Chen2008_LearningToSportscast",
        "name": "Learning to Sportscast",
        "title": "",
        "year": "2008",
        "authors": [
          "Chen, D.",
          "Mooney, R."
        ],
        "task": "[\"Grounded Language\"]",
        "dataset": [
          "ICML_2008"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Sportscasting",
            "Grounded Language"
          ],
          "connections": [
            "Sportscasting",
            "Language"
          ],
          "mechanisms": [
            "Grounded Language"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Grounded Language"
          ],
          "parameter_tuning": [
            "Sportscasting"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2012_FastOnlineLexicon",
      "label": "Fast Online Lexicon Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2012_FastOnlineLexicon",
        "entity_id": "Chen2012_FastOnlineLexicon",
        "name": "Fast Online Lexicon Learning",
        "title": "",
        "year": "2012",
        "authors": [
          "Chen, D."
        ],
        "task": "[\"Grounded Language Acquisition\"]",
        "dataset": [
          "ACL_2012"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Lexicon Learning",
            "Grounded Language"
          ],
          "connections": [
            "Lexicon Learning",
            "Language Acquisition"
          ],
          "mechanisms": [
            "Online Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Lexicon Learning"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_ArcStandardSystem",
      "label": "Arc-Standard System",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_ArcStandardSystem",
        "entity_id": "Chen2014_ArcStandardSystem",
        "name": "Arc-Standard System",
        "title": "",
        "year": "2014",
        "authors": [
          "Nivre, J."
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Stack",
            "Buffer",
            "Set of Dependency Arcs"
          ],
          "connections": [
            "LEFT-ARC",
            "RIGHT-ARC",
            "SHIFT"
          ],
          "mechanisms": [
            "Configuration Transition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Greedy Parsing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_CubeActivationFunction",
      "label": "Cube Activation Function",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_CubeActivationFunction",
        "entity_id": "Chen2014_CubeActivationFunction",
        "name": "Cube Activation Function",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "UAS_DependencyParsing",
          "LAS_DependencyParsing"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Input Layer -> Hidden Layer",
            "Hidden Layer -> Softmax Layer"
          ],
          "mechanisms": [
            "Cube Activation Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Arc Label Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_GreedyArcEagerParser",
      "label": "Greedy Arc-Eager Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_GreedyArcEagerParser",
        "entity_id": "Chen2014_GreedyArcEagerParser",
        "name": "Greedy Arc-Eager Parser",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Stack",
            "Buffer",
            "Transition System"
          ],
          "connections": [
            "LEFT-ARC",
            "RIGHT-ARC",
            "SHIFT"
          ],
          "mechanisms": [
            "Feature Templates",
            "Structured Averaged Perceptron"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Early-update Strategy"
          ],
          "parameter_tuning": [
            "Hyperparameters Tuning"
          ]
        },
        "feature_processing": [
          "Indicator Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_GreedyArcStandardParser",
      "label": "Greedy Arc-Standard Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_GreedyArcStandardParser",
        "entity_id": "Chen2014_GreedyArcStandardParser",
        "name": "Greedy Arc-Standard Parser",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Stack",
            "Buffer",
            "Transition System"
          ],
          "connections": [
            "LEFT-ARC",
            "RIGHT-ARC",
            "SHIFT"
          ],
          "mechanisms": [
            "Feature Templates",
            "Structured Averaged Perceptron"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Early-update Strategy"
          ],
          "parameter_tuning": [
            "Hyperparameters Tuning"
          ]
        },
        "feature_processing": [
          "Indicator Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralDependencyParser",
      "label": "Neural Dependency Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralDependencyParser",
        "entity_id": "Chen2014_NeuralDependencyParser",
        "name": "Neural Dependency Parser",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [],
        "metrics": [
          "Unlabeled Attachment Score",
          "Labeled Attachment Score"
        ],
        "architecture": {
          "components": [
            "Neural network classifier"
          ],
          "connections": [],
          "mechanisms": [
            "Greedy transition-based parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Feature learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Sparse indicator features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralNetworkBasedParser",
      "label": "Neural Network Based Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralNetworkBasedParser",
        "entity_id": "Chen2014_NeuralNetworkBasedParser",
        "name": "Neural Network Based Parser",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Arc Label Embeddings"
          ],
          "mechanisms": [
            "Cube Activation Function",
            "Pre-trained Word Embeddings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Shortest Stack Oracle",
            "Cross-Entropy Loss",
            "L2 Regularization"
          ],
          "parameter_tuning": [
            "AdaGrad",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Dense Features",
          "Pre-computed Matrix Multiplications"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralNetworkDependencyParser",
      "label": "Neural Network Dependency Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralNetworkDependencyParser",
        "entity_id": "Chen2014_NeuralNetworkDependencyParser",
        "name": "Neural Network Dependency Parser",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English Penn Treebank",
          "Chinese Penn Treebank"
        ],
        "metrics": [
          "Unlabeled Attachment Score (UAS)",
          "Labeled Attachment Score (LAS)"
        ],
        "architecture": {
          "components": [
            "Neural Network Classifier",
            "Arc-Standard System"
          ],
          "connections": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "mechanisms": [
            "Dense Vector Representations",
            "Cube Activation Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Embedding size d",
            "Hidden layer size h",
            "Regularization parameter λ",
            "Initial learning rate α"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Arc Label Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralNetworkDependencyParserWithCubeActivation",
      "label": "Neural Network Dependency Parser with Cube Activation Function",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralNetworkDependencyParserWithCubeActivation",
        "entity_id": "Chen2014_NeuralNetworkDependencyParserWithCubeActivation",
        "name": "Neural Network Dependency Parser with Cube Activation Function",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English Penn Treebank_2014",
          "Chinese Penn Treebank_2014"
        ],
        "metrics": [
          "Unlabeled Attachment Score_DependencyParsing",
          "Labeled Attachment Score_DependencyParsing"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Cube Activation Function"
          ],
          "connections": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "mechanisms": [
            "Dense Features",
            "POS Tag Embeddings",
            "Arc Label Embeddings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Embedding Size",
            "Hidden Layer Size",
            "Regularization Parameter",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Arc Label Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralNetworkDependencyParserWithIdentityActivation",
      "label": "Neural Network Dependency Parser with Identity Activation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralNetworkDependencyParserWithIdentityActivation",
        "entity_id": "Chen2014_NeuralNetworkDependencyParserWithIdentityActivation",
        "name": "Neural Network Dependency Parser with Identity Activation",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "UAS_DependencyParsing",
          "LAS_DependencyParsing"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Dependency Label Embeddings"
          ],
          "mechanisms": [
            "Identity Activation Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Dependency Label Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralNetworkDependencyParserWithPretrainedEmbeddings",
      "label": "Neural Network Dependency Parser with Pretrained Embeddings",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralNetworkDependencyParserWithPretrainedEmbeddings",
        "entity_id": "Chen2014_NeuralNetworkDependencyParserWithPretrainedEmbeddings",
        "name": "Neural Network Dependency Parser with Pretrained Embeddings",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": "2014",
        "authors": [
          "Chen, D.",
          "Manning, C. D."
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English Penn Treebank",
          "Chinese Penn Treebank"
        ],
        "metrics": [
          "Unlabeled Attachment Score",
          "Labeled Attachment Score"
        ],
        "architecture": {
          "components": [
            "Neural Network Classifier",
            "Arc-Standard System"
          ],
          "connections": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "mechanisms": [
            "Cube Activation Function",
            "Pre-trained Word Embeddings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Embedding Size d",
            "Hidden Layer Size h",
            "Regularization Parameter λ"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Arc Label Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralNetworkDependencyParserWithRandomInitialization",
      "label": "Neural Network Dependency Parser with Random Initialization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralNetworkDependencyParserWithRandomInitialization",
        "entity_id": "Chen2014_NeuralNetworkDependencyParserWithRandomInitialization",
        "name": "Neural Network Dependency Parser with Random Initialization",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "UAS_DependencyParsing",
          "LAS_DependencyParsing"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Dependency Label Embeddings"
          ],
          "mechanisms": [
            "Random Initialization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Dependency Label Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralNetworkDependencyParserWithSigmoidActivation",
      "label": "Neural Network Dependency Parser with Sigmoid Activation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralNetworkDependencyParserWithSigmoidActivation",
        "entity_id": "Chen2014_NeuralNetworkDependencyParserWithSigmoidActivation",
        "name": "Neural Network Dependency Parser with Sigmoid Activation",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "UAS_DependencyParsing",
          "LAS_DependencyParsing"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Dependency Label Embeddings"
          ],
          "mechanisms": [
            "Sigmoid Activation Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Dependency Label Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralNetworkDependencyParserWithTanhActivation",
      "label": "Neural Network Dependency Parser with Tanh Activation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralNetworkDependencyParserWithTanhActivation",
        "entity_id": "Chen2014_NeuralNetworkDependencyParserWithTanhActivation",
        "name": "Neural Network Dependency Parser with Tanh Activation",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "UAS_DependencyParsing",
          "LAS_DependencyParsing"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Dependency Label Embeddings"
          ],
          "mechanisms": [
            "Tanh Activation Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Dependency Label Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralNetworkParser",
      "label": "Neural Network Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralNetworkParser",
        "entity_id": "Chen2014_NeuralNetworkParser",
        "name": "Neural Network Parser",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [],
        "metrics": [
          "Unlabeled Attachment Score (UAS)",
          "Labeled Attachment Score (LAS)"
        ],
        "architecture": {
          "components": [
            "Word Embeddings",
            "POS Tag Embeddings",
            "Arc Label Embeddings",
            "Hidden Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Cube Activation Function"
          ],
          "mechanisms": [
            "Dense Representations",
            "Transition-based Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-Entropy Loss",
            "L2 Regularization",
            "Mini-batched AdaGrad",
            "Dropout"
          ],
          "parameter_tuning": [
            "Pre-trained Word Embeddings",
            "Random Initialization"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Arc Label Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_NeuralParser",
      "label": "Neural Dependency Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_NeuralParser",
        "entity_id": "Chen2014_NeuralParser",
        "name": "Neural Dependency Parser",
        "title": "A Fast and Accurate Dependency Parser using Neural Networks",
        "year": "2014",
        "authors": [
          "Chen, D.",
          "Manning, C.D."
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [],
        "metrics": [
          "Unlabeled Attachment Score",
          "Labeled Attachment Score"
        ],
        "architecture": {
          "components": [
            "Neural Network Classifier"
          ],
          "connections": [],
          "mechanisms": [
            "Greedy Transition-based Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Dense Feature Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chen2014_PreTrainedWordEmbeddings",
      "label": "Pre-trained Word Embeddings",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chen2014_PreTrainedWordEmbeddings",
        "entity_id": "Chen2014_PreTrainedWordEmbeddings",
        "name": "Pre-trained Word Embeddings",
        "title": "",
        "year": "2014",
        "authors": [
          "Danqi Chen",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Word Embeddings"
          ],
          "connections": [],
          "mechanisms": [
            "Semantic Similarity"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Initialization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Cheng2016_GAOKAOChallenge",
      "label": "GAOKAO Challenge",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cheng2016_GAOKAOChallenge",
        "entity_id": "Cheng2016_GAOKAOChallenge",
        "name": "GAOKAO Challenge",
        "title": "",
        "year": "2016",
        "authors": [
          "Cheng, G.",
          "Zhu, W.",
          "Wang, Z.",
          "Chen, J.",
          "Qu, Y."
        ],
        "task": "[\"Solving Chinese college entrance exam questions\"]",
        "dataset": [
          "GAOKAO dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Information retrieval"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Retrieving relevant pages from Wikipedia"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Ranking and filtering"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Cheng2016_GaokaoChallenge",
      "label": "Gaokao Challenge",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cheng2016_GaokaoChallenge",
        "entity_id": "Cheng2016_GaokaoChallenge",
        "name": "Gaokao Challenge",
        "title": "",
        "year": "2016",
        "authors": [
          "Cheng, G.",
          "Zhu, W.",
          "Wang, Z.",
          "Chen, J.",
          "Qu, Y."
        ],
        "task": "[\"Solving Gaokao questions\"]",
        "dataset": [
          "Gaokao dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Information retrieval"
          ],
          "connections": [
            "Knowledge base integration"
          ],
          "mechanisms": [
            "Retrieving relevant pages"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Ranking and filtering"
          ],
          "parameter_tuning": [
            "Hyperparameter tuning"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Cheng2016_LSTMN",
      "label": "LSTMN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cheng2016_LSTMN",
        "entity_id": "Cheng2016_LSTMN",
        "name": "LSTMN",
        "title": "",
        "year": "2016",
        "authors": [
          "Cheng, J.",
          "Dong, L.",
          "Lapata, M."
        ],
        "task": "[\"Sentence Representation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "LSTM",
            "Intra-Sentence Attention"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chiang2018_SemanticallyAligned",
      "label": "Semantically-Aligned Equation Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2018_SemanticallyAligned",
        "entity_id": "Chiang2018_SemanticallyAligned",
        "name": "Semantically-Aligned Equation Generation",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": "2018",
        "authors": [
          "Chiang",
          "Chen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "LSTM",
            "Recursive Neural Networks"
          ],
          "connections": [
            "Self-Attention"
          ],
          "mechanisms": [
            "Recursive Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Quantity Representation",
          "Recursive Inference"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Chiang2018_SemanticallyAlignedEquationGeneration",
      "label": "Semantically-Aligned Equation Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2018_SemanticallyAlignedEquationGeneration",
        "entity_id": "Chiang2018_SemanticallyAlignedEquationGeneration",
        "name": "Semantically-Aligned Equation Generation",
        "title": "",
        "year": "2018",
        "authors": [
          "Chiang, T.",
          "Chen, Y."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "CoRR_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Equation Generation"
          ],
          "connections": [
            "Mapping Problem Text to Equations"
          ],
          "mechanisms": [
            "Deep Learning",
            "Sequence-to-Sequence"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Seq2Seq Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Dependency Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Chiang2018_StackDecoder",
      "label": "StackDecoder",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2018_StackDecoder",
        "entity_id": "Chiang2018_StackDecoder",
        "name": "StackDecoder",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": "2018",
        "authors": [
          "Chiang",
          "Chen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "Gated Recurrent Unit"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Stopword Removal"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Chiang2019_CharBasedModel",
      "label": "Character-Based Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2019_CharBasedModel",
        "entity_id": "Chiang2019_CharBasedModel",
        "name": "Character-Based Model",
        "title": "",
        "year": "2019",
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblems"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Encoder-Decoder",
            "Stack-Decoder",
            "Semantic Transformer-Decoder"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Gating Mechanism",
            "Semantic Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Postfix Equation Transformation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Character-Level Embedding",
          "Constant Representation Extraction",
          "External Constant Leveraging"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chiang2019_ConstantEmbeddingAnalysis",
      "label": "Constant Embedding Analysis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2019_ConstantEmbeddingAnalysis",
        "entity_id": "Chiang2019_ConstantEmbeddingAnalysis",
        "name": "Constant Embedding Analysis",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": "2019",
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblems"
        ],
        "architecture": {
          "components": [
            "Self-Attention Mechanism",
            "Semantic Representations"
          ],
          "connections": [
            "Encoder-Decoder Framework"
          ],
          "mechanisms": [
            "Semantic Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden State Size"
          ]
        },
        "feature_processing": [
          "Self-Attention on Constants"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chiang2019_DecodingProcessVisualization",
      "label": "Decoding Process Visualization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2019_DecodingProcessVisualization",
        "entity_id": "Chiang2019_DecodingProcessVisualization",
        "name": "Decoding Process Visualization",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": "2019",
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblems"
        ],
        "architecture": {
          "components": [
            "Attention Mechanism",
            "Gating Mechanisms"
          ],
          "connections": [
            "Encoder-Decoder Framework"
          ],
          "mechanisms": [
            "Semantic Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden State Size"
          ]
        },
        "feature_processing": [
          "Attention Map Visualization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chiang2019_EndToEndNeuralMathSolver",
      "label": "End-to-End Neural Math Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2019_EndToEndNeuralMathSolver",
        "entity_id": "Chiang2019_EndToEndNeuralMathSolver",
        "name": "End-to-End Neural Math Solver",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": "2019",
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "[\"Solving Math Word Problems\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Encoder-Decoder connection",
            "Stack operations",
            "Semantic alignment"
          ],
          "mechanisms": [
            "BLSTM for constant representation extraction",
            "Attention mechanism",
            "Gating mechanisms",
            "Semantic transformation functions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning",
            "Postfix equation generation"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Dropout rate"
          ]
        },
        "feature_processing": [
          "Constant representation extraction",
          "External constant leveraging",
          "Semantic representation of operands"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chiang2019_SemanticallyAlignedEquationGeneration",
      "label": "Semantically-Aligned Equation Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2019_SemanticallyAlignedEquationGeneration",
        "entity_id": "Chiang2019_SemanticallyAlignedEquationGeneration",
        "name": "Semantically-Aligned Equation Generation",
        "title": "",
        "year": "2019",
        "authors": [
          "Ting-Rui Chiang",
          "Yun-Nung Chen"
        ],
        "task": "[\"Solving and Reasoning Math Word Problems\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Encoder-Decoder",
            "Decoder-Stack",
            "Stack-Semantic Transformer"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Gating Mechanism",
            "Semantic Meaning Tracking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training",
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Constant Representation Extraction",
          "External Constant Leveraging",
          "Operand Selection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chiang2019_SemanticallyAlignedEquationGenerator",
      "label": "Semantically-Aligned Equation Generator",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2019_SemanticallyAlignedEquationGenerator",
        "entity_id": "Chiang2019_SemanticallyAlignedEquationGenerator",
        "name": "Semantically-Aligned Equation Generator",
        "title": "",
        "year": "2019",
        "authors": [
          "Ting-Rui Chiang",
          "Yun-Nung Chen"
        ],
        "task": "[\"Solving and Reasoning Math Word Problems\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Encoder to Decoder",
            "Stack to Semantic Transformer"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Stack Actions",
            "Operand Selector",
            "Operator Application"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training",
            "Fully supervised"
          ],
          "parameter_tuning": [
            "Learning rate set to 0.001",
            "Hidden state size of LSTM set to 256",
            "Dropout rate set to 0.1"
          ]
        },
        "feature_processing": [
          "Bidirectional LSTM for constant representation extraction",
          "External constant leveraging",
          "Attention mechanism for operand selection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chiang2019_WordBasedModel",
      "label": "Word-Based Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chiang2019_WordBasedModel",
        "entity_id": "Chiang2019_WordBasedModel",
        "name": "Word-Based Model",
        "title": "",
        "year": "2019",
        "authors": [
          "Chiang, Ting-Rui",
          "Chen, Yun-Nung"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblems"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Stack",
            "Semantic Transformer"
          ],
          "connections": [
            "Encoder-Decoder",
            "Stack-Decoder",
            "Semantic Transformer-Decoder"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Gating Mechanism",
            "Semantic Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Postfix Equation Transformation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Constant Representation Extraction",
          "External Constant Leveraging"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Cho2014_AdaptiveHiddenUnit",
      "label": "Adaptive Hidden Unit",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cho2014_AdaptiveHiddenUnit",
        "entity_id": "Cho2014_AdaptiveHiddenUnit",
        "name": "Adaptive Hidden Unit",
        "title": "",
        "year": "2014",
        "authors": [
          "Cho, Kyunghyun",
          "van Merriënboer, Bart",
          "Gulcehre, Caglar",
          "Bahdanau, Dzmitry",
          "Bougares, Fethi",
          "Schwenk, Holger",
          "Bengio, Yoshua"
        ],
        "task": "[\"Sequence Modeling\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Reset Gate",
            "Update Gate"
          ],
          "connections": [
            "Recurrent Connections"
          ],
          "mechanisms": [
            "Adaptive Memory Control"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Cho2014_CSLM",
      "label": "CSLM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cho2014_CSLM",
        "entity_id": "Cho2014_CSLM",
        "name": "CSLM",
        "title": "",
        "year": "2014",
        "authors": [
          "Cho, K.",
          "van Merriënboer, B.",
          "Gulcehre, C.",
          "Bahdanau, D.",
          "Bougares, F.",
          "Schwenk, H.",
          "Bengio, Y."
        ],
        "task": "[\"Statistical Machine Translation\"]",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation",
          "Perplexity_LanguageModel"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Embedding Layer",
            "Rectified Layers",
            "Softmax Layer"
          ],
          "connections": [
            "Input to Embedding",
            "Embedding to Rectified Layers",
            "Rectified Layers to Softmax"
          ],
          "mechanisms": [
            "Word Projection",
            "Concatenation",
            "Non-linear Activation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient Descent",
            "Validation Set Monitoring"
          ],
          "parameter_tuning": [
            "Weight Initialization",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Cho2014_DeepNeuralNetwork",
      "label": "Deep Neural Network",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cho2014_DeepNeuralNetwork",
        "entity_id": "Cho2014_DeepNeuralNetwork",
        "name": "Deep Neural Network",
        "title": "",
        "year": "2014",
        "authors": [
          "Kyunghyun Cho",
          "Bart van Merriënboer",
          "Caglar Gulcehre",
          "Dzmitry Bahdanau",
          "Fethi Bougares",
          "Holger Schwenk",
          "Yoshua Bengio"
        ],
        "task": "[\"Statistical Machine Translation\"]",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent connections"
          ],
          "mechanisms": [
            "Reset gate",
            "Update gate"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based optimization",
            "Joint training"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Batch size"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Phrase pairs scoring"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Cho2014_RecurrentNeuralNetwork",
      "label": "Recurrent Neural Network (RNN)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cho2014_RecurrentNeuralNetwork",
        "entity_id": "Cho2014_RecurrentNeuralNetwork",
        "name": "Recurrent Neural Network (RNN)",
        "title": "",
        "year": "2014",
        "authors": [
          "Cho, Kyunghyun",
          "van Merriënboer, Bart",
          "Gulcehre, Caglar",
          "Bahdanau, Dzmitry",
          "Bougares, Fethi",
          "Schwenk, Holger",
          "Bengio, Yoshua"
        ],
        "task": "[\"Sequence Modeling\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Hidden State",
            "Output"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent Connections"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Cho2014_RNN_Encoder_Decoder",
      "label": "RNN Encoder-Decoder",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cho2014_RNN_Encoder_Decoder",
        "entity_id": "Cho2014_RNN_Encoder_Decoder",
        "name": "RNN Encoder-Decoder",
        "title": "",
        "year": "2014",
        "authors": [
          "Cho, K.",
          "Merrienboer, B.",
          "Gulcehre, C.",
          "Bougares, F.",
          "Schwenk, H.",
          "Bengio, Y."
        ],
        "task": "[\"Machine Translation\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Networks"
          ],
          "connections": [
            "Encoder to Decoder"
          ],
          "mechanisms": [
            "Phrase representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training"
          ],
          "parameter_tuning": [
            "Hyperparameters tuning"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Cho2014_RNNEncoderDecoder",
      "label": "RNN Encoder-Decoder",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cho2014_RNNEncoderDecoder",
        "entity_id": "Cho2014_RNNEncoderDecoder",
        "name": "RNN Encoder-Decoder",
        "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
        "year": "2014",
        "authors": [
          "Kyunghyun Cho",
          "Bart van Merrienboer",
          "Caglar Gulcehre",
          "Dzmitry Bahdanau",
          "Fethi Bougares",
          "Holger Schwenk",
          "Yoshua Bengio"
        ],
        "task": "[\"Phrase Representation for Statistical Machine Translation\"]",
        "dataset": [
          "English-French Translation Task"
        ],
        "metrics": [
          "BLEU_Score"
        ],
        "architecture": {
          "components": [
            "RNN Encoder",
            "RNN Decoder"
          ],
          "connections": [
            "sequence-to-sequence mapping",
            "fixed-length vector representation"
          ],
          "mechanisms": [
            "reset gate",
            "update gate",
            "adaptive memory"
          ]
        },
        "methodology": {
          "training_strategy": [
            "joint training",
            "conditional probability maximization"
          ],
          "parameter_tuning": [
            "gradient-based algorithm",
            "beam search"
          ]
        },
        "feature_processing": [
          "word embeddings",
          "continuous space representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clark2016_Aristo",
      "label": "Aristo",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_Aristo",
        "entity_id": "Clark2016_Aristo",
        "name": "Aristo",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P. D.",
          "Khashabi, D."
        ],
        "task": "[\"Solving non-diagram multiple-choice questions\"]",
        "dataset": [
          "Various datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Text solver",
            "Statistic solvers",
            "Inference solvers"
          ],
          "connections": [
            "Parallel processing"
          ],
          "mechanisms": [
            "Combining scores from multiple solvers"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge base retrieval"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Clark2016_CombiningRetrievalStatisticsInference",
      "label": "Combining Retrieval, Statistics, and Inference",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_CombiningRetrievalStatisticsInference",
        "entity_id": "Clark2016_CombiningRetrievalStatisticsInference",
        "name": "Combining Retrieval, Statistics, and Inference",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P. D.",
          "Khashabi, D."
        ],
        "task": "[\"Answering elementary science questions\"]",
        "dataset": [
          "Elementary science questions"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Retrieval system",
            "Statistical models",
            "Inference models"
          ],
          "connections": [
            "Parallel processing"
          ],
          "mechanisms": [
            "Combining scores from multiple models"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge base retrieval"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Clark2016_ILPSolver",
      "label": "Integer Linear Programming Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_ILPSolver",
        "entity_id": "Clark2016_ILPSolver",
        "name": "Integer Linear Programming Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Knowledge Table Module",
            "ILP Model"
          ],
          "connections": [
            "Tables to ILP Model",
            "Question to ILP Model",
            "Answer Options to ILP Model"
          ],
          "mechanisms": [
            "Proof Graph Construction",
            "Global Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "Similarity Measure Threshold",
            "Structural Constraints"
          ]
        },
        "feature_processing": [
          "Table Construction",
          "Relation Extraction",
          "TF-IDF Scoring"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clark2016_ILPTaskStrengthAnalysis",
      "label": "ILP Task Strength Analysis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_ILPTaskStrengthAnalysis",
        "entity_id": "Clark2016_ILPTaskStrengthAnalysis",
        "name": "ILP Task Strength Analysis",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "ILP Solver"
          ],
          "connections": [
            "Table Joining"
          ],
          "mechanisms": [
            "Propositional Logic"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Table Construction",
          "Propositional Logic Encoding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clark2016_IRSolver",
      "label": "Information Retrieval Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_IRSolver",
        "entity_id": "Clark2016_IRSolver",
        "name": "Information Retrieval Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Lucene Search Engine"
          ],
          "connections": [
            "Query to Search Engine",
            "Search Engine to Retrieved Sentences"
          ],
          "mechanisms": [
            "Text Matching",
            "Relevance Scoring"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Stopword Filtering",
          "Non-stopword Overlap"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clark2016_MultipleRepresentationSystem",
      "label": "Multiple Representation System",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_MultipleRepresentationSystem",
        "entity_id": "Clark2016_MultipleRepresentationSystem",
        "name": "Multiple Representation System",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P.",
          "Khashabi, D."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "IR Solver",
            "PMI Solver",
            "SVM Solver",
            "RULE Solver",
            "ILP Solver"
          ],
          "connections": [
            "Logistic Regression Combiner"
          ],
          "mechanisms": [
            "Information Retrieval",
            "Statistical Reasoning",
            "Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Ensemble Learning"
          ],
          "parameter_tuning": [
            "Logistic Regression Calibration"
          ]
        },
        "feature_processing": [
          "Text Parsing",
          "Corpus Statistics",
          "Rule Extraction",
          "Table Building"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clark2016_PMISolver",
      "label": "Pointwise Mutual Information Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_PMISolver",
        "entity_id": "Clark2016_PMISolver",
        "name": "Pointwise Mutual Information Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "PMI Calculation Module"
          ],
          "connections": [
            "Question to PMI Calculation",
            "Answer Options to PMI Calculation"
          ],
          "mechanisms": [
            "Association Strength Measurement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "Window Size for Co-occurrence"
          ]
        },
        "feature_processing": [
          "Unigram Extraction",
          "Bigram Extraction",
          "Trigram Extraction",
          "Skip-Bigram Extraction",
          "Stopword Filtering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clark2016_PMITaskFailureAnalysis",
      "label": "PMI Task Failure Analysis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_PMITaskFailureAnalysis",
        "entity_id": "Clark2016_PMITaskFailureAnalysis",
        "name": "PMI Task Failure Analysis",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "PMI Solver"
          ],
          "connections": [
            "Question-Answer Co-occurrence"
          ],
          "mechanisms": [
            "Co-occurrence Frequency"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Word Co-occurrence Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clark2016_RULESolver",
      "label": "RULE Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_RULESolver",
        "entity_id": "Clark2016_RULESolver",
        "name": "RULE Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Rule Extraction Module",
            "Reasoning Module"
          ],
          "connections": [
            "Text to Rule Extraction",
            "Rules to Reasoning",
            "Question to Reasoning"
          ],
          "mechanisms": [
            "Implication Extraction",
            "Logical Reasoning",
            "Lexical Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Automatic Rule Extraction"
          ],
          "parameter_tuning": [
            "Rule Confidence Threshold"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Implication Pattern Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clark2016_RULETaskFailureAnalysis",
      "label": "RULE Task Failure Analysis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_RULETaskFailureAnalysis",
        "entity_id": "Clark2016_RULETaskFailureAnalysis",
        "name": "RULE Task Failure Analysis",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "RULE Solver"
          ],
          "connections": [
            "Rule Application"
          ],
          "mechanisms": [
            "Implication Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Analysis",
          "Implication Rule Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clark2016_SVMSolver",
      "label": "Support Vector Machine Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clark2016_SVMSolver",
        "entity_id": "Clark2016_SVMSolver",
        "name": "Support Vector Machine Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Clark, P.",
          "Etzioni, O.",
          "Khot, T.",
          "Sabharwal, A.",
          "Tafjord, O.",
          "Turney, P."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Word Embedding Module",
            "SVM Ranker"
          ],
          "connections": [
            "Question to Word Embedding",
            "Answer Options to Word Embedding",
            "Embeddings to SVM Ranker"
          ],
          "mechanisms": [
            "Cosine Similarity Calculation",
            "Pairwise Cosine Similarity Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Kernel Parameters"
          ]
        },
        "feature_processing": [
          "Word Embedding Generation",
          "Vector Summation",
          "Vector Normalization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Clarke2010_DrivingSemanticParsing",
      "label": "Driving Semantic Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Clarke2010_DrivingSemanticParsing",
        "entity_id": "Clarke2010_DrivingSemanticParsing",
        "name": "Driving Semantic Parsing",
        "title": "",
        "year": "2010",
        "authors": [
          "Clarke, J.",
          "Goldwasser, D.",
          "Chang, M.",
          "Roth, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "Geoquery_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Parser",
            "Feedback Function"
          ],
          "connections": [
            "World Response",
            "Behavioral Feedback"
          ],
          "mechanisms": [
            "Supervised Learning",
            "Unsupervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Behavioral Feedback",
            "World Response"
          ],
          "parameter_tuning": [
            "Feedback Function"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Cocke1966_CockeAlgorithm",
      "label": "Cocke's Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cocke1966_CockeAlgorithm",
        "entity_id": "Cocke1966_CockeAlgorithm",
        "name": "Cocke's Algorithm",
        "title": "",
        "year": "1966",
        "authors": [
          "Cocke, J."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [
          "TimeComplexity_Parsing",
          "SpaceComplexity_Parsing"
        ],
        "architecture": {
          "components": [
            "Parsing table",
            "Dynamic programming"
          ],
          "connections": [
            "State transitions"
          ],
          "mechanisms": [
            "Normal form requirement"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Collins1999_HeadDrivenStatisticalModel",
      "label": "Head-Driven Statistical Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Collins1999_HeadDrivenStatisticalModel",
        "entity_id": "Collins1999_HeadDrivenStatisticalModel",
        "name": "Head-Driven Statistical Model",
        "title": "Head-Driven Statistical Models for Natural Language Parsing",
        "year": "1999",
        "authors": [
          "Michael Collins"
        ],
        "task": "[\"Natural Language Parsing\"]",
        "dataset": [],
        "metrics": [
          "Parsing Accuracy"
        ],
        "architecture": {
          "components": [
            "Statistical Models"
          ],
          "connections": [
            "Head Rules"
          ],
          "mechanisms": [
            "Probabilistic Context-Free Grammar"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Parameter Estimation"
          ]
        },
        "feature_processing": [
          "Syntactic Analysis"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Collins1999_HeadDrivenStatisticalModels",
      "label": "Head-Driven Statistical Models",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Collins1999_HeadDrivenStatisticalModels",
        "entity_id": "Collins1999_HeadDrivenStatisticalModels",
        "name": "Head-Driven Statistical Models",
        "title": "",
        "year": "1999",
        "authors": [
          "Michael Collins"
        ],
        "task": "[\"Natural Language Parsing\"]",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parsing",
            "Statistical Models"
          ],
          "connections": [
            "Dependency Extraction Rules"
          ],
          "mechanisms": [
            "Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Maximum Likelihood Estimation"
          ]
        },
        "feature_processing": [
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Collins2003_HeadDrivenStatisticalModel",
      "label": "Head-Driven Statistical Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Collins2003_HeadDrivenStatisticalModel",
        "entity_id": "Collins2003_HeadDrivenStatisticalModel",
        "name": "Head-Driven Statistical Model",
        "title": "",
        "year": "2003",
        "authors": [
          "Collins, M."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Head Rules",
            "Lexical Items"
          ],
          "connections": [
            "Head Attachment"
          ],
          "mechanisms": [
            "Statistical Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Entropy"
          ],
          "parameter_tuning": [
            "Head Probabilities"
          ]
        },
        "feature_processing": [
          "Lexical Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Collins2008_Active_Learning_Approach",
      "label": "Active Learning Approach",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Collins2008_Active_Learning_Approach",
        "entity_id": "Collins2008_Active_Learning_Approach",
        "name": "Active Learning Approach",
        "title": "",
        "year": "2008",
        "authors": [
          "Collins, B.",
          "Deng, J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": "[\"Dataset Construction\"]",
        "dataset": [
          "ImageNet_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Active Learning Module",
            "Image Collection Module"
          ],
          "connections": [
            "Feedback Loop",
            "Data Selection"
          ],
          "mechanisms": [
            "Query Strategy",
            "Model Update"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Active Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Data Augmentation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Collobert2008_UnifiedArchitecture",
      "label": "Unified Architecture for NLP",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Collobert2008_UnifiedArchitecture",
        "entity_id": "Collobert2008_UnifiedArchitecture",
        "name": "Unified Architecture for NLP",
        "title": "",
        "year": "2008",
        "authors": [
          "Collobert, R.",
          "Weston, J."
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Performance on Various Tasks"
        ],
        "architecture": {
          "components": [
            "Deep Neural Networks"
          ],
          "connections": [
            "Multitask Learning"
          ],
          "mechanisms": [
            "Unified Framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Collobert2008_UnifiedArchitectureForNLP",
      "label": "Unified Architecture for NLP",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Collobert2008_UnifiedArchitectureForNLP",
        "entity_id": "Collobert2008_UnifiedArchitectureForNLP",
        "name": "Unified Architecture for NLP",
        "title": "",
        "year": "2008",
        "authors": [
          "Collobert, R.",
          "Weston, J."
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Deep Neural Networks"
          ],
          "connections": [
            "Multitask Learning"
          ],
          "mechanisms": [
            "Shared Representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Collobert2011_NLPFromScratch",
      "label": "Natural Language Processing (Almost) from Scratch",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Collobert2011_NLPFromScratch",
        "entity_id": "Collobert2011_NLPFromScratch",
        "name": "Natural Language Processing (Almost) from Scratch",
        "title": "",
        "year": "2011",
        "authors": [
          "Collobert, R.",
          "Weston, J.",
          "Bottou, L.",
          "Karlen, M.",
          "Kavukcuoglu, K.",
          "Kuksa, P."
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Performance on Various Tasks"
        ],
        "architecture": {
          "components": [
            "Deep Neural Networks"
          ],
          "connections": [
            "Multitask Learning"
          ],
          "mechanisms": [
            "Unified Framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Costa2003_RecursiveNeuralNetworks",
      "label": "Recursive Neural Networks",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Costa2003_RecursiveNeuralNetworks",
        "entity_id": "Costa2003_RecursiveNeuralNetworks",
        "name": "Recursive Neural Networks",
        "title": "",
        "year": "2003",
        "authors": [
          "Costa, F.",
          "Frasconi, P.",
          "Lombardo, V.",
          "Soda, G."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Neural Networks",
            "Recursive Structure"
          ],
          "connections": [
            "Node Compositions"
          ],
          "mechanisms": [
            "Phrase Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": [
            "Network Weights"
          ]
        },
        "feature_processing": [
          "Word Vectors"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Culotta2007_AdvancedSystem",
      "label": "Advanced System",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Culotta2007_AdvancedSystem",
        "entity_id": "Culotta2007_AdvancedSystem",
        "name": "Advanced System",
        "title": "",
        "year": "2007",
        "authors": [
          "Culotta, A.",
          "Wick, M.",
          "Hall, R.",
          "McCallum, A."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference",
          "MUC_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Complex Model",
            "Non-Pairwise Model"
          ],
          "connections": [
            "Partial Clusters of Mentions"
          ],
          "mechanisms": [
            "Feature Computation Over Partial Clusters"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Heuristics for Selecting Training Examples"
          ],
          "parameter_tuning": [
            "Threshold Optimization"
          ]
        },
        "feature_processing": [
          "Feature Computation Over Partial Clusters"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Cummins1988_ChangeCompareCombineSchemas",
      "label": "Change, Compare, Combine Schemas",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Cummins1988_ChangeCompareCombineSchemas",
        "entity_id": "Cummins1988_ChangeCompareCombineSchemas",
        "name": "Change, Compare, Combine Schemas",
        "title": "",
        "year": "1988",
        "authors": [
          "Cummins, D.",
          "Kintsch, W.",
          "Reusser, K.",
          "Weimer, R."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Simple Arithmetic Word Problems"
        ],
        "metrics": [
          "Schema Matching Accuracy"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Dai2015_Autoencoder",
      "label": "Autoencoder",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Dai2015_Autoencoder",
        "entity_id": "Dai2015_Autoencoder",
        "name": "Autoencoder",
        "title": "",
        "year": "2015",
        "authors": [
          "Dai, Andrew M.",
          "Le, Quoc V."
        ],
        "task": "[\"Unsupervised Learning\"]",
        "dataset": [
          "Monolingual Corpora"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks"
          ],
          "mechanisms": [
            "Reconstruction Loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pretraining",
            "Joint Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Mini-Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Dai2015_SemiSupervisedSequenceLearning",
      "label": "Semi-supervised Sequence Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Dai2015_SemiSupervisedSequenceLearning",
        "entity_id": "Dai2015_SemiSupervisedSequenceLearning",
        "name": "Semi-supervised Sequence Learning",
        "title": "Semi-supervised sequence learning",
        "year": "2015",
        "authors": [
          "Dai, Andrew M.",
          "Le, Quoc V."
        ],
        "task": "[\"Sequence Prediction\"]",
        "dataset": [
          "English Unsupervised",
          "German Unsupervised"
        ],
        "metrics": [
          "Perplexity",
          "BLEU Score"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks",
            "Long Short-Term Memory"
          ],
          "mechanisms": [
            "Autoencoder"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pretraining",
            "Finetuning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "DaumeIII2005_LearningAsSearchOptimization",
      "label": "Learning as Search Optimization (LaSO)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "DaumeIII2005_LearningAsSearchOptimization",
        "entity_id": "DaumeIII2005_LearningAsSearchOptimization",
        "name": "Learning as Search Optimization (LaSO)",
        "title": "",
        "year": "2005",
        "authors": [
          "Daume III, H.",
          "Marcu, D."
        ],
        "task": "[\"Structured Prediction\"]",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "Custom Loss Functions"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "Non-probabilistic Scoring Function"
          ],
          "connections": [
            "RNN Decoder"
          ],
          "mechanisms": [
            "Margin Loss",
            "Beam Search Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Training",
            "LaSO Framework"
          ],
          "parameter_tuning": [
            "Beam Size",
            "Loss Function Parameters"
          ]
        },
        "feature_processing": [
          "Hard Constraints on Successor Sequences"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deane2003_FrameSemanticsBasedGeneration",
      "label": "Frame Semantics Based Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deane2003_FrameSemanticsBasedGeneration",
        "entity_id": "Deane2003_FrameSemanticsBasedGeneration",
        "name": "Frame Semantics Based Generation",
        "title": "",
        "year": "2003",
        "authors": [
          "Deane, P.",
          "Sheehan, K."
        ],
        "task": "[\"Mathematical Word Problem Generation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Frame Semantics"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deerwester1990_LSA",
      "label": "Latent Semantic Analysis (LSA)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deerwester1990_LSA",
        "entity_id": "Deerwester1990_LSA",
        "name": "Latent Semantic Analysis (LSA)",
        "title": "",
        "year": "1990",
        "authors": [
          "Deerwester, S.",
          "Dumais, S. T.",
          "Furnas, G. W.",
          "Landauer, T. K.",
          "Harshman, R."
        ],
        "task": "[\"Information Retrieval\"]",
        "dataset": [
          "Term-Document Matrices"
        ],
        "metrics": [
          "Similarity Measures"
        ],
        "architecture": {
          "components": [
            "Matrix Factorization"
          ],
          "connections": [
            "Low-Rank Approximation"
          ],
          "mechanisms": [
            "Decomposition of Large Matrices"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Global Matrix Factorization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Statistical Information Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Dellarosa1986_ARITHPRO",
      "label": "ARITHPRO",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Dellarosa1986_ARITHPRO",
        "entity_id": "Dellarosa1986_ARITHPRO",
        "name": "ARITHPRO",
        "title": "",
        "year": "1986",
        "authors": [
          "Dellarosa, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "One-step Arithmetic Word Problems"
        ],
        "metrics": [
          "Solution Correctness"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "deMarneffe2006_PASCALRecognizingTextualEntailment",
      "label": "PASCAL Recognizing Textual Entailment",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "deMarneffe2006_PASCALRecognizingTextualEntailment",
        "entity_id": "deMarneffe2006_PASCALRecognizingTextualEntailment",
        "name": "PASCAL Recognizing Textual Entailment",
        "title": "",
        "year": "2006",
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": "[\"Textual Entailment Recognition\"]",
        "dataset": [
          "Brown Corpus"
        ],
        "metrics": [
          "DependencyAccuracy_Classification",
          "DependencyTypeAccuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Typed Dependency Trees",
            "Quasi-Logical Representation",
            "Alignment Module",
            "Learning Module"
          ],
          "connections": [
            "Dependency Trees -> Quasi-Logical Representation",
            "Quasi-Logical Representation -> Alignment Module",
            "Alignment Module -> Learning Module"
          ],
          "mechanisms": [
            "Predicate-Argument Structure Encoding",
            "Event Structure Representation",
            "Structure Alignment",
            "Feature Generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "Predicate-Argument Structure Features",
          "Dependency Relation Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "deMarneffe2006_TypedDependencyExtraction",
      "label": "Typed Dependency Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "deMarneffe2006_TypedDependencyExtraction",
        "entity_id": "deMarneffe2006_TypedDependencyExtraction",
        "name": "Typed Dependency Extraction",
        "title": "",
        "year": "2006",
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "Penn Treebank",
          "Brown Corpus"
        ],
        "metrics": [
          "Dependency Accuracy",
          "Per-Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Dependency Extractor",
            "Dependency Typer"
          ],
          "connections": [
            "Phrase Structure Trees -> Dependency Extraction -> Dependency Typing"
          ],
          "mechanisms": [
            "Rule-based extraction",
            "Pattern matching on phrase structure trees"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Training on Penn Treebank"
          ],
          "parameter_tuning": [
            "Collins head rules",
            "Semantic head identification"
          ]
        },
        "feature_processing": [
          "Handling of prepositions and conjunctions",
          "Processing of conjunct dependencies"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "deMarneffe2006_TypedDependencyExtractor",
      "label": "Typed Dependency Extractor",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "deMarneffe2006_TypedDependencyExtractor",
        "entity_id": "deMarneffe2006_TypedDependencyExtractor",
        "name": "Typed Dependency Extractor",
        "title": "Generating Typed Dependency Parses from Phrase Structure Parses",
        "year": "2006",
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Dependency Extraction Rules"
          ],
          "connections": [
            "Head Identification Rules"
          ],
          "mechanisms": [
            "Collapsing Dependencies"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Statistical Parsing"
          ],
          "parameter_tuning": [
            "Collins Head Rules"
          ]
        },
        "feature_processing": [
          "Semantic Head Retrieval",
          "Dependency Typing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "deMarneffe2006_TypedDependencyParser",
      "label": "Typed Dependency Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "deMarneffe2006_TypedDependencyParser",
        "entity_id": "deMarneffe2006_TypedDependencyParser",
        "name": "Typed Dependency Parser",
        "title": "Generating Typed Dependency Parses from Phrase Structure Parses",
        "year": "2006",
        "authors": [
          "Marie-Catherine de Marneffe",
          "Bill MacCartney",
          "Christopher D. Manning"
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "Penn Treebank",
          "Brown Corpus"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Dependency Extraction Rules",
            "Dependency Typing Rules"
          ],
          "connections": [
            "Phrase Structure Trees -> Dependency Graphs"
          ],
          "mechanisms": [
            "Collapsing Dependencies",
            "Semantic Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Treebank-trained Statistical Parsers"
          ],
          "parameter_tuning": [
            "Rule-based Pattern Matching"
          ]
        },
        "feature_processing": [
          "Semantic Head Retrieval",
          "Collapsing Prepositions and Conjunctions"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deng2009_AdaBoostBasedClassifier",
      "label": "AdaBoost-based Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deng2009_AdaBoostBasedClassifier",
        "entity_id": "Deng2009_AdaBoostBasedClassifier",
        "name": "AdaBoost-based Classifier",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": "2009",
        "authors": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": "[\"Object Classification\"]",
        "dataset": [],
        "metrics": [
          "AUC"
        ],
        "architecture": {
          "components": [
            "AdaBoost"
          ],
          "connections": [
            "Hierarchical Structure"
          ],
          "mechanisms": [
            "Synset Nodes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Sampling"
          ],
          "parameter_tuning": [
            "AdaBoost"
          ]
        },
        "feature_processing": [
          "Image Descriptors"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deng2009_AMT_image_verification",
      "label": "AMT Image Verification",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deng2009_AMT_image_verification",
        "entity_id": "Deng2009_AMT_image_verification",
        "name": "AMT Image Verification",
        "title": "",
        "year": "2009",
        "authors": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": "[\"Image Annotation\"]",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Amazon Mechanical Turk",
            "User Voting System"
          ],
          "connections": [
            "Image Querying",
            "User Feedback Loop"
          ],
          "mechanisms": [
            "Duplicate Removal",
            "Quality Control"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Crowdsourcing"
          ],
          "parameter_tuning": [
            "Number of Votes Required",
            "Confidence Score Threshold"
          ]
        },
        "feature_processing": [
          "Image Downsampling",
          "Image Duplication Removal"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deng2009_ImageNet_Hierarchy_Exploitation",
      "label": "ImageNet Hierarchy Exploitation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deng2009_ImageNet_Hierarchy_Exploitation",
        "entity_id": "Deng2009_ImageNet_Hierarchy_Exploitation",
        "name": "ImageNet Hierarchy Exploitation",
        "title": "",
        "year": "2009",
        "authors": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ],
        "task": "[\"Image Classification\"]",
        "dataset": [
          "ImageNet_2009"
        ],
        "metrics": [
          "AUC_Classification"
        ],
        "architecture": {
          "components": [
            "Tree-max Classifier"
          ],
          "connections": [
            "Parent-child relationships in the hierarchy"
          ],
          "mechanisms": [
            "Hierarchical classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "AdaBoost-based classifier"
          ],
          "parameter_tuning": [
            "Number of images per category"
          ]
        },
        "feature_processing": [
          "Feature extraction from full-resolution images"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deng2009_NBNN",
      "label": "NBNN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deng2009_NBNN",
        "entity_id": "Deng2009_NBNN",
        "name": "NBNN",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": "2009",
        "authors": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ],
        "task": "[\"对象识别\"]",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "Accuracy",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "朴素贝叶斯最近邻",
            "SIFT特征描述符"
          ],
          "connections": [
            "查询图像与类别特征的距离计算"
          ],
          "mechanisms": [
            "基于特征级信息的分类"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习"
          ],
          "parameter_tuning": [
            "特征描述符数量"
          ]
        },
        "feature_processing": [
          "SIFT特征提取"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deng2009_NN_voting",
      "label": "NN-voting",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deng2009_NN_voting",
        "entity_id": "Deng2009_NN_voting",
        "name": "NN-voting",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": "2009",
        "authors": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ],
        "task": "[\"对象识别\"]",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "Accuracy",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "最近邻搜索",
            "投票机制"
          ],
          "connections": [
            "候选图像与目标类别的树结构"
          ],
          "mechanisms": [
            "基于像素距离的相似性匹配"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习"
          ],
          "parameter_tuning": [
            "候选图像数量"
          ]
        },
        "feature_processing": [
          "下采样到32x32"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deng2009_NonParametricObjectRecognition",
      "label": "Non-Parametric Object Recognition",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deng2009_NonParametricObjectRecognition",
        "entity_id": "Deng2009_NonParametricObjectRecognition",
        "name": "Non-Parametric Object Recognition",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": "2009",
        "authors": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": "[\"Object Recognition\"]",
        "dataset": [],
        "metrics": [
          "Accuracy",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Nearest Neighbor"
          ],
          "connections": [
            "Hierarchical Structure"
          ],
          "mechanisms": [
            "Synset Nodes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Sampling"
          ],
          "parameter_tuning": [
            "SSD Pixel Distance"
          ]
        },
        "feature_processing": [
          "Image Descriptors"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deng2009_Tree_max_classifier",
      "label": "Tree-max Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deng2009_Tree_max_classifier",
        "entity_id": "Deng2009_Tree_max_classifier",
        "name": "Tree-max Classifier",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": "2009",
        "authors": [
          "Jia Deng",
          "Wei Dong",
          "Richard Socher",
          "Li-Jia Li",
          "Kai Li",
          "Li Fei-Fei"
        ],
        "task": "[\"图像分类\"]",
        "dataset": [
          "ImageNet"
        ],
        "metrics": [
          "AUC"
        ],
        "architecture": {
          "components": [
            "树结构分类器",
            "AdaBoost-based分类器"
          ],
          "connections": [
            "节点分类得分与子节点分类得分的最大值"
          ],
          "mechanisms": [
            "利用层次结构进行分类"
          ]
        },
        "methodology": {
          "training_strategy": [
            "有监督学习"
          ],
          "parameter_tuning": [
            "训练图像数量"
          ]
        },
        "feature_processing": [
          "无"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deng2009_TreeMaxClassifier",
      "label": "Tree-Max Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deng2009_TreeMaxClassifier",
        "entity_id": "Deng2009_TreeMaxClassifier",
        "name": "Tree-Max Classifier",
        "title": "ImageNet: A Large-Scale Hierarchical Image Database",
        "year": "2009",
        "authors": [
          "Deng, J.",
          "Dong, W.",
          "Socher, R.",
          "Li, L.-J.",
          "Li, K.",
          "Fei-Fei, L."
        ],
        "task": "[\"Object Classification\"]",
        "dataset": [],
        "metrics": [
          "AUC"
        ],
        "architecture": {
          "components": [
            "AdaBoost-based Classifier"
          ],
          "connections": [
            "Hierarchical Structure"
          ],
          "mechanisms": [
            "Synset Nodes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Sampling"
          ],
          "parameter_tuning": [
            "AdaBoost"
          ]
        },
        "feature_processing": [
          "Image Descriptors"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Deng2017_DimensionallyGuidedSynthesis",
      "label": "Dimensionally Guided Synthesis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Deng2017_DimensionallyGuidedSynthesis",
        "entity_id": "Deng2017_DimensionallyGuidedSynthesis",
        "name": "Dimensionally Guided Synthesis",
        "title": "Dimensionally Guided Synthesis of Mathematical Word Problems",
        "year": "2017",
        "authors": [
          "Wang, K.",
          "Su, Z."
        ],
        "task": "[\"Mathematical Word Problem Generation\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Dimensionally Consistent Equation Generator",
            "Natural Language Story Composer"
          ],
          "connections": [
            "Equation Tree"
          ],
          "mechanisms": [
            "Bottom-Up Traversal"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Efficient Generation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dimensional Units"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Descartes_Method",
      "label": "Descartes' Method",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Descartes_Method",
        "entity_id": "Descartes_Method",
        "name": "Descartes' Method",
        "title": "",
        "year": "None",
        "authors": [
          "Descartes, R."
        ],
        "task": "[\"Analytic Geometry Theorem Proving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Assigning coordinates to points"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Algebraic approach"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Devlin2014_FastAndRobustNeuralNetworkJointModels",
      "label": "Fast and Robust Neural Network Joint Models for Statistical Machine Translation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Devlin2014_FastAndRobustNeuralNetworkJointModels",
        "entity_id": "Devlin2014_FastAndRobustNeuralNetworkJointModels",
        "name": "Fast and Robust Neural Network Joint Models for Statistical Machine Translation",
        "title": "",
        "year": "2014",
        "authors": [
          "J. Devlin",
          "R. Zbib",
          "Z. Huang",
          "T. Lamar",
          "R. Schwartz",
          "J. Makhoul"
        ],
        "task": "[\"Statistical Machine Translation\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Decoder"
          ],
          "connections": [
            "Input Sentence to Decoder",
            "Decoder to Neural Network"
          ],
          "mechanisms": [
            "Alignment Information"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rescoring n-best Lists"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Alignment Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Devlin2014_NeuralNetworkJointModel",
      "label": "Neural Network Joint Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Devlin2014_NeuralNetworkJointModel",
        "entity_id": "Devlin2014_NeuralNetworkJointModel",
        "name": "Neural Network Joint Model",
        "title": "",
        "year": "2014",
        "authors": [
          "Devlin, J.",
          "Zbib, R.",
          "Huang, Z.",
          "Lamar, T.",
          "Schwartz, R.",
          "Makhoul, J."
        ],
        "task": "[\"Statistical Machine Translation\"]",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layers",
            "Output Layer"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Predicting One Word at a Time"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "DNS2014_DeepNeuralSolver",
      "label": "Deep Neural Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "DNS2014_DeepNeuralSolver",
        "entity_id": "DNS2014_DeepNeuralSolver",
        "name": "Deep Neural Solver",
        "title": "",
        "year": "2014",
        "authors": [
          "Y. Wang",
          "X. Liu",
          "S. Shi"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "Dolphin18K",
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "GRU",
            "Word Embedding"
          ],
          "connections": [
            "Encoder-Decoder"
          ],
          "mechanisms": [
            "Seq2Seq"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "DNS2017_DeepNeuralSolver",
      "label": "Deep Neural Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "DNS2017_DeepNeuralSolver",
        "entity_id": "DNS2017_DeepNeuralSolver",
        "name": "Deep Neural Solver",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "ALG514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "GRU Network",
            "Word Embedding"
          ],
          "connections": [
            "Sequence Translation",
            "Number Mapping"
          ],
          "mechanisms": [
            "Five Validity Constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Seq2Seq Model Training",
            "Similarity-Based Method"
          ],
          "parameter_tuning": [
            "LSTM-Based Binary Classification"
          ]
        },
        "feature_processing": [
          "Word Embedding Features",
          "Unsupervised Word-Embedding Features"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Dries2017_ProbabilityProblems",
      "label": "Probability Problems Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Dries2017_ProbabilityProblems",
        "entity_id": "Dries2017_ProbabilityProblems",
        "name": "Probability Problems Solver",
        "title": "",
        "year": "2017",
        "authors": [
          "Dries, A.",
          "Kimmig, A.",
          "Davis, J.",
          "Belle, V.",
          "Raedt, L. D."
        ],
        "task": "[\"Solving probability problems\"]",
        "dataset": [
          "Probability problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Declarative language formulation",
            "ProbLog solver"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Formulating questions and computing answers"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Dries2017_ProbabilitySolver",
      "label": "Probability Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Dries2017_ProbabilitySolver",
        "entity_id": "Dries2017_ProbabilitySolver",
        "name": "Probability Solver",
        "title": "",
        "year": "2017",
        "authors": [
          "Dries, A.",
          "Kimmig, A.",
          "Davis, J.",
          "Belle, V.",
          "Raedt, L. D."
        ],
        "task": "[\"Solving probability problems\"]",
        "dataset": [
          "Probability problem datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Declarative language formulation"
          ],
          "connections": [
            "Solver implementation"
          ],
          "mechanisms": [
            "Formulating questions and computing answers"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Model training"
          ],
          "parameter_tuning": [
            "Hyperparameter tuning"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Duchi2011_AdaptiveSubgradientMethods",
      "label": "Adaptive Subgradient Methods (AdaGrad)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Duchi2011_AdaptiveSubgradientMethods",
        "entity_id": "Duchi2011_AdaptiveSubgradientMethods",
        "name": "Adaptive Subgradient Methods (AdaGrad)",
        "title": "",
        "year": "2011",
        "authors": [
          "Duchi, J.",
          "Hazan, E.",
          "Singer, Y."
        ],
        "task": "[\"Optimization\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Parameter Updates"
          ],
          "connections": [
            "Adaptive Learning Rates"
          ],
          "mechanisms": [
            "Accumulating Squared Gradients"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Duda1972_AccumulatorImplementation",
      "label": "Accumulator Implementation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Duda1972_AccumulatorImplementation",
        "entity_id": "Duda1972_AccumulatorImplementation",
        "name": "Accumulator Implementation",
        "title": "",
        "year": "1972",
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "[\"Line Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Two-dimensional accumulator array",
            "Parameter space"
          ],
          "connections": [
            "Mapping figure points to parameter space",
            "Incrementing cell counts"
          ],
          "mechanisms": [
            "Quantization of parameter space",
            "Finding high-count cells"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization intervals for θ and ρ"
          ]
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Duda1972_CircularConfigurationDetection",
      "label": "Circular Configuration Detection",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Duda1972_CircularConfigurationDetection",
        "entity_id": "Duda1972_CircularConfigurationDetection",
        "name": "Circular Configuration Detection",
        "title": "",
        "year": "1972",
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "[\"Circle Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Three-Dimensional Parameter Space",
            "Accumulator Array"
          ],
          "connections": [
            "Point-Surface Transformation",
            "Cone Intersection"
          ],
          "mechanisms": [
            "Intersection Detection",
            "High Count Accumulation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Intervals"
          ]
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Duda1972_GeneralizedTransformMethod",
      "label": "Generalized Transform Method",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Duda1972_GeneralizedTransformMethod",
        "entity_id": "Duda1972_GeneralizedTransformMethod",
        "name": "Generalized Transform Method",
        "title": "",
        "year": "1972",
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "[\"Curve Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Parameter Space",
            "Accumulator Array"
          ],
          "connections": [
            "Point-Curve Transformation",
            "Parameter Quantization"
          ],
          "mechanisms": [
            "Intersection Detection",
            "High Count Accumulation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Intervals"
          ]
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Duda1972_HoughTransform",
      "label": "Hough Transform",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Duda1972_HoughTransform",
        "entity_id": "Duda1972_HoughTransform",
        "name": "Hough Transform",
        "title": "Use of the Hough Transform to detect lines and curves in pictures",
        "year": "1972",
        "authors": [
          "R. Duda",
          "P. Hart"
        ],
        "task": "[\"Line and Curve Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Accumulator Array",
            "Edge Points"
          ],
          "connections": [
            "Edge Points -> Accumulator Array"
          ],
          "mechanisms": [
            "Peak Detection",
            "Quantization"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Steps dθ and dρ"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Duda1972_HoughTransformation",
      "label": "Hough Transformation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Duda1972_HoughTransformation",
        "entity_id": "Duda1972_HoughTransformation",
        "name": "Hough Transformation",
        "title": "",
        "year": "1972",
        "authors": [
          "Duda, R. O.",
          "Hart, P. E."
        ],
        "task": "[\"Line and Curve Detection\"]",
        "dataset": [
          "Synthetic_Images_2004",
          "Natural_Images_2004"
        ],
        "metrics": [
          "Detection_Precision",
          "Detection_Recall"
        ],
        "architecture": {
          "components": [
            "Parameter Space",
            "Accumulator Array"
          ],
          "connections": [
            "Point-Line Transformation",
            "Curve Intersection"
          ],
          "mechanisms": [
            "Quantization",
            "Accumulation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Quantization of Parameter Space"
          ],
          "parameter_tuning": [
            "Angle and Radius Parameters"
          ]
        },
        "feature_processing": [
          "Point-to-Curve Transformation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Duda1972_NormalParameterization",
      "label": "Normal Parameterization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Duda1972_NormalParameterization",
        "entity_id": "Duda1972_NormalParameterization",
        "name": "Normal Parameterization",
        "title": "",
        "year": "1972",
        "authors": [
          "Richard O. Duda",
          "Peter E. Hart"
        ],
        "task": "[\"Line Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Angle",
            "Radius"
          ],
          "connections": [
            "Point-Line Transformation"
          ],
          "mechanisms": [
            "Parameter Space Mapping"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Duda1972_SlopeInterceptParameterization",
      "label": "Slope-Intercept Parameterization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Duda1972_SlopeInterceptParameterization",
        "entity_id": "Duda1972_SlopeInterceptParameterization",
        "name": "Slope-Intercept Parameterization",
        "title": "",
        "year": "1972",
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "[\"Line Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Two-Dimensional Parameter Space"
          ],
          "connections": [
            "Point-Line Transformation"
          ],
          "mechanisms": [
            "Intersection Detection",
            "High Count Accumulation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Duda1972_TransformApproachExample",
      "label": "Transform Approach Example",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Duda1972_TransformApproachExample",
        "entity_id": "Duda1972_TransformApproachExample",
        "name": "Transform Approach Example",
        "title": "",
        "year": "1972",
        "authors": [
          "Duda, R.O.",
          "Hart, P.E."
        ],
        "task": "[\"Line Detection\"]",
        "dataset": [
          "Box Image"
        ],
        "metrics": [
          "Number of Colinear Points"
        ],
        "architecture": {
          "components": [
            "Point-to-Curve Transformation",
            "Accumulator Array"
          ],
          "connections": [
            "Figure Points -> Sinusoidal Curves -> Accumulator Cells"
          ],
          "mechanisms": [
            "Quantization of Parameter Space",
            "Counting Intersections"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "Quantization Intervals for θ and p"
          ]
        },
        "feature_processing": [
          "Simple Differencing Operation for Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Earley1970_BottomUpParser",
      "label": "Bottom-Up Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Earley1970_BottomUpParser",
        "entity_id": "Earley1970_BottomUpParser",
        "name": "Bottom-Up Parser",
        "title": "",
        "year": "1970",
        "authors": [
          "Earley, J."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Shift",
            "Reduce"
          ],
          "connections": [
            "Stack operations"
          ],
          "mechanisms": [
            "Parsing tables"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Earley1970_EfficientContextFreeParsingAlgorithm",
      "label": "Efficient Context-Free Parsing Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Earley1970_EfficientContextFreeParsingAlgorithm",
        "entity_id": "Earley1970_EfficientContextFreeParsingAlgorithm",
        "name": "Efficient Context-Free Parsing Algorithm",
        "title": "An Efficient Context-Free Parsing Algorithm",
        "year": "1970",
        "authors": [
          "Earley, Jay"
        ],
        "task": "[\"Context-Free Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "states",
            "scanner",
            "predictor",
            "completer"
          ],
          "connections": [
            "state transitions",
            "look-ahead"
          ],
          "mechanisms": [
            "dynamic programming",
            "top-down",
            "bottom-up"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Earley1970_EfficientParsingAlgorithm",
      "label": "Efficient Context-Free Parsing Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Earley1970_EfficientParsingAlgorithm",
        "entity_id": "Earley1970_EfficientParsingAlgorithm",
        "name": "Efficient Context-Free Parsing Algorithm",
        "title": "An Efficient Context-Free Parsing Algorithm",
        "year": "1970",
        "authors": [
          "Jay Earley"
        ],
        "task": "[\"Parsing context-free grammars\"]",
        "dataset": [],
        "metrics": [
          "Time complexity",
          "Space complexity"
        ],
        "architecture": {
          "components": [
            "Predictor",
            "Completer",
            "Scanner"
          ],
          "connections": [
            "State transitions",
            "Look-ahead"
          ],
          "mechanisms": [
            "State sets",
            "Derivation trees"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Look-ahead strings",
          "State sets"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Earley1970_EfficientParsingAlgorithm_KleeneStarExtension",
      "label": "Efficient Context-Free Parsing Algorithm with Kleene Star Extension",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Earley1970_EfficientParsingAlgorithm_KleeneStarExtension",
        "entity_id": "Earley1970_EfficientParsingAlgorithm_KleeneStarExtension",
        "name": "Efficient Context-Free Parsing Algorithm with Kleene Star Extension",
        "title": "",
        "year": "1970",
        "authors": [
          "Jay Earley"
        ],
        "task": "[\"Parsing context-free grammars\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Predictor",
            "Completer",
            "Scanner"
          ],
          "connections": [
            "State transitions",
            "Look-ahead handling"
          ],
          "mechanisms": [
            "Kleene star notation support"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Kleene star notation handling"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Earley1970_SelectiveBottomUpParser",
      "label": "Selective Bottom-Up Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Earley1970_SelectiveBottomUpParser",
        "entity_id": "Earley1970_SelectiveBottomUpParser",
        "name": "Selective Bottom-Up Parser",
        "title": "",
        "year": "1970",
        "authors": [
          "Earley, J."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Selective Shift",
            "Reduce"
          ],
          "connections": [
            "Stack operations"
          ],
          "mechanisms": [
            "Parsing tables"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Earley1970_SelectiveTopDownParser",
      "label": "Selective Top-Down Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Earley1970_SelectiveTopDownParser",
        "entity_id": "Earley1970_SelectiveTopDownParser",
        "name": "Selective Top-Down Parser",
        "title": "",
        "year": "1970",
        "authors": [
          "Earley, J."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Selective Predictor",
            "Scanner",
            "Completer"
          ],
          "connections": [
            "State transitions",
            "Look-ahead"
          ],
          "mechanisms": [
            "State sets",
            "Derivation trees"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Look-ahead strings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Earley1970_TopDownParser",
      "label": "Top-Down Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Earley1970_TopDownParser",
        "entity_id": "Earley1970_TopDownParser",
        "name": "Top-Down Parser",
        "title": "",
        "year": "1970",
        "authors": [
          "Earley, J."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Predictor",
            "Scanner",
            "Completer"
          ],
          "connections": [
            "State transitions",
            "Look-ahead"
          ],
          "mechanisms": [
            "State sets",
            "Derivation trees"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Look-ahead strings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Eisenstein2009_ReadingToLearn",
      "label": "Reading to Learn",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Eisenstein2009_ReadingToLearn",
        "entity_id": "Eisenstein2009_ReadingToLearn",
        "name": "Reading to Learn",
        "title": "",
        "year": "2009",
        "authors": [
          "Eisenstein, J.",
          "Clarke, J.",
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "[\"Feature Construction\"]",
        "dataset": [
          "EMNLP_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Construction",
            "Semantic Abstracts"
          ],
          "connections": [
            "Reading",
            "Learning"
          ],
          "mechanisms": [
            "Feature Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Feature Construction"
          ],
          "parameter_tuning": [
            "Semantic Abstracts"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fergus2005_Object_Category_Learning",
      "label": "Object Category Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fergus2005_Object_Category_Learning",
        "entity_id": "Fergus2005_Object_Category_Learning",
        "name": "Object Category Learning",
        "title": "",
        "year": "2005",
        "authors": [
          "Fergus, R.",
          "Fei-Fei, L.",
          "Perona, P.",
          "Zisserman, A."
        ],
        "task": "[\"Object Recognition\"]",
        "dataset": [
          "TinyImage_2008"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Category Model",
            "Image Search Engine"
          ],
          "connections": [
            "Query Expansion",
            "Image Retrieval"
          ],
          "mechanisms": [
            "Semantic Mapping",
            "Category Refinement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "Thresholds",
            "Query Terms"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Image Preprocessing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ferguson1994_MAGI",
      "label": "MAGI",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ferguson1994_MAGI",
        "entity_id": "Ferguson1994_MAGI",
        "name": "MAGI",
        "title": "MAGI: Analogy-based encoding using symmetry and regularity",
        "year": "1994",
        "authors": [
          "Ronald W. Ferguson"
        ],
        "task": "[\"Symmetry Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Symmetry Detection Engine"
          ],
          "connections": [
            "GeoRep to Symmetry Detection"
          ],
          "mechanisms": [
            "Symmetry and Repetition Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Shape and orientation analysis"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ferguson1995_JUXTA",
      "label": "JUXTA",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ferguson1995_JUXTA",
        "entity_id": "Ferguson1995_JUXTA",
        "name": "JUXTA",
        "title": "Understanding illustrations of physical laws by integrating differences in visual and textual representations",
        "year": "1995",
        "authors": [
          "Ronald W. Ferguson",
          "Kenneth D. Forbus"
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Visual Level",
            "Physical Level",
            "Process Level"
          ],
          "connections": [
            "GeoRep to JUXTA"
          ],
          "mechanisms": [
            "Representation Levels",
            "Contextual Analysis"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Visual and physical relation detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ferguson1999_COADiagramInterpreter",
      "label": "COA Diagram Interpreter",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ferguson1999_COADiagramInterpreter",
        "entity_id": "Ferguson1999_COADiagramInterpreter",
        "name": "COA Diagram Interpreter",
        "title": "",
        "year": "1999",
        "authors": [
          "Ferguson, R. W.",
          "Forbus, K. D."
        ],
        "task": "[\"Spatial Reasoning about Course of Action Diagrams\"]",
        "dataset": [
          "COA Diagrams"
        ],
        "metrics": [
          "Recognition Accuracy"
        ],
        "architecture": {
          "components": [
            "GeoRep",
            "HLRD Rules"
          ],
          "connections": [
            "GeoRep generates description of units, areas, and tasks -> HLRD rules interpret"
          ],
          "mechanisms": [
            "Recognizing line-drawn symbols"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Handling ambiguous shapes based on context"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ferguson1999_GeoRep",
      "label": "GeoRep",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ferguson1999_GeoRep",
        "entity_id": "Ferguson1999_GeoRep",
        "name": "GeoRep",
        "title": "GeoRep: A Flexible Tool for Spatial Representation of Line Drawings",
        "year": "1999",
        "authors": [
          "Ronald W. Ferguson",
          "Kenneth D. Forbus"
        ],
        "task": "[\"Spatial Representation and Reasoning\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Low-Level Relational Describer (LLRD)",
            "High-Level Relational Describer (HLRD)"
          ],
          "connections": [
            "LLRD to HLRD"
          ],
          "mechanisms": [
            "Visual Operations Library",
            "Reference Frame Relations",
            "Proximity Detection",
            "Grouping Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning",
            "Domain-specific rules"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Primitive shape detection",
          "Proximity-based relation detection",
          "Interval relations",
          "Polygon and polyline detection",
          "Boundary description"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ferguson1999_HighLevelRelationalDescriber",
      "label": "High-Level Relational Describer (HLRD)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ferguson1999_HighLevelRelationalDescriber",
        "entity_id": "Ferguson1999_HighLevelRelationalDescriber",
        "name": "High-Level Relational Describer (HLRD)",
        "title": "",
        "year": "1999",
        "authors": [
          "Ferguson, R. W.",
          "Forbus, K. D."
        ],
        "task": "[\"Place Vocabulary Construction\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "rule engine",
            "LTRE",
            "truth maintenance system",
            "visual operation library"
          ],
          "connections": [
            "domain-dependent rules",
            "visual relation extension"
          ],
          "mechanisms": [
            "representational links",
            "context-based symbol recognition"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "domain-specific rules",
          "proximate object delimitation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ferguson1999_JUXTA",
      "label": "JUXTA",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ferguson1999_JUXTA",
        "entity_id": "Ferguson1999_JUXTA",
        "name": "JUXTA",
        "title": "",
        "year": "1999",
        "authors": [
          "Ferguson, R. W."
        ],
        "task": "[\"Critiquing Simplified Diagrams of Physical Phenomena\"]",
        "dataset": [
          "Simplified Diagrams"
        ],
        "metrics": [
          "Relevance of Visual Differences"
        ],
        "architecture": {
          "components": [
            "GeoRep",
            "HLRD Rules"
          ],
          "connections": [
            "GeoRep generates visual, physical, and process levels -> HLRD rules interpret and critique"
          ],
          "mechanisms": [
            "Detecting physical and process differences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Detecting aligned differences in diagrams"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ferguson1999_LowLevelRelationalDescriber",
      "label": "Low-Level Relational Describer (LLRD)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ferguson1999_LowLevelRelationalDescriber",
        "entity_id": "Ferguson1999_LowLevelRelationalDescriber",
        "name": "Low-Level Relational Describer (LLRD)",
        "title": "",
        "year": "1999",
        "authors": [
          "Ferguson, R. W.",
          "Forbus, K. D."
        ],
        "task": "[\"Spatial Representation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "proximity detection",
            "visual operations",
            "orientation detection",
            "parallel line detection",
            "connectivity detection",
            "polygon and polyline detection",
            "boundary description",
            "interval relations"
          ],
          "connections": [
            "proximity-based relations",
            "visual operation pipeline"
          ],
          "mechanisms": [
            "universal visual routines",
            "pre-attentive grouping factors"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "proximity calculation",
          "visual element grouping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ferguson1999_SymmetryDetectionModel",
      "label": "Symmetry Detection Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ferguson1999_SymmetryDetectionModel",
        "entity_id": "Ferguson1999_SymmetryDetectionModel",
        "name": "Symmetry Detection Model",
        "title": "",
        "year": "1999",
        "authors": [
          "Ferguson, R. W."
        ],
        "task": "[\"Symmetry Detection\"]",
        "dataset": [
          "Polygon Figures"
        ],
        "metrics": [
          "Symmetry Judgment Accuracy"
        ],
        "architecture": {
          "components": [
            "GeoRep",
            "MAGI"
          ],
          "connections": [
            "GeoRep generates low-level relational description -> MAGI judges symmetry"
          ],
          "mechanisms": [
            "Detecting qualitative visual structure"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not applicable"
          ],
          "parameter_tuning": [
            "Not applicable"
          ]
        },
        "feature_processing": [
          "Detecting concavities and convexities in polygon boundaries"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fernandes2012_LatentStructurePerceptron",
      "label": "Latent Structure Perceptron",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fernandes2012_LatentStructurePerceptron",
        "entity_id": "Fernandes2012_LatentStructurePerceptron",
        "name": "Latent Structure Perceptron",
        "title": "",
        "year": "2012",
        "authors": [
          "E. R. Fernandes",
          "C. N. dos Santos",
          "R. L. Milidiu"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "Ontonotes-5.0",
          "ACE 2004"
        ],
        "metrics": [
          "MUC",
          "BCUB",
          "CEAF",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Feature Induction",
            "Perceptron"
          ],
          "connections": [
            "Latent Structure"
          ],
          "mechanisms": [
            "Feature Induction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Induction Parameters"
          ]
        },
        "feature_processing": [
          "Feature Induction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Filippova2015_SentenceCompression",
      "label": "Sentence Compression",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Filippova2015_SentenceCompression",
        "entity_id": "Filippova2015_SentenceCompression",
        "name": "Sentence Compression",
        "title": "",
        "year": "2015",
        "authors": [
          "Filippova, K.",
          "Alfonseca, E.",
          "Colmenares, C.A.",
          "Kaiser, L.",
          "Vinyals, O."
        ],
        "task": "[\"Sentence Compression\"]",
        "dataset": [
          "Various Text Corpora"
        ],
        "metrics": [
          "ROUGE"
        ],
        "architecture": {
          "components": [
            "LSTM"
          ],
          "connections": [
            "Sequential Deletion"
          ],
          "mechanisms": [
            "Deletion with LSTMs"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross-Entropy Loss"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Finkel2008_SupervisedModel",
      "label": "Supervised Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Finkel2008_SupervisedModel",
        "entity_id": "Finkel2008_SupervisedModel",
        "name": "Supervised Model",
        "title": "",
        "year": "2008",
        "authors": [
          "Finkel, J.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-NWIRE"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Feature-rich Models"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Finley2005_SupervisedClustering",
      "label": "Supervised Clustering",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Finley2005_SupervisedClustering",
        "entity_id": "Finley2005_SupervisedClustering",
        "name": "Supervised Clustering",
        "title": "",
        "year": "2005",
        "authors": [
          "Finley and Joachims"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE_2004",
          "Ontonotes_2012"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_EntityBased",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Support Vector Machines"
          ],
          "connections": [
            "Mention Pair Scoring",
            "Clustering"
          ],
          "mechanisms": [
            "Correlational Clustering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Prediction"
          ],
          "parameter_tuning": [
            "Loss-Based Margin"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fletcher1985_ArithmeticStrategies",
      "label": "Arithmetic Strategies",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fletcher1985_ArithmeticStrategies",
        "entity_id": "Fletcher1985_ArithmeticStrategies",
        "name": "Arithmetic Strategies",
        "title": "",
        "year": "1985",
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "[\"Construct higher-level schemata\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Set schemata",
            "Higher-level schemata"
          ],
          "connections": [
            "Add new schemata to STM",
            "Fill slots of schemata"
          ],
          "mechanisms": [
            "Request set schemata",
            "Complete higher-level schemata"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Set schemata"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fletcher1985_MeaningPostulates",
      "label": "Meaning Postulates",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fletcher1985_MeaningPostulates",
        "entity_id": "Fletcher1985_MeaningPostulates",
        "name": "Meaning Postulates",
        "title": "",
        "year": "1985",
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "[\"Understanding and solving arithmetic word problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Conditions",
            "Actions"
          ],
          "connections": [
            "Triggered by propositions",
            "Modify short-term memory"
          ],
          "mechanisms": [
            "Add propositions to text base",
            "Add information to problem model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Propositional representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fletcher1985_ProblemSolvingProcedures",
      "label": "Problem Solving Procedures",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fletcher1985_ProblemSolvingProcedures",
        "entity_id": "Fletcher1985_ProblemSolvingProcedures",
        "name": "Problem Solving Procedures",
        "title": "",
        "year": "1985",
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "[\"Derive solutions\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Operations on mental blocks",
            "Conversion of schemata"
          ],
          "connections": [
            "Perform operations on STM",
            "Convert one schema to another"
          ],
          "mechanisms": [
            "Adding or deleting blocks",
            "Counting blocks",
            "Matching blocks"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Higher-level schemata"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fletcher1985_WORDPRO",
      "label": "WORDPRO",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fletcher1985_WORDPRO",
        "entity_id": "Fletcher1985_WORDPRO",
        "name": "WORDPRO",
        "title": "Understanding and solving arithmetic word problems: A computer simulation",
        "year": "1985",
        "authors": [
          "Charles R. Fletcher"
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Production rules",
            "Set schema",
            "Transfer schema",
            "Superset schema",
            "More-than/Less-than schema"
          ],
          "connections": [
            "STM (Short-Term Memory)",
            "LTM (Long-Term Memory)"
          ],
          "mechanisms": [
            "Meaning postulates",
            "Arithmetic strategies",
            "Problem-solving procedures"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Simulating third-grade children's problem-solving processes"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Propositional representation",
          "Bilevel representation (text base and problem model)"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fletcher1985_WORDPRO_Expansion",
      "label": "WORDPRO Expansion",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fletcher1985_WORDPRO_Expansion",
        "entity_id": "Fletcher1985_WORDPRO_Expansion",
        "name": "WORDPRO Expansion",
        "title": "",
        "year": "1985",
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Transfer Schema",
            "Superset Schema",
            "Comparison Schema"
          ],
          "connections": [
            "Meaning Postulates",
            "Arithmetic Strategies",
            "Problem-Solving Procedures"
          ],
          "mechanisms": [
            "Production Rules",
            "STM and LTM Interaction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Expanding Problem Domain",
            "Adapting to Different Ability Levels",
            "Interfacing with Parser"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Surface Representation Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fletcher1986_WORDPRO",
      "label": "WORDPRO",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fletcher1986_WORDPRO",
        "entity_id": "Fletcher1986_WORDPRO",
        "name": "WORDPRO",
        "title": "",
        "year": "1986",
        "authors": [
          "Fletcher, C. R."
        ],
        "task": "[\"理解并解决简单的算术文字题\"]",
        "dataset": [
          "自定义算术问题数据集"
        ],
        "metrics": [
          "正确率"
        ],
        "architecture": {
          "components": [
            "生产规则系统",
            "短时记忆模块",
            "长时记忆模块"
          ],
          "connections": [
            "生产规则触发机制",
            "短时记忆与长时记忆交互"
          ],
          "mechanisms": [
            "命题表示",
            "双层表示模型",
            "核心ference解析"
          ]
        },
        "methodology": {
          "training_strategy": [
            "基于Kintsch和Greeno的理论进行实现"
          ],
          "parameter_tuning": [
            "无特定参数调整"
          ]
        },
        "feature_processing": [
          "命题分析",
          "核心ference解析"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fleuriot2001_GeometryTheoremProving",
      "label": "Geometry Theorem Proving",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fleuriot2001_GeometryTheoremProving",
        "entity_id": "Fleuriot2001_GeometryTheoremProving",
        "name": "Geometry Theorem Proving",
        "title": "",
        "year": "2001",
        "authors": [
          "Fleuriot, J."
        ],
        "task": "[\"Geometry Theorem Proving\"]",
        "dataset": [
          "HighSchoolTextbooks_1959"
        ],
        "metrics": [
          "Accuracy_GeometryTheoremProving"
        ],
        "architecture": {
          "components": [
            "Formalization in Isabelle",
            "Heuristic Knowledge"
          ],
          "connections": [
            "Backward Chaining Search Strategy",
            "Forward Chaining"
          ],
          "mechanisms": [
            "Diagram Accompanying Statements"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Search Strategies",
            "Heuristic Knowledge"
          ],
          "parameter_tuning": [
            "Specific Heuristic Built into the Machine"
          ]
        },
        "feature_processing": [
          "Diagram Accompanying Statements"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Forbus1980_MD_PV",
      "label": "MD/PV Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Forbus1980_MD_PV",
        "entity_id": "Forbus1980_MD_PV",
        "name": "MD/PV Model",
        "title": "Spatial and qualitative aspects of reasoning about motion",
        "year": "1980",
        "authors": [
          "Kenneth D. Forbus"
        ],
        "task": "[\"Spatial Reasoning\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Metric Diagram",
            "Place Vocabulary"
          ],
          "connections": [
            "MD to PV"
          ],
          "mechanisms": [
            "Query-based Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Spatial relation extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Forbus1993_LTRE",
      "label": "LTRE",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Forbus1993_LTRE",
        "entity_id": "Forbus1993_LTRE",
        "name": "LTRE",
        "title": "",
        "year": "1993",
        "authors": [
          "Forbus, K. D.",
          "de Kleer, J."
        ],
        "task": "[\"Rule-based Reasoning\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Logic-based Truth Maintenance System",
            "Rule Engine"
          ],
          "connections": [],
          "mechanisms": [
            "Application of rules",
            "Maintenance of truth values"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None (not a learning algorithm)"
          ],
          "parameter_tuning": [
            "None (not a learning algorithm)"
          ]
        },
        "feature_processing": [
          "Logical rule application"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Freund1998_AveragedPerceptron",
      "label": "Averaged Perceptron",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Freund1998_AveragedPerceptron",
        "entity_id": "Freund1998_AveragedPerceptron",
        "name": "Averaged Perceptron",
        "title": "",
        "year": "1998",
        "authors": [
          "Freund, Y.",
          "Schapire, R.E."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function"
          ],
          "connections": [],
          "mechanisms": [
            "Online Learning",
            "Weight Averaging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Pairwise Coreference Scoring"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fukui2016_Multimodal_Compact_Bilinear_Pooling",
      "label": "Multimodal Compact Bilinear Pooling",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fukui2016_Multimodal_Compact_Bilinear_Pooling",
        "entity_id": "Fukui2016_Multimodal_Compact_Bilinear_Pooling",
        "name": "Multimodal Compact Bilinear Pooling",
        "title": "",
        "year": "2016",
        "authors": [
          "Akira Fukui",
          "Dhruv Batra",
          "Devi Parikh",
          "Trevor Darrell",
          "Marcus Rohrbach"
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "VQA_v2.0"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "bilinear pooling"
          ],
          "connections": [
            "attended image features",
            "language features"
          ],
          "mechanisms": [
            "fully-connected layer"
          ]
        },
        "methodology": {
          "training_strategy": [
            "re-training on balanced dataset"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image features from ResNet",
          "question features from LSTM"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Fukui2016_MultimodalCompactBilinearPooling",
      "label": "Multimodal Compact Bilinear Pooling",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Fukui2016_MultimodalCompactBilinearPooling",
        "entity_id": "Fukui2016_MultimodalCompactBilinearPooling",
        "name": "Multimodal Compact Bilinear Pooling",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": "2016",
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Multimodal compact bilinear pooling"
          ],
          "connections": [
            "Image features",
            "Language features"
          ],
          "mechanisms": [
            "Fully-connected layer"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Furukawa2003_AccurateLineSegmentExtraction",
      "label": "Accurate Line Segment Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Furukawa2003_AccurateLineSegmentExtraction",
        "entity_id": "Furukawa2003_AccurateLineSegmentExtraction",
        "name": "Accurate Line Segment Extraction",
        "title": "Accurate and robust line segment extraction by analyzing distribution around peaks in Hough space",
        "year": "2003",
        "authors": [
          "Y. Furukawa",
          "Y. Shinagawa"
        ],
        "task": "[\"Line Segment Extraction\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Accumulator Array",
            "Edge Points"
          ],
          "connections": [
            "Edge Points -> Accumulator Array"
          ],
          "mechanisms": [
            "Peak Detection",
            "Distribution Analysis"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Steps dθ and dρ"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Garg2011_TemporalRestrictedBoltzmannMachine",
      "label": "Temporal Restricted Boltzmann Machine",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Garg2011_TemporalRestrictedBoltzmannMachine",
        "entity_id": "Garg2011_TemporalRestrictedBoltzmannMachine",
        "name": "Temporal Restricted Boltzmann Machine",
        "title": "",
        "year": "2011",
        "authors": [
          "Garg, N.",
          "Henderson, J."
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Restricted Boltzmann Machine"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Gehring2017_ConvolutionalSEQ2SEQ",
      "label": "ConvS2S",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Gehring2017_ConvolutionalSEQ2SEQ",
        "entity_id": "Gehring2017_ConvolutionalSEQ2SEQ",
        "name": "ConvS2S",
        "title": "",
        "year": "2017",
        "authors": [
          "Jonas Gehring",
          "Michael Auli",
          "David Grangier",
          "Denis Yarats",
          "Yann N Dauphin"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Convolutional Layers",
            "Gate Linear Units"
          ],
          "connections": [
            "Encoder-Decoder"
          ],
          "mechanisms": [
            "Convolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Early Stopping",
            "Learning Rate Annealing"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden Size"
          ]
        },
        "feature_processing": [
          "Significant Number Identification",
          "Number Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Gehring2017_ConvS2S",
      "label": "ConvS2S",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Gehring2017_ConvS2S",
        "entity_id": "Gehring2017_ConvS2S",
        "name": "ConvS2S",
        "title": "",
        "year": "2017",
        "authors": [
          "Jonas Gehring",
          "Michael Auli",
          "David Grangier",
          "Denis Yarats",
          "Yann N Dauphin"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Convolutional Encoder",
            "Convolutional Decoder",
            "Gate Linear Units"
          ],
          "connections": [
            "Convolutional Layers"
          ],
          "mechanisms": [
            "Gated Linear Units"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Four-layer encoder",
            "Three-layer decoder",
            "Early stopping",
            "Learning rate annealing"
          ],
          "parameter_tuning": [
            "Max-epochs 100",
            "Kernel width 3",
            "Hidden size 256"
          ]
        },
        "feature_processing": [
          "Number Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Gelernter1959_GeometryMachine",
      "label": "Geometry Machine",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Gelernter1959_GeometryMachine",
        "entity_id": "Gelernter1959_GeometryMachine",
        "name": "Geometry Machine",
        "title": "",
        "year": "1959",
        "authors": [
          "Gelernter, H."
        ],
        "task": "[\"几何定理证明\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Heuristic Knowledge",
            "Backward Chaining Search Strategy"
          ],
          "connections": [
            "Diagram-based Heuristic",
            "Search Strategy"
          ],
          "mechanisms": [
            "Diagram-based Rejection of False Goals"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backward Chaining"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Diagram Analysis"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_EasyFirstNonDirectionalDependencyParser",
      "label": "Easy-First Non-Directional Dependency Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_EasyFirstNonDirectionalDependencyParser",
        "entity_id": "Goldberg2010_EasyFirstNonDirectionalDependencyParser",
        "name": "Easy-First Non-Directional Dependency Parsing",
        "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing",
        "year": "2010",
        "authors": [
          "Goldberg, Yoav",
          "Elhadad, Michael"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "WSJ Treebank_2010",
          "CoNLL 2007 English dataset_2007"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Root_Classification",
          "Complete_Classification"
        ],
        "architecture": {
          "components": [
            "ATTACHLEFT",
            "ATTACHRIGHT",
            "Perceptron"
          ],
          "connections": [
            "score(ACTION(i))",
            "edgeFor(best)"
          ],
          "mechanisms": [
            "best-first",
            "greedy",
            "non-directional"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron"
          ],
          "parameter_tuning": [
            "weight vector w~"
          ]
        },
        "feature_processing": [
          "binary valued features",
          "POS tags",
          "head word form",
          "left-most and right-most child POS tags",
          "structural features",
          "unigram features",
          "bigram features",
          "pp-attachment features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
      "label": "Easy-First Non-Directional Dependency Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
        "entity_id": "Goldberg2010_EasyFirstNonDirectionalDependencyParsing",
        "name": "Easy-First Non-Directional Dependency Parsing",
        "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing",
        "year": "2010",
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "WSJ Treebank",
          "CoNLL 2007 English test set"
        ],
        "metrics": [
          "Accuracy",
          "Root",
          "Complete"
        ],
        "architecture": {
          "components": [
            "ATTACHLEFT",
            "ATTACHRIGHT"
          ],
          "connections": [
            "Dependency edges"
          ],
          "mechanisms": [
            "Non-directional parsing",
            "Best-first parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured perceptron"
          ],
          "parameter_tuning": [
            "Feature representation",
            "Weight vector updates"
          ]
        },
        "feature_processing": [
          "POS tagging",
          "Feature templates"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_EasyFirstNonDirectionalParser",
      "label": "Easy-First Non-Directional Dependency Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_EasyFirstNonDirectionalParser",
        "entity_id": "Goldberg2010_EasyFirstNonDirectionalParser",
        "name": "Easy-First Non-Directional Dependency Parsing",
        "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing",
        "year": "2010",
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [],
        "metrics": [
          "Accuracy",
          "Root",
          "Complete"
        ],
        "architecture": {
          "components": [
            "ATTACHLEFT",
            "ATTACHRIGHT"
          ],
          "connections": [
            "Dependency Edges"
          ],
          "mechanisms": [
            "Score Function",
            "Feature Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "POS Tagging",
          "Feature Templates"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_FeatureRepresentation",
      "label": "Feature Representation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_FeatureRepresentation",
        "entity_id": "Goldberg2010_FeatureRepresentation",
        "name": "Feature Representation",
        "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing",
        "year": "2010",
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Unlabeled_Accuracy",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Structural Features",
            "Unigram Features",
            "Bigram Features",
            "PP-Attachment Features"
          ],
          "connections": [
            "Action Features",
            "Sentence Context",
            "Partial Structures"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Score Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron Training"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Binary Valued Features",
          "POS Tagging",
          "Head Word Form",
          "Left-Most and Right-Most Child POS Tags"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_GraphBasedParsing",
      "label": "Graph-based Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_GraphBasedParsing",
        "entity_id": "Goldberg2010_GraphBasedParsing",
        "name": "Graph-based Parsing",
        "title": "",
        "year": "2010",
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Global optimization",
            "Exhaustive search"
          ],
          "connections": [
            "Edge scoring",
            "Tree construction"
          ],
          "mechanisms": [
            "First-order models",
            "Higher-order models"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Feature selection",
            "Model complexity control"
          ]
        },
        "feature_processing": [
          "Edge-based features",
          "Tree-based features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_HeapBasedArgmax",
      "label": "Heap-Based Argmax Computation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_HeapBasedArgmax",
        "entity_id": "Goldberg2010_HeapBasedArgmax",
        "name": "Heap-Based Argmax Computation",
        "title": "",
        "year": "2010",
        "authors": [
          "Goldberg, Y.",
          "Elhadad, M."
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Unlabeled_Accuracy",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Heap Data Structure"
          ],
          "connections": [
            "Heap for argmax computation"
          ],
          "mechanisms": [
            "Efficient argmax computation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron Training"
          ],
          "parameter_tuning": [
            "Heap size"
          ]
        },
        "feature_processing": [
          "Feature scores"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_NonDirectionalParsing",
      "label": "Non-directional Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_NonDirectionalParsing",
        "entity_id": "Goldberg2010_NonDirectionalParsing",
        "name": "Non-directional Parsing",
        "title": "",
        "year": "2010",
        "authors": [
          "Goldberg, Yoav",
          "Elhadad, Michael"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "ATTACHLEFT",
            "ATTACHRIGHT"
          ],
          "connections": [
            "pi, pi+1"
          ],
          "mechanisms": [
            "score(ACTION(i))",
            "edgeFor(best)",
            "pending"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "weight vector w~",
            "feature representation φ"
          ]
        },
        "feature_processing": [
          "Binary valued features",
          "POS tags",
          "Head word forms",
          "Left-most and right-most child POS tags"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_OptimizedFeatureExtraction",
      "label": "Optimized Feature Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_OptimizedFeatureExtraction",
        "entity_id": "Goldberg2010_OptimizedFeatureExtraction",
        "name": "Optimized Feature Extraction",
        "title": "",
        "year": "2010",
        "authors": [
          "Goldberg, Y.",
          "Elhadad, M."
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Unlabeled_Accuracy",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Heap",
            "Feature Extraction Module"
          ],
          "connections": [
            "Heap for argmax computation",
            "Feature extraction for each action/location pair"
          ],
          "mechanisms": [
            "Reuse of extracted features",
            "Heap-based optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron Training"
          ],
          "parameter_tuning": [
            "Window size for feature extraction"
          ]
        },
        "feature_processing": [
          "Local context features",
          "Syntactic structure features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_StructuredPerceptronTraining",
      "label": "Structured Perceptron Training",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_StructuredPerceptronTraining",
        "entity_id": "Goldberg2010_StructuredPerceptronTraining",
        "name": "Structured Perceptron Training",
        "title": "",
        "year": "2010",
        "authors": [
          "Goldberg, Yoav",
          "Elhadad, Michael"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "argmax",
            "score(act(i))",
            "edgeFor(act(i))"
          ],
          "connections": [
            "choice",
            "good",
            "w~"
          ],
          "mechanisms": [
            "isValid(action, Gold, Arcs)",
            "parameter updates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "weight vector w~",
            "feature representation φ"
          ]
        },
        "feature_processing": [
          "Binary valued features",
          "POS tags",
          "Head word forms",
          "Left-most and right-most child POS tags"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldberg2010_TransitionBasedParsing",
      "label": "Transition-based Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldberg2010_TransitionBasedParsing",
        "entity_id": "Goldberg2010_TransitionBasedParsing",
        "name": "Transition-based Parsing",
        "title": "",
        "year": "2010",
        "authors": [
          "Yoav Goldberg",
          "Michael Elhadad"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "WSJ_Treebank_2010",
          "CoNLL_2007_English_test_set_2010"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Root_Prediction",
          "Complete_Correct_Parses"
        ],
        "architecture": {
          "components": [
            "Shift-reduce framework",
            "Left-to-right processing"
          ],
          "connections": [
            "Word-by-word traversal",
            "Local decision-making"
          ],
          "mechanisms": [
            "Feature extraction from left context",
            "Limited lookahead"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Feature engineering"
          ]
        },
        "feature_processing": [
          "POS tagging",
          "Syntactic structure analysis"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2013_NECO",
      "label": "NECO",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2013_NECO",
        "entity_id": "Goldwasser2013_NECO",
        "name": "NECO",
        "title": "Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves",
        "year": "2013",
        "authors": [
          "Hajishirzi, H.",
          "Zilles, L.",
          "Weld, D.S.",
          "Zettlemoyer, L."
        ],
        "task": "[\"Coreference Resolution\", \"Named-Entity Linking\"]",
        "dataset": [],
        "metrics": [
          "MUC Coreference Error",
          "NEL Error"
        ],
        "architecture": {
          "components": [
            "Deterministic Coreference System",
            "Wikipedia Linking"
          ],
          "connections": [
            "NEL-informed Mention-Merging Sieves"
          ],
          "mechanisms": [
            "Improved Mention-Detection",
            "Context Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint Training"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_ApproximatedStructuralUpdate",
      "label": "Approximated Structural Update",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_ApproximatedStructuralUpdate",
        "entity_id": "Goldwasser2014_ApproximatedStructuralUpdate",
        "name": "Approximated Structural Update",
        "title": "",
        "year": "2014",
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector",
            "Confidence Score"
          ],
          "connections": [
            "Input Sentence",
            "Logical Formula"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Weight Update",
            "Confidence Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Incremental Learning",
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Weight Vector",
            "Confidence Score"
          ]
        },
        "feature_processing": [
          "Lexical Information",
          "Syntactic Patterns"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_BinaryPerceptron",
      "label": "Binary Perceptron",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_BinaryPerceptron",
        "entity_id": "Goldwasser2014_BinaryPerceptron",
        "name": "Binary Perceptron",
        "title": "Learning from Natural Instructions",
        "year": "2014",
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Feature Representation"
          ],
          "mechanisms": [
            "Binary Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-Driven Updates"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_CombinedFeedbackPerceptron",
      "label": "Combined Feedback Perceptron",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_CombinedFeedbackPerceptron",
        "entity_id": "Goldwasser2014_CombinedFeedbackPerceptron",
        "name": "Combined Feedback Perceptron",
        "title": "",
        "year": "2014",
        "authors": [
          "Dan Goldwasser",
          "Dan Roth"
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary Perceptron",
            "Structured Perceptron"
          ],
          "connections": [
            "Combines binary and structured updates"
          ],
          "mechanisms": [
            "Loss Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative training with feedback"
          ],
          "parameter_tuning": [
            "Weight updates based on feedback"
          ]
        },
        "feature_processing": [
          "Lexical and syntactic features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_CombPercept_w_AprxLoss",
      "label": "CombPercept w AprxLoss",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_CombPercept_w_AprxLoss",
        "entity_id": "Goldwasser2014_CombPercept_w_AprxLoss",
        "name": "CombPercept w AprxLoss",
        "title": "",
        "year": "2014",
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "Geoquery_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary Update",
            "Structural Update",
            "Loss Approximation"
          ],
          "connections": [
            "Binary Update -> Loss Approximation",
            "Structural Update -> Loss Approximation"
          ],
          "mechanisms": [
            "Loss Approximation",
            "Feature Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-driven Updates"
          ],
          "parameter_tuning": [
            "Weight Vector Adjustment"
          ]
        },
        "feature_processing": [
          "Lexical Similarity",
          "Syntactic Information"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_IntegerLinearProgramming",
      "label": "Integer Linear Programming (ILP)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_IntegerLinearProgramming",
        "entity_id": "Goldwasser2014_IntegerLinearProgramming",
        "name": "Integer Linear Programming (ILP)",
        "title": "",
        "year": "2014",
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Decision Variables",
            "Objective Function",
            "Constraints"
          ],
          "connections": [
            "Feature Functions",
            "Flow Constraints"
          ],
          "mechanisms": [
            "Optimization",
            "Constraint Satisfaction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Learning",
            "Feedback-driven Learning"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features",
          "Dependency Tree Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_LearningFromNaturalInstructions",
      "label": "Learning from Natural Instructions",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_LearningFromNaturalInstructions",
        "entity_id": "Goldwasser2014_LearningFromNaturalInstructions",
        "name": "Learning from Natural Instructions",
        "title": "Learning from natural instructions",
        "year": "2014",
        "authors": [
          "Dan Goldwasser",
          "Dan Roth"
        ],
        "task": "[\"Interpreting Natural Language Instructions\"]",
        "dataset": [
          "Freecell Solitaire Card Game",
          "Geoquery"
        ],
        "metrics": [
          "Accuracy_AnswerExtraction"
        ],
        "architecture": {
          "components": [
            "semantic interpreter",
            "response-driven learning framework"
          ],
          "connections": [
            "instruction interpretation",
            "game rule classification"
          ],
          "mechanisms": [
            "integer linear programming",
            "feedback function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "response-driven learning",
            "binary feedback"
          ],
          "parameter_tuning": [
            "weight vector updates"
          ]
        },
        "feature_processing": [
          "lexical and syntactic features",
          "compositional decision features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_LossApproximation",
      "label": "Loss Approximation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_LossApproximation",
        "entity_id": "Goldwasser2014_LossApproximation",
        "name": "Loss Approximation",
        "title": "Learning from Natural Instructions",
        "year": "2014",
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Feature Representation"
          ],
          "mechanisms": [
            "Loss Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-Driven Updates"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_SimpleBinaryUpdate",
      "label": "Simple Binary Update",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_SimpleBinaryUpdate",
        "entity_id": "Goldwasser2014_SimpleBinaryUpdate",
        "name": "Simple Binary Update",
        "title": "",
        "year": "2014",
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Input Sentence",
            "Logical Formula"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Weight Demotion"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Binary Classification",
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Weight Vector"
          ]
        },
        "feature_processing": [
          "Lexical Information",
          "Syntactic Patterns"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_StructuredPerceptron",
      "label": "Structured Perceptron",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_StructuredPerceptron",
        "entity_id": "Goldwasser2014_StructuredPerceptron",
        "name": "Structured Perceptron",
        "title": "Learning from Natural Instructions",
        "year": "2014",
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Feature Representation"
          ],
          "mechanisms": [
            "Structured Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Error-Driven Updates"
          ],
          "parameter_tuning": [
            "Weight Vector Updates"
          ]
        },
        "feature_processing": [
          "Lexical Mapping",
          "Syntactic Information"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goldwasser2014_StructuredUpdate",
      "label": "Structured Update",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goldwasser2014_StructuredUpdate",
        "entity_id": "Goldwasser2014_StructuredUpdate",
        "name": "Structured Update",
        "title": "",
        "year": "2014",
        "authors": [
          "Goldwasser, D.",
          "Roth, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "Geoquery_2014",
          "SolitaireCardGame_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Weight Vector"
          ],
          "connections": [
            "Input Sentence",
            "Logical Formula"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Weight Update"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Incremental Learning",
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Weight Vector"
          ]
        },
        "feature_processing": [
          "Lexical Information",
          "Syntactic Patterns"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goyal2016_DeepLSTM",
      "label": "Deeper LSTM Question + norm Image",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goyal2016_DeepLSTM",
        "entity_id": "Goyal2016_DeepLSTM",
        "name": "Deeper LSTM Question + norm Image",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": "2016",
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "CNN embedding",
            "LSTM embedding",
            "Point-wise multiplication",
            "Multi-layer perceptron classifier"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goyal2017_Counter_example_explanation_model",
      "label": "Counter-example Explanation Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goyal2017_Counter_example_explanation_model",
        "entity_id": "Goyal2017_Counter_example_explanation_model",
        "name": "Counter-example Explanation Model",
        "title": "",
        "year": "2017",
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Recall_at_5"
        ],
        "architecture": {
          "components": [
            "Shared Base",
            "Answering Head",
            "Explaining Head"
          ],
          "connections": [
            "Joint QI Embedding",
            "Fully Connected Layer",
            "Softmax",
            "Inner Product"
          ],
          "mechanisms": [
            "Point-wise Multiplication",
            "Pairwise Hinge Ranking Loss",
            "Cross-Entropy Loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Pairwise Hinge Ranking Loss"
          ],
          "parameter_tuning": [
            "Hyperparameter M",
            "Trade-off Weight Parameter λ"
          ]
        },
        "feature_processing": [
          "Image CNN Embedding",
          "Question LSTM Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goyal2017_Deep_LSTM_Question_plus_norm_Image",
      "label": "Deeper LSTM Question+ norm Image",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goyal2017_Deep_LSTM_Question_plus_norm_Image",
        "entity_id": "Goyal2017_Deep_LSTM_Question_plus_norm_Image",
        "name": "Deeper LSTM Question+ norm Image",
        "title": "",
        "year": "2017",
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "VQA_Accuracy"
        ],
        "architecture": {
          "components": [
            "CNN embedding",
            "LSTM embedding",
            "point-wise multiplication",
            "multi-layer perceptron classifier"
          ],
          "connections": [
            "image embedding -> point-wise multiplication",
            "question embedding -> point-wise multiplication",
            "point-wise multiplication -> MLP classifier"
          ],
          "mechanisms": [
            "embedding fusion",
            "classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "CNN feature extraction",
          "LSTM sequence modeling"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goyal2017_Hierarchical_Co_attention",
      "label": "Hierarchical Co-attention",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goyal2017_Hierarchical_Co_attention",
        "entity_id": "Goyal2017_Hierarchical_Co_attention",
        "name": "Hierarchical Co-attention",
        "title": "",
        "year": "2017",
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "VQA_Accuracy"
        ],
        "architecture": {
          "components": [
            "word-level co-attention",
            "phrase-level co-attention",
            "question-level co-attention"
          ],
          "connections": [
            "word-level -> phrase-level",
            "phrase-level -> question-level",
            "co-attention -> answer prediction"
          ],
          "mechanisms": [
            "multi-level co-attention",
            "answer prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image feature extraction",
          "question feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goyal2017_Language_only",
      "label": "Language-only",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goyal2017_Language_only",
        "entity_id": "Goyal2017_Language_only",
        "name": "Language-only",
        "title": "",
        "year": "2017",
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "VQA_Accuracy"
        ],
        "architecture": {
          "components": [
            "LSTM embedding",
            "multi-layer perceptron classifier"
          ],
          "connections": [
            "question embedding -> MLP classifier"
          ],
          "mechanisms": [
            "language modeling",
            "classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "LSTM sequence modeling"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goyal2017_Multimodal_Compact_Bilinear_Pooling",
      "label": "Multimodal Compact Bilinear Pooling",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goyal2017_Multimodal_Compact_Bilinear_Pooling",
        "entity_id": "Goyal2017_Multimodal_Compact_Bilinear_Pooling",
        "name": "Multimodal Compact Bilinear Pooling",
        "title": "",
        "year": "2017",
        "authors": [
          "Goyal, Y.",
          "Khot, T.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "VQA_v2.0_2017"
        ],
        "metrics": [
          "VQA_Accuracy"
        ],
        "architecture": {
          "components": [
            "multimodal compact bilinear pooling",
            "fully-connected layer"
          ],
          "connections": [
            "image features -> bilinear pooling",
            "language features -> bilinear pooling",
            "bilinear pooling -> fully-connected layer"
          ],
          "mechanisms": [
            "bilinear pooling",
            "answer prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "supervised learning"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image feature extraction",
          "language feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Goyal2017_VQA_LSTM_CNN",
      "label": "Deeper LSTM Question + norm Image",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Goyal2017_VQA_LSTM_CNN",
        "entity_id": "Goyal2017_VQA_LSTM_CNN",
        "name": "Deeper LSTM Question + norm Image",
        "title": "",
        "year": "2017",
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "VQA_v2.0"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "LSTM",
            "CNN"
          ],
          "connections": [
            "point-wise multiplication"
          ],
          "mechanisms": [
            "multi-layer perceptron classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "re-training on balanced dataset"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image features from VGGNet",
          "question features from LSTM"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Griffiths1965_BottomUpParser",
      "label": "Bottom-Up Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Griffiths1965_BottomUpParser",
        "entity_id": "Griffiths1965_BottomUpParser",
        "name": "Bottom-Up Parser",
        "title": "",
        "year": "1965",
        "authors": [
          "Griffiths, T.",
          "Petrick, S."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "Propositional Calculus Grammar",
          "GRE Grammar",
          "NSE Grammar"
        ],
        "metrics": [
          "Primitive Operations Count"
        ],
        "architecture": {
          "components": [
            "Shift-Reduce"
          ],
          "connections": [
            "LR Parsing"
          ],
          "mechanisms": [
            "Deterministic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Shift-Reduce"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "None"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Griffiths1965_SelectiveBottomUpParser",
      "label": "Selective Bottom-Up Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Griffiths1965_SelectiveBottomUpParser",
        "entity_id": "Griffiths1965_SelectiveBottomUpParser",
        "name": "Selective Bottom-Up Parser",
        "title": "",
        "year": "1965",
        "authors": [
          "Griffiths, T.",
          "Petrick, S."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "Propositional Calculus Grammar",
          "GRE Grammar",
          "NSE Grammar"
        ],
        "metrics": [
          "Primitive Operations Count"
        ],
        "architecture": {
          "components": [
            "Selective Shift-Reduce"
          ],
          "connections": [
            "Selective LR Parsing"
          ],
          "mechanisms": [
            "Selective Deterministic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Selective Shift-Reduce"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "None"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Griffiths1965_SelectiveTopDownParser",
      "label": "Selective Top-Down Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Griffiths1965_SelectiveTopDownParser",
        "entity_id": "Griffiths1965_SelectiveTopDownParser",
        "name": "Selective Top-Down Parser",
        "title": "",
        "year": "1965",
        "authors": [
          "Griffiths, T.",
          "Petrick, S."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "Propositional Calculus Grammar",
          "GRE Grammar",
          "NSE Grammar"
        ],
        "metrics": [
          "Primitive Operations Count"
        ],
        "architecture": {
          "components": [
            "Selective Backtracking"
          ],
          "connections": [
            "Selective Recursive Descent"
          ],
          "mechanisms": [
            "Selective Predictive Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Selective Backtracking"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "None"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Griffiths1965_TopDownParser",
      "label": "Top-Down Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Griffiths1965_TopDownParser",
        "entity_id": "Griffiths1965_TopDownParser",
        "name": "Top-Down Parser",
        "title": "",
        "year": "1965",
        "authors": [
          "Griffiths, T.",
          "Petrick, S."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "Propositional Calculus Grammar",
          "GRE Grammar",
          "NSE Grammar"
        ],
        "metrics": [
          "Primitive Operations Count"
        ],
        "architecture": {
          "components": [
            "Backtracking"
          ],
          "connections": [
            "Recursive Descent"
          ],
          "mechanisms": [
            "Predictive Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backtracking"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "None"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Gulwani2011_GeometryConstructionsSynthesizer",
      "label": "Geometry Constructions Synthesizer",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Gulwani2011_GeometryConstructionsSynthesizer",
        "entity_id": "Gulwani2011_GeometryConstructionsSynthesizer",
        "name": "Geometry Constructions Synthesizer",
        "title": "",
        "year": "2011",
        "authors": [
          "Gulwani, S.",
          "Korthikanti, V. A.",
          "Tiwari, A."
        ],
        "task": "[\"Geometry Construction Synthesis\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_AgreementConstraints",
      "label": "Agreement Constraints",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_AgreementConstraints",
        "entity_id": "Haghighi2009_AgreementConstraints",
        "name": "Agreement Constraints",
        "title": "",
        "year": "2009",
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Number Feature Assignment",
            "NER Labeling"
          ],
          "mechanisms": [
            "Person, Number, and Entity Type Agreement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_AppositiveConstraint",
      "label": "Appositive Constraint",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_AppositiveConstraint",
        "entity_id": "Haghighi2009_AppositiveConstraint",
        "name": "Appositive Constraint",
        "title": "",
        "year": "2009",
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Appositive Annotation",
            "Coreference Constraint"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_DeterministicCoreference",
      "label": "Deterministic Coreference Resolution",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_DeterministicCoreference",
        "entity_id": "Haghighi2009_DeterministicCoreference",
        "name": "Deterministic Coreference Resolution",
        "title": "",
        "year": "2009",
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module",
            "Selection Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists",
            "Tree Distance Minimization"
          ],
          "mechanisms": [
            "Syntactic Constraints",
            "Semantic Compatibility",
            "Deterministic Decision Making"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning",
            "Treebank Parsing"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_PredicateNominativeConstraint",
      "label": "Predicate Nominative Constraint",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_PredicateNominativeConstraint",
        "entity_id": "Haghighi2009_PredicateNominativeConstraint",
        "name": "Predicate Nominative Constraint",
        "title": "",
        "year": "2009",
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Predicate Nominative Annotation",
            "Coreference Constraint"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_SemanticComponent",
      "label": "Semantic Component",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_SemanticComponent",
        "entity_id": "Haghighi2009_SemanticComponent",
        "name": "Semantic Component",
        "title": "",
        "year": "2009",
        "authors": [
          "Haghighi, A.",
          "Klein, D."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Semantic Head Matching",
            "Transductive Learning"
          ],
          "connections": [
            "Syntactic Patterns",
            "Wikipedia Articles"
          ],
          "mechanisms": [
            "Bootstrapping",
            "Syntactic Patterns"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Transductive Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Semantic Head Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_SemanticKnowledgeExtraction",
      "label": "Semantic Knowledge Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_SemanticKnowledgeExtraction",
        "entity_id": "Haghighi2009_SemanticKnowledgeExtraction",
        "name": "Semantic Knowledge Extraction",
        "title": "",
        "year": "2009",
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "BLIPP",
          "WIKI"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Tree Fragments Extraction",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Bootstrapping Technique",
            "Coreference Patterns"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_SimpleCoreferenceResolution",
      "label": "Simple Coreference Resolution",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_SimpleCoreferenceResolution",
        "entity_id": "Haghighi2009_SimpleCoreferenceResolution",
        "name": "Simple Coreference Resolution",
        "title": "Simple Coreference Resolution with Rich Syntactic and Semantic Features",
        "year": "2009",
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST",
          "BLIPP",
          "WIKI"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module",
            "Selection Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists Extraction",
            "Tree Distance Minimization"
          ],
          "mechanisms": [
            "Syntactic Constraints",
            "Semantic Compatibility Filtering",
            "Selection of Closest Compatible Mention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning",
            "Deterministic Function of Rich Features"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Lists Extraction",
          "Appositive Annotation",
          "Predicate Nominative Annotation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_SyntacticConfigurationConstraints",
      "label": "Syntactic Configuration Constraints",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_SyntacticConfigurationConstraints",
        "entity_id": "Haghighi2009_SyntacticConfigurationConstraints",
        "name": "Syntactic Configuration Constraints",
        "title": "",
        "year": "2009",
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Appositive Annotation",
            "i-within-i Constraint"
          ],
          "mechanisms": [
            "NP Appositive Annotation",
            "Role Appositives"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_SyntacticSalience",
      "label": "Syntactic Salience",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_SyntacticSalience",
        "entity_id": "Haghighi2009_SyntacticSalience",
        "name": "Syntactic Salience",
        "title": "",
        "year": "2009",
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module"
          ],
          "connections": [
            "Syntactic Paths",
            "Compatibility Lists"
          ],
          "mechanisms": [
            "Tree Distance Minimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Haghighi2009_SyntacticSemanticCoreference",
      "label": "Syntactic and Semantic Coreference Resolution",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Haghighi2009_SyntacticSemanticCoreference",
        "entity_id": "Haghighi2009_SyntacticSemanticCoreference",
        "name": "Syntactic and Semantic Coreference Resolution",
        "title": "",
        "year": "2009",
        "authors": [
          "Aria Haghighi",
          "Dan Klein"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC-6-TEST"
        ],
        "metrics": [
          "Pairwise F1",
          "b3",
          "MUC",
          "CEAF"
        ],
        "architecture": {
          "components": [
            "Syntactic Module",
            "Semantic Module",
            "Selection Module"
          ],
          "connections": [
            "Syntactic Paths Extraction",
            "Compatibility Lists Extraction",
            "Tree Distance Minimization"
          ],
          "mechanisms": [
            "Deterministic Syntactic Constraints",
            "Semantic Compatibility Filtering",
            "Closest Mention Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning from Unlabeled Corpus"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Compatibility Mining"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hajishirzi2013_ExactNELsieve",
      "label": "Exact NEL sieve",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hajishirzi2013_ExactNELsieve",
        "entity_id": "Hajishirzi2013_ExactNELsieve",
        "name": "Exact NEL sieve",
        "title": "",
        "year": "2013",
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": "[\"Coreference resolution and named-entity linking\"]",
        "dataset": [
          "ACE2004_NWIRE_2004",
          "CONLL2011_2011"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "Pairwise_Coreference",
          "F1_NEL"
        ],
        "architecture": {
          "components": [
            "Entity links",
            "Wikipedia pages"
          ],
          "connections": [
            "Mention merging",
            "Cluster merging"
          ],
          "mechanisms": [
            "Link matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic rules",
            "NEL constraints"
          ],
          "parameter_tuning": [
            "Confidence thresholds"
          ]
        },
        "feature_processing": [
          "Exact link assignment"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hajishirzi2013_NECO",
      "label": "NECO",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hajishirzi2013_NECO",
        "entity_id": "Hajishirzi2013_NECO",
        "name": "NECO",
        "title": "Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves",
        "year": "2013",
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": "[\"Coreference Resolution and Named-Entity Linking\"]",
        "dataset": [
          "ACE2004-NWIRE",
          "CoNLL2011"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "PairwiseF1_Coreference",
          "F1_NamedEntityLinking"
        ],
        "architecture": {
          "components": [
            "Stanford Sieve Model",
            "NEL-informed sieves",
            "GLOW",
            "WikipediaMiner"
          ],
          "connections": [
            "mention detection",
            "cluster merging",
            "NEL constraints"
          ],
          "mechanisms": [
            "mention pruning",
            "attribute propagation",
            "exact and head entity links"
          ]
        },
        "methodology": {
          "training_strategy": [
            "multi-pass sieves",
            "automatic mention detection",
            "joint error reduction"
          ],
          "parameter_tuning": [
            "confidence thresholds for NEL systems"
          ]
        },
        "feature_processing": [
          "mention attributes from Freebase and Wikipedia",
          "fine-grained attributes",
          "coarse attributes"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hajishirzi2013_NECO_GoldNEL",
      "label": "NECO with Gold NEL",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hajishirzi2013_NECO_GoldNEL",
        "entity_id": "Hajishirzi2013_NECO_GoldNEL",
        "name": "NECO with Gold NEL",
        "title": "",
        "year": "2013",
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": "[\"Coreference Resolution and Named-Entity Linking\"]",
        "dataset": [
          "ACE2004_NWIRE_2004"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "Pairwise_Coreference"
        ],
        "architecture": {
          "components": [
            "Stanford Sieve Model",
            "NEL Constraints",
            "Mention Detection",
            "Mention Attributes"
          ],
          "connections": [
            "Mention Detection -> NEL Constraints -> Cluster Merging"
          ],
          "mechanisms": [
            "Gold Linking",
            "Fine-grained Attributes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gold Standard Annotations"
          ],
          "parameter_tuning": [
            "High Confidence Links"
          ]
        },
        "feature_processing": [
          "Gold Linking",
          "Fine-grained Attributes"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hajishirzi2013_RelaxedNELsieve",
      "label": "Relaxed NEL sieve",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hajishirzi2013_RelaxedNELsieve",
        "entity_id": "Hajishirzi2013_RelaxedNELsieve",
        "name": "Relaxed NEL sieve",
        "title": "",
        "year": "2013",
        "authors": [
          "Hannaneh Hajishirzi",
          "Leila Zilles",
          "Daniel S. Weld",
          "Luke Zettlemoyer"
        ],
        "task": "[\"Coreference resolution and named-entity linking\"]",
        "dataset": [
          "ACE2004_NWIRE_2004",
          "CONLL2011_2011"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "Pairwise_Coreference",
          "F1_NEL"
        ],
        "architecture": {
          "components": [
            "Fine-grained attributes",
            "Freebase notable types",
            "Wikipedia categories"
          ],
          "connections": [
            "Mention merging",
            "Cluster merging"
          ],
          "mechanisms": [
            "Attribute comparison",
            "Entity linking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic rules",
            "NEL constraints"
          ],
          "parameter_tuning": [
            "Confidence thresholds"
          ]
        },
        "feature_processing": [
          "Fine-grained attribute extraction",
          "Head link assignment"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hall2012_FactoredParser",
      "label": "Factored Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hall2012_FactoredParser",
        "entity_id": "Hall2012_FactoredParser",
        "name": "Factored Parser",
        "title": "",
        "year": "2012",
        "authors": [
          "Hall, D.",
          "Klein, D."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Annotation Schemes",
            "Factorization"
          ],
          "connections": [
            "Combined Annotations"
          ],
          "mechanisms": [
            "Joint Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Expectation Propagation"
          ],
          "parameter_tuning": [
            "Factor Parameters"
          ]
        },
        "feature_processing": [
          "Syntactic and Semantic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Henderson2003_NeuralNetworkProbabilityEstimation",
      "label": "Neural Network Probability Estimation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Henderson2003_NeuralNetworkProbabilityEstimation",
        "entity_id": "Henderson2003_NeuralNetworkProbabilityEstimation",
        "name": "Neural Network Probability Estimation",
        "title": "",
        "year": "2003",
        "authors": [
          "Henderson, J."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Neural Networks",
            "Probability Estimation"
          ],
          "connections": [
            "Parsing Decisions"
          ],
          "mechanisms": [
            "Left-Corner Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": [
            "Network Weights"
          ]
        },
        "feature_processing": [
          "Parsing History"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Henderson2004_SynchronyNetworkParser",
      "label": "Synchrony Network Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Henderson2004_SynchronyNetworkParser",
        "entity_id": "Henderson2004_SynchronyNetworkParser",
        "name": "Synchrony Network Parser",
        "title": "",
        "year": "2004",
        "authors": [
          "Henderson, J."
        ],
        "task": "[\"Constituency Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Neural Network"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hermann2014_MultilingualDistributedRepresentations",
      "label": "Multilingual Distributed Representations Without Word Alignment",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hermann2014_MultilingualDistributedRepresentations",
        "entity_id": "Hermann2014_MultilingualDistributedRepresentations",
        "name": "Multilingual Distributed Representations Without Word Alignment",
        "title": "",
        "year": "2014",
        "authors": [
          "K. M. Hermann",
          "P. Blunsom"
        ],
        "task": "[\"Multilingual Representation Learning\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Feedforward Networks"
          ],
          "connections": [
            "Input Sentence to Feedforward Network"
          ],
          "mechanisms": [
            "Distributed Representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hernandez2017_ComputerModelsIntelligenceTest",
      "label": "Computer Models for Intelligence Test",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hernandez2017_ComputerModelsIntelligenceTest",
        "entity_id": "Hernandez2017_ComputerModelsIntelligenceTest",
        "name": "Computer Models for Intelligence Test",
        "title": "",
        "year": "2017",
        "authors": [
          "Hernández-Orallo, J.",
          "Martínez-Plumed, F.",
          "Schmid, U.",
          "Siebers, M.",
          "Dowe, D. L."
        ],
        "task": "[\"Solving intelligence test problems\"]",
        "dataset": [
          "Intelligence test problems"
        ],
        "metrics": [
          "Progress and implications"
        ],
        "architecture": {
          "components": [
            "Computer models"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Progress and implications"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Hernandez2017_IQTestModels",
      "label": "IQ Test Models",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hernandez2017_IQTestModels",
        "entity_id": "Hernandez2017_IQTestModels",
        "name": "IQ Test Models",
        "title": "",
        "year": "2017",
        "authors": [
          "Hernández-Orallo, J.",
          "Martínez-Plumed, F.",
          "Schmid, U.",
          "Siebers, M.",
          "Dowe, D. L."
        ],
        "task": "[\"Solving IQ test problems\"]",
        "dataset": [
          "Various IQ test datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Computer models"
          ],
          "connections": [
            "Intelligence test problem solving"
          ],
          "mechanisms": [
            "Progress and implications"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Model training"
          ],
          "parameter_tuning": [
            "Hyperparameter tuning"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Hilbert1899_AxiomaticGeometry",
      "label": "Axiomatic Geometry",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hilbert1899_AxiomaticGeometry",
        "entity_id": "Hilbert1899_AxiomaticGeometry",
        "name": "Axiomatic Geometry",
        "title": "",
        "year": "1899",
        "authors": [
          "Hilbert, D."
        ],
        "task": "[\"Geometry Theorem Proving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Formalization of axioms"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "No geometric intuition required"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_AdaptiveSequenceChunker",
      "label": "Adaptive Sequence Chunker",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_AdaptiveSequenceChunker",
        "entity_id": "Hochreiter1997_AdaptiveSequenceChunker",
        "name": "Adaptive Sequence Chunker",
        "title": "",
        "year": "1997",
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "[\"Sequence modeling\"]",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Hierarchical chunker systems"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Sequential network construction"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_BackPropagationThroughTime",
      "label": "Back-Propagation Through Time (BPTT)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_BackPropagationThroughTime",
        "entity_id": "Hochreiter1997_BackPropagationThroughTime",
        "name": "Back-Propagation Through Time (BPTT)",
        "title": "",
        "year": "1997",
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "[\"Sequence modeling\"]",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Recurrent neural networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_ConstantErrorCarrousel",
      "label": "Constant Error Carrousel (CEC)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_ConstantErrorCarrousel",
        "entity_id": "Hochreiter1997_ConstantErrorCarrousel",
        "name": "Constant Error Carrousel (CEC)",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Long-term memory storage\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Linear unit",
            "Fixed self-connection"
          ],
          "connections": [
            "Self-connection"
          ],
          "mechanisms": [
            "Constant error flow"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_ConstantErrorFlow",
      "label": "Constant Error Flow",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_ConstantErrorFlow",
        "entity_id": "Hochreiter1997_ConstantErrorFlow",
        "name": "Constant Error Flow",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Long-term memory maintenance\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Single unit",
            "Self-connection"
          ],
          "connections": [
            "Single connection to itself"
          ],
          "mechanisms": [
            "Constant error flow"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Avoid vanishing error signals"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_ElmanNets",
      "label": "Elman Nets",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_ElmanNets",
        "entity_id": "Hochreiter1997_ElmanNets",
        "name": "Elman Nets",
        "title": "",
        "year": "1997",
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "[\"Sequence modeling\"]",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Recurrent neural networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Elman's training procedure"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_FocusedRecurrentBackprop",
      "label": "Focused Recurrent Backpropagation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_FocusedRecurrentBackprop",
        "entity_id": "Hochreiter1997_FocusedRecurrentBackprop",
        "name": "Focused Recurrent Backpropagation",
        "title": "",
        "year": "1997",
        "authors": [
          "Mozer, M. C."
        ],
        "task": "[\"Temporal Sequence Recognition\"]",
        "dataset": [
          "EmbeddedReberGrammar_1997"
        ],
        "metrics": [
          "ErrorRate_Classification",
          "SuccessRate_Classification"
        ],
        "architecture": {
          "components": [
            "Hidden Units",
            "Output Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Truncated Backpropagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Local Input/Output Representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_InputWeightConflict",
      "label": "Input Weight Conflict",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_InputWeightConflict",
        "entity_id": "Hochreiter1997_InputWeightConflict",
        "name": "Input Weight Conflict",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Long-term memory maintenance\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Single unit",
            "Self-connection",
            "Additional input weight"
          ],
          "connections": [
            "Single connection to itself",
            "Connection to additional input"
          ],
          "mechanisms": [
            "Input weight conflict"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Address conflicting weight update signals"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_LongShortTermMemory",
      "label": "Long Short-Term Memory (LSTM)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_LongShortTermMemory",
        "entity_id": "Hochreiter1997_LongShortTermMemory",
        "name": "Long Short-Term Memory (LSTM)",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Sequence Modeling\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Memory Cell",
            "Input Gate",
            "Forget Gate",
            "Output Gate"
          ],
          "connections": [
            "Recurrent Connections"
          ],
          "mechanisms": [
            "Adaptive Information Flow Control"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_MemoryCellBlock",
      "label": "Memory Cell Block",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_MemoryCellBlock",
        "entity_id": "Hochreiter1997_MemoryCellBlock",
        "name": "Memory Cell Block",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Information storage\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Memory cells",
            "Input gate",
            "Output gate"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Protecting memory contents from perturbation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_MultiplicativeGateUnits",
      "label": "Multiplicative Gate Units",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_MultiplicativeGateUnits",
        "entity_id": "Hochreiter1997_MultiplicativeGateUnits",
        "name": "Multiplicative Gate Units",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Controlling access to constant error flow\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Input gate",
            "Output gate"
          ],
          "connections": [
            "Connections to memory cells"
          ],
          "mechanisms": [
            "Opening and closing access to CEC"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient-based learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_NaiveConstantErrorFlow",
      "label": "Naive Constant Error Flow",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_NaiveConstantErrorFlow",
        "entity_id": "Hochreiter1997_NaiveConstantErrorFlow",
        "name": "Naive Constant Error Flow",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Long-term memory maintenance\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Single unit",
            "Self-connection"
          ],
          "connections": [
            "Single connection to itself"
          ],
          "mechanisms": [
            "Naive constant error flow"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Avoid vanishing error signals"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_NeuralSequenceChunker",
      "label": "Neural Sequence Chunker",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_NeuralSequenceChunker",
        "entity_id": "Hochreiter1997_NeuralSequenceChunker",
        "name": "Neural Sequence Chunker",
        "title": "",
        "year": "1997",
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "[\"Sequence modeling\"]",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Two interconnected networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Chunking"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_OutputGateBias",
      "label": "Output Gate Bias Initialization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_OutputGateBias",
        "entity_id": "Hochreiter1997_OutputGateBias",
        "name": "Output Gate Bias Initialization",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Long Time Lag Problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Output Gates"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Negative Initial Bias"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Initial Bias Values"
          ]
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_OutputWeightConflict",
      "label": "Output Weight Conflict",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_OutputWeightConflict",
        "entity_id": "Hochreiter1997_OutputWeightConflict",
        "name": "Output Weight Conflict",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Long-term memory maintenance\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Single unit",
            "Self-connection",
            "Additional output weight"
          ],
          "connections": [
            "Single connection to itself",
            "Connection to additional output"
          ],
          "mechanisms": [
            "Output weight conflict"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Address conflicting weight update signals"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_RealTimeRecurrentLearning",
      "label": "Real-Time Recurrent Learning (RTRL)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_RealTimeRecurrentLearning",
        "entity_id": "Hochreiter1997_RealTimeRecurrentLearning",
        "name": "Real-Time Recurrent Learning (RTRL)",
        "title": "",
        "year": "1997",
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "[\"Sequence modeling\"]",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Recurrent neural networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Real-time learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_RecurrentCascadeCorrelation",
      "label": "Recurrent Cascade-Correlation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_RecurrentCascadeCorrelation",
        "entity_id": "Hochreiter1997_RecurrentCascadeCorrelation",
        "name": "Recurrent Cascade-Correlation",
        "title": "",
        "year": "1997",
        "authors": [
          "Sepp Hochreiter",
          "Jürgen Schmidhuber"
        ],
        "task": "[\"Sequence modeling\"]",
        "dataset": [],
        "metrics": [
          "Error rate"
        ],
        "architecture": {
          "components": [
            "Recurrent neural networks"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Gradient-based learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cascade correlation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_SequentialNetworkConstruction",
      "label": "Sequential Network Construction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_SequentialNetworkConstruction",
        "entity_id": "Hochreiter1997_SequentialNetworkConstruction",
        "name": "Sequential Network Construction",
        "title": "",
        "year": "1997",
        "authors": [
          "Fahlman, S. E."
        ],
        "task": "[\"Long Time Lag Problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Memory Cells",
            "Gate Units"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Incremental Addition of Units"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_StateDriftRemedies",
      "label": "State Drift Remedies",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_StateDriftRemedies",
        "entity_id": "Hochreiter1997_StateDriftRemedies",
        "name": "State Drift Remedies",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Long Time Lag Problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Input Gates"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Zero-Biased Input Gates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Input Gate Bias"
          ]
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hochreiter1997_TemporalOrderProblem",
      "label": "Temporal Order Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hochreiter1997_TemporalOrderProblem",
        "entity_id": "Hochreiter1997_TemporalOrderProblem",
        "name": "Temporal Order Problem Solver",
        "title": "",
        "year": "1997",
        "authors": [
          "Hochreiter, S.",
          "Schmidhuber, J."
        ],
        "task": "[\"Extracting information conveyed by temporal order\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Memory cells",
            "Input gates",
            "Output gates"
          ],
          "connections": [
            "Fully connected hidden layer"
          ],
          "mechanisms": [
            "Storing relevant inputs"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Truncated backpropagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hodosh2016_Focused_Evaluation",
      "label": "Focused Evaluation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hodosh2016_Focused_Evaluation",
        "entity_id": "Hodosh2016_Focused_Evaluation",
        "name": "Focused Evaluation",
        "title": "",
        "year": "2016",
        "authors": [
          "Hodosh, M.",
          "Hockenmaier, J."
        ],
        "task": "[\"Image Captioning\"]",
        "dataset": [
          "ImageNet_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "binary forced-choice task"
          ],
          "connections": [
            "image caption pairs"
          ],
          "mechanisms": [
            "nearest neighbor selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "human annotation"
          ],
          "parameter_tuning": [
            "none"
          ]
        },
        "feature_processing": [
          "image features",
          "caption features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hosseini2014_ARIS",
      "label": "ARIS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hosseini2014_ARIS",
        "entity_id": "Hosseini2014_ARIS",
        "name": "ARIS",
        "title": "",
        "year": "2014",
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [
          "MA1_2014",
          "IXL_2014",
          "MA2_2014"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Entities",
            "Containers",
            "Attributes",
            "Quantities",
            "State transitions"
          ],
          "connections": [
            "Dependency parser",
            "Coreference resolution"
          ],
          "mechanisms": [
            "Verb categorization",
            "State progression",
            "Equation generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-validation",
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Verb categories",
            "Feature extraction"
          ]
        },
        "feature_processing": [
          "Stanford dependency parser",
          "Named entity recognizer",
          "Coreference resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hosseini2014_ARIS_Variant",
      "label": "ARIS Variant",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hosseini2014_ARIS_Variant",
        "entity_id": "Hosseini2014_ARIS_Variant",
        "name": "ARIS Variant",
        "title": "",
        "year": "2014",
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": "[\"Solving Arithmetic Word Problems\"]",
        "dataset": [
          "MA1",
          "IXL",
          "MA2"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Verb Category Classifier",
            "State Transition Model"
          ],
          "connections": [
            "Verb Category Classification -> State Transition"
          ],
          "mechanisms": [
            "Verb Categorization",
            "State Progression"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Verb Category Classification",
            "State Transition Learning"
          ],
          "parameter_tuning": [
            "SVM Parameters",
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Coreference Resolution",
          "Named Entity Recognition"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hosseini2014_ARIS2",
      "label": "ARIS2",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hosseini2014_ARIS2",
        "entity_id": "Hosseini2014_ARIS2",
        "name": "ARIS2",
        "title": "",
        "year": "2014",
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "MA1_2014",
          "IXL_2014",
          "MA2_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "Verb_Categorization_Accuracy"
        ],
        "architecture": {
          "components": [
            "Entity Recognition",
            "Container Identification",
            "Verb Category Classification"
          ],
          "connections": [
            "Dependency Parsing",
            "Coreference Resolution"
          ],
          "mechanisms": [
            "State Transition Model",
            "Verb Category Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "No repeated verbs in training and test sets"
          ],
          "parameter_tuning": [
            "Support Vector Machines",
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Similarity-based Features",
          "WordNet-based Features",
          "Structural Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hosseini2014_StateTransitionModel",
      "label": "State Transition Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hosseini2014_StateTransitionModel",
        "entity_id": "Hosseini2014_StateTransitionModel",
        "name": "State Transition Model",
        "title": "",
        "year": "2014",
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "MA1_2014",
          "IXL_2014",
          "MA2_2014"
        ],
        "metrics": [
          "Verb_Categorization_Accuracy",
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Entities",
            "Containers",
            "Attributes",
            "Quantities",
            "Relations"
          ],
          "connections": [
            "State Transitions",
            "Algebraic Operations"
          ],
          "mechanisms": [
            "Observation",
            "Positive/Negative Updates",
            "Transfers",
            "Construction/Destruction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Verb Category Classification"
          ],
          "parameter_tuning": [
            "Support Vector Machines",
            "Feature Extraction"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Named Entity Recognition",
          "Coreference Resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hosseini2014_VerbCategorization",
      "label": "Verb Categorization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hosseini2014_VerbCategorization",
        "entity_id": "Hosseini2014_VerbCategorization",
        "name": "Verb Categorization",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": "2014",
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": "[\"Solving Arithmetic Word Problems\"]",
        "dataset": [
          "ADDSUB_2014"
        ],
        "metrics": [
          "Accuracy_AnswerExtraction"
        ],
        "architecture": {
          "components": [
            "Verb Categories",
            "Semantic Parsing"
          ],
          "connections": [
            "Entity and Container Relationships"
          ],
          "mechanisms": [
            "Addition and Subtraction Operations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Verb Category Rules"
          ]
        },
        "feature_processing": [
          "Verb Extraction",
          "Entity Identification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hosseini2014_VerbCategorizationSolver",
      "label": "Verb Categorization Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hosseini2014_VerbCategorizationSolver",
        "entity_id": "Hosseini2014_VerbCategorizationSolver",
        "name": "Verb Categorization Solver",
        "title": "",
        "year": "2014",
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Verb categorization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hosseini2014_VerbCategoryBasedSolver",
      "label": "Verb Category Based Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hosseini2014_VerbCategoryBasedSolver",
        "entity_id": "Hosseini2014_VerbCategoryBasedSolver",
        "name": "Verb Category Based Solver",
        "title": "",
        "year": "2014",
        "authors": [
          "M. J. Hosseini",
          "H. Hajishirzi",
          "O. Etzioni",
          "N. Kushman"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Verb Categorization",
            "Addition/Subtraction Operations"
          ],
          "connections": [
            "Dependency Parsing",
            "Verb Classification"
          ],
          "mechanisms": [
            "Feature Extraction from Text"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Verb Category Labels"
          ]
        },
        "feature_processing": [
          "Verb Categorization Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hosseini2014_VerbCategoryClassifier",
      "label": "Verb Category Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hosseini2014_VerbCategoryClassifier",
        "entity_id": "Hosseini2014_VerbCategoryClassifier",
        "name": "Verb Category Classifier",
        "title": "",
        "year": "2014",
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "MA1_2014",
          "IXL_2014",
          "MA2_2014"
        ],
        "metrics": [
          "Verb_Categorization_Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature Extractor",
            "Support Vector Machine (SVM)"
          ],
          "connections": [
            "Feature Extractor -> SVM"
          ],
          "mechanisms": [
            "Verb Category Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-validation"
          ],
          "parameter_tuning": [
            "Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Similarity-based Features",
          "WordNet-based Features",
          "Structural Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Hosseini2014_VerbCategoryLearning",
      "label": "Verb Category Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Hosseini2014_VerbCategoryLearning",
        "entity_id": "Hosseini2014_VerbCategoryLearning",
        "name": "Verb Category Learning",
        "title": "",
        "year": "2014",
        "authors": [
          "Hosseini, M. J.",
          "Hajishirzi, H.",
          "Etzioni, O.",
          "Kushman, N."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Verb Categorization",
            "Learning Model"
          ],
          "connections": [
            "Verb Categories -> Equation Templates"
          ],
          "mechanisms": [
            "Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Verb Category Parameters"
          ]
        },
        "feature_processing": [
          "Verb Category Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2012_ImprovedWordRepresentations",
      "label": "Improved Word Representations",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2012_ImprovedWordRepresentations",
        "entity_id": "Huang2012_ImprovedWordRepresentations",
        "name": "Improved Word Representations",
        "title": "",
        "year": "2012",
        "authors": [
          "Huang, E.H.",
          "Socher, R.",
          "Manning, C.D.",
          "Ng, A.Y."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Global Context",
            "Multiple Word Prototypes"
          ],
          "connections": [
            "Hierarchical Clustering"
          ],
          "mechanisms": [
            "Contextual Information"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "Number of Senses"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2012_MultiSenseModel",
      "label": "Multi-Sense Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2012_MultiSenseModel",
        "entity_id": "Huang2012_MultiSenseModel",
        "name": "Multi-Sense Model",
        "title": "",
        "year": "2012",
        "authors": [
          "Huang, E.H.",
          "Socher, R.",
          "Manning, C.D.",
          "Ng, A.Y."
        ],
        "task": "[\"Verbal Comprehension Questions\"]",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2012_MultiSenseWordEmbedding",
      "label": "Multi-Sense Word Embedding",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2012_MultiSenseWordEmbedding",
        "entity_id": "Huang2012_MultiSenseWordEmbedding",
        "name": "Multi-Sense Word Embedding",
        "title": "Improving Word Representations via Global Context and Multiple Word Prototypes",
        "year": "2012",
        "authors": [
          "Eric H Huang",
          "Richard Socher",
          "Christopher D Manning",
          "Andrew Y Ng"
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_AnswerExtractionRankingSVM",
      "label": "Answer Extraction Ranking SVM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_AnswerExtractionRankingSVM",
        "entity_id": "Huang2016_AnswerExtractionRankingSVM",
        "name": "Answer Extraction Ranking SVM",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": "2016",
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "[\"Automatic Answer Extraction\"]",
        "dataset": [
          "YahooAnswers_MathPosts_2016"
        ],
        "metrics": [
          "Precision_AnswerExtraction",
          "Recall_AnswerExtraction"
        ],
        "architecture": {
          "components": [
            "Ranking SVM"
          ],
          "connections": [
            "Feature extraction from answer text",
            "Conditional probability calculation"
          ],
          "mechanisms": [
            "Maximizing margin between correct and incorrect instances"
          ]
        },
        "methodology": {
          "training_strategy": [
            "5-fold cross-validation"
          ],
          "parameter_tuning": [
            "Parameter vector ν"
          ]
        },
        "feature_processing": [
          "Local context features",
          "Global features",
          "Number value features",
          "Number set features",
          "Dimension features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_EquationExtractionAlgorithm",
      "label": "Equation Extraction Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_EquationExtractionAlgorithm",
        "entity_id": "Huang2016_EquationExtractionAlgorithm",
        "name": "Equation Extraction Algorithm",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": "2016",
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "[\"Automatic Equation Annotation\"]",
        "dataset": [
          "YahooAnswers_MathPosts_2016"
        ],
        "metrics": [
          "Precision_EquationExtraction",
          "Recall_EquationExtraction"
        ],
        "architecture": {
          "components": [
            "Candidate extraction",
            "Solution voting"
          ],
          "connections": [
            "Regular expression matching",
            "Equation system construction",
            "Solution verification"
          ],
          "mechanisms": [
            "Reducing duplicate equations",
            "Selecting equation system with maximum degree"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not explicitly mentioned"
          ],
          "parameter_tuning": [
            "Not explicitly mentioned"
          ]
        },
        "feature_processing": [
          "Regular expression matching",
          "Solution verification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_EquationExtractor",
      "label": "Equation Extractor",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_EquationExtractor",
        "entity_id": "Huang2016_EquationExtractor",
        "name": "Equation Extractor",
        "title": "",
        "year": "2016",
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "[\"Equation Extraction\"]",
        "dataset": [
          "Yahoo_Answers_2008"
        ],
        "metrics": [
          "Precision_EquationExtraction",
          "Recall_EquationExtraction"
        ],
        "architecture": {
          "components": [
            "Candidate Extraction",
            "Solution Voting"
          ],
          "connections": [
            "Candidate Equations to Solution Voting"
          ],
          "mechanisms": [
            "Regular Expression Matching",
            "Equation Induction Check",
            "Solution Bipartite Graph"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross Validation"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Equation Matching",
          "Solution Verification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_LargeScaleDataset",
      "label": "Ranking SVM Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_LargeScaleDataset",
        "entity_id": "Huang2016_LargeScaleDataset",
        "name": "Ranking SVM Model",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": "2016",
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.Y.",
          "Yin, J.",
          "Ma, W.Y."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Ranking SVM"
          ],
          "connections": [
            "Equation System Extraction"
          ],
          "mechanisms": [
            "Gold Answer Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_LargeScaleDatasetConstruction",
      "label": "Large-Scale Dataset Construction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_LargeScaleDatasetConstruction",
        "entity_id": "Huang2016_LargeScaleDatasetConstruction",
        "name": "Large-Scale Dataset Construction",
        "title": "",
        "year": "2016",
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Data Collection",
            "Preprocessing",
            "Answer Extraction",
            "Equation Extraction"
          ],
          "connections": [
            "Yahoo! Answers -> Preprocessing -> Answer Extraction -> Equation Extraction"
          ],
          "mechanisms": [
            "Ranking SVM",
            "Logistic Regression Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Semi-automatic Extraction"
          ],
          "parameter_tuning": [
            "Threshold Setting for Confidence Score"
          ]
        },
        "feature_processing": [
          "TF-IDF",
          "Weighted Jaccard Similarity",
          "Regular Expression Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_MathDQN",
      "label": "MathDQN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_MathDQN",
        "entity_id": "Huang2016_MathDQN",
        "name": "MathDQN",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": "2016",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Average Precision"
        ],
        "architecture": {
          "components": [
            "Deep Q-Network",
            "Feed-Forward Neural Network"
          ],
          "connections": [
            "State-Action Mapping"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Reward Function Design"
          ]
        },
        "feature_processing": [
          "State Representation",
          "Action Selection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_RankingSVM",
      "label": "Ranking SVM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_RankingSVM",
        "entity_id": "Huang2016_RankingSVM",
        "name": "Ranking SVM",
        "title": "",
        "year": "2016",
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.Y.",
          "Yin, J.",
          "Ma, W.Y."
        ],
        "task": "[\"自动数学应用题求解\"]",
        "dataset": [
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_AnswerExtraction"
        ],
        "architecture": {
          "components": [
            "特征提取模块",
            "SVM分类器"
          ],
          "connections": [
            "特征向量输入到SVM分类器"
          ],
          "mechanisms": [
            "特征向量计算",
            "SVM训练与预测"
          ]
        },
        "methodology": {
          "training_strategy": [
            "使用交叉验证进行模型训练"
          ],
          "parameter_tuning": [
            "调整正则化参数C"
          ]
        },
        "feature_processing": [
          "TF-IDF特征提取",
          "词频统计"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_RankingSVMForAnswerExtraction",
      "label": "Ranking SVM for Answer Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_RankingSVMForAnswerExtraction",
        "entity_id": "Huang2016_RankingSVMForAnswerExtraction",
        "name": "Ranking SVM for Answer Extraction",
        "title": "",
        "year": "2016",
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "[\"Answer Extraction\"]",
        "dataset": [
          "Yahoo_Answers_2008"
        ],
        "metrics": [
          "Accuracy_AnswerExtraction",
          "Precision_AnswerExtraction",
          "Recall_AnswerExtraction"
        ],
        "architecture": {
          "components": [
            "Feature Extraction",
            "Ranking SVM"
          ],
          "connections": [
            "Feature Vector to Ranking SVM"
          ],
          "mechanisms": [
            "Conditional Probability Calculation",
            "Quadratic Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross Validation"
          ],
          "parameter_tuning": [
            "Regularization Parameter C"
          ]
        },
        "feature_processing": [
          "Local Context Features",
          "Global Features",
          "Number Value Features",
          "Number Set Features",
          "Dimension Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_SIM",
      "label": "SIM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_SIM",
        "entity_id": "Huang2016_SIM",
        "name": "SIM",
        "title": "",
        "year": "2016",
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.Y.",
          "Yin, J.",
          "Ma, W.Y."
        ],
        "task": "[\"自动解数学文字题\"]",
        "dataset": [
          "Alg514",
          "SingleEQ",
          "Dolphin18K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "TF-IDF向量",
            "加权Jaccard相似性"
          ],
          "connections": [
            "问题句子与训练集问题的相似性计算"
          ],
          "mechanisms": [
            "模板选择",
            "模板槽填充"
          ]
        },
        "methodology": {
          "training_strategy": [
            "基于相似性的匹配"
          ],
          "parameter_tuning": [
            "无"
          ]
        },
        "feature_processing": [
          "TF-IDF向量化"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_SimpleSimilarityBasedMethod",
      "label": "SIM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_SimpleSimilarityBasedMethod",
        "entity_id": "Huang2016_SimpleSimilarityBasedMethod",
        "name": "SIM",
        "title": "",
        "year": "2016",
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.Y.",
          "Yin, J.",
          "Ma, W.Y."
        ],
        "task": "[\"自动求解数学文字题\"]",
        "dataset": [
          "Alg514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "词汇相似性计算",
            "模板选择",
            "模板槽填充"
          ],
          "connections": [
            "问题句子到模板映射"
          ],
          "mechanisms": [
            "基于相似性的方法"
          ]
        },
        "methodology": {
          "training_strategy": [
            "加权Jaccard相似性计算"
          ],
          "parameter_tuning": [
            "TF-IDF分数向量"
          ]
        },
        "feature_processing": [
          "问题句子建模"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2016_Solver",
      "label": "Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_Solver",
        "entity_id": "Huang2016_Solver",
        "name": "Solver",
        "title": "How Well Do Computers Solve Math Word Problems?",
        "year": "2016",
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin",
          "Wei-Ying Ma"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Ranking SVM model"
          ],
          "connections": [
            "Answer extraction"
          ],
          "mechanisms": [
            "Gold answers extraction",
            "Equation systems extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Logistic regression classifier"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Post classification",
          "Problem cleaning",
          "Gold answers extraction",
          "Equation systems extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2017_CASS",
      "label": "CASS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2017_CASS",
        "entity_id": "Huang2017_CASS",
        "name": "CASS",
        "title": "",
        "year": "2018",
        "authors": [
          "Huang, D.",
          "Liu, J.",
          "Lin, C.",
          "Yin, J."
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "Dolphin18K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Copy Mechanism",
            "Alignment Mechanism"
          ],
          "connections": [
            "Input Sequence",
            "Output Sequence"
          ],
          "mechanisms": [
            "Reinforcement Learning",
            "Policy Gradient"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Policy Gradient Parameters"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Quantity Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Huang2017_FeatureBasedModel",
      "label": "Feature-Based Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2017_FeatureBasedModel",
        "entity_id": "Huang2017_FeatureBasedModel",
        "name": "Feature-Based Model",
        "title": "Learning Fine-Grained Expressions to Solve Math Word Problems",
        "year": "2017",
        "authors": [
          "Danqing Huang",
          "Shuming Shi",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Retrieval",
            "Equation Ranking"
          ],
          "connections": [
            "Feature Vectors"
          ],
          "mechanisms": [
            "Ranking Algorithms"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Engineering"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2017_FGExpression",
      "label": "FG-Expression",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2017_FGExpression",
        "entity_id": "Huang2017_FGExpression",
        "name": "FG-Expression",
        "title": "",
        "year": "2017",
        "authors": [
          "D. Huang",
          "S. Shi",
          "J. Yin",
          "C.-Y. Lin"
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Template Fragment Parsing",
            "Fine-Grained Units"
          ],
          "connections": [
            "Textual Information to Template Fragments"
          ],
          "mechanisms": [
            "Feature Selection",
            "Ranking Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Template Fragment Parameters"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features",
          "Dependency Paths"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Huang2017_FineGrainedExpressions",
      "label": "Fine-Grained Expressions",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2017_FineGrainedExpressions",
        "entity_id": "Huang2017_FineGrainedExpressions",
        "name": "Fine-Grained Expressions",
        "title": "",
        "year": "2017",
        "authors": [
          "D. Huang",
          "S. Shi",
          "J. Yin",
          "C.-Y. Lin"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Dolphin18K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Fragment",
            "Semantic Parser"
          ],
          "connections": [
            "Textual Information to Template Fragments"
          ],
          "mechanisms": [
            "Fine-Grained Units"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Parameter Optimization"
          ]
        },
        "feature_processing": [
          "Feature Selection",
          "Context Feature"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Huang2017_FineGrainedInference",
      "label": "Fine-Grained Inference",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2017_FineGrainedInference",
        "entity_id": "Huang2017_FineGrainedInference",
        "name": "Fine-Grained Inference",
        "title": "",
        "year": "2017",
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Representation",
            "Fine-Grained Inference"
          ],
          "connections": [
            "Mapping Sentences to Grounded Equations"
          ],
          "mechanisms": [
            "Deep Learning",
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Q-Network"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Dependency Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Huang2017_NeuralMathWordProblemSolver",
      "label": "Neural Math Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2017_NeuralMathWordProblemSolver",
        "entity_id": "Huang2017_NeuralMathWordProblemSolver",
        "name": "Neural Math Word Problem Solver",
        "title": "",
        "year": "2017",
        "authors": [
          "D. Huang",
          "J. Liu",
          "C. Lin",
          "J. Yin"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Dolphin18K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network",
            "Reinforcement Learning"
          ],
          "connections": [
            "Policy Gradient"
          ],
          "mechanisms": [
            "Copy Mechanism",
            "Alignment Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Policy Gradient"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Dependency Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Huang2018_CASS",
      "label": "CASS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2018_CASS",
        "entity_id": "Huang2018_CASS",
        "name": "CASS",
        "title": "Neural Math Word Problem Solver with Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Danqing Huang",
          "Jing Liu",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": "[\"Solving Math Word Problems\"]",
        "dataset": [
          "Alg514_2014",
          "NumWord_2015",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_AnswerExtraction",
          "BLEU_Score_Translation"
        ],
        "architecture": {
          "components": [
            "Sequence-to-Sequence Model",
            "Copy Mechanism",
            "Alignment Mechanism"
          ],
          "connections": [
            "Encoder-Decoder",
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Reinforcement Learning",
            "Policy Gradient"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation",
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Beam Size",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Copy Mechanism",
          "Alignment Mechanism"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2018_FeatureBasedModel",
      "label": "Feature-Based Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2018_FeatureBasedModel",
        "entity_id": "Huang2018_FeatureBasedModel",
        "name": "Feature-Based Model",
        "title": "",
        "year": "2018",
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.-Y.",
          "Yin, J."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Retrieval",
            "Equation Ranking"
          ],
          "connections": [
            "Feature Vector Creation",
            "Learning to Rank"
          ],
          "mechanisms": [
            "Candidate Template Derivation",
            "Number Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Template Matching",
          "Equation Generation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2018_HybridModel",
      "label": "Hybrid Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2018_HybridModel",
        "entity_id": "Huang2018_HybridModel",
        "name": "Hybrid Model",
        "title": "",
        "year": "2018",
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.-Y.",
          "Yin, J."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Neural Model",
            "Feature-Based Model"
          ],
          "connections": [
            "Neural Template Feature",
            "Neural Answer Feature"
          ],
          "mechanisms": [
            "Model Combination",
            "Feature Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Neural Output Incorporation",
          "Feature-Based Model Enhancement"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2018_PolicyGradient",
      "label": "Policy Gradient",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2018_PolicyGradient",
        "entity_id": "Huang2018_PolicyGradient",
        "name": "Policy Gradient",
        "title": "",
        "year": "2018",
        "authors": [
          "Danqing Huang",
          "Jing Liu",
          "Chin-Yew Lin",
          "Jian Yin"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Policy Network",
            "Reward Function"
          ],
          "connections": [
            "Input: Math Problem Description",
            "Output: Equation Tokens"
          ],
          "mechanisms": [
            "REINFORCE Algorithm",
            "Policy Gradient Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pre-training with MLE",
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Beam Size for Sampling"
          ]
        },
        "feature_processing": [
          "Equation Generation",
          "Number Alignment"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Huang2018_ReinforcementLearning",
      "label": "Neural Math Word Problem Solver with Reinforcement Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2018_ReinforcementLearning",
        "entity_id": "Huang2018_ReinforcementLearning",
        "name": "Neural Math Word Problem Solver with Reinforcement Learning",
        "title": "Neural Math Word Problem Solver with Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Huang, D.",
          "Liu, J.",
          "Lin, C.Y.",
          "Yin, J."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Sequence-to-Sequence Model",
            "Copy Mechanism",
            "Alignment Mechanism"
          ],
          "connections": [
            "Deep Q-Network"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Isbell2006_CobotInLambdaMOO",
      "label": "Cobot in LambdaMOO",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Isbell2006_CobotInLambdaMOO",
        "entity_id": "Isbell2006_CobotInLambdaMOO",
        "name": "Cobot in LambdaMOO",
        "title": "",
        "year": "2006",
        "authors": [
          "Isbell, C.",
          "Kearns, M.",
          "Singh, S.",
          "Shelton, C.",
          "Stone, P.",
          "Kormann, D."
        ],
        "task": "[\"Adaptive Social Statistics Agent\"]",
        "dataset": [
          "AAMAS_2006"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Adaptive Social Statistics Agent",
            "LambdaMOO"
          ],
          "connections": [
            "Adaptive Social Statistics",
            "Agent"
          ],
          "mechanisms": [
            "Adaptive Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adaptive Learning"
          ],
          "parameter_tuning": [
            "Social Statistics"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Jia2016_CopyMechanism",
      "label": "Copy Mechanism",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Jia2016_CopyMechanism",
        "entity_id": "Jia2016_CopyMechanism",
        "name": "Copy Mechanism",
        "title": "",
        "year": "2016",
        "authors": [
          "Jia, R.",
          "Liang, P."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Copy Mechanism",
            "Attention-Based Copy"
          ],
          "connections": [
            "Source Tokens",
            "Target Vocabulary"
          ],
          "mechanisms": [
            "Generation Probability",
            "Sigmoid Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Token Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Jung2004_BuildingDetectionFromAerialImages",
      "label": "Building Detection from Aerial Images",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Jung2004_BuildingDetectionFromAerialImages",
        "entity_id": "Jung2004_BuildingDetectionFromAerialImages",
        "name": "Building Detection from Aerial Images",
        "title": "",
        "year": "2004",
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "[\"Building Detection\"]",
        "dataset": [
          "AerialImages_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection",
          "FalsePositiveRate_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Windowed Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Edge Map -> Windowed Hough Transform -> Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Sliding Window",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Dmin",
            "Dmax",
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Detection",
          "Morphological Erosion"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Jung2004_LicensePlateDetection",
      "label": "License Plate Detection",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Jung2004_LicensePlateDetection",
        "entity_id": "Jung2004_LicensePlateDetection",
        "name": "License Plate Detection",
        "title": "",
        "year": "2004",
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "[\"License Plate Detection\"]",
        "dataset": [
          "OriginalImage_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Windowed Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Edge Map -> Windowed Hough Transform -> Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Sliding Window",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Dmin",
            "Dmax",
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Jung2004_RectangleDetectionAlgorithm",
      "label": "Rectangle Detection Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Jung2004_RectangleDetectionAlgorithm",
        "entity_id": "Jung2004_RectangleDetectionAlgorithm",
        "name": "Rectangle Detection Algorithm",
        "title": "Rectangle detection based on a windowed Hough Transform",
        "year": "2004",
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "[\"Rectangle Detection\"]",
        "dataset": [
          "SyntheticImages_2004",
          "NaturalImages_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Sliding Window",
            "Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Sliding Window -> Hough Transform",
            "Hough Transform -> Peak Extraction",
            "Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Windowed Hough Transform",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Edge Detection",
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Map Generation",
          "Butterfly Pattern Enhancement"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Jung2004_RectangleDetectionOnNoisyImages",
      "label": "Rectangle Detection on Noisy Images",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Jung2004_RectangleDetectionOnNoisyImages",
        "entity_id": "Jung2004_RectangleDetectionOnNoisyImages",
        "name": "Rectangle Detection on Noisy Images",
        "title": "",
        "year": "2004",
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "[\"Rectangle Detection\"]",
        "dataset": [
          "SyntheticImages_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection",
          "FalsePositiveRate_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Windowed Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Edge Map -> Windowed Hough Transform -> Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Sliding Window",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Jung2004_RectangleDetectionOnSyntheticImages",
      "label": "Rectangle Detection on Synthetic Images",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Jung2004_RectangleDetectionOnSyntheticImages",
        "entity_id": "Jung2004_RectangleDetectionOnSyntheticImages",
        "name": "Rectangle Detection on Synthetic Images",
        "title": "",
        "year": "2004",
        "authors": [
          "Claudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "[\"Rectangle Detection\"]",
        "dataset": [
          "SyntheticImages_2004"
        ],
        "metrics": [
          "DetectionAccuracy_RectangleDetection"
        ],
        "architecture": {
          "components": [
            "Windowed Hough Transform",
            "Peak Extraction",
            "Geometric Constraints"
          ],
          "connections": [
            "Edge Map -> Windowed Hough Transform -> Peak Extraction -> Geometric Constraints"
          ],
          "mechanisms": [
            "Sliding Window",
            "Local Maxima Detection",
            "Rectangle Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Tθ",
            "Tρ",
            "TL",
            "Tα"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Jung2004_WindowedHoughTransform",
      "label": "Windowed Hough Transform",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Jung2004_WindowedHoughTransform",
        "entity_id": "Jung2004_WindowedHoughTransform",
        "name": "Windowed Hough Transform",
        "title": "Rectangle detection based on a windowed Hough transform",
        "year": "2004",
        "authors": [
          "Cláudio Rosito Jung",
          "Rodrigo Schramm"
        ],
        "task": "[\"矩形检测\"]",
        "dataset": [
          "合成图像",
          "自然图像"
        ],
        "metrics": [
          "检测精度",
          "召回率"
        ],
        "architecture": {
          "components": [
            "滑动窗口",
            "霍夫变换",
            "峰值检测"
          ],
          "connections": [
            "滑动窗口与霍夫变换结合",
            "峰值检测与几何约束结合"
          ],
          "mechanisms": [
            "几何约束",
            "环形搜索区域"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习"
          ],
          "parameter_tuning": [
            "角度和距离量化步长",
            "阈值调整"
          ]
        },
        "feature_processing": [
          "边缘检测",
          "噪声去除"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kalchbrenner2013_RecurrentContinuousTranslationModels",
      "label": "Recurrent Continuous Translation Models",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kalchbrenner2013_RecurrentContinuousTranslationModels",
        "entity_id": "Kalchbrenner2013_RecurrentContinuousTranslationModels",
        "name": "Recurrent Continuous Translation Models",
        "title": "",
        "year": "2013",
        "authors": [
          "Kalchbrenner, N.",
          "Blunsom, P."
        ],
        "task": "[\"Machine Translation\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Convolutional Neural Networks",
            "Recurrent Neural Networks"
          ],
          "connections": [
            "Input to Vector",
            "Vector to Output"
          ],
          "mechanisms": [
            "Mapping sentences to vectors"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training"
          ],
          "parameter_tuning": [
            "Hyperparameters tuning"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kasami1969_SyntaxAnalysisProcedure",
      "label": "Kasami's Syntax Analysis Procedure",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kasami1969_SyntaxAnalysisProcedure",
        "entity_id": "Kasami1969_SyntaxAnalysisProcedure",
        "name": "Kasami's Syntax Analysis Procedure",
        "title": "",
        "year": "1969",
        "authors": [
          "Kasami, T.",
          "Torii, K."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [
          "TimeComplexity_Parsing",
          "SpaceComplexity_Parsing"
        ],
        "architecture": {
          "components": [
            "Parsing table",
            "Dynamic programming"
          ],
          "connections": [
            "State transitions"
          ],
          "mechanisms": [
            "Unambiguous context-free grammars"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kate2006_StringKernels",
      "label": "Using String-Kernels for Learning Semantic Parsers",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kate2006_StringKernels",
        "entity_id": "Kate2006_StringKernels",
        "name": "Using String-Kernels for Learning Semantic Parsers",
        "title": "",
        "year": "2006",
        "authors": [
          "Kate, R.",
          "Mooney, R."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "ACL_2006"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "String-Kernels",
            "Semantic Parsers"
          ],
          "connections": [
            "String-Kernels",
            "Semantic Parsing"
          ],
          "mechanisms": [
            "Kernel Methods"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Kernel Methods"
          ],
          "parameter_tuning": [
            "String-Kernels"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kate2008_TransformingMeaningRepresentation",
      "label": "Transforming Meaning Representation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kate2008_TransformingMeaningRepresentation",
        "entity_id": "Kate2008_TransformingMeaningRepresentation",
        "name": "Transforming Meaning Representation",
        "title": "",
        "year": "2008",
        "authors": [
          "Kate, R."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "CoNLL_2008"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Meaning Representation Grammars"
          ],
          "connections": [
            "Semantic Parsing",
            "Grammar Transformation"
          ],
          "mechanisms": [
            "Inductive Logic Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Grammar Transformation"
          ],
          "parameter_tuning": [
            "Meaning Representation"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KAZB2014_TemplateBasedStatisticalLearning",
      "label": "KAZB",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KAZB2014_TemplateBasedStatisticalLearning",
        "entity_id": "KAZB2014_TemplateBasedStatisticalLearning",
        "name": "KAZB",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"自动解代数文字题\"]",
        "dataset": [
          "Alg514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "问题句子映射到方程模板"
          ],
          "connections": [
            "问题句子与方程模板之间的映射"
          ],
          "mechanisms": [
            "跨句子推理"
          ]
        },
        "methodology": {
          "training_strategy": [
            "统计学习方法"
          ],
          "parameter_tuning": [
            "无"
          ]
        },
        "feature_processing": [
          "无"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Khot2015_Praline",
      "label": "Praline",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Khot2015_Praline",
        "entity_id": "Khot2015_Praline",
        "name": "Praline",
        "title": "",
        "year": "2015",
        "authors": [
          "Khot, T.",
          "Balasubramanian, N.",
          "Gribkoff, E.",
          "Sabharwal, A.",
          "Clark, P.",
          "Etzioni, O."
        ],
        "task": "[\"Elementary Science Question Answering\"]",
        "dataset": [
          "NY_Regents_Science_Exam_2016"
        ],
        "metrics": [
          "Score_Percentage"
        ],
        "architecture": {
          "components": [
            "Markov Logic Networks (MLNs)"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Parameter tuning for MLNs"
          ],
          "parameter_tuning": [
            "Optimal parameter values"
          ]
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kim2012_UnsupervisedPCFG",
      "label": "Unsupervised PCFG Induction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kim2012_UnsupervisedPCFG",
        "entity_id": "Kim2012_UnsupervisedPCFG",
        "name": "Unsupervised PCFG Induction",
        "title": "",
        "year": "2012",
        "authors": [
          "Kim, J.",
          "Mooney, R."
        ],
        "task": "[\"Grounded Language Learning\"]",
        "dataset": [
          "EMNLP_2012"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "PCFG Induction",
            "Grounded Language"
          ],
          "connections": [
            "PCFG Induction",
            "Language Learning"
          ],
          "mechanisms": [
            "Unsupervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "PCFG Induction"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kintsch1985_ChangeCompareCombineSchemas",
      "label": "Change, Compare, Combine Schemas",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kintsch1985_ChangeCompareCombineSchemas",
        "entity_id": "Kintsch1985_ChangeCompareCombineSchemas",
        "name": "Change, Compare, Combine Schemas",
        "title": "",
        "year": "1985",
        "authors": [
          "Kintsch, W.",
          "Greeno, J.G."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Simple Arithmetic Word Problems"
        ],
        "metrics": [
          "Schema Matching Accuracy"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KintschGreeno1985_ComparisonSchema",
      "label": "Comparison Schema",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KintschGreeno1985_ComparisonSchema",
        "entity_id": "KintschGreeno1985_ComparisonSchema",
        "name": "Comparison Schema",
        "title": "",
        "year": "1985",
        "authors": [
          "W. Kintsch",
          "J. G. Greeno"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "small set",
            "large set",
            "difference set"
          ],
          "connections": [
            "compare sets"
          ],
          "mechanisms": [
            "subtraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "propositional representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KintschGreeno1985_SupersetSchema",
      "label": "Superset Schema",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KintschGreeno1985_SupersetSchema",
        "entity_id": "KintschGreeno1985_SupersetSchema",
        "name": "Superset Schema",
        "title": "",
        "year": "1985",
        "authors": [
          "W. Kintsch",
          "J. G. Greeno"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "superset",
            "subset1",
            "subset2"
          ],
          "connections": [
            "organize subsets"
          ],
          "mechanisms": [
            "addition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "propositional representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KintschGreeno1985_TransferSchema",
      "label": "Transfer Schema",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KintschGreeno1985_TransferSchema",
        "entity_id": "KintschGreeno1985_TransferSchema",
        "name": "Transfer Schema",
        "title": "",
        "year": "1985",
        "authors": [
          "W. Kintsch",
          "J. G. Greeno"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "start set",
            "transfer set",
            "result set"
          ],
          "connections": [
            "transfer-in slot",
            "start slot",
            "result slot"
          ],
          "mechanisms": [
            "addition",
            "subtraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "propositional representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kiros2015_SkipThoughtVectors",
      "label": "Skip-Thought Vectors",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kiros2015_SkipThoughtVectors",
        "entity_id": "Kiros2015_SkipThoughtVectors",
        "name": "Skip-Thought Vectors",
        "title": "Skip-thought vectors",
        "year": "2015",
        "authors": [
          "Kiros, Ryan",
          "Zhu, Yukun",
          "Salakhutdinov, Ruslan",
          "Zemel, Richard S.",
          "Torralba, Antonio",
          "Urtasun, Raquel",
          "Fidler, Sanja"
        ],
        "task": "[\"Sequence Prediction\"]",
        "dataset": [
          "English Unsupervised",
          "German Unsupervised"
        ],
        "metrics": [
          "Perplexity",
          "BLEU Score"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks",
            "Long Short-Term Memory"
          ],
          "mechanisms": [
            "Skip-Thought"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pretraining",
            "Finetuning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Klein2003_AccurateUnlexicalizedParsing",
      "label": "Accurate Unlexicalized Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Klein2003_AccurateUnlexicalizedParsing",
        "entity_id": "Klein2003_AccurateUnlexicalizedParsing",
        "name": "Accurate Unlexicalized Parsing",
        "title": "",
        "year": "2003",
        "authors": [
          "Dan Klein",
          "Christopher D. Manning"
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parsing",
            "Statistical Models"
          ],
          "connections": [
            "Dependency Extraction Rules"
          ],
          "mechanisms": [
            "Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Maximum Likelihood Estimation"
          ]
        },
        "feature_processing": [
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Klein2003_StanfordParser",
      "label": "Stanford Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Klein2003_StanfordParser",
        "entity_id": "Klein2003_StanfordParser",
        "name": "Stanford Parser",
        "title": "",
        "year": "2003",
        "authors": [
          "Klein, Dan",
          "Manning, Christopher D."
        ],
        "task": "[\"Phrase Structure Parsing\"]",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Per-Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Phrase Structure Parser",
            "Typed Dependency Extractor"
          ],
          "connections": [
            "Phrase Structure Trees -> Typed Dependencies"
          ],
          "mechanisms": [
            "Rule-based Dependency Extraction",
            "Collapsing Prepositions and Conjunctions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Statistical Parsing"
          ],
          "parameter_tuning": [
            "Collins Head Rules",
            "Semantic Head Retrieval"
          ]
        },
        "feature_processing": [
          "Phrase Structure Trees",
          "Head Identification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Klein2003a_ProbabilisticContextFreeGrammar",
      "label": "Probabilistic Context-Free Grammar (PCFG)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Klein2003a_ProbabilisticContextFreeGrammar",
        "entity_id": "Klein2003a_ProbabilisticContextFreeGrammar",
        "name": "Probabilistic Context-Free Grammar (PCFG)",
        "title": "",
        "year": "2003",
        "authors": [
          "Klein, D.",
          "Manning, C. D."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Grammar Rules",
            "Probabilities"
          ],
          "connections": [
            "Rule Application"
          ],
          "mechanisms": [
            "Probabilistic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Rule Splitting"
          ]
        },
        "feature_processing": [
          "Syntactic Categories"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Knox2009_InteractivelyShapingAgents",
      "label": "Interactively Shaping Agents",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Knox2009_InteractivelyShapingAgents",
        "entity_id": "Knox2009_InteractivelyShapingAgents",
        "name": "Interactively Shaping Agents",
        "title": "",
        "year": "2009",
        "authors": [
          "Knox, B.",
          "Stone, P."
        ],
        "task": "[\"Human Reinforcement\"]",
        "dataset": [
          "KCAP_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Human Reinforcement",
            "Agent Shaping"
          ],
          "connections": [
            "Human Interaction",
            "Agent"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Human Reinforcement"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Knuth1965_LRkAlgorithm",
      "label": "LR(k) Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Knuth1965_LRkAlgorithm",
        "entity_id": "Knuth1965_LRkAlgorithm",
        "name": "LR(k) Algorithm",
        "title": "",
        "year": "1965",
        "authors": [
          "Knuth, D.E."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [
          "TimeComplexity_Parsing",
          "SpaceComplexity_Parsing"
        ],
        "architecture": {
          "components": [
            "Predictor",
            "Scanner",
            "Completer"
          ],
          "connections": [
            "State transitions",
            "Look-ahead"
          ],
          "mechanisms": [
            "Stack-based parsing"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Knuth1968_ContextFreeLanguagesAlgorithm",
      "label": "Context-Free Languages Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Knuth1968_ContextFreeLanguagesAlgorithm",
        "entity_id": "Knuth1968_ContextFreeLanguagesAlgorithm",
        "name": "Context-Free Languages Algorithm",
        "title": "",
        "year": "1968",
        "authors": [
          "KNUTH, D.E."
        ],
        "task": "[\"Derivation Tree Analysis\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Directed Graph Construction"
          ],
          "connections": [
            "Vertices and Arcs"
          ],
          "mechanisms": [
            "Addition of Directed Graphs"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Knuth1968_ContextFreeSemanticsAlgorithm",
      "label": "Context-Free Semantics Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Knuth1968_ContextFreeSemanticsAlgorithm",
        "entity_id": "Knuth1968_ContextFreeSemanticsAlgorithm",
        "name": "Context-Free Semantics Algorithm",
        "title": "Semantics of Context-Free Languages",
        "year": "1968",
        "authors": [
          "Donald E. Knuth"
        ],
        "task": "[\"Semantic Analysis of Context-Free Grammars\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Directed Graph Construction"
          ],
          "connections": [
            "Graph Pasting"
          ],
          "mechanisms": [
            "Cycle Detection"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koedinger1990_SearchStrategies",
      "label": "Search Strategies",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koedinger1990_SearchStrategies",
        "entity_id": "Koedinger1990_SearchStrategies",
        "name": "Search Strategies",
        "title": "",
        "year": "1990",
        "authors": [
          "Koedinger, K.R."
        ],
        "task": "[\"Geometry Theorem Proving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Sophisticated search strategies"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Heuristic knowledge"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koncel-Kedziorski2015_ALGES",
      "label": "ALGES",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel-Kedziorski2015_ALGES",
        "entity_id": "Koncel-Kedziorski2015_ALGES",
        "name": "ALGES",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": "2015",
        "authors": [
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi",
          "Ashish Sabharwal",
          "Oren Etzioni",
          "Siena Dumas Ang"
        ],
        "task": "[\"Solving algebraic word problems\"]",
        "dataset": [
          "SINGLEEQ"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming (ILP)",
            "Local discriminative model",
            "Global discriminative model"
          ],
          "connections": [
            "Equation tree generation",
            "Equation tree scoring"
          ],
          "mechanisms": [
            "Type-consistent algebraic equations",
            "Bottom-up approach for learning correspondences between spans of text and arithmetic operators"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weakly supervised learning",
            "Using word problems and their correct answers as training data"
          ],
          "parameter_tuning": [
            "Learning local and global models from a small number of word problems and their solutions"
          ]
        },
        "feature_processing": [
          "Quantified Sets (Qsets)",
          "Dependency parse relations",
          "Semantic and intertextual relationships"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koncel-Kedziorski2015_CombineFunction",
      "label": "Combine Function",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel-Kedziorski2015_CombineFunction",
        "entity_id": "Koncel-Kedziorski2015_CombineFunction",
        "name": "Combine Function",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Combine Function"
          ],
          "connections": [
            "Arithmetic Operators",
            "Qsets"
          ],
          "mechanisms": [
            "Recursive Combination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Qset Properties",
          "Arithmetic Operations"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koncel-Kedziorski2015_GlobalEquationModel",
      "label": "Global Equation Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel-Kedziorski2015_GlobalEquationModel",
        "entity_id": "Koncel-Kedziorski2015_GlobalEquationModel",
        "name": "Global Equation Model",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Discriminative Model",
            "Feature Vectors"
          ],
          "connections": [
            "Equation Trees",
            "Problem Text"
          ],
          "mechanisms": [
            "Soft Constraints",
            "Global Structure"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Feature Engineering"
          ],
          "parameter_tuning": [
            "Global Classifier Parameters"
          ]
        },
        "feature_processing": [
          "Soft Constraint Features",
          "Global Lexical Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koncel-Kedziorski2015_ILP_EquationTreeGenerator",
      "label": "ILP-based Equation Tree Generator",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel-Kedziorski2015_ILP_EquationTreeGenerator",
        "entity_id": "Koncel-Kedziorski2015_ILP_EquationTreeGenerator",
        "name": "ILP-based Equation Tree Generator",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming",
            "Equation Trees"
          ],
          "connections": [
            "Qset Extraction",
            "Equation Tree Generation"
          ],
          "mechanisms": [
            "Type Consistency",
            "Global Constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision",
            "Unannotated Data"
          ],
          "parameter_tuning": [
            "Max Stack Depth",
            "Number of Candidates"
          ]
        },
        "feature_processing": [
          "Qset Properties",
          "Semantic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koncel-Kedziorski2015_ILP_Optimization",
      "label": "ILP Optimization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel-Kedziorski2015_ILP_Optimization",
        "entity_id": "Koncel-Kedziorski2015_ILP_Optimization",
        "name": "ILP Optimization",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming",
            "Postfix Notation",
            "Equation Tree Generation"
          ],
          "connections": [
            "Type Consistency",
            "Global Constraints",
            "Expression Complexity"
          ],
          "mechanisms": [
            "Constraint Satisfaction",
            "Soft Constraint Minimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision",
            "Type Consistency",
            "Global Structure"
          ],
          "parameter_tuning": [
            "Stack Depth Limits",
            "Soft Constraint Weights"
          ]
        },
        "feature_processing": [
          "Postfix Expression Encoding",
          "Symbol Type Assignment"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koncel-Kedziorski2015_LocalQsetRelationshipModel",
      "label": "Local Qset Relationship Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel-Kedziorski2015_LocalQsetRelationshipModel",
        "entity_id": "Koncel-Kedziorski2015_LocalQsetRelationshipModel",
        "name": "Local Qset Relationship Model",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multi-class SVM",
            "Feature Vectors"
          ],
          "connections": [
            "Qset Pairs",
            "Math Operators"
          ],
          "mechanisms": [
            "Pairwise Relationships",
            "Semantic Features"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Feature Engineering"
          ],
          "parameter_tuning": [
            "RBF Kernel Parameters"
          ]
        },
        "feature_processing": [
          "Single Qset Features",
          "Relational Features",
          "Target Quantity Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koncel-Kedziorski2015_ParsingAlgebraicWordProblems",
      "label": "Parsing Algebraic Word Problems",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel-Kedziorski2015_ParsingAlgebraicWordProblems",
        "entity_id": "Koncel-Kedziorski2015_ParsingAlgebraicWordProblems",
        "name": "Parsing Algebraic Word Problems",
        "title": "",
        "year": "2015",
        "authors": [
          "R. Koncel-Kedziorski",
          "H. Hajishirzi",
          "A. Sabharwal",
          "O. Etzioni",
          "S. D. Ang"
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [
          "ALG514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Semantic Parser",
            "Equation Generator"
          ],
          "connections": [
            "Text to Equation"
          ],
          "mechanisms": [
            "Parsing into Equations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Parameter Optimization"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Koncel-Kedziorski2015_QsetReordering",
      "label": "Qset Reordering",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel-Kedziorski2015_QsetReordering",
        "entity_id": "Koncel-Kedziorski2015_QsetReordering",
        "name": "Qset Reordering",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Qset Reordering Rules"
          ],
          "connections": [
            "Container Match Rule",
            "Question Keywords Rule"
          ],
          "mechanisms": [
            "Semantic and Textual Information"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Weak Supervision"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Semantic Properties",
          "Textual Properties"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koncel-Kedziorski2015_SINGLEEQ",
      "label": "SINGLEEQ",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel-Kedziorski2015_SINGLEEQ",
        "entity_id": "Koncel-Kedziorski2015_SINGLEEQ",
        "name": "SINGLEEQ",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": "2015",
        "authors": [
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi",
          "Ashish Sabharwal",
          "Oren Etzioni",
          "Siena Ang"
        ],
        "task": "[\"Single Equation Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Single Equation Solver"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Koncel2016_ThemeRewriting",
      "label": "Theme Rewriting Approach",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Koncel2016_ThemeRewriting",
        "entity_id": "Koncel2016_ThemeRewriting",
        "name": "Theme Rewriting Approach",
        "title": "",
        "year": "2016",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Konstas, I.",
          "Zettlemoyer, L.",
          "Hajishirzi, H."
        ],
        "task": "[\"Generating algebra word problems\"]",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Theme rewriting"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Rewriting to fit a particular theme"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "KoncelKedziorski2015_ALGES",
      "label": "ALGES",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2015_ALGES",
        "entity_id": "KoncelKedziorski2015_ALGES",
        "name": "ALGES",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": "2015",
        "authors": [
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi",
          "Ashish Sabharwal",
          "Oren Etzioni",
          "Siena Dumas Ang"
        ],
        "task": "[\"Solving Algebraic Word Problems\"]",
        "dataset": [
          "SINGLEEQ_2015"
        ],
        "metrics": [
          "Accuracy_AnswerExtraction"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming",
            "Discriminative Models"
          ],
          "connections": [
            "Local Model",
            "Global Model"
          ],
          "mechanisms": [
            "Equation Tree Generation",
            "Equation Tree Scoring"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Weak Supervision"
          ],
          "parameter_tuning": [
            "ILP Constraints",
            "Soft Constraints"
          ]
        },
        "feature_processing": [
          "Qset Grounding",
          "Qset Reordering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KoncelKedziorski2015_EnumerateTrees",
      "label": "Enumerate Trees",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2015_EnumerateTrees",
        "entity_id": "KoncelKedziorski2015_EnumerateTrees",
        "name": "Enumerate Trees",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Integer Linear Programming",
            "Candidate Trees"
          ],
          "connections": [
            "Enumerating Possible Equation Trees",
            "Ranking Candidate Trees"
          ],
          "mechanisms": [
            "Scoring Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Scoring Function Parameters"
          ]
        },
        "feature_processing": [
          "Equation Tree Enumeration",
          "Candidate Tree Ranking"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KoncelKedziorski2015_EquationParser",
      "label": "Equation Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2015_EquationParser",
        "entity_id": "KoncelKedziorski2015_EquationParser",
        "name": "Equation Parser",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski",
          "Hajishirzi",
          "Sabharwal",
          "Etzioni",
          "Ang"
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Semantic Parser",
            "Logic Representation"
          ],
          "connections": [
            "Dependency Parsing"
          ],
          "mechanisms": [
            "Rule-Based Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Coreference Resolution"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "KoncelKedziorski2015_EquationTrees",
      "label": "Equation Trees",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2015_EquationTrees",
        "entity_id": "KoncelKedziorski2015_EquationTrees",
        "name": "Equation Trees",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Equation Generation",
            "Scoring"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KoncelKedziorski2015_ExpressionTreeMapping",
      "label": "Expression Tree Mapping",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2015_ExpressionTreeMapping",
        "entity_id": "KoncelKedziorski2015_ExpressionTreeMapping",
        "name": "Expression Tree Mapping",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S.D."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Expression Trees"
          ],
          "connections": [
            "Mapping from Word Problems to Expression Trees"
          ],
          "mechanisms": [
            "Tree Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Tree Structure Optimization"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KoncelKedziorski2015_IntegerLinearProgramming",
      "label": "Integer Linear Programming",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2015_IntegerLinearProgramming",
        "entity_id": "KoncelKedziorski2015_IntegerLinearProgramming",
        "name": "Integer Linear Programming",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "IntegerLinearProgramming_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Enumerated Trees"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KoncelKedziorski2015_SingleEquation",
      "label": "Single Equation Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2015_SingleEquation",
        "entity_id": "KoncelKedziorski2015_SingleEquation",
        "name": "Single Equation Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S."
        ],
        "task": "[\"Solving algebra word problems\"]",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Equations"
          ],
          "connections": [
            "Equation solving"
          ],
          "mechanisms": [
            "Single equation generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Equation-based learning"
          ],
          "parameter_tuning": [
            "Equation parameters"
          ]
        },
        "feature_processing": [
          "Equation extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KoncelKedziorski2015_SingleEquationSolver",
      "label": "SINGLEEQ",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2015_SingleEquationSolver",
        "entity_id": "KoncelKedziorski2015_SingleEquationSolver",
        "name": "SINGLEEQ",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S."
        ],
        "task": "[\"Single Equation Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Single Equation Parsing"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Single Equation Parsing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KoncelKedziorski2015_SingleLinearEquationSolver",
      "label": "Single Linear Equation Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2015_SingleLinearEquationSolver",
        "entity_id": "KoncelKedziorski2015_SingleLinearEquationSolver",
        "name": "Single Linear Equation Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H.",
          "Sabharwal, A.",
          "Etzioni, O.",
          "Ang, S. D."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "SingleEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Equation Parser",
            "Solver"
          ],
          "connections": [
            "Text -> Equation -> Solution"
          ],
          "mechanisms": [
            "Parsing Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Parsing"
          ],
          "parameter_tuning": [
            "Parsing Rules"
          ]
        },
        "feature_processing": [
          "Textual Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "KoncelKedziorski2016_RetrievalModel",
      "label": "Retrieval Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "KoncelKedziorski2016_RetrievalModel",
        "entity_id": "KoncelKedziorski2016_RetrievalModel",
        "name": "Retrieval Model",
        "title": "",
        "year": "2016",
        "authors": [
          "Koncel-Kedziorski, R.",
          "Roy, S.",
          "Amini, A.",
          "Kushman, N.",
          "Hajishirzi, H."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Similarity Metric"
          ],
          "connections": [
            "Jaccard Distance",
            "Cosine Similarity"
          ],
          "mechanisms": [
            "Nearest Neighbor"
          ]
        },
        "methodology": {
          "training_strategy": [
            "No training required"
          ],
          "parameter_tuning": [
            "Similarity threshold"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kook1987_VIEWER",
      "label": "VIEWER",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kook1987_VIEWER",
        "entity_id": "Kook1987_VIEWER",
        "name": "VIEWER",
        "title": "",
        "year": "1987",
        "authors": [
          "Kook, H. J."
        ],
        "task": "[\"Physics Problem Modeling\"]",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Model Accuracy"
        ],
        "architecture": {
          "components": [
            "Object Recognition",
            "Canonical Model Generation"
          ],
          "connections": [
            "Object Recognition -> Canonical Model Generation"
          ],
          "mechanisms": [
            "Expert System",
            "Inference Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Inference"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Object Classification",
          "Model Transformation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kosslyn1994_DiagramEffectiveness",
      "label": "Diagram Effectiveness",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kosslyn1994_DiagramEffectiveness",
        "entity_id": "Kosslyn1994_DiagramEffectiveness",
        "name": "Diagram Effectiveness",
        "title": "",
        "year": "1994",
        "authors": [
          "Kosslyn, S. M."
        ],
        "task": "[\"Understanding Diagrams\"]",
        "dataset": [],
        "metrics": [
          "Effectiveness",
          "Clarity"
        ],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kuhlmann2004_GuidingReinforcementLearner",
      "label": "Guiding a Reinforcement Learner with Natural Language Advice",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kuhlmann2004_GuidingReinforcementLearner",
        "entity_id": "Kuhlmann2004_GuidingReinforcementLearner",
        "name": "Guiding a Reinforcement Learner with Natural Language Advice",
        "title": "",
        "year": "2004",
        "authors": [
          "Kuhlmann, G.",
          "Stone, P.",
          "Mooney, R.",
          "Shavlik, J."
        ],
        "task": "[\"Reinforcement Learning\"]",
        "dataset": [
          "RoboCup Soccer"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Reinforcement Learning",
            "Natural Language Advice"
          ],
          "connections": [
            "Natural Language",
            "Reinforcement Learning"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Natural Language Advice"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_AlgebraWordProblemSolver",
      "label": "Algebra Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_AlgebraWordProblemSolver",
        "entity_id": "Kushman2014_AlgebraWordProblemSolver",
        "name": "Algebra Word Problem Solver",
        "title": "Learning to automatically solve algebra word problems",
        "year": "2014",
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": "[\"Automatically Solving Algebra Word Problems\"]",
        "dataset": [
          "Algebra.com Dataset"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "equation templates",
            "alignment model"
          ],
          "connections": [
            "template instantiation",
            "variable and number alignment"
          ],
          "mechanisms": [
            "canonicalization",
            "dependency parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "varied supervision",
            "numerical solutions",
            "full equation systems"
          ],
          "parameter_tuning": [
            "beam search",
            "L-BFGS optimization"
          ]
        },
        "feature_processing": [
          "document level features",
          "single slot features",
          "slot pair features",
          "solution features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_AutomaticAlgebraSolver",
      "label": "Automatic Algebra Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_AutomaticAlgebraSolver",
        "entity_id": "Kushman2014_AutomaticAlgebraSolver",
        "name": "Automatic Algebra Solver",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Learning from equations or final answers"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_BeamSearchInference",
      "label": "Beam Search Inference",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_BeamSearchInference",
        "entity_id": "Kushman2014_BeamSearchInference",
        "name": "Beam Search Inference",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "Template Selection",
            "Slot Alignment"
          ],
          "connections": [
            "Iterative Alignment of Slots to Words",
            "Pruning of Partial Derivations"
          ],
          "mechanisms": [
            "Canonicalized Ordering for Template Slots"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Approximate Computation"
          ],
          "parameter_tuning": [
            "Top-k Partial Derivations",
            "Maximum Beam Size"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Part-of-Speech Tagging"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_BeamSearchNormalization",
      "label": "Beam Search Normalization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_BeamSearchNormalization",
        "entity_id": "Kushman2014_BeamSearchNormalization",
        "name": "Beam Search Normalization",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "Normalization Constant"
          ],
          "connections": [
            "Template Selection",
            "Slot Alignment"
          ],
          "mechanisms": [
            "Exponential Search Space",
            "Canonical Ordering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Approximation"
          ],
          "parameter_tuning": [
            "Top-k Partial Derivations",
            "Pruning Strategy"
          ]
        },
        "feature_processing": [
          "Canonicalized Ordering",
          "Partial Hypotheses"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_EquationSetSolver",
      "label": "Equation Set Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_EquationSetSolver",
        "entity_id": "Kushman2014_EquationSetSolver",
        "name": "Equation Set Solver",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Zettlemoyer, L.",
          "Barzilay, R.",
          "Artzi, Y."
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "ALG514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Feature Representation",
            "Parameter Vector"
          ],
          "connections": [
            "Template Matching",
            "Feature Extraction"
          ],
          "mechanisms": [
            "Log-linear Model",
            "RankSVM"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Marginal Data Log-likelihood Optimization",
            "Beam Search Inference"
          ],
          "parameter_tuning": [
            "L-BFGS"
          ]
        },
        "feature_processing": [
          "Lexical and Syntactic Features",
          "Dependency Path Between Slots"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Kushman2014_EquationSystem",
      "label": "Equation System",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_EquationSystem",
        "entity_id": "Kushman2014_EquationSystem",
        "name": "Equation System",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Solving algebra word problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Equation templates"
          ],
          "connections": [],
          "mechanisms": [
            "Mapping to templates"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_EquationSystemSolver",
      "label": "Equation System Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_EquationSystemSolver",
        "entity_id": "Kushman2014_EquationSystemSolver",
        "name": "Equation System Solver",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": "2014",
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Equation Accuracy",
          "Answer Accuracy"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Log-linear Distribution",
            "Beam Search"
          ],
          "connections": [
            "Alignment between Equations and Text"
          ],
          "mechanisms": [
            "Latent Variable Modeling",
            "Marginal Data Log-Likelihood Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Weak Supervision",
            "L-BFGS Optimization"
          ],
          "parameter_tuning": [
            "L2 Regularization"
          ]
        },
        "feature_processing": [
          "Part-of-Speech Tagging",
          "Lematization",
          "Dependency Parsing",
          "Canonicalization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_EquationTemplateInstantiation",
      "label": "Equation Template Instantiation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_EquationTemplateInstantiation",
        "entity_id": "Kushman2014_EquationTemplateInstantiation",
        "name": "Equation Template Instantiation",
        "title": "",
        "year": "2014",
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": "[\"Solving Algebra Word Problems\"]",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Selection",
            "Template Instantiation"
          ],
          "connections": [
            "Template to Equation",
            "Equation to Solution"
          ],
          "mechanisms": [
            "Slot Filling",
            "Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Weak Supervision"
          ],
          "parameter_tuning": [
            "Beam Search",
            "L-BFGS Optimization"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Part-of-Speech Tagging",
          "Lematization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_EquationTemplateSystem",
      "label": "Equation Template System",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_EquationTemplateSystem",
        "entity_id": "Kushman2014_EquationTemplateSystem",
        "name": "Equation Template System",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Equation Templates"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_KAZB",
      "label": "KAZB",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_KAZB",
        "entity_id": "Kushman2014_KAZB",
        "name": "KAZB",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "Equation Template Alignment"
          ],
          "connections": [
            "Text-to-Equation Mapping"
          ],
          "mechanisms": [
            "Statistical Approach"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pre-extracted Equation Templates"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Text Alignment"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_LogLinearModel",
      "label": "Log-Linear Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_LogLinearModel",
        "entity_id": "Kushman2014_LogLinearModel",
        "name": "Log-Linear Model",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": "2014",
        "authors": [
          "Nate Kushman",
          "Yoav Artzi",
          "Luke Zettlemoyer",
          "Regina Barzilay"
        ],
        "task": "[\"Automatically solving algebra word problems\"]",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Feature function",
            "Parameter vector"
          ],
          "connections": [
            "Feature function to parameter vector",
            "Parameter vector to derivation probability"
          ],
          "mechanisms": [
            "Log-linear distribution",
            "Marginal data log-likelihood optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam search inference",
            "Conditional log-likelihood maximization"
          ],
          "parameter_tuning": [
            "L-BFGS optimization",
            "L2-norm regularization"
          ]
        },
        "feature_processing": [
          "Dependency parses",
          "Part-of-speech tags",
          "Lematizations"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_SlotSignatureGeneration",
      "label": "Slot Signature Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_SlotSignatureGeneration",
        "entity_id": "Kushman2014_SlotSignatureGeneration",
        "name": "Slot Signature Generation",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Slot Signatures",
            "Pairwise Slot Signatures"
          ],
          "connections": [
            "System Templates",
            "Constituent Equations"
          ],
          "mechanisms": [
            "Shared Terms",
            "Concatenation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Feature Sharing"
          ],
          "parameter_tuning": [
            "Signature Types"
          ]
        },
        "feature_processing": [
          "Dependency Paths",
          "Lexicalized Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_SystemTemplateMapping",
      "label": "System Template Mapping",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_SystemTemplateMapping",
        "entity_id": "Kushman2014_SystemTemplateMapping",
        "name": "System Template Mapping",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "System Templates"
          ],
          "connections": [
            "Mapping from Word Problems to System Templates"
          ],
          "mechanisms": [
            "Pattern Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Template Selection"
          ]
        },
        "feature_processing": [
          "Pattern Recognition"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_TEMPLATE",
      "label": "TEMPLATE",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_TEMPLATE",
        "entity_id": "Kushman2014_TEMPLATE",
        "name": "TEMPLATE",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": "2014",
        "authors": [
          "Nathan Kushman",
          "Luke Zettlemoyer",
          "Regina Barzilay",
          "Yoav Artzi"
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Template-based Solver"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_TemplateBased",
      "label": "Template-Based Solution",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_TemplateBased",
        "entity_id": "Kushman2014_TemplateBased",
        "name": "Template-Based Solution",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Zettlemoyer, L.",
          "Barzilay, R.",
          "Artzi, Y."
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "Dolphin_2016"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Predefined Templates",
            "Unknown Slots"
          ],
          "connections": [
            "Finding Matching Template",
            "Inferring Unknown Slots"
          ],
          "mechanisms": [
            "Template Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based System"
          ],
          "parameter_tuning": [
            "Template Definition"
          ]
        },
        "feature_processing": [
          "Template Matching",
          "Slot Inference"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_TemplateBasedAlgebra",
      "label": "Template Based Algebra Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_TemplateBasedAlgebra",
        "entity_id": "Kushman2014_TemplateBasedAlgebra",
        "name": "Template Based Algebra Solver",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Zettlemoyer, L.",
          "Barzilay, R.",
          "Artzi, Y."
        ],
        "task": "[\"Solving algebra word problems\"]",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Templates"
          ],
          "connections": [
            "Template matching"
          ],
          "mechanisms": [
            "Pattern recognition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Template-based learning"
          ],
          "parameter_tuning": [
            "Template parameters"
          ]
        },
        "feature_processing": [
          "Template extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_TemplateBasedAlgebraSolver",
      "label": "TEMPLATE",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_TemplateBasedAlgebraSolver",
        "entity_id": "Kushman2014_TemplateBasedAlgebraSolver",
        "name": "TEMPLATE",
        "title": "Learning to Automatically Solve Algebra Word Problems",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Zettlemoyer, L.",
          "Barzilay, R.",
          "Artzi, Y."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Template Matching"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Template Matching"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_TemplateBasedSolver",
      "label": "Template Based Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_TemplateBasedSolver",
        "entity_id": "Kushman2014_TemplateBasedSolver",
        "name": "Template Based Solver",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Zettlemoyer, L.",
          "Barzilay, R.",
          "Artzi, Y."
        ],
        "task": "[\"Solving algebra word problems\"]",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Templates"
          ],
          "connections": [
            "Template matching"
          ],
          "mechanisms": [
            "Pattern recognition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Template-based learning"
          ],
          "parameter_tuning": [
            "Template parameters"
          ]
        },
        "feature_processing": [
          "Template extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_TemplateBasedStatisticalLearning",
      "label": "KAZB",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_TemplateBasedStatisticalLearning",
        "entity_id": "Kushman2014_TemplateBasedStatisticalLearning",
        "name": "KAZB",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"自动求解数学文字题\"]",
        "dataset": [
          "Alg514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "模板匹配",
            "句子推理"
          ],
          "connections": [
            "问题句子到模板映射"
          ],
          "mechanisms": [
            "统计学习"
          ]
        },
        "methodology": {
          "training_strategy": [
            "跨句子推理"
          ],
          "parameter_tuning": [
            "模板定义"
          ]
        },
        "feature_processing": [
          "问题句子建模"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_TemplateCanonicalization",
      "label": "Template Canonicalization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_TemplateCanonicalization",
        "entity_id": "Kushman2014_TemplateCanonicalization",
        "name": "Template Canonicalization",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "Symbolic Solution",
            "Mathematical Solver"
          ],
          "connections": [
            "Unknown Slots",
            "Number Slots"
          ],
          "mechanisms": [
            "Normal Form Representation",
            "Maxima Solver"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Canonicalization Process"
          ],
          "parameter_tuning": [
            "Symbolic Solution Generation"
          ]
        },
        "feature_processing": [
          "Mathematical Relations",
          "Symbolic Expressions"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kushman2014_TemplateInduction",
      "label": "Template Induction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kushman2014_TemplateInduction",
        "entity_id": "Kushman2014_TemplateInduction",
        "name": "Template Induction",
        "title": "",
        "year": "2014",
        "authors": [
          "Kushman, N.",
          "Artzi, Y.",
          "Zettlemoyer, L.",
          "Barzilay, R."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Algebra.com_2014"
        ],
        "metrics": [
          "Equation_Accuracy",
          "Answer_Accuracy"
        ],
        "architecture": {
          "components": [
            "System Templates",
            "Unknown Slots",
            "Number Slots"
          ],
          "connections": [
            "Replacing Variables with Unknown Slots",
            "Replacing Numbers with Number Slots"
          ],
          "mechanisms": [
            "Generalizing Equations to Templates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Conditional Log-Likelihood Maximization"
          ]
        },
        "feature_processing": [
          "Canonicalization of Templates"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_ConstantReplacementOperators",
      "label": "Constant Replacement Operators",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_ConstantReplacementOperators",
        "entity_id": "Kwiatkowski2013_ConstantReplacementOperators",
        "name": "Constant Replacement Operators",
        "title": "",
        "year": "2013",
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "Entity-Typed Constants",
            "Domain-Independent Constants"
          ],
          "connections": [
            "Logical Form Transformation",
            "Ontology Alignment"
          ],
          "mechanisms": [
            "Constant Substitution",
            "Type Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic CCG Parsing",
            "Latent Variable Learning"
          ],
          "parameter_tuning": [
            "Linear Model Estimation"
          ]
        },
        "feature_processing": [
          "Lexical Similarity",
          "Wiktionary Definitions"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_DomainIndependentCCGParser",
      "label": "Domain-Independent CCG Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_DomainIndependentCCGParser",
        "entity_id": "Kwiatkowski2013_DomainIndependentCCGParser",
        "name": "Domain-Independent CCG Parser",
        "title": "",
        "year": "2013",
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "CCG Grammar",
            "Lexical Categories",
            "Combinatory Rules"
          ],
          "connections": [
            "Lexical Category Assignment",
            "Logical Form Construction"
          ],
          "mechanisms": [
            "Syntactic Parsing",
            "Logical Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic CCG Parsing",
            "Latent Variable Learning"
          ],
          "parameter_tuning": [
            "Linear Model Estimation"
          ]
        },
        "feature_processing": [
          "POS Tagging",
          "Wiktionary Integration"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_DynamicProgramForDerivations",
      "label": "Dynamic Program for Derivations",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_DynamicProgramForDerivations",
        "entity_id": "Kwiatkowski2013_DynamicProgramForDerivations",
        "name": "Dynamic Program for Derivations",
        "title": "",
        "year": "2013",
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "CKY-style chart parser",
            "Hyper-graph chart structure"
          ],
          "connections": [
            "Logical form generation",
            "Derivation scoring"
          ],
          "mechanisms": [
            "Pruning strategies",
            "Constant matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online learning",
            "Perceptron"
          ],
          "parameter_tuning": [
            "Feature weights initialization",
            "Pruning parameters"
          ]
        },
        "feature_processing": [
          "CCG parse features",
          "Structural features",
          "Lexical features",
          "Knowledge base features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_OnlineLearningAlgorithm",
      "label": "Online Learning Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_OnlineLearningAlgorithm",
        "entity_id": "Kwiatkowski2013_OnlineLearningAlgorithm",
        "name": "Online Learning Algorithm",
        "title": "",
        "year": "2013",
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "[\"Question Answering\"]",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "Perceptron",
            "Feature Vector",
            "Weight Vector"
          ],
          "connections": [
            "Feature Extraction",
            "Weight Update"
          ],
          "mechanisms": [
            "Margin-based Separation",
            "Parameter Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Perceptron Update Rule",
            "Margin-based Learning"
          ],
          "parameter_tuning": [
            "Initial Weight Initialization",
            "Iteration Control"
          ]
        },
        "feature_processing": [
          "Indicator Features",
          "Lexical Features",
          "Structural Features",
          "Knowledge Base Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_OnTheFlyOntologyMatching",
      "label": "On-the-fly Ontology Matching",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_OnTheFlyOntologyMatching",
        "entity_id": "Kwiatkowski2013_OnTheFlyOntologyMatching",
        "name": "On-the-fly Ontology Matching",
        "title": "Scaling Semantic Parsers with On-the-fly Ontology Matching",
        "year": "2013",
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "[\"语义解析\"]",
        "dataset": [
          "GeoQuery",
          "Freebase QA"
        ],
        "metrics": [
          "Recall",
          "Precision",
          "F1"
        ],
        "architecture": {
          "components": [
            "概率组合范畴语法(CCG)",
            "本体匹配模型"
          ],
          "connections": [
            "CCG与本体匹配结合",
            "逻辑形式转换"
          ],
          "mechanisms": [
            "动态规划",
            "线性评分模型"
          ]
        },
        "methodology": {
          "training_strategy": [
            "感知器算法",
            "弱监督学习"
          ],
          "parameter_tuning": [
            "特征权重初始化",
            "剪枝参数设置"
          ]
        },
        "feature_processing": [
          "词类信息",
          "知识库特征"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_OntologyMatchingModel",
      "label": "Ontology Matching Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_OntologyMatchingModel",
        "entity_id": "Kwiatkowski2013_OntologyMatchingModel",
        "name": "Ontology Matching Model",
        "title": "",
        "year": "2013",
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "Type-Equivalent Domain-Specific Meanings",
            "Lexical Similarity"
          ],
          "connections": [
            "Domain-Independent Constants",
            "Domain-Dependent Constants"
          ],
          "mechanisms": [
            "Structure Matching",
            "Constant Replacement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Learning",
            "Question-Answer Pairs"
          ],
          "parameter_tuning": [
            "Linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Knowledge Base Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_ProbabilisticCCG",
      "label": "Probabilistic Combinatory Categorial Grammar (CCG)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_ProbabilisticCCG",
        "entity_id": "Kwiatkowski2013_ProbabilisticCCG",
        "name": "Probabilistic Combinatory Categorial Grammar (CCG)",
        "title": "",
        "year": "2013",
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "CCG Parser",
            "Lexical Categories",
            "Combinatory Rules"
          ],
          "connections": [
            "CCG Lexical Entries",
            "Logical Forms"
          ],
          "mechanisms": [
            "Syntax-Semantics Mapping",
            "Logical Form Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Learning",
            "Question-Answer Pairs"
          ],
          "parameter_tuning": [
            "Linear Model Parameters"
          ]
        },
        "feature_processing": [
          "POS Tagging",
          "Lexical Templates"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_SemanticParser",
      "label": "Semantic Parser with On-the-fly Ontology Matching",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_SemanticParser",
        "entity_id": "Kwiatkowski2013_SemanticParser",
        "name": "Semantic Parser with On-the-fly Ontology Matching",
        "title": "Scaling Semantic Parsers with On-the-fly Ontology Matching",
        "year": "2013",
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "[\"Question Answering\", \"Semantic Parsing\"]",
        "dataset": [],
        "metrics": [
          "Recall",
          "Precision",
          "F1"
        ],
        "architecture": {
          "components": [
            "Probabilistic CCG",
            "Ontology Matching Model"
          ],
          "connections": [
            "CCG Parsing",
            "Logical Form Transformation"
          ],
          "mechanisms": [
            "Domain-independent Parsing",
            "Structure Matching",
            "Constant Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Perceptron",
            "Latent Variable Learning"
          ],
          "parameter_tuning": [
            "Feature Weights"
          ]
        },
        "feature_processing": [
          "CCG Lexical Categories",
          "Wiktionary Definitions",
          "Knowledge Base Constraints"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_SemanticParsers",
      "label": "Semantic Parsers with On-the-fly Ontology Matching",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_SemanticParsers",
        "entity_id": "Kwiatkowski2013_SemanticParsers",
        "name": "Semantic Parsers with On-the-fly Ontology Matching",
        "title": "Scaling Semantic Parsers with On-the-fly Ontology Matching",
        "year": "2013",
        "authors": [
          "Kwiatkowski, T.",
          "Choi, E.",
          "Artzi, Y.",
          "Zettlemoyer, L."
        ],
        "task": "[\"Question Answering\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Probabilistic CCG"
          ],
          "connections": [
            "Logical Forms"
          ],
          "mechanisms": [
            "Ontology Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_SemanticParserWithOntologyMatching",
      "label": "Semantic Parser with On-the-fly Ontology Matching",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_SemanticParserWithOntologyMatching",
        "entity_id": "Kwiatkowski2013_SemanticParserWithOntologyMatching",
        "name": "Semantic Parser with On-the-fly Ontology Matching",
        "title": "",
        "year": "2013",
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall",
          "Precision",
          "F1"
        ],
        "architecture": {
          "components": [
            "Probabilistic CCG",
            "Ontology Matching Model"
          ],
          "connections": [
            "CCG Parsing",
            "Logical Form Transformation"
          ],
          "mechanisms": [
            "Domain-independent Parsing",
            "Structure Matching",
            "Constant Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning",
            "Perceptron"
          ],
          "parameter_tuning": [
            "Feature Weights"
          ]
        },
        "feature_processing": [
          "CCG Parse Features",
          "Structural Features",
          "Lexical Features",
          "Knowledge Base Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Kwiatkowski2013_StructureMatchingOperators",
      "label": "Structure Matching Operators",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Kwiatkowski2013_StructureMatchingOperators",
        "entity_id": "Kwiatkowski2013_StructureMatchingOperators",
        "name": "Structure Matching Operators",
        "title": "",
        "year": "2013",
        "authors": [
          "Tom Kwiatkowski",
          "Eunsol Choi",
          "Yoav Artzi",
          "Luke Zettlemoyer"
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "GeoQuery_1996",
          "FreebaseQA_2013"
        ],
        "metrics": [
          "Recall_QuestionAnswering",
          "Precision_QuestionAnswering",
          "F1_Score_QuestionAnswering"
        ],
        "architecture": {
          "components": [
            "Collapse Literal to Constant",
            "Collapse Literal to Literal",
            "Split Literal"
          ],
          "connections": [
            "Logical Form Transformation",
            "Ontology Alignment"
          ],
          "mechanisms": [
            "Literal Simplification",
            "Predicate Expansion"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic CCG Parsing",
            "Latent Variable Learning"
          ],
          "parameter_tuning": [
            "Linear Model Estimation"
          ]
        },
        "feature_processing": [
          "Logical Form Manipulation",
          "Type Checking"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lagunovsky1999_StraightLineExtraction",
      "label": "Straight-line-based Primitive Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lagunovsky1999_StraightLineExtraction",
        "entity_id": "Lagunovsky1999_StraightLineExtraction",
        "name": "Straight-line-based Primitive Extraction",
        "title": "Straight-line-based Primitive Extraction in Grey-scale Object Recognition",
        "year": "1999",
        "authors": [
          "D. Lagunovsky",
          "S. Ablameyko"
        ],
        "task": "[\"Primitive Extraction\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Linear Primitives",
            "Grouping"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lagunovsky1999_StraightLinePrimitiveExtraction",
      "label": "Straight-line-based Primitive Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lagunovsky1999_StraightLinePrimitiveExtraction",
        "entity_id": "Lagunovsky1999_StraightLinePrimitiveExtraction",
        "name": "Straight-line-based Primitive Extraction",
        "title": "",
        "year": "1999",
        "authors": [
          "D. Lagunovsky",
          "S. Ablameyko"
        ],
        "task": "[\"Object Recognition\"]",
        "dataset": [
          "SyntheticImages_1999"
        ],
        "metrics": [
          "DetectionAccuracy"
        ],
        "architecture": {
          "components": [
            "Edge Detection",
            "Linear Primitive Extraction"
          ],
          "connections": [
            "Edge Elements to Linear Segments"
          ],
          "mechanisms": [
            "Grouping Line Segments"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Not Applicable"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lebret2014_HPCA",
      "label": "Hellinger PCA (HPCA)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lebret2014_HPCA",
        "entity_id": "Lebret2014_HPCA",
        "name": "Hellinger PCA (HPCA)",
        "title": "",
        "year": "2014",
        "authors": [
          "Lebret, R.",
          "Collobert, R."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "Co-occurrence Matrices"
        ],
        "metrics": [
          "Square Root Transformation"
        ],
        "architecture": {
          "components": [
            "Principal Component Analysis"
          ],
          "connections": [
            "Hellinger Distance"
          ],
          "mechanisms": [
            "Dimensionality Reduction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Matrix Factorization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Statistical Information Transformation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lev2004_LogicPuzzles",
      "label": "Logic Puzzles Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lev2004_LogicPuzzles",
        "entity_id": "Lev2004_LogicPuzzles",
        "name": "Logic Puzzles Solver",
        "title": "",
        "year": "2004",
        "authors": [
          "Lev, I.",
          "MacCartney, B.",
          "Manning, C. D.",
          "Levy, R."
        ],
        "task": "[\"Solving logic puzzles\"]",
        "dataset": [
          "Various logic puzzle datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Robust natural language processing"
          ],
          "connections": [
            "Precise semantics"
          ],
          "mechanisms": [
            "Transforming robust natural language to precise semantics"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Model training"
          ],
          "parameter_tuning": [
            "Hyperparameter tuning"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Lev2004_SolvingLogicPuzzles",
      "label": "Solving Logic Puzzles",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lev2004_SolvingLogicPuzzles",
        "entity_id": "Lev2004_SolvingLogicPuzzles",
        "name": "Solving Logic Puzzles",
        "title": "",
        "year": "2004",
        "authors": [
          "Lev, I.",
          "MacCartney, B.",
          "Manning, C. D.",
          "Levy, R."
        ],
        "task": "[\"Transforming robust natural language to precise semantics\"]",
        "dataset": [
          "Logic puzzles"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Robust natural language processing"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Transforming to precise semantics"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Levy2014_PPMI",
      "label": "Positive Pointwise Mutual Information (PPMI)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Levy2014_PPMI",
        "entity_id": "Levy2014_PPMI",
        "name": "Positive Pointwise Mutual Information (PPMI)",
        "title": "",
        "year": "2014",
        "authors": [
          "Levy, O.",
          "Goldberg, Y.",
          "Ramat-Gan, I."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "Co-occurrence Matrices"
        ],
        "metrics": [
          "Pointwise Mutual Information"
        ],
        "architecture": {
          "components": [
            "Co-occurrence Matrix Transformation"
          ],
          "connections": [
            "Normalized Co-occurrence Counts"
          ],
          "mechanisms": [
            "Information-Theoretic Transformation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Matrix Transformation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Statistical Information Transformation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Li2016_SelfAttentionForQA",
      "label": "Self-Attention for Question Answering",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Li2016_SelfAttentionForQA",
        "entity_id": "Li2016_SelfAttentionForQA",
        "name": "Self-Attention for Question Answering",
        "title": "",
        "year": "2016",
        "authors": [
          "Li, P.",
          "Li, W.",
          "He, Z.",
          "Wang, X.",
          "Cao, Y.",
          "Zhou, J.",
          "Xu, W."
        ],
        "task": "[\"Question Answering\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Self-Attention Mechanism",
            "Factoid QA Model"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2009_LearningSemanticCorrespondences",
      "label": "Learning Semantic Correspondences",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2009_LearningSemanticCorrespondences",
        "entity_id": "Liang2009_LearningSemanticCorrespondences",
        "name": "Learning Semantic Correspondences",
        "title": "",
        "year": "2009",
        "authors": [
          "Liang, P.",
          "Jordan, M.",
          "Klein, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "ACL_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Correspondences",
            "Less Supervision"
          ],
          "connections": [
            "Semantic Parsing",
            "Correspondences"
          ],
          "mechanisms": [
            "Supervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Semantic Correspondences"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2011_LearningDependencyBasedCompositional",
      "label": "Learning Dependency-Based Compositional",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2011_LearningDependencyBasedCompositional",
        "entity_id": "Liang2011_LearningDependencyBasedCompositional",
        "name": "Learning Dependency-Based Compositional",
        "title": "",
        "year": "2011",
        "authors": [
          "Liang, P.",
          "Jordan, M.",
          "Klein, D."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "ACL_2011"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Dependency-Based Compositional",
            "Semantic Parsing"
          ],
          "connections": [
            "Dependency-Based",
            "Compositional"
          ],
          "mechanisms": [
            "Supervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Dependency-Based Compositional"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_ExplanationGenerator",
      "label": "Explanation Generator (EG)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_ExplanationGenerator",
        "entity_id": "Liang2016_ExplanationGenerator",
        "name": "Explanation Generator (EG)",
        "title": "",
        "year": "2016",
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "[\"Explanation Generation\"]",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "Reasoning Chain Interpreter",
            "Template-Based Explanation Generator"
          ],
          "connections": [
            "Reasoning Chain Parsing",
            "Template Application"
          ],
          "mechanisms": [
            "Explanation Text Generation",
            "Reasoning Chain Interpretation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Reasoning Chain Parsing",
          "Template Application"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_InferenceEngine",
      "label": "Inference Engine (IE)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_InferenceEngine",
        "entity_id": "Liang2016_InferenceEngine",
        "name": "Inference Engine (IE)",
        "title": "",
        "year": "2016",
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "[\"Logical Inference\"]",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "Inference Rules",
            "Mathematical Operation Utilities"
          ],
          "connections": [
            "Fact Selection",
            "Mathematical Operations"
          ],
          "mechanisms": [
            "Inference",
            "Fact Derivation",
            "Mathematical Computation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Fact Selection",
          "Mathematical Operation Execution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_LanguageAnalyzer",
      "label": "Language Analyzer (LA)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_LanguageAnalyzer",
        "entity_id": "Liang2016_LanguageAnalyzer",
        "name": "Language Analyzer (LA)",
        "title": "",
        "year": "2016",
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "Stanford CoreNLP suite"
          ],
          "connections": [
            "Tokenization",
            "Sentence Splitting",
            "POS Tagging",
            "Lemmatization",
            "Named Entity Recognition",
            "Parsing",
            "Co-reference Resolution"
          ],
          "mechanisms": [
            "Syntactic Tree Generation",
            "Dependency Relation Extraction",
            "Co-reference Chain Annotation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based Annotation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Tokenization",
          "POS Tagging",
          "Dependency Parsing",
          "Co-reference Resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_LogicFormConverter",
      "label": "Logic Form Converter (LFC)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_LogicFormConverter",
        "entity_id": "Liang2016_LogicFormConverter",
        "name": "Logic Form Converter (LFC)",
        "title": "",
        "year": "2016",
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "[\"Logical Representation Conversion\"]",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "First-Order Logic Predicate Generator"
          ],
          "connections": [
            "Deterministic Mapping Rules",
            "Dependency Structure Parsing"
          ],
          "mechanisms": [
            "Predicate Generation",
            "Logical Form Transformation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dependency Parsing",
          "Predicate Generation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_SolutionTypeClassifier",
      "label": "Solution Type Classifier (STC)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_SolutionTypeClassifier",
        "entity_id": "Liang2016_SolutionTypeClassifier",
        "name": "Solution Type Classifier (STC)",
        "title": "",
        "year": "2016",
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "[\"Mathematical Operation Classification\"]",
        "dataset": [
          "MA1_2014",
          "MA2_2014",
          "IXL_2014"
        ],
        "metrics": [
          "CrossValidationAccuracy"
        ],
        "architecture": {
          "components": [
            "SVM Classifier with Linear Kernel"
          ],
          "connections": [
            "Verb Category Features",
            "Keyword Indicators",
            "Pattern Matching Indicators"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Kernel Function Selection"
          ]
        },
        "feature_processing": [
          "Verb Category Feature Extraction",
          "Keyword Detection",
          "Pattern Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_TagBased",
      "label": "Tag-Based Approach",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_TagBased",
        "entity_id": "Liang2016_TagBased",
        "name": "Tag-Based Approach",
        "title": "",
        "year": "2016",
        "authors": [
          "Liang, C.",
          "Hsu, K.",
          "Huang, C.",
          "Li, C.",
          "Miao, S.",
          "Su, K."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_2014"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Tag Rules",
            "Logic Forms"
          ],
          "connections": [
            "Converting Variables",
            "Values to Logic Statements"
          ],
          "mechanisms": [
            "Inference Techniques"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based System"
          ],
          "parameter_tuning": [
            "Tag Annotation",
            "Rule Generation"
          ]
        },
        "feature_processing": [
          "Tag Annotation",
          "Rule Generation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_TagBasedApproach",
      "label": "Tag-Based Approach",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_TagBasedApproach",
        "entity_id": "Liang2016_TagBasedApproach",
        "name": "Tag-Based Approach",
        "title": "",
        "year": "2016",
        "authors": [
          "Liang, C.",
          "Hsu, K.",
          "Huang, C.",
          "Li, C.",
          "Miao, S.",
          "Su, K."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "TagBased_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Map Rules",
            "Logic Forms"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_TagBasedFramework",
      "label": "Tag-based Statistical Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_TagBasedFramework",
        "entity_id": "Liang2016_TagBasedFramework",
        "name": "Tag-based Statistical Framework",
        "title": "",
        "year": "2016",
        "authors": [
          "Chao-Chun Liang",
          "Kuang-Yi Hsu",
          "Chien-Tsung Huang",
          "Chung-Min Li",
          "Shen-Yu Miao",
          "Keh-Yih Su"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "MA1",
          "MA2",
          "IXL"
        ],
        "metrics": [
          "Accuracy",
          "Cross Validation Accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "LA -> STC -> LFC -> IE -> EG"
          ],
          "mechanisms": [
            "Tag-based annotation",
            "Logic inference",
            "Syntactic and semantic tagging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "SVM with linear kernel"
          ]
        },
        "feature_processing": [
          "Dependency parsing",
          "Co-reference resolution",
          "POS tagging",
          "Named entity recognition"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_TagBasedMathWordProblemSolver",
      "label": "Tag-Based Math Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_TagBasedMathWordProblemSolver",
        "entity_id": "Liang2016_TagBasedMathWordProblemSolver",
        "name": "Tag-Based Math Word Problem Solver",
        "title": "A Tag-based English Math Word Problem Solver with Understanding, Reasoning and Explanation",
        "year": "2016",
        "authors": [
          "Chao-Chun Liang",
          "Kuang-Yi Hsu",
          "Chien-Tsung Huang",
          "Chung-Min Li",
          "Shen-Yu Miao",
          "Keh-Yih Su"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "MA1",
          "IXL",
          "MA2"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "Syntactic Tree",
            "Co-Reference Chains",
            "Logic Forms",
            "Reasoning Chains"
          ],
          "mechanisms": [
            "Tag-Based Annotation",
            "Logic Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Support Vector Machines"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Verb Category Features",
          "Keyword Indicators",
          "Pattern-Matching Indicators"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_TagBasedMathWordProblemSolverWithExplanation",
      "label": "Tag-Based Math Word Problem Solver with Explanation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_TagBasedMathWordProblemSolverWithExplanation",
        "entity_id": "Liang2016_TagBasedMathWordProblemSolverWithExplanation",
        "name": "Tag-Based Math Word Problem Solver with Explanation",
        "title": "A Tag-based English Math Word Problem Solver with Understanding, Reasoning and Explanation",
        "year": "2016",
        "authors": [
          "Liang, C.-C.",
          "Hsu, K.-Y.",
          "Huang, C.-T.",
          "Li, C.-M.",
          "Miao, S.-Y.",
          "Su, K.-Y."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "MA1",
          "IXL",
          "MA2"
        ],
        "metrics": [
          "Accuracy",
          "Solution Type Accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "Syntactic Tree",
            "Logic Forms",
            "Domain Dependent Concepts"
          ],
          "mechanisms": [
            "Tag-Based Annotation",
            "Logic Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Statistical Classifiers",
            "SVM Classifier"
          ],
          "parameter_tuning": [
            "Feature Sets",
            "Kernel Functions"
          ]
        },
        "feature_processing": [
          "Verb Category Features",
          "Keyword Indicators",
          "Pattern-Matching Indicators"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_TagBasedMWP",
      "label": "Tag-based statistical MWP solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_TagBasedMWP",
        "entity_id": "Liang2016_TagBasedMWP",
        "name": "Tag-based statistical MWP solver",
        "title": "A Tag-based English Math Word Problem Solver with Understanding, Reasoning and Explanation",
        "year": "2016",
        "authors": [
          "Chao-Chun Liang",
          "Kuang-Yi Hsu",
          "Chien-Tsung Huang",
          "Chung-Min Li",
          "Shen-Yu Miao",
          "Keh-Yih Su"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "MA1",
          "MA2",
          "IXL"
        ],
        "metrics": [
          "Accuracy",
          "Cross-validation accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "LA -> STC -> LFC -> IE -> EG"
          ],
          "mechanisms": [
            "Tag-based annotation",
            "Logic inference",
            "First-order logic predicates"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning",
            "Rule-based logic inference"
          ],
          "parameter_tuning": [
            "SVM classifier with linear kernel"
          ]
        },
        "feature_processing": [
          "Dependency parsing",
          "Co-reference resolution",
          "POS tagging",
          "Named entity recognition"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liang2016_TagBasedSolver",
      "label": "Tag-based English Math Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liang2016_TagBasedSolver",
        "entity_id": "Liang2016_TagBasedSolver",
        "name": "Tag-based English Math Word Problem Solver",
        "title": "A Tag-based English Math Word Problem Solver with Understanding, Reasoning and Explanation",
        "year": "2016",
        "authors": [
          "Chao-Chun Liang",
          "Kuang-Yi Hsu",
          "Chien-Tsung Huang",
          "Chung-Min Li",
          "Shen-Yu Miao",
          "Keh-Yih Su"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy_Classification",
          "Solution_Type_Accuracy"
        ],
        "architecture": {
          "components": [
            "Language Analyzer",
            "Solution Type Classifier",
            "Logic Form Converter",
            "Inference Engine",
            "Explanation Generator"
          ],
          "connections": [
            "Pipeline"
          ],
          "mechanisms": [
            "Tag-based annotation",
            "First-order logic predicates",
            "Logic inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning",
            "SVM with linear kernel"
          ],
          "parameter_tuning": [
            "Feature extraction",
            "Pattern matching"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "POS tagging",
          "Named entity recognition",
          "Dependency parsing",
          "Co-reference resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liguda2012_AugmentedSemanticNetworks",
      "label": "Augmented Semantic Networks",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liguda2012_AugmentedSemanticNetworks",
        "entity_id": "Liguda2012_AugmentedSemanticNetworks",
        "name": "Augmented Semantic Networks",
        "title": "",
        "year": "2012",
        "authors": [
          "Liguda, C.",
          "Pfeiffer, T."
        ],
        "task": "[\"Modeling math word problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Semantic networks"
          ],
          "connections": [],
          "mechanisms": [
            "Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liguda2012_ModelingWordProblems",
      "label": "Modeling Word Problems",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liguda2012_ModelingWordProblems",
        "entity_id": "Liguda2012_ModelingWordProblems",
        "name": "Modeling Word Problems",
        "title": "",
        "year": "2012",
        "authors": [
          "Liguda, C.",
          "Pfeiffer, T."
        ],
        "task": "[\"Mathematical Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Augmented Semantic Networks"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin1998_BuildingDetection",
      "label": "Building Detection and Description",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin1998_BuildingDetection",
        "entity_id": "Lin1998_BuildingDetection",
        "name": "Building Detection and Description",
        "title": "Building Detection and Description from a Single Intensity Image",
        "year": "1998",
        "authors": [
          "C. Lin",
          "R. Nevatia"
        ],
        "task": "[\"Building Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Line Detection",
            "Anti-parallel Lines"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin1998_BuildingDetectionAndDescription",
      "label": "Building Detection and Description",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin1998_BuildingDetectionAndDescription",
        "entity_id": "Lin1998_BuildingDetectionAndDescription",
        "name": "Building Detection and Description",
        "title": "",
        "year": "1998",
        "authors": [
          "C. Lin",
          "R. Nevatia"
        ],
        "task": "[\"Building Detection\"]",
        "dataset": [
          "AerialImages_1998"
        ],
        "metrics": [
          "DetectionAccuracy"
        ],
        "architecture": {
          "components": [
            "Line Detection",
            "Anti-Parallel Line Search"
          ],
          "connections": [
            "Initial Line Segment to Search Region"
          ],
          "mechanisms": [
            "Defining Search Regions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Not Applicable"
          ]
        },
        "feature_processing": [
          "Line Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin1998_MINIPAR",
      "label": "MINIPAR",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin1998_MINIPAR",
        "entity_id": "Lin1998_MINIPAR",
        "name": "MINIPAR",
        "title": "",
        "year": "1998",
        "authors": [
          "Dekang Lin"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Dependency Parsing"
          ],
          "connections": [
            "Dependency Extraction Rules"
          ],
          "mechanisms": [
            "Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Rule-Based"
          ]
        },
        "feature_processing": [
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_BidirectionalLSTM",
      "label": "Bidirectional LSTM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_BidirectionalLSTM",
        "entity_id": "Lin2017_BidirectionalLSTM",
        "name": "Bidirectional LSTM",
        "title": "",
        "year": "2017",
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "[\"Sentence Embedding\"]",
        "dataset": [
          "Age dataset",
          "Yelp dataset",
          "SNLI dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "LSTM cells",
            "Forward LSTM",
            "Backward LSTM"
          ],
          "connections": [
            "Concatenation of forward and backward LSTM outputs"
          ],
          "mechanisms": [
            "Bidirectional processing of sequences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Batch size",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_GatedEncoder",
      "label": "Gated Encoder",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_GatedEncoder",
        "entity_id": "Lin2017_GatedEncoder",
        "name": "Gated Encoder",
        "title": "",
        "year": "2017",
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "[\"Textual Entailment\"]",
        "dataset": [
          "SNLI dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Factor matrices",
            "Multiplicative interactions"
          ],
          "connections": [
            "Three-way multiplicative interaction"
          ],
          "mechanisms": [
            "Encoding semantic relations between sentences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "AdaGrad"
          ],
          "parameter_tuning": [
            "Learning rate"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_MultiplicativeInteractions",
      "label": "Multiplicative Interactions",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_MultiplicativeInteractions",
        "entity_id": "Lin2017_MultiplicativeInteractions",
        "name": "Multiplicative Interactions",
        "title": "",
        "year": "2017",
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "[\"Textual Entailment\"]",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Matrix Embedding",
            "Gated Encoder"
          ],
          "connections": [
            "Three-way Multiplicative Interaction"
          ],
          "mechanisms": [
            "Factor Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Shared Parameters",
            "Independent Processing"
          ],
          "parameter_tuning": [
            "Weight Matrices"
          ]
        },
        "feature_processing": [
          "Batched Dot Product"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_PenalizationTerm",
      "label": "Penalization Term",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_PenalizationTerm",
        "entity_id": "Lin2017_PenalizationTerm",
        "name": "Penalization Term",
        "title": "",
        "year": "2017",
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "[\"Sentence Embedding\"]",
        "dataset": [
          "Age dataset",
          "Yelp dataset",
          "SNLI dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Frobenius norm",
            "Identity matrix"
          ],
          "connections": [
            "Dot product of annotation matrix and its transpose"
          ],
          "mechanisms": [
            "Encouraging diversity in attention weights"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Penalization coefficient"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_PrunedMLP",
      "label": "Pruned MLP",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_PrunedMLP",
        "entity_id": "Lin2017_PrunedMLP",
        "name": "Pruned MLP",
        "title": "",
        "year": "2017",
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "[\"Sentence Embedding\"]",
        "dataset": [
          "Age dataset",
          "Yelp dataset",
          "SNLI dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Hidden layers",
            "Weight pruning"
          ],
          "connections": [
            "Structured connections reflecting matrix embedding"
          ],
          "mechanisms": [
            "Reducing parameters in fully connected layer"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Number of hidden units",
            "Pruning parameters"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_SelfAttentionMechanism",
      "label": "Self-Attention Mechanism",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_SelfAttentionMechanism",
        "entity_id": "Lin2017_SelfAttentionMechanism",
        "name": "Self-Attention Mechanism",
        "title": "",
        "year": "2017",
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "[\"Sentence Embedding\"]",
        "dataset": [
          "Age_Dataset_2017",
          "Yelp_Dataset_2017",
          "SNLI_Dataset_2015"
        ],
        "metrics": [
          "ClassificationAccuracy_SentenceEmbedding"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Self-Attention Mechanism",
            "Fully Connected Layer",
            "Softmax Layer"
          ],
          "connections": [
            "Bidirectional LSTM -> Self-Attention Mechanism",
            "Self-Attention Mechanism -> Fully Connected Layer",
            "Fully Connected Layer -> Softmax Layer"
          ],
          "mechanisms": [
            "Self-Attention",
            "Penalization Term"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Hidden Unit Number",
            "Penalization Term Coefficient"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "LSTM Hidden States"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_SelfAttentiveEmbedding",
      "label": "Structured Self-attentive Sentence Embedding",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_SelfAttentiveEmbedding",
        "entity_id": "Lin2017_SelfAttentiveEmbedding",
        "name": "Structured Self-attentive Sentence Embedding",
        "title": "A Structured Self-attentive Sentence Embedding",
        "year": "2017",
        "authors": [
          "Lin, Z.",
          "Feng, M.",
          "dos Santos, C.N.",
          "Yu, M.",
          "Xiang, B.",
          "Zhou, B.",
          "Bengio, Y."
        ],
        "task": "[\"Sentence Embedding\"]",
        "dataset": [],
        "metrics": [
          "Performance Gain"
        ],
        "architecture": {
          "components": [
            "Self-Attention Mechanism",
            "Regularization Term"
          ],
          "connections": [
            "2-D Matrix Representation"
          ],
          "mechanisms": [
            "Interpretable Embedding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_StructuredSelfAttention",
      "label": "Structured Self-Attention",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_StructuredSelfAttention",
        "entity_id": "Lin2017_StructuredSelfAttention",
        "name": "Structured Self-Attention",
        "title": "",
        "year": "2017",
        "authors": [
          "Lin, Z.",
          "Feng, M.",
          "dos Santos, C.N.",
          "Yu, M.",
          "Xiang, B.",
          "Zhou, B.",
          "Bengio, Y."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM Encoder",
            "Multi-hop Attention"
          ],
          "connections": [
            "Bidirectional LSTM"
          ],
          "mechanisms": [
            "Self-Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training",
            "Cross entropy loss"
          ],
          "parameter_tuning": [
            "Attention hops",
            "Redundancy reduction"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "label": "Structured Self-Attentive Sentence Embedding",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
        "entity_id": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
        "name": "Structured Self-Attentive Sentence Embedding",
        "title": "A Structured Self-Attentive Sentence Embedding",
        "year": "2017",
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "[\"Sentence Embedding\"]",
        "dataset": [
          "Age Dataset",
          "Yelp Dataset",
          "SNLI Dataset"
        ],
        "metrics": [
          "Classification Accuracy"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Self-Attention Mechanism"
          ],
          "connections": [
            "Weighted Sum of Hidden States",
            "Annotation Matrix"
          ],
          "mechanisms": [
            "Self-Attention",
            "Penalization Term"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Hidden Unit Number",
            "Penalization Term Coefficient"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "POS Tag Embeddings",
          "Attention Weights"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_StructuredSelfAttentiveSentenceEmbeddingWithPenalization",
      "label": "Structured Self-Attentive Sentence Embedding with Penalization Term",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_StructuredSelfAttentiveSentenceEmbeddingWithPenalization",
        "entity_id": "Lin2017_StructuredSelfAttentiveSentenceEmbeddingWithPenalization",
        "name": "Structured Self-Attentive Sentence Embedding with Penalization Term",
        "title": "",
        "year": "2017",
        "authors": [
          "Zhouhan Lin",
          "Minwei Feng",
          "Cicero Nogueira dos Santos",
          "Mo Yu",
          "Bing Xiang",
          "Bowen Zhou",
          "Yoshua Bengio"
        ],
        "task": "[\"Sentence Embedding\"]",
        "dataset": [
          "Age_Dataset_2017",
          "Yelp_Dataset_2017",
          "SNLI_Dataset_2015"
        ],
        "metrics": [
          "ClassificationAccuracy_SentenceEmbedding"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Self-Attention Mechanism",
            "Penalization Term"
          ],
          "connections": [
            "Matrix Embedding",
            "Fully Connected Layer",
            "Softmax Layer"
          ],
          "mechanisms": [
            "Weighted Sum of Hidden States",
            "Dot Product",
            "Frobenius Norm"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Pruned MLP"
          ],
          "parameter_tuning": [
            "Hidden Unit Number",
            "Penalization Coefficient"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "LSTM Hidden States"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lin2017_StructuredSelfAttentiveSentenceEmbeddingWithPrunedMLP",
      "label": "Structured Self-Attentive Sentence Embedding with Pruned MLP",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lin2017_StructuredSelfAttentiveSentenceEmbeddingWithPrunedMLP",
        "entity_id": "Lin2017_StructuredSelfAttentiveSentenceEmbeddingWithPrunedMLP",
        "name": "Structured Self-Attentive Sentence Embedding with Pruned MLP",
        "title": "A Structured Self-attentive Sentence Embedding",
        "year": "2017",
        "authors": [
          "Lin, Z.",
          "Feng, M.",
          "dos Santos, C. N.",
          "Yu, M.",
          "Xiang, B.",
          "Zhou, B.",
          "Bengio, Y."
        ],
        "task": "[\"Sentence Embedding\"]",
        "dataset": [
          "Age Dataset",
          "Yelp Dataset",
          "SNLI Dataset"
        ],
        "metrics": [
          "Classification Accuracy",
          "Test Set Accuracy"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Self-Attention Mechanism",
            "Pruned MLP"
          ],
          "connections": [
            "Matrix Embedding",
            "Annotation Matrix",
            "Weight Pruning"
          ],
          "mechanisms": [
            "Self-Attention",
            "Penalization Term"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Hidden Unit Numbers",
            "Penalization Coefficient"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "LSTM Hidden States"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ling2015_AttentionBasedWordEmbedding",
      "label": "Attention-Based Word Embedding",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ling2015_AttentionBasedWordEmbedding",
        "entity_id": "Ling2015_AttentionBasedWordEmbedding",
        "name": "Attention-Based Word Embedding",
        "title": "",
        "year": "2015",
        "authors": [
          "Ling, W.",
          "Chu-Cheng, L.",
          "Tsvetkov, Y.",
          "Amir, S."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Attention Mechanism",
            "Word Embedding"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ling2017_AlgebraicWordProblems",
      "label": "Algebraic Word Problems Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ling2017_AlgebraicWordProblems",
        "entity_id": "Ling2017_AlgebraicWordProblems",
        "name": "Algebraic Word Problems Solver",
        "title": "",
        "year": "2017",
        "authors": [
          "Ling, W.",
          "Yogatama, D.",
          "Dyer, C.",
          "Blunsom, P."
        ],
        "task": "[\"Solving algebraic word problems\"]",
        "dataset": [
          "Algebraic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Sequence-to-sequence model"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Generating answer rationales"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Ling2017_AlgebraicWordProblemSolver",
      "label": "Algebraic Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ling2017_AlgebraicWordProblemSolver",
        "entity_id": "Ling2017_AlgebraicWordProblemSolver",
        "name": "Algebraic Word Problem Solver",
        "title": "",
        "year": "2017",
        "authors": [
          "Ling, W.",
          "Yogatama, D.",
          "Dyer, C.",
          "Blunsom, P."
        ],
        "task": "[\"Solving algebraic word problems\"]",
        "dataset": [
          "Various algebraic word problem datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Sequence-to-sequence model",
            "Answer rationale generation"
          ],
          "connections": [
            "Generating answer rationales in natural language"
          ],
          "mechanisms": [
            "Sequence-to-sequence learning",
            "Natural language generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Not specified"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Ling2017_ProgramInduction",
      "label": "Program Induction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ling2017_ProgramInduction",
        "entity_id": "Ling2017_ProgramInduction",
        "name": "Program Induction",
        "title": "",
        "year": "2017",
        "authors": [
          "Ling, W.",
          "Yogatama, D.",
          "Dyer, C.",
          "Blunsom, P."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Rationale Generation",
            "Equation Generation"
          ],
          "connections": [
            "Rationale to Equation"
          ],
          "mechanisms": [
            "Rationale-Based Equation Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Rationale Generation Parameters"
          ]
        },
        "feature_processing": [
          "Hand-Crafted Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liu2016a_SentenceLevelAttention",
      "label": "Sentence-Level Attention",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liu2016a_SentenceLevelAttention",
        "entity_id": "Liu2016a_SentenceLevelAttention",
        "name": "Sentence-Level Attention",
        "title": "",
        "year": "2016",
        "authors": [
          "Liu, Y.",
          "Sun, C.",
          "Lin, L.",
          "Wang, X."
        ],
        "task": "[\"Sentence Representation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Attention Mechanism",
            "LSTM"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Liu2016b_600DBiLSTMEncoders",
      "label": "600D(300+300) BiLSTM encoders",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Liu2016b_600DBiLSTMEncoders",
        "entity_id": "Liu2016b_600DBiLSTMEncoders",
        "name": "600D(300+300) BiLSTM encoders",
        "title": "",
        "year": "2016",
        "authors": [
          "Liu, Y.",
          "Sun, C.",
          "Lin, L.",
          "Wang, X."
        ],
        "task": "[\"Textual Entailment\"]",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM"
          ],
          "connections": [
            "Bidirectional"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lu2016_Hierarchical_Co_attention",
      "label": "Hierarchical Co-attention",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lu2016_Hierarchical_Co_attention",
        "entity_id": "Lu2016_Hierarchical_Co_attention",
        "name": "Hierarchical Co-attention",
        "title": "",
        "year": "2016",
        "authors": [
          "Jiasen Lu",
          "Jianwei Yang",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "VQA_v2.0"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "word-level",
            "phrase-level",
            "entire question-level"
          ],
          "connections": [
            "co-attention mechanism"
          ],
          "mechanisms": [
            "multi-level attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "re-training on balanced dataset"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "image features from VGGNet",
          "question features from LSTM"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lu2016_HierarchicalCoAttention",
      "label": "Hierarchical Co-attention",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lu2016_HierarchicalCoAttention",
        "entity_id": "Lu2016_HierarchicalCoAttention",
        "name": "Hierarchical Co-attention",
        "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
        "year": "2016",
        "authors": [
          "Yash Goyal",
          "Tejas Khot",
          "Douglas Summers-Stay",
          "Dhruv Batra",
          "Devi Parikh"
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Word-level attention",
            "Phrase-level attention",
            "Entire question-level attention"
          ],
          "connections": [
            "Co-attention mechanism"
          ],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Lund1996_HAL",
      "label": "Hyperspace Analogue to Language (HAL)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Lund1996_HAL",
        "entity_id": "Lund1996_HAL",
        "name": "Hyperspace Analogue to Language (HAL)",
        "title": "",
        "year": "1996",
        "authors": [
          "Lund, K.",
          "Burgess, C."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "Term-Term Matrices"
        ],
        "metrics": [
          "Co-occurrence Counts"
        ],
        "architecture": {
          "components": [
            "Matrix of Term-Term Co-occurrences"
          ],
          "connections": [
            "Word-Word Relationships"
          ],
          "mechanisms": [
            "Contextual Co-occurrence"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Global Matrix Factorization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2015_AttentionMechanism",
      "label": "Attention Mechanism",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2015_AttentionMechanism",
        "entity_id": "Luong2015_AttentionMechanism",
        "name": "Attention Mechanism",
        "title": "Effective approaches to attention-based neural machine translation",
        "year": "2015",
        "authors": [
          "Luong, Minh-Thang",
          "Pham, Hieu",
          "Manning, Christopher D."
        ],
        "task": "[\"Neural Machine Translation\"]",
        "dataset": [
          "WMT'15 English-German"
        ],
        "metrics": [
          "BLEU Score"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Attention Layer"
          ],
          "connections": [
            "Recurrent Neural Networks",
            "Long Short-Term Memory"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2015_GlobalAttentionModel",
      "label": "Global Attention Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2015_GlobalAttentionModel",
        "entity_id": "Luong2015_GlobalAttentionModel",
        "name": "Global Attention Model",
        "title": "",
        "year": "2015",
        "authors": [
          "Luong, T.",
          "Pham, H.",
          "Manning, C.D."
        ],
        "task": "[\"Sequence-to-Sequence Learning\"]",
        "dataset": [
          "PTB_2015",
          "IWSLT2014_GermanToEnglish"
        ],
        "metrics": [
          "BLEU_SentenceLevel",
          "UAS_Parsing",
          "LAS_Parsing"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder"
          ],
          "connections": [
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Global Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Standard Seq2Seq Training"
          ],
          "parameter_tuning": [
            "Mini-batch Adagrad"
          ]
        },
        "feature_processing": [
          "Word Embeddings Initialization",
          "Digit Normalization",
          "Singleton Words Replacement"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2015_InputFeeding",
      "label": "Input Feeding",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2015_InputFeeding",
        "entity_id": "Luong2015_InputFeeding",
        "name": "Input Feeding",
        "title": "",
        "year": "2015",
        "authors": [
          "Luong, T.",
          "Pham, H.",
          "Manning, C.D."
        ],
        "task": "[\"Neural Machine Translation\"]",
        "dataset": [
          "IWSLT2014_GermanToEnglish"
        ],
        "metrics": [
          "BLEU_SentenceLevel"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder",
            "Attention Mechanism"
          ],
          "connections": [
            "Input Feeding from Attention Distribution"
          ],
          "mechanisms": [
            "Attention Distribution Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Standard Word-Level Cross-Entropy Loss"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Gradient Clipping"
          ]
        },
        "feature_processing": [
          "Attention Distribution from Previous Time-Step"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2015_SequenceToSequenceLearning",
      "label": "Sequence to Sequence Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2015_SequenceToSequenceLearning",
        "entity_id": "Luong2015_SequenceToSequenceLearning",
        "name": "Sequence to Sequence Learning",
        "title": "Multi-task sequence to sequence learning",
        "year": "2015",
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "[\"Machine Translation, Constituency Parsing, Image Caption Generation\"]",
        "dataset": [
          "WMT'15 English-German",
          "Penn Tree Bank",
          "High-Confidence Corpus",
          "Image Captioning"
        ],
        "metrics": [
          "BLEU Score",
          "Perplexity",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks",
            "Long Short-Term Memory"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Embedding",
          "Reversing Input Sequences"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2016_AttentionFreeSeq2Seq",
      "label": "Attention-Free Sequence to Sequence Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2016_AttentionFreeSeq2Seq",
        "entity_id": "Luong2016_AttentionFreeSeq2Seq",
        "name": "Attention-Free Sequence to Sequence Model",
        "title": "",
        "year": "2016",
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "[\"Sequence to Sequence Learning\"]",
        "dataset": [
          "WMT'15 English-German Translation",
          "Penn Tree Bank Parsing",
          "High-Confidence Parsing Corpus"
        ],
        "metrics": [
          "BLEU",
          "F1",
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks"
          ],
          "mechanisms": [
            "No Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Multi-task Learning"
          ],
          "parameter_tuning": [
            "Mixing Ratios"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2016_ManyToManySetting",
      "label": "Many-to-Many Setting",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2016_ManyToManySetting",
        "entity_id": "Luong2016_ManyToManySetting",
        "name": "Many-to-Many Setting",
        "title": "",
        "year": "2016",
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "[\"Multi-task Sequence-to-Sequence Learning\"]",
        "dataset": [
          "WMT15_EnglishGermanTranslation_2015",
          "MonolingualCorpora_2015"
        ],
        "metrics": [
          "BLEU_Translation",
          "Perplexity_LanguageModeling"
        ],
        "architecture": {
          "components": [
            "Multiple Encoders",
            "Multiple Decoders"
          ],
          "connections": [
            "Shared Encoders and Decoders"
          ],
          "mechanisms": [
            "Parameter Sharing",
            "Unsupervised Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Mixing Ratios"
          ],
          "parameter_tuning": [
            "Mixing Coefficients"
          ]
        },
        "feature_processing": [
          "Sequence Processing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2016_ManyToOneSetting",
      "label": "Many-to-One Setting",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2016_ManyToOneSetting",
        "entity_id": "Luong2016_ManyToOneSetting",
        "name": "Many-to-One Setting",
        "title": "",
        "year": "2016",
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "[\"Multi-task Sequence-to-Sequence Learning\"]",
        "dataset": [
          "WMT15_EnglishGermanTranslation_2015",
          "ImageCaptionGeneration_2015"
        ],
        "metrics": [
          "BLEU_Translation",
          "Perplexity_LanguageModeling"
        ],
        "architecture": {
          "components": [
            "Multiple Encoders",
            "Single Decoder"
          ],
          "connections": [
            "Shared Decoder",
            "Separate Encoders"
          ],
          "mechanisms": [
            "Parameter Sharing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Mixing Ratios"
          ],
          "parameter_tuning": [
            "Mixing Coefficients"
          ]
        },
        "feature_processing": [
          "Sequence Processing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2016_MultiTaskSeq2Seq",
      "label": "Multi-task sequence to sequence learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2016_MultiTaskSeq2Seq",
        "entity_id": "Luong2016_MultiTaskSeq2Seq",
        "name": "Multi-task sequence to sequence learning",
        "title": "",
        "year": "2016",
        "authors": [
          "Minh-Thang Luong",
          "Quoc V. Le",
          "Ilya Sutskever",
          "Oriol Vinyals",
          "Lukasz Kaiser"
        ],
        "task": "[\"multi-task learning\"]",
        "dataset": [
          "WMT'15 English-German translation",
          "Penn Tree Bank parsing",
          "High-confidence parsing corpus",
          "image caption generation"
        ],
        "metrics": [
          "BLEU",
          "F1",
          "perplexity"
        ],
        "architecture": {
          "components": [
            "encoder",
            "decoder"
          ],
          "connections": [
            "recurrent connections",
            "embeddings"
          ],
          "mechanisms": [
            "attention mechanism",
            "autoencoder",
            "skip-thought vectors"
          ]
        },
        "methodology": {
          "training_strategy": [
            "one-to-many setting",
            "many-to-one setting",
            "many-to-many setting"
          ],
          "parameter_tuning": [
            "mixing ratio",
            "learning rate halving"
          ]
        },
        "feature_processing": [
          "input sequence reversal",
          "dropout"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2016_MultiTaskSequenceToSequenceLearning",
      "label": "Multi-task Sequence to Sequence Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2016_MultiTaskSequenceToSequenceLearning",
        "entity_id": "Luong2016_MultiTaskSequenceToSequenceLearning",
        "name": "Multi-task Sequence to Sequence Learning",
        "title": "MULTI-TASK SEQUENCE TO SEQUENCE LEARNING",
        "year": "2016",
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "[\"机器翻译、句法分析、图像字幕生成\"]",
        "dataset": [
          "WMT'15 English-German",
          "Penn Tree Bank",
          "High-Confidence Corpus",
          "Image Captioning"
        ],
        "metrics": [
          "BLEU Score",
          "Perplexity",
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "One-to-many",
            "Many-to-one",
            "Many-to-many"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Autoencoder",
            "Skip-thought Vectors"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Mixing Ratio",
            "Learning Rate"
          ]
        },
        "feature_processing": [
          "Monolingual Corpora",
          "Temporal Ordering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Luong2016_OneToManySetting",
      "label": "One-to-Many Setting",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Luong2016_OneToManySetting",
        "entity_id": "Luong2016_OneToManySetting",
        "name": "One-to-Many Setting",
        "title": "",
        "year": "2016",
        "authors": [
          "Luong, Minh-Thang",
          "Le, Quoc V.",
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Kaiser, Lukasz"
        ],
        "task": "[\"Multi-task Sequence-to-Sequence Learning\"]",
        "dataset": [
          "WMT15_EnglishGermanTranslation_2015",
          "PennTreeBankParsing_1993"
        ],
        "metrics": [
          "BLEU_Translation",
          "F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Multiple Decoders"
          ],
          "connections": [
            "Shared Encoder",
            "Separate Decoders"
          ],
          "mechanisms": [
            "Parameter Sharing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Mixing Ratios"
          ],
          "parameter_tuning": [
            "Mixing Coefficients"
          ]
        },
        "feature_processing": [
          "Sequence Processing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ma2010_ExecutiveControllingModule",
      "label": "Executive Controlling Module",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ma2010_ExecutiveControllingModule",
        "entity_id": "Ma2010_ExecutiveControllingModule",
        "name": "Executive Controlling Module",
        "title": "",
        "year": "2010",
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "[\"Coordinating system modules\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Goal stack",
            "Fact base",
            "Frame identification",
            "Working memory",
            "Rule base"
          ],
          "connections": [
            "Controls interaction between modules"
          ],
          "mechanisms": [
            "Determines current goal and triggers rule base"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ma2010_FrameBasedCalculus",
      "label": "Frame-Based Calculus",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ma2010_FrameBasedCalculus",
        "entity_id": "Ma2010_FrameBasedCalculus",
        "name": "Frame-Based Calculus",
        "title": "Frame-Based Calculus of solving Arithmetic Multi-Step Addition and Subtraction word problems",
        "year": "2010",
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "[\"Solving multi-step addition and subtraction word problems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "MSWPAS-NP",
            "MSWPAS-CP"
          ],
          "connections": [
            "Natural language processing",
            "Frame-based calculus"
          ],
          "mechanisms": [
            "Means-end Analysis",
            "Production rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Problem representation",
            "Planning",
            "Trying to solve and assessment"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Comprehending the natural language of problems",
          "Constructing problem frames"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ma2010_FrameIdentificationModule",
      "label": "Frame Identification Module",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ma2010_FrameIdentificationModule",
        "entity_id": "Ma2010_FrameIdentificationModule",
        "name": "Frame Identification Module",
        "title": "",
        "year": "2010",
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "[\"Identifying and selecting frames from fact base\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Object slot",
            "Specification slot",
            "Time slot",
            "Role slot"
          ],
          "connections": [
            "Identifies related frames based on slot values"
          ],
          "mechanisms": [
            "Slot value matching"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Identifies related propositions"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ma2010_MeansEndAnalysis",
      "label": "Means-end Analysis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ma2010_MeansEndAnalysis",
        "entity_id": "Ma2010_MeansEndAnalysis",
        "name": "Means-end Analysis",
        "title": "",
        "year": "2010",
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "[\"Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Present Object",
            "Desired Object",
            "Operator"
          ],
          "connections": [
            "Find Difference",
            "Apply Operator",
            "Transform Object"
          ],
          "mechanisms": [
            "Planning",
            "Sub-goal Generation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ma2010_MSMPAS_CP",
      "label": "MSWPAS-CP",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ma2010_MSMPAS_CP",
        "entity_id": "Ma2010_MSMPAS_CP",
        "name": "MSWPAS-CP",
        "title": "",
        "year": "2010",
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "[\"Solving multi-step addition and subtraction word problems\"]",
        "dataset": [
          "ChineseElementarySchoolTextbooks_2010"
        ],
        "metrics": [
          "Correctness_Solving"
        ],
        "architecture": {
          "components": [
            "Goal Stack",
            "Fact Base",
            "Frame Identification Module",
            "Working Memory",
            "Rule Base",
            "Executive Controlling Module"
          ],
          "connections": [
            "Goal Stack -> Executive Controlling Module",
            "Fact Base <-> Working Memory",
            "Frame Identification Module -> Working Memory",
            "Rule Base -> Working Memory"
          ],
          "mechanisms": [
            "Means-end Analysis",
            "Frame-based Calculus"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Problem Representation",
            "Planning",
            "Trying to Solve and Assessment"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Natural Language Processing",
          "Semantic Frame Construction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ma2010_ProductionRules",
      "label": "Production Rules",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ma2010_ProductionRules",
        "entity_id": "Ma2010_ProductionRules",
        "name": "Production Rules",
        "title": "",
        "year": "2010",
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "[\"Solving Multi-Step Addition and Subtraction Word Problems\"]",
        "dataset": [
          "ChineseElementarySchoolTextbooks_2010"
        ],
        "metrics": [
          "Correctness_Solving"
        ],
        "architecture": {
          "components": [
            "Rule Base",
            "Fact Base",
            "Working Memory",
            "Goal Stack",
            "Frame Identification Module",
            "Executive Controlling Module"
          ],
          "connections": [
            "Rule Base -> Fact Base",
            "Fact Base -> Working Memory",
            "Goal Stack -> Working Memory",
            "Frame Identification Module -> Working Memory",
            "Executive Controlling Module -> All Modules"
          ],
          "mechanisms": [
            "Means-end Analysis",
            "Frame-based Calculus"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Means-end Analysis"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Frame-based Representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ma2010_RuleBase",
      "label": "Rule Base",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ma2010_RuleBase",
        "entity_id": "Ma2010_RuleBase",
        "name": "Rule Base",
        "title": "",
        "year": "2010",
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "[\"Storing domain knowledge\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Production rules"
          ],
          "connections": [
            "Matches rules to current goal"
          ],
          "mechanisms": [
            "Expands when solving more problems"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ma2010_WorkingMemory",
      "label": "Working Memory",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ma2010_WorkingMemory",
        "entity_id": "Ma2010_WorkingMemory",
        "name": "Working Memory",
        "title": "",
        "year": "2010",
        "authors": [
          "Ma Yuhui",
          "Zhou Ying",
          "Cui Guangzuo",
          "Ren Yun",
          "Huang Ronghuai"
        ],
        "task": "[\"Simulating short-term memory\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Current goal",
            "Assignment frames",
            "Relation frame"
          ],
          "connections": [
            "Stores and updates current goal and related frames"
          ],
          "mechanisms": [
            "Reset when goal changes"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Maccartney2008_ModelingSemanticContainment",
      "label": "Modeling Semantic Containment and Exclusion",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Maccartney2008_ModelingSemanticContainment",
        "entity_id": "Maccartney2008_ModelingSemanticContainment",
        "name": "Modeling Semantic Containment and Exclusion",
        "title": "",
        "year": "2008",
        "authors": [
          "Maccartney, B.",
          "Manning, C."
        ],
        "task": "[\"Natural Language Inference\"]",
        "dataset": [
          "RTE Datasets"
        ],
        "metrics": [
          "Accuracy",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Semantic Containment Module",
            "Semantic Exclusion Module"
          ],
          "connections": [
            "Logical Inference Rules"
          ],
          "mechanisms": [
            "Monotonicity Verification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameters for Monotonicity"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Semantic Role Labeling"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Malinowski2014_MultiWorldQA",
      "label": "Multi-World Approach to Question Answering",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Malinowski2014_MultiWorldQA",
        "entity_id": "Malinowski2014_MultiWorldQA",
        "name": "Multi-World Approach to Question Answering",
        "title": "",
        "year": "2014",
        "authors": [
          "Malinowski, M.",
          "Fritz, M."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "MS COCO"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Uncertain Input Handling"
          ],
          "connections": [
            "Multi-World Model"
          ],
          "mechanisms": [
            "Scene Understanding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Uncertain Input Training"
          ],
          "parameter_tuning": [
            "Uncertainty Parameters"
          ]
        },
        "feature_processing": [
          "Scene Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Malinowski2015_NeuralQA",
      "label": "Neural-Based Approach to Answering Questions about Images",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Malinowski2015_NeuralQA",
        "entity_id": "Malinowski2015_NeuralQA",
        "name": "Neural-Based Approach to Answering Questions about Images",
        "title": "",
        "year": "2015",
        "authors": [
          "Malinowski, M.",
          "Rohrbach, M.",
          "Fritz, M."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "MS COCO"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Neural Network"
          ],
          "connections": [
            "Image and Question Fusion"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Neural Network Parameters"
          ]
        },
        "feature_processing": [
          "Image Features",
          "Question Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "MaltParser_2014",
      "label": "MaltParser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "MaltParser_2014",
        "entity_id": "MaltParser_2014",
        "name": "MaltParser",
        "title": "",
        "year": "2014",
        "authors": [
          "Joakim Nivre",
          "Johan Hall",
          "Jens Nilsson"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Stack",
            "Buffer",
            "Transition System"
          ],
          "connections": [
            "LEFT-ARC",
            "RIGHT-ARC",
            "SHIFT"
          ],
          "mechanisms": [
            "Feature Templates",
            "Liblinear Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stackproj",
            "Nivreeager"
          ],
          "parameter_tuning": [
            "Hyperparameters Tuning"
          ]
        },
        "feature_processing": [
          "Indicator Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "MathDQN2018_MathDQN",
      "label": "MathDQN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "MathDQN2018_MathDQN",
        "entity_id": "MathDQN2018_MathDQN",
        "name": "MathDQN",
        "title": "",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H.T."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Deep Q-Network",
            "Markov Decision Process"
          ],
          "connections": [
            "State Transition"
          ],
          "mechanisms": [
            "Reward Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Q-Network Parameters"
          ]
        },
        "feature_processing": [
          "Quantity Encoding",
          "Operator Selection"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Matuszek2012_JointModelOfLanguage",
      "label": "Joint Model of Language and Perception",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Matuszek2012_JointModelOfLanguage",
        "entity_id": "Matuszek2012_JointModelOfLanguage",
        "name": "Joint Model of Language and Perception",
        "title": "",
        "year": "2012",
        "authors": [
          "Matuszek, C.",
          "FitzGerald, N.",
          "Zettlemoyer, L.",
          "Bo, L.",
          "Fox, D."
        ],
        "task": "[\"Grounded Attribute Learning\"]",
        "dataset": [
          "ICML_2012"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Joint Model",
            "Language",
            "Perception"
          ],
          "connections": [
            "Language",
            "Perception"
          ],
          "mechanisms": [
            "Joint Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint Learning"
          ],
          "parameter_tuning": [
            "Joint Model"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mayberry1999_ShiftReduceConstituencyParser",
      "label": "Shift Reduce Constituency Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mayberry1999_ShiftReduceConstituencyParser",
        "entity_id": "Mayberry1999_ShiftReduceConstituencyParser",
        "name": "Shift Reduce Constituency Parser",
        "title": "",
        "year": "1999",
        "authors": [
          "Mayberry III, M.",
          "Miikkulainen, R."
        ],
        "task": "[\"Constituency Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Neural Network",
            "One-hot Word Representations"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Menchetti2005_WideCoverageProcessing",
      "label": "Wide Coverage Processing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Menchetti2005_WideCoverageProcessing",
        "entity_id": "Menchetti2005_WideCoverageProcessing",
        "name": "Wide Coverage Processing",
        "title": "",
        "year": "2005",
        "authors": [
          "Menchetti, S.",
          "Costa, F.",
          "Frasconi, P.",
          "Pontil, M."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Kernel Methods",
            "Neural Networks"
          ],
          "connections": [
            "Structured Data"
          ],
          "mechanisms": [
            "Pattern Recognition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Kernel Methods"
          ],
          "parameter_tuning": [
            "Kernel Parameters"
          ]
        },
        "feature_processing": [
          "Structured Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mi2016_AlignmentMechanism",
      "label": "Alignment Mechanism",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mi2016_AlignmentMechanism",
        "entity_id": "Mi2016_AlignmentMechanism",
        "name": "Alignment Mechanism",
        "title": "",
        "year": "2016",
        "authors": [
          "Mi, H.",
          "Wang, Z.",
          "Ittycheriah, A."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Supervised Alignment",
            "Cross Entropy Loss"
          ],
          "connections": [
            "Source Tokens",
            "Target Tokens"
          ],
          "mechanisms": [
            "True Alignment",
            "Predicted Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Token Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_AdditiveCompositionality",
      "label": "Additive Compositionality",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_AdditiveCompositionality",
        "entity_id": "Mikolov2013_AdditiveCompositionality",
        "name": "Additive Compositionality",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": "2013",
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "[\"Analogical Reasoning\"]",
        "dataset": [
          "Phrase Analogy Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Word Vectors",
            "Element-wise Addition"
          ],
          "connections": [
            "Vector Summation"
          ],
          "mechanisms": [
            "Linear Structure"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Skip-gram Model"
          ],
          "parameter_tuning": [
            "Vector Dimensionality"
          ]
        },
        "feature_processing": [
          "Vector Representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_CBOW",
      "label": "Continuous Bag-of-Words (CBOW) Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_CBOW",
        "entity_id": "Mikolov2013_CBOW",
        "name": "Continuous Bag-of-Words (CBOW) Model",
        "title": "",
        "year": "2013",
        "authors": [
          "Mikolov, T.",
          "Chen, K.",
          "Corrado, G.",
          "Dean, J."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Log Probability"
        ],
        "architecture": {
          "components": [
            "Single-Layer Architecture"
          ],
          "connections": [
            "Inner Product Between Word Vectors"
          ],
          "mechanisms": [
            "Prediction of Target Words"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Training"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_DistributedRepresentationsOfWordsAndPhrases",
      "label": "Distributed Representations of Words and Phrases",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_DistributedRepresentationsOfWordsAndPhrases",
        "entity_id": "Mikolov2013_DistributedRepresentationsOfWordsAndPhrases",
        "name": "Distributed Representations of Words and Phrases",
        "title": "",
        "year": "2013",
        "authors": [
          "Mikolov, T.",
          "Sutskever, I.",
          "Chen, K.",
          "Corrado, G.S.",
          "Dean, J."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Continuous Bag-of-Words",
            "Skip-gram"
          ],
          "connections": [
            "Negative Sampling"
          ],
          "mechanisms": [
            "Word Compositionality"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Window Size",
            "Embedding Dimension"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_HierarchicalSoftmax",
      "label": "Hierarchical Softmax",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_HierarchicalSoftmax",
        "entity_id": "Mikolov2013_HierarchicalSoftmax",
        "name": "Hierarchical Softmax",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": "2013",
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "News Articles"
        ],
        "metrics": [
          "Accuracy",
          "Training Speed"
        ],
        "architecture": {
          "components": [
            "Binary Tree",
            "Output Nodes"
          ],
          "connections": [
            "Root to Leaf"
          ],
          "mechanisms": [
            "Binary Tree Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of Frequent Words"
          ],
          "parameter_tuning": [
            "Tree Structure"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_NegativeSampling",
      "label": "Negative Sampling",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_NegativeSampling",
        "entity_id": "Mikolov2013_NegativeSampling",
        "name": "Negative Sampling",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": "2013",
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "News Articles"
        ],
        "metrics": [
          "Accuracy",
          "Training Speed"
        ],
        "architecture": {
          "components": [
            "Noise Distribution",
            "Logistic Regression"
          ],
          "connections": [
            "Target Word to Noise Samples"
          ],
          "mechanisms": [
            "Logistic Regression"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of Frequent Words"
          ],
          "parameter_tuning": [
            "Number of Negative Samples"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_PhraseSkipGram",
      "label": "Phrase Skip-gram",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_PhraseSkipGram",
        "entity_id": "Mikolov2013_PhraseSkipGram",
        "name": "Phrase Skip-gram",
        "title": "",
        "year": "2013",
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "[\"Learning vector representations for phrases\"]",
        "dataset": [
          "NewsArticles_2013"
        ],
        "metrics": [
          "Accuracy_PhraseAnalogy"
        ],
        "architecture": {
          "components": [
            "Skip-gram model",
            "Phrase identification"
          ],
          "connections": [
            "Word vectors",
            "Phrase vectors"
          ],
          "mechanisms": [
            "Data-driven phrase formation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of frequent words"
          ],
          "parameter_tuning": [
            "Dimensionality",
            "Context size",
            "Threshold for phrase formation"
          ]
        },
        "feature_processing": [
          "Phrase formation based on unigram and bigram counts"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_SkipGram",
      "label": "Skip-gram model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_SkipGram",
        "entity_id": "Mikolov2013_SkipGram",
        "name": "Skip-gram model",
        "title": "Distributed Representations of Words and Phrases and their Compositionality",
        "year": "2013",
        "authors": [
          "Mikolov, T.",
          "Sutskever, I.",
          "Chen, K.",
          "Corrado, G.",
          "Dean, J."
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "News Articles"
        ],
        "metrics": [
          "Accuracy",
          "Training Speed"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Output Layer"
          ],
          "connections": [
            "Input to Hidden",
            "Hidden to Output"
          ],
          "mechanisms": [
            "Negative Sampling",
            "Hierarchical Softmax"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of Frequent Words",
            "Negative Sampling"
          ],
          "parameter_tuning": [
            "Dimensionality",
            "Context Size"
          ]
        },
        "feature_processing": [
          "Word Tokenization",
          "Subsampling"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_SkipGramModel",
      "label": "Skip-Gram Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_SkipGramModel",
        "entity_id": "Mikolov2013_SkipGramModel",
        "name": "Skip-Gram Model",
        "title": "",
        "year": "2013",
        "authors": [
          "Mikolov, T.",
          "Sutskever, I.",
          "Chen, K.",
          "Corrado, G.S.",
          "Dean, J."
        ],
        "task": "[\"Verbal Comprehension Questions\"]",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_SkipGramWithSubsampling",
      "label": "Skip-gram with Subsampling",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_SkipGramWithSubsampling",
        "entity_id": "Mikolov2013_SkipGramWithSubsampling",
        "name": "Skip-gram with Subsampling",
        "title": "",
        "year": "2013",
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "[\"Word Representation Learning\"]",
        "dataset": [
          "NewsArticles_2013"
        ],
        "metrics": [
          "Accuracy_AnalogicalReasoning",
          "TrainingSpeed",
          "TotalAccuracy_AnalogicalReasoning",
          "SyntacticAccuracy_AnalogicalReasoning",
          "SemanticAccuracy_AnalogicalReasoning"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layer",
            "Output Layer"
          ],
          "connections": [
            "Input to Hidden",
            "Hidden to Output"
          ],
          "mechanisms": [
            "Subsampling of Frequent Words"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Subsampling of Frequent Words"
          ],
          "parameter_tuning": [
            "Threshold for Subsampling"
          ]
        },
        "feature_processing": [
          "Subsampling of Frequent Words"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mikolov2013_Subsampling",
      "label": "Subsampling of Frequent Words",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mikolov2013_Subsampling",
        "entity_id": "Mikolov2013_Subsampling",
        "name": "Subsampling of Frequent Words",
        "title": "",
        "year": "2013",
        "authors": [
          "Tomas Mikolov",
          "Ilya Sutskever",
          "Kai Chen",
          "Greg Corrado",
          "Jeffrey Dean"
        ],
        "task": "[\"Word Representation Learning\"]",
        "dataset": [
          "NewsArticles_2013"
        ],
        "metrics": [
          "TrainingSpeed",
          "Accuracy_AnalogicalReasoning"
        ],
        "architecture": {
          "components": [
            "Skip-gram model"
          ],
          "connections": [
            "Input word -> Context words"
          ],
          "mechanisms": [
            "Probability-based word discarding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Discard frequent words with probability"
          ],
          "parameter_tuning": [
            "Threshold t"
          ]
        },
        "feature_processing": [
          "Word frequency filtering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Milne2008_WikipediaMiner",
      "label": "WikipediaMiner",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Milne2008_WikipediaMiner",
        "entity_id": "Milne2008_WikipediaMiner",
        "name": "WikipediaMiner",
        "title": "",
        "year": "2008",
        "authors": [
          "Milne, D.",
          "Witten, I.H."
        ],
        "task": "[\"Named Entity Linking\"]",
        "dataset": [
          "ACE2004_NWIRE_2004"
        ],
        "metrics": [
          "F1_NEL"
        ],
        "architecture": {
          "components": [
            "mention linking",
            "semantic similarity"
          ],
          "connections": [
            "Wikipedia pages",
            "context"
          ],
          "mechanisms": [
            "disambiguation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "semantic scoring function"
          ],
          "parameter_tuning": [
            "n-gram statistics",
            "shared links"
          ]
        },
        "feature_processing": [
          "semantic similarity",
          "context"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_ChangeFormula",
      "label": "Change Formula",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_ChangeFormula",
        "entity_id": "Mitra2016_ChangeFormula",
        "name": "Change Formula",
        "title": "",
        "year": "2016",
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "[\"Solving Arithmetic Word Problems\"]",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Template",
            "Equation Generator"
          ],
          "connections": [
            "Variable Mapping",
            "Equation Formation"
          ],
          "mechanisms": [
            "Slot Filling",
            "Equation Translation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Log-linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Variable Extraction",
          "Attribute Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_ComparisonFormula",
      "label": "Comparison Formula",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_ComparisonFormula",
        "entity_id": "Mitra2016_ComparisonFormula",
        "name": "Comparison Formula",
        "title": "",
        "year": "2016",
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "[\"Solving Arithmetic Word Problems\"]",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Template",
            "Equation Generator"
          ],
          "connections": [
            "Variable Mapping",
            "Equation Formation"
          ],
          "mechanisms": [
            "Slot Filling",
            "Equation Translation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Log-linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Variable Extraction",
          "Attribute Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_EquationGeneration",
      "label": "Equation Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_EquationGeneration",
        "entity_id": "Mitra2016_EquationGeneration",
        "name": "Equation Generation",
        "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
        "year": "2016",
        "authors": [
          "Mitra, Arindam",
          "Baral, Chitta"
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Formula Application",
            "Feature Extraction",
            "Log-linear Model"
          ],
          "connections": [
            "Formula to Equation Mapping",
            "Feature Vector Calculation"
          ],
          "mechanisms": [
            "Probabilistic Model",
            "Parameter Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Stochastic Gradient Descent"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Semantic Relation Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_FeatureFunction",
      "label": "Feature Function",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_FeatureFunction",
        "entity_id": "Mitra2016_FeatureFunction",
        "name": "Feature Function",
        "title": "",
        "year": "2016",
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Variable Attributes",
            "Boolean Relations",
            "Semantic Relations"
          ],
          "connections": [
            "Attribute Matching",
            "Relation Computation"
          ],
          "mechanisms": [
            "Contextual Information Extraction",
            "Mathematical Relation Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Vector Computation"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "WordNet Integration",
          "ConceptNet Integration"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_Formula",
      "label": "Formula",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_Formula",
        "entity_id": "Mitra2016_Formula",
        "name": "Formula",
        "title": "",
        "year": "2016",
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_2014"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Template-Based Method",
            "Predefined Formulas"
          ],
          "connections": [
            "Mapping Identified Variables",
            "Attributes to Formulas"
          ],
          "mechanisms": [
            "Rule-Based Matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based System"
          ],
          "parameter_tuning": [
            "Formula Definition"
          ]
        },
        "feature_processing": [
          "Variable Identification",
          "Attribute Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_FormulaAlignment",
      "label": "Formula Alignment",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_FormulaAlignment",
        "entity_id": "Mitra2016_FormulaAlignment",
        "name": "Formula Alignment",
        "title": "",
        "year": "2016",
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [
          "Arithmetic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Formulas"
          ],
          "connections": [
            "Formula alignment"
          ],
          "mechanisms": [
            "Formula mapping"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Formula-based learning"
          ],
          "parameter_tuning": [
            "Formula parameters"
          ]
        },
        "feature_processing": [
          "Formula extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_FormulaApplication",
      "label": "Formula Application",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_FormulaApplication",
        "entity_id": "Mitra2016_FormulaApplication",
        "name": "Formula Application",
        "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
        "year": "2016",
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Part Whole",
            "Change",
            "Comparison"
          ],
          "connections": [
            "Mapping sentences to formulas",
            "Generating equations from formulas"
          ],
          "mechanisms": [
            "Log-linear model",
            "Feature extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Stochastic gradient descent"
          ]
        },
        "feature_processing": [
          "WordNet",
          "ConceptNet",
          "Stanford CoreNLP"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_FormulaBasedSolver",
      "label": "Formula-Based Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_FormulaBasedSolver",
        "entity_id": "Mitra2016_FormulaBasedSolver",
        "name": "Formula-Based Solver",
        "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
        "year": "2016",
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Variable Identification",
            "Formula Recognition",
            "Equation Generation"
          ],
          "connections": [
            "Part-Whole",
            "Change",
            "Comparison"
          ],
          "mechanisms": [
            "Log-linear Model",
            "Feature Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Parameter Vector θ"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Machine Readable Dictionaries",
          "Semantic Relations Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_FormulaLearning",
      "label": "Formula Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_FormulaLearning",
        "entity_id": "Mitra2016_FormulaLearning",
        "name": "Formula Learning",
        "title": "",
        "year": "2016",
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "[\"Simple Arithmetic Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Formula Usage"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_FormulaSolver",
      "label": "FormulaSolver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_FormulaSolver",
        "entity_id": "Mitra2016_FormulaSolver",
        "name": "FormulaSolver",
        "title": "Learning To Use Formulas To Solve Simple Arithmetic Problems",
        "year": "2016",
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Standard Primary School Test Questions"
        ],
        "metrics": [
          "Problem Solving Accuracy"
        ],
        "architecture": {
          "components": [
            "Variable Identifier",
            "Formula Recognizer",
            "Equation Generator"
          ],
          "connections": [
            "Variable to Formula Mapping"
          ],
          "mechanisms": [
            "Formula Recognition"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Formula Scoring"
          ]
        },
        "feature_processing": [
          "Variable Extraction",
          "Formula Recognition"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_LogLinearModel",
      "label": "Log-Linear Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_LogLinearModel",
        "entity_id": "Mitra2016_LogLinearModel",
        "name": "Log-Linear Model",
        "title": "",
        "year": "2016",
        "authors": [
          "Mitra, A.",
          "Baral, C."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Parameter Vector"
          ],
          "connections": [
            "Feature Vector Mapping",
            "Dot Product"
          ],
          "mechanisms": [
            "Log-Linear Probability Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Stochastic Gradient Descent"
          ],
          "parameter_tuning": [
            "Conditional Log-Likelihood Maximization"
          ]
        },
        "feature_processing": [
          "Variable Attributes Extraction",
          "Boolean Relation Computation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mitra2016_PartWholeFormula",
      "label": "Part Whole Formula",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mitra2016_PartWholeFormula",
        "entity_id": "Mitra2016_PartWholeFormula",
        "name": "Part Whole Formula",
        "title": "",
        "year": "2016",
        "authors": [
          "Arindam Mitra",
          "Chitta Baral"
        ],
        "task": "[\"Solving Arithmetic Word Problems\"]",
        "dataset": [
          "AddSub_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Template",
            "Equation Generator"
          ],
          "connections": [
            "Variable Mapping",
            "Equation Formation"
          ],
          "mechanisms": [
            "Slot Filling",
            "Equation Translation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Log-linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Variable Extraction",
          "Attribute Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mnih2013_vLBL",
      "label": "Vector Log-Bilinear Model (vLBL)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mnih2013_vLBL",
        "entity_id": "Mnih2013_vLBL",
        "name": "Vector Log-Bilinear Model (vLBL)",
        "title": "",
        "year": "2013",
        "authors": [
          "Mnih, A.",
          "Kavukcuoglu, K."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "Text Corpora"
        ],
        "metrics": [
          "Log Probability"
        ],
        "architecture": {
          "components": [
            "Single-Layer Architecture"
          ],
          "connections": [
            "Inner Product Between Word Vectors"
          ],
          "mechanisms": [
            "Prediction of Context Words"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Training"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Contextual Information Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Mou2015a_300DTreeBasedCNNEncoders",
      "label": "300D Tree-based CNN encoders",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Mou2015a_300DTreeBasedCNNEncoders",
        "entity_id": "Mou2015a_300DTreeBasedCNNEncoders",
        "name": "300D Tree-based CNN encoders",
        "title": "",
        "year": "2015",
        "authors": [
          "Mou, L.",
          "Men, R.",
          "Li, G.",
          "Xu, Y.",
          "Zhang, L.",
          "Yan, R.",
          "Jin, Z."
        ],
        "task": "[\"Textual Entailment\"]",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "CNN",
            "Tree-based"
          ],
          "connections": [
            "Convolutional"
          ],
          "mechanisms": [
            "Hierarchical"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "MSTParser_2014",
      "label": "MSTParser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "MSTParser_2014",
        "entity_id": "MSTParser_2014",
        "name": "MSTParser",
        "title": "",
        "year": "2014",
        "authors": [
          "Ryan McDonald",
          "Fernando Pereira"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "English_Penn_Treebank_2014",
          "Chinese_Penn_Treebank_2014"
        ],
        "metrics": [
          "Unlabeled_Attachment_Score_Parsing",
          "Labeled_Attachment_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Graph-Based Parser"
          ],
          "connections": [
            "First-Order Graph"
          ],
          "mechanisms": [
            "Default Options"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Default Options"
          ],
          "parameter_tuning": [
            "Hyperparameters Tuning"
          ]
        },
        "feature_processing": [
          "Indicator Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Munkhdalai2016a_300DNTISLSTMLSTMEncoders",
      "label": "300D NTI-SLSTM-LSTM encoders",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Munkhdalai2016a_300DNTISLSTMLSTMEncoders",
        "entity_id": "Munkhdalai2016a_300DNTISLSTMLSTMEncoders",
        "name": "300D NTI-SLSTM-LSTM encoders",
        "title": "",
        "year": "2016",
        "authors": [
          "Munkhdalai, T.",
          "Yu, H."
        ],
        "task": "[\"Textual Entailment\"]",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "NTI-SLSTM",
            "LSTM"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Munkhdalai2016b_300DNSEEncoders",
      "label": "300D NSE encoders",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Munkhdalai2016b_300DNSEEncoders",
        "entity_id": "Munkhdalai2016b_300DNSEEncoders",
        "name": "300D NSE encoders",
        "title": "",
        "year": "2016",
        "authors": [
          "Munkhdalai, T.",
          "Yu, H."
        ],
        "task": "[\"Textual Entailment\"]",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "NSE"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Neelakantan2014_EfficientNonParametricEstimation",
      "label": "Efficient Non-Parametric Estimation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Neelakantan2014_EfficientNonParametricEstimation",
        "entity_id": "Neelakantan2014_EfficientNonParametricEstimation",
        "name": "Efficient Non-Parametric Estimation",
        "title": "",
        "year": "2014",
        "authors": [
          "Neelakantan, A.",
          "Shankar, J.",
          "Passos, A.",
          "McCallum, A."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Multiple Embeddings per Word"
          ],
          "connections": [
            "Vector Space"
          ],
          "mechanisms": [
            "Non-Parametric Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "Number of Embeddings"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ng2002_BestLinkDecisionModel",
      "label": "Best-Link Decision Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ng2002_BestLinkDecisionModel",
        "entity_id": "Ng2002_BestLinkDecisionModel",
        "name": "Best-Link Decision Model",
        "title": "",
        "year": "2002",
        "authors": [
          "Ng, V.",
          "Cardie, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function",
            "Document-Level Decision Model"
          ],
          "connections": [
            "Pairwise Coreference Function -> Document-Level Decision Model"
          ],
          "mechanisms": [
            "Best-Link Antecedent Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Threshold Optimization"
          ]
        },
        "feature_processing": [
          "Pairwise Coreference Scoring"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ng2002_ClosestLinkMethod",
      "label": "Closest-Link Method",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ng2002_ClosestLinkMethod",
        "entity_id": "Ng2002_ClosestLinkMethod",
        "name": "Closest-Link Method",
        "title": "",
        "year": "2002",
        "authors": [
          "Ng, V.",
          "Cardie, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004_2004"
        ],
        "metrics": [
          "B-Cubed_F-Score_Coreference"
        ],
        "architecture": {
          "components": [
            "Pairwise Coreference Function",
            "Document-Level Decision Model"
          ],
          "connections": [
            "Pairwise Coreference Function -> Document-Level Decision Model"
          ],
          "mechanisms": [
            "Closest-Link Antecedent Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Threshold Optimization"
          ]
        },
        "feature_processing": [
          "Pairwise Coreference Scoring"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1976_ISAAC",
      "label": "ISAAC",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1976_ISAAC",
        "entity_id": "Novak1976_ISAAC",
        "name": "ISAAC",
        "title": "",
        "year": "1976",
        "authors": [
          "Novak, G. S."
        ],
        "task": "[\"Physics Problem Solving\"]",
        "dataset": [
          "College-Level Physics Problems"
        ],
        "metrics": [
          "Correctness of Solution"
        ],
        "architecture": {
          "components": [
            "English Parser",
            "Equation Solver",
            "Diagram Generator"
          ],
          "connections": [
            "Text Parsing -> Equation Solving -> Diagram Generation"
          ],
          "mechanisms": [
            "Natural Language Processing",
            "Symbolic Reasoning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Parsing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntax Parsing",
          "Semantic Analysis"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1985_BEATRIX",
      "label": "BEATRIX",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1985_BEATRIX",
        "entity_id": "Novak1985_BEATRIX",
        "name": "BEATRIX",
        "title": "Understanding Natural Language with Diagrams",
        "year": "1985",
        "authors": [
          "Novak, G."
        ],
        "task": "[\"Physics Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Correctness"
        ],
        "architecture": {
          "components": [
            "English Parser",
            "Diagram Parser",
            "Blackboard Architecture"
          ],
          "connections": [
            "Coreference Resolution"
          ],
          "mechanisms": [
            "Opportunistic Co-parsers"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Propositional Representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_ATNParser",
      "label": "ATN Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_ATNParser",
        "entity_id": "Novak1990_ATNParser",
        "name": "ATN Parser",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S."
        ],
        "task": "[\"Natural Language Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Augmented Transition Network"
          ],
          "connections": [
            "State transitions"
          ],
          "mechanisms": [
            "Parsing rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based parsing"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Part-of-speech tagging"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_AugmentedTransitionNetworkGrammar",
      "label": "Augmented Transition Network Grammar",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_AugmentedTransitionNetworkGrammar",
        "entity_id": "Novak1990_AugmentedTransitionNetworkGrammar",
        "name": "Augmented Transition Network Grammar",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S."
        ],
        "task": "[\"English Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Grammar Rules",
            "Parse Tree"
          ],
          "connections": [
            "Input Sentence to Parse Tree"
          ],
          "mechanisms": [
            "Top-down Parsing",
            "Semantic Delay"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Noun Phrase Parsing",
          "Verb Clause Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_BEATRIX",
      "label": "BEATRIX",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_BEATRIX",
        "entity_id": "Novak1990_BEATRIX",
        "name": "BEATRIX",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S.",
          "Bulko, W. C."
        ],
        "task": "[\"Understanding textbook physics problems specified by a combination of English text and a diagram\"]",
        "dataset": [
          "Custom_Arithmetic_Problems_1986"
        ],
        "metrics": [
          "Accuracy_SolvingArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "English Parser",
            "Diagram Parser",
            "Coreference Resolver"
          ],
          "connections": [
            "English Parser -> Coreference Resolver",
            "Diagram Parser -> Coreference Resolver"
          ],
          "mechanisms": [
            "Opportunistic co-parsing",
            "Blackboard architecture"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based parsing",
            "Production system"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Meaning postulates",
          "Arithmetic strategies",
          "Problem-solving procedures"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_BlackboardArchitecture",
      "label": "Blackboard Architecture",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_BlackboardArchitecture",
        "entity_id": "Novak1990_BlackboardArchitecture",
        "name": "Blackboard Architecture",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S.",
          "Bulko, W."
        ],
        "task": "[\"Understanding Natural Language with Diagrams\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "TEXT",
            "PICTURE",
            "TEXT-MODEL",
            "PICTURE-MODEL",
            "PROBLEM-MODEL"
          ],
          "connections": [
            "TEXT to TEXT-MODEL",
            "PICTURE to PICTURE-MODEL",
            "TEXT-MODEL and PICTURE-MODEL to PROBLEM-MODEL"
          ],
          "mechanisms": [
            "Opportunistic Co-parsing",
            "Coreference Resolution",
            "Semantic Inference"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Recognition",
          "Semantic Processing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_DiagramParsingKS",
      "label": "Diagram Parsing Knowledge Sources",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_DiagramParsingKS",
        "entity_id": "Novak1990_DiagramParsingKS",
        "name": "Diagram Parsing Knowledge Sources",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G."
        ],
        "task": "[\"Diagram Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Knowledge sources",
            "Picture elements"
          ],
          "connections": [
            "Recognition of related groups of diagram elements"
          ],
          "mechanisms": [
            "Syntactic recognition",
            "Triggering additional KS’s"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parsing diagram elements"
          ],
          "parameter_tuning": [
            "None mentioned"
          ]
        },
        "feature_processing": [
          "Local analysis of combinations of diagram elements"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_FindCOEF",
      "label": "Find-COEF",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_FindCOEF",
        "entity_id": "Novak1990_FindCOEF",
        "name": "Find-COEF",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Coefficient matching"
          ],
          "connections": [
            "Text and diagram correlation"
          ],
          "mechanisms": [
            "Feature alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based matching"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Coefficient detection",
          "Surface contact"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_IdentifyPulleySystem",
      "label": "Identify-Pulley-System",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_IdentifyPulleySystem",
        "entity_id": "Novak1990_IdentifyPulleySystem",
        "name": "Identify-Pulley-System",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S."
        ],
        "task": "[\"Diagram Interpretation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Pulley recognition"
          ],
          "connections": [
            "Pulley and rope relationships"
          ],
          "mechanisms": [
            "Component association"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based recognition"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Circle detection",
          "Line intersection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_KnowledgeSources",
      "label": "Knowledge Sources",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_KnowledgeSources",
        "entity_id": "Novak1990_KnowledgeSources",
        "name": "Knowledge Sources",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S.",
          "Bulko, W."
        ],
        "task": "[\"Physics Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Control KS",
            "Identify KS",
            "Parse KS",
            "Match KS",
            "Retrieve KS",
            "Semantic KS",
            "Special KS"
          ],
          "connections": [
            "TEXT",
            "PICTURE",
            "TEXT-MODEL",
            "PICTURE-MODEL",
            "PROBLEM-MODEL"
          ],
          "mechanisms": [
            "Coreference Resolution",
            "Syntactic Recognition",
            "Semantic Processing"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_MatchNormalForce",
      "label": "Match-Normal-Force",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_MatchNormalForce",
        "entity_id": "Novak1990_MatchNormalForce",
        "name": "Match-Normal-Force",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Force matching"
          ],
          "connections": [
            "Text and diagram correlation"
          ],
          "mechanisms": [
            "Feature alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based matching"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Force detection",
          "Surface contact"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_PictureGrammar",
      "label": "Picture Grammar",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_PictureGrammar",
        "entity_id": "Novak1990_PictureGrammar",
        "name": "Picture Grammar",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S."
        ],
        "task": "[\"Diagram Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Diagram Elements",
            "Combinations of Elements"
          ],
          "connections": [
            "Element Combinations to Meaningful Groupings"
          ],
          "mechanisms": [
            "Syntactic Recognition",
            "Forward Inference"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Line Recognition",
          "Circle Recognition",
          "Angle Recognition"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_PostTheProblem",
      "label": "Post-the-Problem",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_PostTheProblem",
        "entity_id": "Novak1990_PostTheProblem",
        "name": "Post-the-Problem",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S."
        ],
        "task": "[\"Initialization\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Text and diagram posting"
          ],
          "connections": [
            "Blackboard initialization"
          ],
          "mechanisms": [
            "Data placement"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based initialization"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Text parsing",
          "Diagram parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_PropagateAngleROTN",
      "label": "Propagate-Angle-ROTN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_PropagateAngleROTN",
        "entity_id": "Novak1990_PropagateAngleROTN",
        "name": "Propagate-Angle-ROTN",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G. S."
        ],
        "task": "[\"Diagram Interpretation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Angle propagation"
          ],
          "connections": [
            "Angle relationships"
          ],
          "mechanisms": [
            "Rotation inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based inference"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Angle detection",
          "Surface orientation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_TransitionNetworkParser",
      "label": "Transition Network Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_TransitionNetworkParser",
        "entity_id": "Novak1990_TransitionNetworkParser",
        "name": "Transition Network Parser",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G."
        ],
        "task": "[\"Natural Language Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "ATN Grammar",
            "Meta-language"
          ],
          "connections": [
            "Parsing of sentences",
            "Semantic networks or case frames"
          ],
          "mechanisms": [
            "Syntactic parsing",
            "Top-down parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parsing English text"
          ],
          "parameter_tuning": [
            "None mentioned"
          ]
        },
        "feature_processing": [
          "Deferred semantic processing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Novak1990_UnderstandingModule",
      "label": "Understanding Module",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Novak1990_UnderstandingModule",
        "entity_id": "Novak1990_UnderstandingModule",
        "name": "Understanding Module",
        "title": "",
        "year": "1990",
        "authors": [
          "Novak, G."
        ],
        "task": "[\"Unified Model Creation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Text and diagram parsing",
            "Semantic processing"
          ],
          "connections": [
            "TEXT-MODEL and PICTURE-MODEL levels",
            "PROBLEM-MODEL level"
          ],
          "mechanisms": [
            "Coreference resolution",
            "Property inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Controlled parsing of text and diagram"
          ],
          "parameter_tuning": [
            "None mentioned"
          ]
        },
        "feature_processing": [
          "Forward inferences",
          "Common-sense physics"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Parikh2016_DecomposableAttentionModel",
      "label": "Decomposable Attention Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Parikh2016_DecomposableAttentionModel",
        "entity_id": "Parikh2016_DecomposableAttentionModel",
        "name": "Decomposable Attention Model",
        "title": "",
        "year": "2016",
        "authors": [
          "Parikh, A.P.",
          "Tackstrom, O.",
          "Das, D.",
          "Uszkoreit, J."
        ],
        "task": "[\"Natural Language Inference\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Attention Mechanism"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Pennington2014_AsymmetricContextWindow",
      "label": "Asymmetric Context Window",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Pennington2014_AsymmetricContextWindow",
        "entity_id": "Pennington2014_AsymmetricContextWindow",
        "name": "Asymmetric Context Window",
        "title": "",
        "year": "2014",
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C.D."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "Wikipedia_2014",
          "Gigaword_5"
        ],
        "metrics": [
          "Accuracy_Analogy"
        ],
        "architecture": {
          "components": [
            "Word Vectors",
            "Context Vectors"
          ],
          "connections": [
            "Dot Product"
          ],
          "mechanisms": [
            "Weighted Least Squares Regression"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Asymmetric Context Window"
          ],
          "parameter_tuning": [
            "Vector Dimension",
            "Context Window Size"
          ]
        },
        "feature_processing": [
          "Co-occurrence Counts"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Pennington2014_GloVe",
      "label": "GloVe",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Pennington2014_GloVe",
        "entity_id": "Pennington2014_GloVe",
        "name": "GloVe",
        "title": "",
        "year": "2014",
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C."
        ],
        "task": "[\"Word Embedding\"]",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "None"
        ],
        "architecture": {
          "components": [
            "Global Vectors"
          ],
          "connections": [
            "Word co-occurrence matrix"
          ],
          "mechanisms": [
            "Matrix factorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised learning"
          ],
          "parameter_tuning": [
            "Vector dimension"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Pennington2014_GloVeModel",
      "label": "GloVe Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Pennington2014_GloVeModel",
        "entity_id": "Pennington2014_GloVeModel",
        "name": "GloVe Model",
        "title": "",
        "year": "2014",
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C.D."
        ],
        "task": "[\"Verbal Comprehension Questions\"]",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Pennington2014_SymmetricContextWindow",
      "label": "Symmetric Context Window",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Pennington2014_SymmetricContextWindow",
        "entity_id": "Pennington2014_SymmetricContextWindow",
        "name": "Symmetric Context Window",
        "title": "",
        "year": "2014",
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C.D."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "Wikipedia_2014",
          "Gigaword_5"
        ],
        "metrics": [
          "Accuracy_Analogy"
        ],
        "architecture": {
          "components": [
            "Word Vectors",
            "Context Vectors"
          ],
          "connections": [
            "Dot Product"
          ],
          "mechanisms": [
            "Weighted Least Squares Regression"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Symmetric Context Window"
          ],
          "parameter_tuning": [
            "Vector Dimension",
            "Context Window Size"
          ]
        },
        "feature_processing": [
          "Co-occurrence Counts"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Pennington2014_WeightedLeastSquaresRegression",
      "label": "Weighted Least Squares Regression",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Pennington2014_WeightedLeastSquaresRegression",
        "entity_id": "Pennington2014_WeightedLeastSquaresRegression",
        "name": "Weighted Least Squares Regression",
        "title": "",
        "year": "2014",
        "authors": [
          "Pennington, J.",
          "Socher, R.",
          "Manning, C.D."
        ],
        "task": "[\"Word Representation Learning\"]",
        "dataset": [
          "Wikipedia_2010",
          "Wikipedia_2014",
          "Gigaword_5",
          "Common_Crawl"
        ],
        "metrics": [
          "Accuracy_Analogy",
          "Spearman_Rank_Correlation_Similarity"
        ],
        "architecture": {
          "components": [
            "Weighting Function",
            "Logarithmic Transformation"
          ],
          "connections": [
            "Co-occurrence Matrix",
            "Vector Differences"
          ],
          "mechanisms": [
            "Global Statistics Utilization",
            "Efficient Statistical Information Leveraging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "AdaGrad"
          ],
          "parameter_tuning": [
            "xmax=100",
            "α=3/4"
          ]
        },
        "feature_processing": [
          "Co-occurrence Counts",
          "Context Window"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Peters2018_ELMo",
      "label": "ELMo",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Peters2018_ELMo",
        "entity_id": "Peters2018_ELMo",
        "name": "ELMo",
        "title": "",
        "year": "2018",
        "authors": [
          "Peters, M.E.",
          "Neumann, M.",
          "Iyyer, M.",
          "Gardner, M.",
          "Clark, C.",
          "Lee, K.",
          "Zettlemoyer, L."
        ],
        "task": "[\"Word Embedding\"]",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "None"
        ],
        "architecture": {
          "components": [
            "Character embeddings",
            "Bidirectional LSTM"
          ],
          "connections": [
            "Character-level CNN"
          ],
          "mechanisms": [
            "Contextualized word representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised learning"
          ],
          "parameter_tuning": [
            "Layer weights"
          ]
        },
        "feature_processing": [
          "Character embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Petrov2006_LearningAlgorithmForSplittingCategories",
      "label": "Learning Algorithm for Splitting Categories",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Petrov2006_LearningAlgorithmForSplittingCategories",
        "entity_id": "Petrov2006_LearningAlgorithmForSplittingCategories",
        "name": "Learning Algorithm for Splitting Categories",
        "title": "",
        "year": "2006",
        "authors": [
          "Petrov, S.",
          "Klein, D."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Subcategories",
            "Splitting Rules"
          ],
          "connections": [
            "Category Splitting"
          ],
          "mechanisms": [
            "Likelihood Maximization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Split and Merge"
          ],
          "parameter_tuning": [
            "Subcategory Parameters"
          ]
        },
        "feature_processing": [
          "Syntactic Categories"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Poincare1902_MechanicalRules",
      "label": "Mechanical Rules",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Poincare1902_MechanicalRules",
        "entity_id": "Poincare1902_MechanicalRules",
        "name": "Mechanical Rules",
        "title": "",
        "year": "1902",
        "authors": [
          "Poincare, H."
        ],
        "task": "[\"Geometry Theorem Proving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Purely mechanical rules"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Axioms application without understanding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Polozov2015_PersonalizedMathProblemGenerator",
      "label": "Personalized Math Problem Generator",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Polozov2015_PersonalizedMathProblemGenerator",
        "entity_id": "Polozov2015_PersonalizedMathProblemGenerator",
        "name": "Personalized Math Problem Generator",
        "title": "",
        "year": "2015",
        "authors": [
          "Polozov, O.",
          "O’Rourke, E.",
          "Smith, A. M.",
          "Zettlemoyer, L.",
          "Gulwani, S.",
          "Popovic, Z."
        ],
        "task": "[\"Generating personalized math problems\"]",
        "dataset": [
          "Various math problem datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Answer Set Programming"
          ],
          "connections": [
            "Pedagogical and narrative requirements"
          ],
          "mechanisms": [
            "Generating coherent and personalized story problems"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Model training"
          ],
          "parameter_tuning": [
            "Hyperparameter tuning"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Polozov2015_PersonalizedWordProblemGeneration",
      "label": "Personalized Word Problem Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Polozov2015_PersonalizedWordProblemGeneration",
        "entity_id": "Polozov2015_PersonalizedWordProblemGeneration",
        "name": "Personalized Word Problem Generation",
        "title": "",
        "year": "2015",
        "authors": [
          "Polozov, O.",
          "O’Rourke, E.",
          "Smith, A. M.",
          "Zettlemoyer, L.",
          "Gulwani, S.",
          "Popovic, Z."
        ],
        "task": "[\"Generating personalized mathematical word problems\"]",
        "dataset": [
          "Mathematical word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Answer Set Programming"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Generating coherent and personalized story problems"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "PougetAbadie2014_AutomaticSegmentation",
      "label": "Overcoming the Curse of Sentence Length for Neural Machine Translation Using Automatic Segmentation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "PougetAbadie2014_AutomaticSegmentation",
        "entity_id": "PougetAbadie2014_AutomaticSegmentation",
        "name": "Overcoming the Curse of Sentence Length for Neural Machine Translation Using Automatic Segmentation",
        "title": "",
        "year": "2014",
        "authors": [
          "J. Pouget-Abadie",
          "D. Bahdanau",
          "B. van Merrienboer",
          "K. Cho",
          "Y. Bengio"
        ],
        "task": "[\"Neural Machine Translation\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Neural Network",
            "Segmentation"
          ],
          "connections": [
            "Input Sentence to Segmentation Module",
            "Segmentation Module to Neural Network"
          ],
          "mechanisms": [
            "Automatic Segmentation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rescoring n-best Lists"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Segmentation Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_MultiPassSieve",
      "label": "Multi-Pass Sieve",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_MultiPassSieve",
        "entity_id": "Raghunathan2010_MultiPassSieve",
        "name": "Multi-Pass Sieve",
        "title": "A Multi-Pass Sieve for Coreference Resolution",
        "year": "2010",
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV_2004",
          "ACE2004-CULOTTA-TEST_2004",
          "ACE2004-NWIRE_2004",
          "MUC6-TEST_2006"
        ],
        "metrics": [
          "MUC",
          "B3",
          "Pairwise F1"
        ],
        "architecture": {
          "components": [
            "Sieve Framework",
            "Coreference Models"
          ],
          "connections": [
            "Cluster Head Match",
            "Word Inclusion",
            "Compatible Modifiers"
          ],
          "mechanisms": [
            "Attribute Sharing",
            "Mention Selection",
            "Search Pruning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic Models"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Exact Extent Match",
          "Precise Constructs",
          "Strict Head Matching",
          "Relaxed Head Matching",
          "Pronouns"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_MultiPassSieveCoreferenceResolution",
      "label": "Multi-Pass Sieve Coreference Resolution",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_MultiPassSieveCoreferenceResolution",
        "entity_id": "Raghunathan2010_MultiPassSieveCoreferenceResolution",
        "name": "Multi-Pass Sieve Coreference Resolution",
        "title": "",
        "year": "2010",
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV_2004",
          "ACE2004-CULOTTA-TEST_2004",
          "ACE2004-NWIRE_2004",
          "MUC6-TEST_2006"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "PairwiseF1_Coreference"
        ],
        "architecture": {
          "components": [
            "Sieve Framework",
            "Coreference Models"
          ],
          "connections": [
            "Exact Match",
            "Precise Constructs",
            "Strict Head Matching",
            "Relaxed Head Matching",
            "Pronouns"
          ],
          "mechanisms": [
            "Attribute Sharing",
            "Mention Selection",
            "Search Pruning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic Models",
            "Unsupervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Syntactic Information",
          "Mention Attributes",
          "Cluster Information"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_Pass1ExactMatch",
      "label": "Pass 1 - Exact Match",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_Pass1ExactMatch",
        "entity_id": "Raghunathan2010_Pass1ExactMatch",
        "name": "Pass 1 - Exact Match",
        "title": "",
        "year": "2010",
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Exact Extent Match"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Exact Extent Match"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_Pass2PreciseConstructs",
      "label": "Pass 2 - Precise Constructs",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_Pass2PreciseConstructs",
        "entity_id": "Raghunathan2010_Pass2PreciseConstructs",
        "name": "Pass 2 - Precise Constructs",
        "title": "",
        "year": "2010",
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Appositive",
            "Predicate Nominative",
            "Role Appositive",
            "Relative Pronoun",
            "Acronym",
            "Demonym"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Appositive",
          "Predicate Nominative",
          "Role Appositive",
          "Relative Pronoun",
          "Acronym",
          "Demonym"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_Pass3StrictHeadMatching",
      "label": "Pass 3 - Strict Head Matching",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_Pass3StrictHeadMatching",
        "entity_id": "Raghunathan2010_Pass3StrictHeadMatching",
        "name": "Pass 3 - Strict Head Matching",
        "title": "",
        "year": "2010",
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Cluster Head Match",
            "Word Inclusion",
            "Compatible Modifiers Only",
            "Not i-within-i"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Cluster Head Match",
          "Word Inclusion",
          "Compatible Modifiers Only",
          "Not i-within-i"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_Pass4VariantsOfStrictHead",
      "label": "Pass 4 - Variants of Strict Head",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_Pass4VariantsOfStrictHead",
        "entity_id": "Raghunathan2010_Pass4VariantsOfStrictHead",
        "name": "Pass 4 - Variants of Strict Head",
        "title": "",
        "year": "2010",
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Cluster Head Match",
            "Word Inclusion",
            "Not i-within-i"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Cluster Head Match",
          "Word Inclusion",
          "Not i-within-i"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_Pass5VariantsOfStrictHead",
      "label": "Pass 5 - Variants of Strict Head",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_Pass5VariantsOfStrictHead",
        "entity_id": "Raghunathan2010_Pass5VariantsOfStrictHead",
        "name": "Pass 5 - Variants of Strict Head",
        "title": "",
        "year": "2010",
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Cluster Head Match",
            "Compatible Modifiers Only",
            "Not i-within-i"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Cluster Head Match",
          "Compatible Modifiers Only",
          "Not i-within-i"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_Pass6RelaxedHeadMatching",
      "label": "Pass 6 - Relaxed Head Matching",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_Pass6RelaxedHeadMatching",
        "entity_id": "Raghunathan2010_Pass6RelaxedHeadMatching",
        "name": "Pass 6 - Relaxed Head Matching",
        "title": "",
        "year": "2010",
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Cluster Head Match",
            "Word Inclusion",
            "Not i-within-i"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Cluster Head Match",
          "Word Inclusion",
          "Not i-within-i"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_Pass7Pronouns",
      "label": "Pass 7 - Pronouns",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_Pass7Pronouns",
        "entity_id": "Raghunathan2010_Pass7Pronouns",
        "name": "Pass 7 - Pronouns",
        "title": "",
        "year": "2010",
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "Pairwise Precision",
          "Pairwise Recall",
          "Pairwise F1",
          "MUC Scoring",
          "B3 Scoring"
        ],
        "architecture": {
          "components": [
            "Number Agreement",
            "Gender Agreement",
            "Person Agreement",
            "Animacy Agreement",
            "NER Label Agreement"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Deterministic"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Agreement",
          "Gender Agreement",
          "Person Agreement",
          "Animacy Agreement",
          "NER Label Agreement"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_SieveBasedCoreferenceResolution",
      "label": "Sieve-Based Coreference Resolution",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_SieveBasedCoreferenceResolution",
        "entity_id": "Raghunathan2010_SieveBasedCoreferenceResolution",
        "name": "Sieve-Based Coreference Resolution",
        "title": "",
        "year": "2010",
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV_2004",
          "ACE2004-CULOTTA-TEST_2004",
          "ACE2004-NWIRE_2004",
          "MUC6-TEST_2006"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "PairwiseF1_Coreference"
        ],
        "architecture": {
          "components": [
            "Exact Match",
            "Precise Constructs",
            "Strict Head Matching",
            "Relaxed Head Matching",
            "Pronouns"
          ],
          "connections": [
            "Pass 1 -> Pass 2",
            "Pass 2 -> Pass 3",
            "Pass 3 -> Pass 4",
            "Pass 4 -> Pass 5",
            "Pass 5 -> Pass 6",
            "Pass 6 -> Pass 7"
          ],
          "mechanisms": [
            "Multi-Pass Sieve",
            "Attribute Sharing",
            "Mention Selection",
            "Search Pruning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Exact Extent Match",
          "Appositive",
          "Predicate Nominative",
          "Role Appositive",
          "Relative Pronoun",
          "Acronym",
          "Demonym",
          "Cluster Head Match",
          "Word Inclusion",
          "Compatible Modifiers Only",
          "Not i-within-i",
          "Pronoun Match"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_SieveBasedCoreferenceResolutionWithPreciseConstructs",
      "label": "Sieve-Based Coreference Resolution with Precise Constructs",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_SieveBasedCoreferenceResolutionWithPreciseConstructs",
        "entity_id": "Raghunathan2010_SieveBasedCoreferenceResolutionWithPreciseConstructs",
        "name": "Sieve-Based Coreference Resolution with Precise Constructs",
        "title": "",
        "year": "2010",
        "authors": [
          "Karthik Raghunathan",
          "Heeyoung Lee",
          "Sudarshan Rangarajan",
          "Nathanael Chambers",
          "Mihai Surdeanu",
          "Dan Jurafsky",
          "Christopher Manning"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV_2004",
          "ACE2004-CULOTTA-TEST_2004",
          "ACE2004-NWIRE_2004",
          "MUC6-TEST_2006"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "PairwiseF1_Coreference"
        ],
        "architecture": {
          "components": [
            "Pass 1-Exact Match",
            "Pass 2-Precise Constructs",
            "Pass 3-Strict Head Matching",
            "Pass 4-Variants of Strict Head",
            "Pass 5-Variants of Strict Head",
            "Pass 6-Relaxed Head Matching",
            "Pass 7-Pronouns"
          ],
          "connections": [
            "Cluster Head Match",
            "Word Inclusion",
            "Compatible Modifiers Only",
            "Not i-within-i",
            "Pronoun Match"
          ],
          "mechanisms": [
            "Attribute Sharing",
            "Mention Selection",
            "Search Pruning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Exact Extent Match",
          "Appositive",
          "Predicate Nominative",
          "Role Appositive",
          "Relative Pronoun",
          "Acronym",
          "Demonym"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_SieveBasedCoreferenceResolutionWithPronouns",
      "label": "Sieve-Based Coreference Resolution with Pronouns",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_SieveBasedCoreferenceResolutionWithPronouns",
        "entity_id": "Raghunathan2010_SieveBasedCoreferenceResolutionWithPronouns",
        "name": "Sieve-Based Coreference Resolution with Pronouns",
        "title": "A Multi-Pass Sieve for Coreference Resolution",
        "year": "2010",
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "MUC",
          "B3",
          "Pairwise F1"
        ],
        "architecture": {
          "components": [
            "Multi-Pass Sieve",
            "Coreference Models"
          ],
          "connections": [
            "Exact Match",
            "Precise Constructs",
            "Strict Head Matching",
            "Relaxed Head Matching",
            "Pronouns"
          ],
          "mechanisms": [
            "Attribute Sharing",
            "Mention Selection",
            "Search Pruning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deterministic Models",
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Syntactic Information",
          "Semantic Features",
          "Discourse Salience"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Raghunathan2010_SinglePassVariant",
      "label": "Single-Pass Variant",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Raghunathan2010_SinglePassVariant",
        "entity_id": "Raghunathan2010_SinglePassVariant",
        "name": "Single-Pass Variant",
        "title": "",
        "year": "2010",
        "authors": [
          "Raghunathan, K.",
          "Lee, H.",
          "Rangarajan, S.",
          "Chambers, N.",
          "Surdeanu, M.",
          "Jurafsky, D.",
          "Manning, C."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004-ROTH-DEV",
          "ACE2004-CULOTTA-TEST",
          "ACE2004-NWIRE",
          "MUC6-TEST"
        ],
        "metrics": [
          "MUC_Scoring",
          "B3_Scoring",
          "Pairwise_F1"
        ],
        "architecture": {
          "components": [
            "Feature Extraction",
            "Coreference Model"
          ],
          "connections": [
            "Feature Input -> Coreference Model"
          ],
          "mechanisms": [
            "Single-Pass Decision Making"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ranzato2016_SequenceLevelTraining",
      "label": "Sequence Level Training with Recurrent Neural Networks",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ranzato2016_SequenceLevelTraining",
        "entity_id": "Ranzato2016_SequenceLevelTraining",
        "name": "Sequence Level Training with Recurrent Neural Networks",
        "title": "",
        "year": "2016",
        "authors": [
          "Ranzato, M.A.",
          "Chopra, S.",
          "Auli, M.",
          "Zaremba, W."
        ],
        "task": "[\"Sequence Prediction\"]",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "BLEU Score"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network",
            "Actor-Critic"
          ],
          "connections": [
            "Policy Gradient"
          ],
          "mechanisms": [
            "Scheduled Sampling",
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Policy Gradient",
            "Scheduled Sampling"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Beam Size"
          ]
        },
        "feature_processing": [
          "Sequence-Level Cost Functions"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ratinov2011_GLOW",
      "label": "GLOW",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ratinov2011_GLOW",
        "entity_id": "Ratinov2011_GLOW",
        "name": "GLOW",
        "title": "",
        "year": "2011",
        "authors": [
          "Ratinov, L.",
          "Downey, D.",
          "Anderson, M."
        ],
        "task": "[\"Named Entity Linking\"]",
        "dataset": [
          "ACE2004_NWIRE_2004"
        ],
        "metrics": [
          "F1_NEL"
        ],
        "architecture": {
          "components": [
            "mention detection",
            "integer linear programming"
          ],
          "connections": [
            "local constraints",
            "global constraints"
          ],
          "mechanisms": [
            "entity link co-occurrence"
          ]
        },
        "methodology": {
          "training_strategy": [
            "optimization problem"
          ],
          "parameter_tuning": [
            "confidence values"
          ]
        },
        "feature_processing": [
          "local constraints",
          "global constraints"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Riley1983_ChangeCompareCombineSchemas",
      "label": "Change, Compare, Combine Schemas",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Riley1983_ChangeCompareCombineSchemas",
        "entity_id": "Riley1983_ChangeCompareCombineSchemas",
        "name": "Change, Compare, Combine Schemas",
        "title": "",
        "year": "1983",
        "authors": [
          "Riley, M.S.",
          "Greeno, J.G.",
          "Heller, J.I."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Simple Arithmetic Word Problems"
        ],
        "metrics": [
          "Schema Matching Accuracy"
        ],
        "architecture": {
          "components": [
            "Change Schema",
            "Compare Schema",
            "Combine Schema"
          ],
          "connections": [
            "Interrelated by equality a+b=c"
          ],
          "mechanisms": [
            "Model Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Schema-based problem solving"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Key word identification",
          "Quantity extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Robaidek2018_BidirectionalLSTM",
      "label": "Bidirectional LSTM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Robaidek2018_BidirectionalLSTM",
        "entity_id": "Robaidek2018_BidirectionalLSTM",
        "name": "Bidirectional LSTM",
        "title": "",
        "year": "2018",
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "BidirectionalLSTM_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Self Attention"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Robaidek2018_BiLSTMClassifier",
      "label": "BiLSTM Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Robaidek2018_BiLSTMClassifier",
        "entity_id": "Robaidek2018_BiLSTMClassifier",
        "name": "BiLSTM Classifier",
        "title": "",
        "year": "2018",
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Softmax Layer"
          ],
          "connections": [
            "Word Embedding -> Bidirectional LSTM -> Softmax"
          ],
          "mechanisms": [
            "Cross Entropy Loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end training"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Hidden state size",
            "Dropout rate"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Robaidek2018_EquationTemplate",
      "label": "Equation Template",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Robaidek2018_EquationTemplate",
        "entity_id": "Robaidek2018_EquationTemplate",
        "name": "Equation Template",
        "title": "",
        "year": "2018",
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "Equation Template Generator"
          ],
          "connections": [
            "Word Problem Text -> Equation Template"
          ],
          "mechanisms": [
            "Number Abstraction",
            "Template Population"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross Entropy Loss"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden State Size"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Text Normalization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Robaidek2018_NeuralEquationClassifier",
      "label": "Neural Equation Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Robaidek2018_NeuralEquationClassifier",
        "entity_id": "Robaidek2018_NeuralEquationClassifier",
        "name": "Neural Equation Classifier",
        "title": "",
        "year": "2018",
        "authors": [
          "Benjamin Robaidek",
          "Rik Koncel-Kedziorski",
          "Hannaneh Hajishirzi"
        ],
        "task": "[\"Solving Algebra Word Problems\"]",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "BiLSTM"
          ],
          "connections": [
            "softmax"
          ],
          "mechanisms": [
            "cross-entropy loss"
          ]
        },
        "methodology": {
          "training_strategy": [
            "end-to-end training"
          ],
          "parameter_tuning": [
            "learning rate",
            "dropout rate"
          ]
        },
        "feature_processing": [
          "number mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Robaidek2018_SemanticLimitations",
      "label": "Semantic Limitations",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Robaidek2018_SemanticLimitations",
        "entity_id": "Robaidek2018_SemanticLimitations",
        "name": "Semantic Limitations",
        "title": "",
        "year": "2018",
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Word Problem Text",
            "Equation Templates"
          ],
          "connections": [
            "Mapping Text to Templates"
          ],
          "mechanisms": [
            "Semantic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross Entropy Loss"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Template Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Robaidek2018_Seq2SeqModel",
      "label": "Seq2Seq Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Robaidek2018_Seq2SeqModel",
        "entity_id": "Robaidek2018_Seq2SeqModel",
        "name": "Seq2Seq Model",
        "title": "",
        "year": "2018",
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder (LSTM/CNN)",
            "Decoder (LSTM/CNN)",
            "Attention Mechanism"
          ],
          "connections": [
            "Word Embedding -> Encoder -> Attention -> Decoder"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Sequence Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Teacher forcing"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Hidden state size",
            "Dropout rate",
            "Kernel width"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Robaidek2018_WorldKnowledge",
      "label": "World Knowledge",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Robaidek2018_WorldKnowledge",
        "entity_id": "Robaidek2018_WorldKnowledge",
        "name": "World Knowledge",
        "title": "",
        "year": "2018",
        "authors": [
          "Robaidek, B.",
          "Koncel-Kedziorski, R.",
          "Hajishirzi, H."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "DRAW_2016",
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Word Problem Text",
            "Equation Templates"
          ],
          "connections": [
            "Mapping Text to Templates"
          ],
          "mechanisms": [
            "External Knowledge Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross Entropy Loss"
          ]
        },
        "feature_processing": [
          "Contextual Information",
          "Geographical Directions"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Rohde2006_COALS",
      "label": "COALS Method",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Rohde2006_COALS",
        "entity_id": "Rohde2006_COALS",
        "name": "COALS Method",
        "title": "",
        "year": "2006",
        "authors": [
          "Rohde, D. L. T.",
          "Gonnerman, L. M.",
          "Plaut, D. C."
        ],
        "task": "[\"Word Representation\"]",
        "dataset": [
          "Co-occurrence Matrices"
        ],
        "metrics": [
          "Entropy-Based Normalization",
          "Correlation-Based Normalization"
        ],
        "architecture": {
          "components": [
            "Transformed Co-occurrence Matrix"
          ],
          "connections": [
            "Normalized Co-occurrence Counts"
          ],
          "mechanisms": [
            "Compression of Raw Counts"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Normalization Techniques"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Statistical Information Compression"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_ALGES",
      "label": "ALGES",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_ALGES",
        "entity_id": "Roy2015_ALGES",
        "name": "ALGES",
        "title": "Parsing Algebraic Word Problems into Equations",
        "year": "2015",
        "authors": [
          "Koncel-Kedziorski",
          "Hajishirzi",
          "Sabharwal",
          "Etzioni",
          "Ang"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Equation Tree",
            "Integer Linear Programming"
          ],
          "connections": [
            "Syntactic Validity",
            "Type Consistency"
          ],
          "mechanisms": [
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-validation"
          ],
          "parameter_tuning": [
            "Beam Size"
          ]
        },
        "feature_processing": [
          "Syntactic Parsing",
          "Coreference Resolution"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2015_ARIS",
      "label": "ARIS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_ARIS",
        "entity_id": "Roy2015_ARIS",
        "name": "ARIS",
        "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
        "year": "2015",
        "authors": [
          "Mohammad Javad Hosseini",
          "Hannaneh Hajishirzi",
          "Oren Etzioni",
          "Nate Kushman"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Standard Primary School Test Questions"
        ],
        "metrics": [
          "Verb Categorization Accuracy",
          "Problem Solving Accuracy"
        ],
        "architecture": {
          "components": [
            "Sentence Analyzer",
            "Equation Generator"
          ],
          "connections": [
            "Sentence to Equation Mapping"
          ],
          "mechanisms": [
            "Verb Categorization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Verb Category Classification"
          ]
        },
        "feature_processing": [
          "Verb Identification",
          "Variable Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_ArithmeticWordProblemSolver",
      "label": "Arithmetic Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_ArithmeticWordProblemSolver",
        "entity_id": "Roy2015_ArithmeticWordProblemSolver",
        "name": "Arithmetic Word Problem Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [
          "AllArith_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblem",
          "ErrorReduction_ErrorAnalysis"
        ],
        "architecture": {
          "components": [
            "Irrelevance Classifier",
            "LCA Operation Classifier"
          ],
          "connections": [
            "Combining scores from classifiers",
            "Constrained inference"
          ],
          "mechanisms": [
            "Monotonic expression tree",
            "Solution expression tree"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning",
            "Beam search"
          ],
          "parameter_tuning": [
            "Scaling parameters",
            "Development set tuning"
          ]
        },
        "feature_processing": [
          "Context features",
          "Rule-based extraction features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_BankOfClassifiers",
      "label": "Bank of Classifiers",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_BankOfClassifiers",
        "entity_id": "Roy2015_BankOfClassifiers",
        "name": "Bank of Classifiers",
        "title": "",
        "year": "2015",
        "authors": [
          "Punyakanok, V.",
          "Roth, D."
        ],
        "task": "[\"Quantity Segmentation\"]",
        "dataset": [
          "RTE_Datasets_2015",
          "Newswire_Text_2015"
        ],
        "metrics": [
          "F1_Score_Quantitative_Reasoning",
          "Precision_Quantitative_Reasoning",
          "Recall_Quantitative_Reasoning"
        ],
        "architecture": {
          "components": [
            "Classifiers"
          ],
          "connections": [
            "Sequential Inference"
          ],
          "mechanisms": [
            "Feature Extraction",
            "Decision Making"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Retraining with New Features"
          ],
          "parameter_tuning": [
            "Thresholds",
            "Weights"
          ]
        },
        "feature_processing": [
          "Word Class Features",
          "Character-Based Features",
          "Part of Speech Tags"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_EquationParsing",
      "label": "Equation Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_EquationParsing",
        "entity_id": "Roy2015_EquationParsing",
        "name": "Equation Parsing",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Sentence Parsing",
            "Equation Generation"
          ],
          "connections": [
            "Sentence to Equation"
          ],
          "mechanisms": [
            "Semantic Parsing",
            "Equation Construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Parsing Rules"
          ]
        },
        "feature_processing": [
          "Hand-Crafted Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_ExpressionTree",
      "label": "Expression Tree",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_ExpressionTree",
        "entity_id": "Roy2015_ExpressionTree",
        "name": "Expression Tree",
        "title": "",
        "year": "2015",
        "authors": [
          "S. Roy",
          "D. Roth"
        ],
        "task": "[\"Solving Arithmetic Word Problems\"]",
        "dataset": [
          "AI2_2014",
          "IL_2014",
          "CC_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "binary classifier",
            "expression tree"
          ],
          "connections": [
            "bottom-up construction"
          ],
          "mechanisms": [
            "beam search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "binary classification"
          ],
          "parameter_tuning": [
            "beam search"
          ]
        },
        "feature_processing": [
          "quantity extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2015_GeneralArithmetic",
      "label": "General Arithmetic Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_GeneralArithmetic",
        "entity_id": "Roy2015_GeneralArithmetic",
        "name": "General Arithmetic Solver",
        "title": "Solving General Arithmetic Word Problems",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Trees"
          ],
          "connections": [
            "Constrained Inference Framework"
          ],
          "mechanisms": [
            "Quantity Schemas"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_GeneralArithmeticWordProblemSolver",
      "label": "General Arithmetic Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_GeneralArithmeticWordProblemSolver",
        "entity_id": "Roy2015_GeneralArithmeticWordProblemSolver",
        "name": "General Arithmetic Word Problem Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Parsing",
            "Reasoning Engine"
          ],
          "connections": [
            "Text -> Semantic Representation -> Solution"
          ],
          "mechanisms": [
            "Semantic Parsing Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Parsing"
          ],
          "parameter_tuning": [
            "Parsing Rules"
          ]
        },
        "feature_processing": [
          "Textual Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_ImplicitQuantityProductionRules",
      "label": "Implicit Quantity Production Rules",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_ImplicitQuantityProductionRules",
        "entity_id": "Roy2015_ImplicitQuantityProductionRules",
        "name": "Implicit Quantity Production Rules",
        "title": "",
        "year": "2015",
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "[\"Quantity Entailment\"]",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Range Implication",
            "Compatible Term Combination",
            "Ratio to Percentage",
            "Composition"
          ],
          "connections": [
            "Implicit Quantity Production Rules"
          ],
          "mechanisms": [
            "Logical Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Quantity Extraction",
          "Standardization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_IrrelevanceClassifier",
      "label": "Irrelevance Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_IrrelevanceClassifier",
        "entity_id": "Roy2015_IrrelevanceClassifier",
        "name": "Irrelevance Classifier",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary Classifier"
          ],
          "connections": [],
          "mechanisms": [
            "Relevance Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-Based Extraction Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_LCA",
      "label": "Lowest Common Ancestors (LCA)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_LCA",
        "entity_id": "Roy2015_LCA",
        "name": "Lowest Common Ancestors (LCA)",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [
          "Arithmetic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Math expression trees"
          ],
          "connections": [
            "Tree traversal"
          ],
          "mechanisms": [
            "Lowest common ancestor finding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Tree-based learning"
          ],
          "parameter_tuning": [
            "Tree parameters"
          ]
        },
        "feature_processing": [
          "Tree structure extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_LCA++",
      "label": "LCA++",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_LCA++",
        "entity_id": "Roy2015_LCA++",
        "name": "LCA++",
        "title": "Solving General Arithmetic Word Problems",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Irrelevance Classifier",
            "LCA Operation Classifier"
          ],
          "connections": [
            "Monotonic Expression Tree"
          ],
          "mechanisms": [
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross Validation"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Neighborhood Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_LCAOperationClassifier",
      "label": "LCA Operation Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_LCAOperationClassifier",
        "entity_id": "Roy2015_LCAOperationClassifier",
        "name": "LCA Operation Classifier",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multiclass Classifier"
          ],
          "connections": [],
          "mechanisms": [
            "Lowest Common Ancestor Node Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-Based Extraction Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_LightweightLogicalInference",
      "label": "Lightweight Logical Inference",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_LightweightLogicalInference",
        "entity_id": "Roy2015_LightweightLogicalInference",
        "name": "Lightweight Logical Inference",
        "title": "",
        "year": "2015",
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "[\"Quantity Entailment\"]",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Implicit Quantity Production Rules",
            "Quantity Comparison"
          ],
          "connections": [
            "Logical Inference"
          ],
          "mechanisms": [
            "Monotonicity Verification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Quantity Extraction",
          "Standardization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_MathWordProblemSolver",
      "label": "MathWordProblemSolver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_MathWordProblemSolver",
        "entity_id": "Roy2015_MathWordProblemSolver",
        "name": "MathWordProblemSolver",
        "title": "Reasoning about Quantities in Natural Language",
        "year": "2015",
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quantity Pair Classifier",
            "Operation Classifier",
            "Order Classifier"
          ],
          "connections": [
            "Cascade of Classifiers"
          ],
          "mechanisms": [
            "Sparse Averaged Perceptron"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gold Annotations"
          ],
          "parameter_tuning": [
            "Feature Engineering"
          ]
        },
        "feature_processing": [
          "Unigrams and Bigrams",
          "POS Tags",
          "Quantity Units Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_MonotonicExpressionTree",
      "label": "Monotonic Expression Tree",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_MonotonicExpressionTree",
        "entity_id": "Roy2015_MonotonicExpressionTree",
        "name": "Monotonic Expression Tree",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Binary Tree Representation"
          ],
          "connections": [
            "Addition/Subtraction Nodes",
            "Multiplication/Division Nodes"
          ],
          "mechanisms": [
            "Normalization of Expression Trees"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Monotonic Restriction"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_MultiStepArithmetic",
      "label": "Multi-Step Arithmetic",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_MultiStepArithmetic",
        "entity_id": "Roy2015_MultiStepArithmetic",
        "name": "Multi-Step Arithmetic",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Vieira, T.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Multi-Step Reasoning"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_PipelineClassifiers",
      "label": "Pipeline Classifiers",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_PipelineClassifiers",
        "entity_id": "Roy2015_PipelineClassifiers",
        "name": "Pipeline Classifiers",
        "title": "",
        "year": "2015",
        "authors": [
          "S. Roy",
          "T. Vieira",
          "D. Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "IL_Dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multiple Classifiers"
          ],
          "connections": [
            "Sequential Processing"
          ],
          "mechanisms": [
            "Feature Extraction from Text"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Classifier Parameters"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Neighborhood Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_QuantityEntailment",
      "label": "Quantity Entailment",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_QuantityEntailment",
        "entity_id": "Roy2015_QuantityEntailment",
        "name": "Quantity Entailment",
        "title": "Reasoning about Quantities in Natural Language",
        "year": "2015",
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "[\"数量推理\"]",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1_Score_QuantityEntailment",
          "Precision_QuantityEntailment",
          "Recall_QuantityEntailment"
        ],
        "architecture": {
          "components": [
            "数量识别模块",
            "标准化模块",
            "推理框架"
          ],
          "connections": [
            "数量识别与标准化结合",
            "推理框架与数量比较规则结合"
          ],
          "mechanisms": [
            "隐含数量生成规则",
            "数量比较规则"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习",
            "半监督学习"
          ],
          "parameter_tuning": [
            "特征选择",
            "阈值调整"
          ]
        },
        "feature_processing": [
          "词类特征",
          "字符基础特征",
          "词性标注"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_QuantityExtraction",
      "label": "QuantityExtraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_QuantityExtraction",
        "entity_id": "Roy2015_QuantityExtraction",
        "name": "QuantityExtraction",
        "title": "Reasoning about Quantities in Natural Language",
        "year": "2015",
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "[\"Quantity Extraction and Standardization\"]",
        "dataset": [
          "RTE Datasets",
          "Newswire Text"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Segmentation",
            "Standardization",
            "Unit Inference"
          ],
          "connections": [
            "Segmentation -> Standardization",
            "Standardization -> Unit Inference"
          ],
          "mechanisms": [
            "Sequence Segmentation",
            "Rule-based Standardization",
            "Semantic Role Labeling",
            "Coreference Resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-validation"
          ],
          "parameter_tuning": [
            "Feature Engineering",
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "Word Class Features",
          "Character-based Features",
          "Part of Speech Tags",
          "Contextual Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_QuantityValueRepresentation",
      "label": "Quantity-Value Representation (QVR)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_QuantityValueRepresentation",
        "entity_id": "Roy2015_QuantityValueRepresentation",
        "name": "Quantity-Value Representation (QVR)",
        "title": "",
        "year": "2015",
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "[\"Quantitative Reasoning\"]",
        "dataset": [
          "RTE_Datasets_2015",
          "Newswire_Text_2015"
        ],
        "metrics": [
          "F1_Score_Quantitative_Reasoning",
          "Precision_Quantitative_Reasoning",
          "Recall_Quantitative_Reasoning"
        ],
        "architecture": {
          "components": [
            "Value",
            "Units",
            "Change"
          ],
          "connections": [
            "Value to Units",
            "Value to Change",
            "Units to Change"
          ],
          "mechanisms": [
            "Normalization",
            "Standardization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based",
            "Feature-based"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Segmentation",
          "Standardization",
          "Unit Inference"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_SemiCRFModel",
      "label": "Semi-CRF Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_SemiCRFModel",
        "entity_id": "Roy2015_SemiCRFModel",
        "name": "Semi-CRF Model",
        "title": "",
        "year": "2015",
        "authors": [
          "Sarawagi, S.",
          "Collins, M.",
          "Freund, Y.",
          "Schapire, R."
        ],
        "task": "[\"Quantity Segmentation\"]",
        "dataset": [
          "RTE_Datasets_2015",
          "Newswire_Text_2015"
        ],
        "metrics": [
          "F1_Score_Quantitative_Reasoning",
          "Precision_Quantitative_Reasoning",
          "Recall_Quantitative_Reasoning"
        ],
        "architecture": {
          "components": [
            "Conditional Random Fields"
          ],
          "connections": [
            "Sequence Segmentation"
          ],
          "mechanisms": [
            "Structured Perceptron Training",
            "Parameter Averaging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Perceptron",
            "Parameter Averaging"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Regularization"
          ]
        },
        "feature_processing": [
          "Word Class Features",
          "Character-Based Features",
          "Part of Speech Tags"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_SolveWordProblem",
      "label": "SolveWordProblem",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_SolveWordProblem",
        "entity_id": "Roy2015_SolveWordProblem",
        "name": "SolveWordProblem",
        "title": "Reasoning about Quantities in Natural Language",
        "year": "2015",
        "authors": [
          "Subhro Roy",
          "Tim Vieira",
          "Dan Roth"
        ],
        "task": "[\"Solving Math Word Problems\"]",
        "dataset": [
          "Elementary Math Word Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quantity Pair Classifier",
            "Operation Classifier",
            "Order Classifier"
          ],
          "connections": [
            "Quantity Pair Classifier -> Operation Classifier -> Order Classifier"
          ],
          "mechanisms": [
            "Cascade of Classifiers",
            "Feature-based Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-validation"
          ],
          "parameter_tuning": [
            "Feature Engineering",
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "Unigrams and Bigrams",
          "POS Tags",
          "Quantity Units Matching",
          "Relevant Operations",
          "Relevant Order of Quantities"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2015_SolvingGeneralArithmetic",
      "label": "Solving General Arithmetic Word Problems",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_SolvingGeneralArithmetic",
        "entity_id": "Roy2015_SolvingGeneralArithmetic",
        "name": "Solving General Arithmetic Word Problems",
        "title": "Solving General Arithmetic Word Problems",
        "year": "2015",
        "authors": [
          "Roy",
          "Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary Classifier",
            "Expression Tree"
          ],
          "connections": [
            "Beam Search"
          ],
          "mechanisms": [
            "Local Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Feature Extraction",
          "Quantity Relevance"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2015_UnitDependencyGraph",
      "label": "Unit Dependency Graph",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_UnitDependencyGraph",
        "entity_id": "Roy2015_UnitDependencyGraph",
        "name": "Unit Dependency Graph",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Math23K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Unit Dependency Graph",
            "Constrained Inference Framework"
          ],
          "connections": [
            "Unit Extraction",
            "Domain Knowledge Integration"
          ],
          "mechanisms": [
            "Unit Compatibility Reasoning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Decomposed Model Training"
          ],
          "parameter_tuning": [
            "Minimal Additional Annotations"
          ]
        },
        "feature_processing": [
          "Unit Extraction",
          "Domain Knowledge Integration"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2016_ExpressionTreeBasedSolver",
      "label": "Expression Tree Based Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2016_ExpressionTreeBasedSolver",
        "entity_id": "Roy2016_ExpressionTreeBasedSolver",
        "name": "Expression Tree Based Solver",
        "title": "Solving General Arithmetic Word Problems",
        "year": "2016",
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "Commoncore_2016"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblem",
          "Precision_ArithmeticWordProblem",
          "Recall_ArithmeticWordProblem"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Constrained Inference Framework",
            "Quantity Schema"
          ],
          "connections": [
            "Decomposition of Arithmetic Expressions",
            "Combining Classifiers"
          ],
          "mechanisms": [
            "Monotonic Expression Tree",
            "Global Inference Module"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Beam Search"
          ],
          "parameter_tuning": [
            "wIRR"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Verb Categorization",
          "Unit Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2016_GlobalInferenceModule",
      "label": "Global Inference Module",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2016_GlobalInferenceModule",
        "entity_id": "Roy2016_GlobalInferenceModule",
        "name": "Global Inference Module",
        "title": "Solving General Arithmetic Word Problems",
        "year": "2016",
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2 Dataset",
          "IL Dataset",
          "Commoncore Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Scoring Functions",
            "Beam Search",
            "Constrained Optimization"
          ],
          "connections": [
            "PAIR Scoring Function",
            "IRR Scoring Function"
          ],
          "mechanisms": [
            "Monotonic Expression Trees",
            "Quantity Schemas"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Cross-validation"
          ],
          "parameter_tuning": [
            "wIRR"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Beam Search Pruning"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2016_LCAOperationClassifier",
      "label": "LCA Operation Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2016_LCAOperationClassifier",
        "entity_id": "Roy2016_LCAOperationClassifier",
        "name": "LCA Operation Classifier",
        "title": "",
        "year": "2016",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_Dataset_2014",
          "IL_Dataset_2015",
          "Commoncore_Dataset_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multi-class SVM Classifier"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Gold Annotations"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Individual Quantity Features",
          "Quantity Pair Features",
          "Question Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2016_MonotonicExpressionTree",
      "label": "Monotonic Expression Tree",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2016_MonotonicExpressionTree",
        "entity_id": "Roy2016_MonotonicExpressionTree",
        "name": "Monotonic Expression Tree",
        "title": "Solving General Arithmetic Word Problems",
        "year": "2016",
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_Dataset_2014",
          "IL_Dataset_2015",
          "Commoncore_Dataset_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Monotonic Property",
            "LCA Node"
          ],
          "connections": [
            "Leaf Nodes to Internal Nodes",
            "Internal Nodes to Root"
          ],
          "mechanisms": [
            "Decomposition Strategy",
            "Constrained Inference Framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Multiclass Classification",
            "Binary Classification"
          ],
          "parameter_tuning": [
            "wIRR"
          ]
        },
        "feature_processing": [
          "Quantity Schemas",
          "Dependency Parsing",
          "Shallow Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2016_RelevanceClassifier",
      "label": "Relevance Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2016_RelevanceClassifier",
        "entity_id": "Roy2016_RelevanceClassifier",
        "name": "Relevance Classifier",
        "title": "",
        "year": "2016",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_Dataset_2014",
          "IL_Dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary SVM Classifier"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Gold Annotations"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Unit Features",
          "Related NP Features",
          "Miscellaneous Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_ConstrainedInference",
      "label": "Constrained Inference Module",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_ConstrainedInference",
        "entity_id": "Roy2017_ConstrainedInference",
        "name": "Constrained Inference Module",
        "title": "",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Combine vertex and edge predictions to construct UDG\"]",
        "dataset": [
          "AllArith_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Inference Module"
          ],
          "connections": [
            "Input: Scores from Vertex and Edge Classifiers",
            "Output: Unit Dependency Graph"
          ],
          "mechanisms": [
            "Scoring Function",
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [
          "Scores from Classifiers"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_ConstrainedInferenceModule",
      "label": "Constrained Inference Module",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_ConstrainedInferenceModule",
        "entity_id": "Roy2017_ConstrainedInferenceModule",
        "name": "Constrained Inference Module",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Inference Module"
          ],
          "connections": [
            "Vertex Classifier -> Constrained Inference Module",
            "Edge Classifier -> Constrained Inference Module"
          ],
          "mechanisms": [
            "Constrained Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_DecomposedModel",
      "label": "Decomposed Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_DecomposedModel",
        "entity_id": "Roy2017_DecomposedModel",
        "name": "Decomposed Model",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Vertex Classifier",
            "Edge Classifier",
            "Constrained Inference Module"
          ],
          "connections": [
            "Vertex Classifier -> Constrained Inference Module",
            "Edge Classifier -> Constrained Inference Module"
          ],
          "mechanisms": [
            "Structured Prediction",
            "Joint Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Beam Search"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-based Extraction Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_EdgeClassifier",
      "label": "Edge Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_EdgeClassifier",
        "entity_id": "Roy2017_EdgeClassifier",
        "name": "Edge Classifier",
        "title": "",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Classify edges in Unit Dependency Graphs\"]",
        "dataset": [
          "AllArith_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Multiclass Classifier"
          ],
          "connections": [
            "Input: Pair of Nodes",
            "Output: Edge Labels"
          ],
          "mechanisms": [
            "SAME UNIT",
            "RATE→Num",
            "RATE←Num",
            "RATE→Den",
            "RATE←Den"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameters for Multiclass Classification"
          ]
        },
        "feature_processing": [
          "Context Features",
          "Rule-based Detection",
          "Common Tokens in Units"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_EDGELABEL",
      "label": "EDGELABEL",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_EDGELABEL",
        "entity_id": "Roy2017_EDGELABEL",
        "name": "EDGELABEL",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Edge Label Prediction\"]",
        "dataset": [
          "AllArith_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Algorithm 1"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Heuristic-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context Features",
          "Rule based Extraction Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_JointInferenceProcedure",
      "label": "Joint Inference Procedure",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_JointInferenceProcedure",
        "entity_id": "Roy2017_JointInferenceProcedure",
        "name": "Joint Inference Procedure",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "AllArithLex_2017",
          "AllArithTmpl_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Joint Inference Module"
          ],
          "connections": [
            "Decomposed Model -> Joint Inference Procedure"
          ],
          "mechanisms": [
            "Joint Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Scaling Parameters"
          ]
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_RuleBasedExtraction",
      "label": "Rule Based Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_RuleBasedExtraction",
        "entity_id": "Roy2017_RuleBasedExtraction",
        "name": "Rule Based Extraction",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Unit Extraction\"]",
        "dataset": [
          "AllArith_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Rule-based system"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Context Features",
          "Rule based Extraction Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_UNITDEP",
      "label": "UNITDEP",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_UNITDEP",
        "entity_id": "Roy2017_UNITDEP",
        "name": "UNITDEP",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2017",
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "[\"算术文字题求解\"]",
        "dataset": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl"
        ],
        "metrics": [
          "Accuracy",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Unit Dependency Graph",
            "Vertex Classifier",
            "Edge Classifier",
            "Constrained Inference"
          ],
          "connections": [
            "Vertex Classifier -> Edge Classifier -> Constrained Inference"
          ],
          "mechanisms": [
            "使用单位依赖图来改进算术文字题求解器的性能"
          ]
        },
        "methodology": {
          "training_strategy": [
            "使用带约束的推理框架进行训练"
          ],
          "parameter_tuning": [
            "调整λ参数以优化性能"
          ]
        },
        "feature_processing": [
          "context_features",
          "rule_based_extraction_features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_UnitDependencyGraph",
      "label": "Unit Dependency Graph",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_UnitDependencyGraph",
        "entity_id": "Roy2017_UnitDependencyGraph",
        "name": "Unit Dependency Graph",
        "title": "",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Unit Dependency Graph",
            "Classifier"
          ],
          "connections": [
            "Node Classifier",
            "Edge Classifier"
          ],
          "mechanisms": [
            "Rate Consistency"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Classifier Parameters"
          ]
        },
        "feature_processing": [
          "Unit Dependency Graph Construction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2017_VertexClassifier",
      "label": "Vertex Classifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_VertexClassifier",
        "entity_id": "Roy2017_VertexClassifier",
        "name": "Vertex Classifier",
        "title": "",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Classify vertices in Unit Dependency Graphs\"]",
        "dataset": [
          "AllArith_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Binary Classifier"
          ],
          "connections": [
            "Input: Problem Text and Vertex",
            "Output: RATE or NOT RATE"
          ],
          "mechanisms": [
            "Context Features",
            "Rule-based Extraction Features"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameters for Binary Classification"
          ]
        },
        "feature_processing": [
          "Unigrams",
          "Bigrams",
          "POS Tags",
          "Conjunctions",
          "Rule-based Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2018_DeclarativeKnowledge",
      "label": "Declarative Knowledge Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2018_DeclarativeKnowledge",
        "entity_id": "Roy2018_DeclarativeKnowledge",
        "name": "Declarative Knowledge Solver",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": "2018",
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "[\"Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Declarative rules"
          ],
          "connections": [
            "Equation generation"
          ],
          "mechanisms": [
            "Constrained inference framework"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Variables and attributes extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2018_DeclarativeKnowledgeMapping",
      "label": "Declarative Knowledge Mapping",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2018_DeclarativeKnowledgeMapping",
        "entity_id": "Roy2018_DeclarativeKnowledgeMapping",
        "name": "Declarative Knowledge Mapping",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": "2018",
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith",
          "Perturb",
          "Aggregate"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Concept Selection",
            "Declarative Rule Selection"
          ],
          "connections": [
            "Concept to Operation",
            "Rule to Operation"
          ],
          "mechanisms": [
            "Latent Variable Modeling",
            "Feature Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-stage Learning",
            "Latent Structured SVM"
          ],
          "parameter_tuning": [
            "Weight Vectors",
            "Regularization Parameter C"
          ]
        },
        "feature_processing": [
          "Dependency Parse Labels",
          "Coreference Resolution",
          "Verb Classification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2018_DeclarativeMapping",
      "label": "Declarative Mapping",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2018_DeclarativeMapping",
        "entity_id": "Roy2018_DeclarativeMapping",
        "name": "Declarative Mapping",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": "2018",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Declarative Rules"
          ],
          "connections": [
            "Equation Generation"
          ],
          "mechanisms": [
            "Semantic Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2018_DimensionalAnalysis",
      "label": "Dimensional Analysis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2018_DimensionalAnalysis",
        "entity_id": "Roy2018_DimensionalAnalysis",
        "name": "Dimensional Analysis",
        "title": "",
        "year": "2018",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "Perturb_2018",
          "Aggregate_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Unit Extraction",
            "Rate Component Detection"
          ],
          "connections": [
            "Unit to Operation Mapping",
            "Rate Component to Operation Mapping"
          ],
          "mechanisms": [
            "Unit Compatibility Check",
            "Rate Component Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Modeling"
          ],
          "parameter_tuning": [
            "Unit Compatibility Threshold",
            "Rate Component Detection Accuracy"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Unit Extraction",
          "Rate Component Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2018_ExplicitMath",
      "label": "Explicit Math",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2018_ExplicitMath",
        "entity_id": "Roy2018_ExplicitMath",
        "name": "Explicit Math",
        "title": "",
        "year": "2018",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "Perturb_2018",
          "Aggregate_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Math Term Detection",
            "Explicit Math Pattern Recognition"
          ],
          "connections": [
            "Math Term to Operation Mapping",
            "Pattern to Operation Mapping"
          ],
          "mechanisms": [
            "Math Term-based Inference",
            "Pattern-based Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Modeling"
          ],
          "parameter_tuning": [
            "Math Term Detection Accuracy",
            "Pattern Recognition Accuracy"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Math Term Detection",
          "Pattern Recognition"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2018_KNOWLEDGE",
      "label": "KNOWLEDGE",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2018_KNOWLEDGE",
        "entity_id": "Roy2018_KNOWLEDGE",
        "name": "KNOWLEDGE",
        "title": "Mapping to Declarative Knowledge for Word Problem Solving",
        "year": "2018",
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith",
          "AllArithLex",
          "AllArithTmpl",
          "Perturb",
          "Aggregate"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Transfer",
            "Dimensional Analysis",
            "Part-Whole Relation",
            "Explicit Math"
          ],
          "connections": [
            "Concept prediction",
            "Declarative rule selection"
          ],
          "mechanisms": [
            "Latent variable modeling",
            "Beam search inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-stage learning",
            "Latent structured SVM"
          ],
          "parameter_tuning": [
            "Weight vectors for concept and rule selection"
          ]
        },
        "feature_processing": [
          "Dependency parsing",
          "Coreference resolution",
          "Verb classification",
          "Rate component detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2018_PartWholeRelation",
      "label": "Part-Whole Relation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2018_PartWholeRelation",
        "entity_id": "Roy2018_PartWholeRelation",
        "name": "Part-Whole Relation",
        "title": "",
        "year": "2018",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "Perturb_2018",
          "Aggregate_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Hyponym Detection",
            "Hypernym Detection",
            "Sibling Detection"
          ],
          "connections": [
            "Hyponym to Operation Mapping",
            "Hypernym to Operation Mapping",
            "Sibling to Operation Mapping"
          ],
          "mechanisms": [
            "Hyponymy-based Inference",
            "Hypernymy-based Inference",
            "Sibling-based Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Modeling"
          ],
          "parameter_tuning": [
            "Hyponym Detection Accuracy",
            "Hypernym Detection Accuracy",
            "Sibling Detection Accuracy"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Hyponym Detection",
          "Hypernym Detection",
          "Sibling Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2018_TransferConcept",
      "label": "Transfer Concept",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2018_TransferConcept",
        "entity_id": "Roy2018_TransferConcept",
        "name": "Transfer Concept",
        "title": "",
        "year": "2018",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AllArith_2017",
          "Perturb_2018",
          "Aggregate_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Verb Classification",
            "Coreference Resolution"
          ],
          "connections": [
            "Verb to Operation Mapping",
            "Coreference to Operation Mapping"
          ],
          "mechanisms": [
            "Verb-based Inference",
            "Coreference-based Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variable Modeling"
          ],
          "parameter_tuning": [
            "Verb Similarity Threshold",
            "Coreference Similarity Score"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Verb Classification",
          "Coreference Resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2018_UnitDependencyGraph",
      "label": "Unit Dependency Graph",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2018_UnitDependencyGraph",
        "entity_id": "Roy2018_UnitDependencyGraph",
        "name": "Unit Dependency Graph",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2018",
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Error Reduction"
        ],
        "architecture": {
          "components": [
            "Unit Dependency Graphs"
          ],
          "connections": [
            "Constrained Inference Framework"
          ],
          "mechanisms": [
            "Domain Knowledge"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameters"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sachan2017_FromTextbooksToKnowledge",
      "label": "From Textbooks to Knowledge",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sachan2017_FromTextbooksToKnowledge",
        "entity_id": "Sachan2017_FromTextbooksToKnowledge",
        "name": "From Textbooks to Knowledge",
        "title": "",
        "year": "2017",
        "authors": [
          "M. Sachan",
          "A. Dubey",
          "E. P. Xing"
        ],
        "task": "[\"Geometry Problem Solving\"]",
        "dataset": [
          "Geometry Textbooks"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Axiomatic Knowledge",
            "Reasoning Engine"
          ],
          "connections": [
            "Textbook Information to Problem Solving"
          ],
          "mechanisms": [
            "Structured Axiomatic Knowledge"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Parameter Optimization"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Sachan2017_TextbookAxiomaticKnowledge",
      "label": "Textbook Axiomatic Knowledge",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sachan2017_TextbookAxiomaticKnowledge",
        "entity_id": "Sachan2017_TextbookAxiomaticKnowledge",
        "name": "Textbook Axiomatic Knowledge",
        "title": "",
        "year": "2017",
        "authors": [
          "Sachan, M.",
          "Dubey, A.",
          "Xing, E. P."
        ],
        "task": "[\"Harvesting axiomatic knowledge from textbooks\"]",
        "dataset": [
          "Publicly available math textbooks"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Knowledge extraction",
            "Reasoning engine"
          ],
          "connections": [
            "Integration of structured axiomatic knowledge"
          ],
          "mechanisms": [
            "Logical inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Sadigh2012_AutomatedExerciseGeneration",
      "label": "Automated Exercise Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sadigh2012_AutomatedExerciseGeneration",
        "entity_id": "Sadigh2012_AutomatedExerciseGeneration",
        "name": "Automated Exercise Generation",
        "title": "",
        "year": "2012",
        "authors": [
          "Sadigh, D.",
          "Seshia, S. A.",
          "Gupta, M."
        ],
        "task": "[\"Exercise Generation for Embedded Systems\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Schwenk2007_ContinuousSpaceLanguageModel",
      "label": "Continuous Space Language Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Schwenk2007_ContinuousSpaceLanguageModel",
        "entity_id": "Schwenk2007_ContinuousSpaceLanguageModel",
        "name": "Continuous Space Language Model",
        "title": "",
        "year": "2007",
        "authors": [
          "Holger Schwenk"
        ],
        "task": "[\"Language Modeling\"]",
        "dataset": [
          "Target corpus"
        ],
        "metrics": [
          "Perplexity_LanguageModel"
        ],
        "architecture": {
          "components": [
            "Embedding layer",
            "Rectified layers",
            "Softmax output"
          ],
          "connections": [
            "Fully connected"
          ],
          "mechanisms": [
            "Word embeddings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic gradient descent"
          ],
          "parameter_tuning": [
            "Embedding dimension",
            "Layer sizes"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Schwenk2012_FeedforwardNeuralNetwork",
      "label": "Feedforward Neural Network",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Schwenk2012_FeedforwardNeuralNetwork",
        "entity_id": "Schwenk2012_FeedforwardNeuralNetwork",
        "name": "Feedforward Neural Network",
        "title": "",
        "year": "2012",
        "authors": [
          "Schwenk, H."
        ],
        "task": "[\"Phrase Pair Scoring\"]",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layers",
            "Output Layer"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Fixed-size Input and Output"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_CornerDetection",
      "label": "Corner Detection",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_CornerDetection",
        "entity_id": "Seo2014_CornerDetection",
        "name": "Corner Detection",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Corners"
          ],
          "connections": [
            "Matching Corners to Primitives"
          ],
          "mechanisms": [
            "Harris Corner Detector"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Encouraging Visual Coherence"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Scoring Corners Based on Proximity to Primitives"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_DiagramParser",
      "label": "Diagram Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_DiagramParser",
        "entity_id": "Seo2014_DiagramParser",
        "name": "Diagram Parser",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, Minjoon",
          "Hajishirzi, Hannaneh",
          "Farhadi, Ali",
          "Etzioni, Oren",
          "Malcolm, Clint"
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "SAT_Geometry_Questions_2015"
        ],
        "metrics": [
          "Diagram Score",
          "High-confidence Visual Literals"
        ],
        "architecture": {
          "components": [
            "Visual Element Extraction",
            "Coordinate Calculation",
            "Relationship Identification",
            "Entity Alignment"
          ],
          "connections": [
            "Text-Diagram Alignment",
            "Literal Grounding"
          ],
          "mechanisms": [
            "Optical Character Recognition",
            "Diagram Score Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Thresholds for High-confidence Literals"
          ]
        },
        "feature_processing": [
          "Visual Feature Extraction",
          "Textual Entity Recognition"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_DiagramUnderstanding",
      "label": "Diagram Understanding",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_DiagramUnderstanding",
        "entity_id": "Seo2014_DiagramUnderstanding",
        "name": "Diagram Understanding",
        "title": "",
        "year": "2014",
        "authors": [
          "M. J. Seo",
          "H. Hajishirzi",
          "A. Farhadi",
          "O. Etzioni"
        ],
        "task": "[\"Geometry Problem Solving\"]",
        "dataset": [
          "Geometry Diagrams"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Hough Transform",
            "Objective Function"
          ],
          "connections": [
            "Visual Elements to Logical Expressions"
          ],
          "mechanisms": [
            "Primitive Detection",
            "Textual-Visual Alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Pixel Coverage",
          "Visual Coherence"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Seo2014_G-ALIGNER",
      "label": "G-ALIGNER",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_G-ALIGNER",
        "entity_id": "Seo2014_G-ALIGNER",
        "name": "G-ALIGNER",
        "title": "Diagram Understanding in Geometry Questions",
        "year": "2014",
        "authors": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "Geometry Questions Dataset_2014"
        ],
        "metrics": [
          "F1 Score_Identifying Primitives",
          "F1 Score_Aligning Visual Elements"
        ],
        "architecture": {
          "components": [
            "Primitive Detection",
            "Textual Mention Extraction",
            "Alignment Constraint Function"
          ],
          "connections": [
            "Visual Coherence Function",
            "Coverage Function"
          ],
          "mechanisms": [
            "Submodular Optimization",
            "Greedy Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Optimization",
            "Initialization of Primitives",
            "Corner Detection"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Hough Transform",
          "Gaussian Blur",
          "Binarization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_GAligner",
      "label": "G-ALIGNER",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_GAligner",
        "entity_id": "Seo2014_GAligner",
        "name": "G-ALIGNER",
        "title": "",
        "year": "2014",
        "authors": [
          "Min Joon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni"
        ],
        "task": "[\"Diagram Understanding in Geometry Questions\"]",
        "dataset": [
          "GeometryQuestions_2014"
        ],
        "metrics": [
          "F1_PrecisionRecall"
        ],
        "architecture": {
          "components": [
            "submodular optimization",
            "greedy algorithm"
          ],
          "connections": [
            "visual and textual alignment"
          ],
          "mechanisms": [
            "primitive identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "no parameter tuning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "corner detection",
          "OCR"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_GALINGER",
      "label": "G-ALINGER",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_GALINGER",
        "entity_id": "Seo2014_GALINGER",
        "name": "G-ALINGER",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M.J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Geometry understanding and text understanding\"]",
        "dataset": [
          "AI2_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Hough transform",
            "Objective function",
            "Greedy algorithm"
          ],
          "connections": [
            "Primitive detection",
            "Pixel coverage",
            "Visual coherence",
            "Textual-visual alignment"
          ],
          "mechanisms": [
            "Sub-modular function optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised learning"
          ],
          "parameter_tuning": [
            "Hyperparameters for objective function"
          ]
        },
        "feature_processing": [
          "Primitive feature extraction",
          "Pixel feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Seo2014_GEOREP",
      "label": "GeoRep",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_GEOREP",
        "entity_id": "Seo2014_GEOREP",
        "name": "GeoRep",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M.J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "Geometry Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Structure Mapping Engine"
          ],
          "connections": [
            "Line Diagrams",
            "Qualitative Spatial Descriptions"
          ],
          "mechanisms": [
            "Two-Level Representation Architecture"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Structure Mapping Parameters"
          ]
        },
        "feature_processing": [
          "Visual Element Extraction",
          "Spatial Information"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Seo2014_Geos",
      "label": "GEOS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_Geos",
        "entity_id": "Seo2014_Geos",
        "name": "GEOS",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M.J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Solving geometric word problems\"]",
        "dataset": [
          "AI2_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Text parser",
            "Diagram parser",
            "Logical expression generator"
          ],
          "connections": [
            "Text-Diagram alignment",
            "Logical expression optimization"
          ],
          "mechanisms": [
            "Primitive detection",
            "Textual-visual alignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised learning"
          ],
          "parameter_tuning": [
            "Hyperparameters for logical expression optimization"
          ]
        },
        "feature_processing": [
          "Syntactic parsing",
          "Coreference resolution"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Seo2014_GeoSolver",
      "label": "GeoSolver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_GeoSolver",
        "entity_id": "Seo2014_GeoSolver",
        "name": "GeoSolver",
        "title": "Diagram Understanding in Geometry Questions",
        "year": "2014",
        "authors": [
          "Seo",
          "Hajishirzi",
          "Farhadi",
          "Etzioni"
        ],
        "task": "[\"Geometry Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Diagram Parser",
            "Text Parser"
          ],
          "connections": [
            "Visual-Text Alignment"
          ],
          "mechanisms": [
            "Hough Transform"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Thresholds"
          ]
        },
        "feature_processing": [
          "Visual Features",
          "Textual Features"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Seo2014_GreedyMethod",
      "label": "Greedy Method",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_GreedyMethod",
        "entity_id": "Seo2014_GreedyMethod",
        "name": "Greedy Method",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Primitive Identification",
            "Alignment with Textual Mentions"
          ],
          "connections": [
            "Coverage Function",
            "Visual Coherence Function",
            "Alignment Constraint Function"
          ],
          "mechanisms": [
            "Submodular Optimization",
            "Greedy Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Optimization"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Hough Transform for Initial Primitives",
          "Corner Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_HarrisCornerDetector",
      "label": "Harris Corner Detector",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_HarrisCornerDetector",
        "entity_id": "Seo2014_HarrisCornerDetector",
        "name": "Harris Corner Detector",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Corner Detection\"]",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Corner Detection"
          ],
          "connections": [
            "Visual Coherence Function"
          ],
          "mechanisms": [
            "Feature Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Initialization"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Corner Scoring"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_HoughTransform",
      "label": "Hough Transform",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_HoughTransform",
        "entity_id": "Seo2014_HoughTransform",
        "name": "Hough Transform",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Primitive Detection\"]",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Line Detection",
            "Circle Detection"
          ],
          "connections": [
            "Parametric Representation",
            "Post-processing for Endpoints"
          ],
          "mechanisms": [
            "Thresholding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Parameter Tuning"
          ],
          "parameter_tuning": [
            "Threshold for Line Detection",
            "Threshold for Circle Detection",
            "Non-maximum Suppression Parameters"
          ]
        },
        "feature_processing": [
          "Gaussian Blur",
          "Binarization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_OptimizationProcedure",
      "label": "Optimization Procedure",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_OptimizationProcedure",
        "entity_id": "Seo2014_OptimizationProcedure",
        "name": "Optimization Procedure",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall",
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Coverage Function",
            "Visual Coherence Function",
            "Alignment Constraint Function"
          ],
          "connections": [
            "Maximizing Agreement Between Textual and Visual Data"
          ],
          "mechanisms": [
            "Submodular Optimization",
            "Greedy Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Greedy Method"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Primitive Extraction",
          "Corner Detection",
          "Textual Mention Initialization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_PrimitiveExtraction",
      "label": "Primitive Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_PrimitiveExtraction",
        "entity_id": "Seo2014_PrimitiveExtraction",
        "name": "Primitive Extraction",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Line Segments",
            "Circle Segments",
            "Arcs"
          ],
          "connections": [
            "Combining Primitives into Visual Elements"
          ],
          "mechanisms": [
            "Hough Transform",
            "Post-processing for Endpoint Determination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Over-generation of Primitives"
          ],
          "parameter_tuning": [
            "Low Threshold for Over-generation"
          ]
        },
        "feature_processing": [
          "Noise Removal",
          "Binarization",
          "Continuous Binary Point Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_SubmodularOptimization",
      "label": "Submodular Optimization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_SubmodularOptimization",
        "entity_id": "Seo2014_SubmodularOptimization",
        "name": "Submodular Optimization",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall",
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Coverage Function",
            "Visual Coherence Function",
            "Alignment Constraint Function"
          ],
          "connections": [
            "Maximizing Agreement Between Textual and Visual Data"
          ],
          "mechanisms": [
            "Submodular Objective Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Iterative Greedy Method"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Primitive Extraction",
          "Corner Detection",
          "Textual Mention Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2014_TextualMentionExtraction",
      "label": "Textual Mention Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_TextualMentionExtraction",
        "entity_id": "Seo2014_TextualMentionExtraction",
        "name": "Textual Mention Extraction",
        "title": "",
        "year": "2014",
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O."
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "Geometry Questions Dataset"
        ],
        "metrics": [
          "F1 Score",
          "Precision",
          "Recall"
        ],
        "architecture": {
          "components": [
            "Textual Mentions"
          ],
          "connections": [
            "Aligning Textual Mentions to Visual Elements"
          ],
          "mechanisms": [
            "Keyword Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Extracting Mentions from Textual Descriptions"
          ],
          "parameter_tuning": [
            "Not Required"
          ]
        },
        "feature_processing": [
          "Keyword Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2015_GEOS",
      "label": "GEOS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2015_GEOS",
        "entity_id": "Seo2015_GEOS",
        "name": "GEOS",
        "title": "Solving Geometry Problems: Combining Text and Diagram Interpretation",
        "year": "2015",
        "authors": [
          "Minjoon Seo",
          "Hannaneh Hajishirzi",
          "Ali Farhadi",
          "Oren Etzioni",
          "Clint Malcolm"
        ],
        "task": "[\"Geometry Problem Solving\"]",
        "dataset": [
          "SAT_Geometry_2015"
        ],
        "metrics": [
          "Accuracy_GeometryTheoremProving",
          "Precision_GeometryTheoremProving",
          "Recall_GeometryTheoremProving"
        ],
        "architecture": {
          "components": [
            "Text Parser",
            "Diagram Parser",
            "Geometric Solver"
          ],
          "connections": [
            "Text-Diagram Alignment",
            "Submodular Optimization"
          ],
          "mechanisms": [
            "Logical Representation",
            "Submodular Set Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Rule-based Parsing"
          ],
          "parameter_tuning": [
            "λ"
          ]
        },
        "feature_processing": [
          "Concept Identification",
          "Relation Identification",
          "High-confidence Visual Literals"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2015_GeoShader",
      "label": "GeoShader",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2015_GeoShader",
        "entity_id": "Seo2015_GeoShader",
        "name": "GeoShader",
        "title": "",
        "year": "2015",
        "authors": [
          "Alvin, C.",
          "Gulwani, S.",
          "Majumdar, R.",
          "Mukhopadhyay, S."
        ],
        "task": "[\"Solving geometry problems with shaded areas\"]",
        "dataset": [
          "AI2_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Hypergraph",
            "Intermediate facts extraction"
          ],
          "connections": [
            "Fact-to-fact relationships"
          ],
          "mechanisms": [
            "Analysis hypergraph"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based reasoning"
          ],
          "parameter_tuning": [
            "Hyperparameters for hypergraph analysis"
          ]
        },
        "feature_processing": [
          "Diagram parsing",
          "Intermediate fact extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Seo2015_HypergraphRepresentation",
      "label": "Hypergraph Representation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2015_HypergraphRepresentation",
        "entity_id": "Seo2015_HypergraphRepresentation",
        "name": "Hypergraph Representation",
        "title": "",
        "year": "2015",
        "authors": [
          "Seo, Minjoon",
          "Hajishirzi, Hannaneh",
          "Farhadi, Ali",
          "Etzioni, Oren",
          "Malcolm, Clint"
        ],
        "task": "[\"Geometry Question Interpretation\"]",
        "dataset": [
          "SAT_Geometry_Questions_2015"
        ],
        "metrics": [
          "Accuracy_Classification",
          "F1_Score_Text_Interpretation"
        ],
        "architecture": {
          "components": [
            "Concept Nodes",
            "Relations",
            "Edges"
          ],
          "connections": [
            "Concept Nodes to Relations"
          ],
          "mechanisms": [
            "Concept Identification",
            "Relation Identification",
            "Literal Parsing",
            "Relation Completion"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Log-linear Model Parameters"
          ]
        },
        "feature_processing": [
          "Concept Identification Features",
          "Relation Type Features",
          "Geometry Language Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2015_LogicalExpressionDerivation",
      "label": "Logical Expression Derivation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2015_LogicalExpressionDerivation",
        "entity_id": "Seo2015_LogicalExpressionDerivation",
        "name": "Logical Expression Derivation",
        "title": "",
        "year": "2015",
        "authors": [
          "Seo, M.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O.",
          "Malcolm, C."
        ],
        "task": "[\"Geometry Problem Solving\"]",
        "dataset": [
          "SAT_Geometry_Questions_2015"
        ],
        "metrics": [
          "Accuracy_Classification",
          "F1_Score"
        ],
        "architecture": {
          "components": [
            "Text Parsing",
            "Diagram Parsing",
            "Literal Selection"
          ],
          "connections": [
            "Text-Diagram Integration",
            "Submodular Optimization"
          ],
          "mechanisms": [
            "Hypergraph Representation",
            "Log-linear Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Submodular Optimization"
          ],
          "parameter_tuning": [
            "Trade-off Parameter λ"
          ]
        },
        "feature_processing": [
          "Concept Identification",
          "Relation Identification",
          "Relation Completion"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seo2015_LogLinearModel",
      "label": "Log-linear Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2015_LogLinearModel",
        "entity_id": "Seo2015_LogLinearModel",
        "name": "Log-linear Model",
        "title": "",
        "year": "2015",
        "authors": [
          "Seo, Minjoon",
          "Hajishirzi, Hannaneh",
          "Farhadi, Ali",
          "Etzioni, Oren",
          "Malcolm, Clint"
        ],
        "task": "[\"Relation Scoring\"]",
        "dataset": [
          "SAT_Geometry_Questions_2015"
        ],
        "metrics": [
          "Accuracy_Classification",
          "F1_Score_Text_Interpretation"
        ],
        "architecture": {
          "components": [
            "Feature Vectors",
            "Parameters"
          ],
          "connections": [
            "Feature Vector to Score"
          ],
          "mechanisms": [
            "Maximum Likelihood Estimation",
            "L2 Regularization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "L2 Regularization Parameter"
          ]
        },
        "feature_processing": [
          "Structural Features",
          "Geometry Language Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Seq2SeqET2018_Seq2SeqET",
      "label": "Seq2SeqET",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seq2SeqET2018_Seq2SeqET",
        "entity_id": "Seq2SeqET2018_Seq2SeqET",
        "name": "Seq2SeqET",
        "title": "",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Wang, Y.",
          "Cai, D.",
          "Zhang, D.",
          "Liu, X."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Expression Tree"
          ],
          "connections": [
            "Encoder-Decoder"
          ],
          "mechanisms": [
            "Equation Normalization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Model Parameters"
          ]
        },
        "feature_processing": [
          "Text Embedding",
          "GRU Network"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Serban2016_DialogueSystems",
      "label": "Dialogue Systems",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Serban2016_DialogueSystems",
        "entity_id": "Serban2016_DialogueSystems",
        "name": "Dialogue Systems",
        "title": "",
        "year": "2016",
        "authors": [
          "Serban, I.V.",
          "Sordoni, A.",
          "Bengio, Y.",
          "Courville, A.C.",
          "Pineau, J."
        ],
        "task": "[\"Dialogue Generation\"]",
        "dataset": [
          "Various Dialogue Corpora"
        ],
        "metrics": [
          "BLEU",
          "ROUGE"
        ],
        "architecture": {
          "components": [
            "Hierarchical Neural Network"
          ],
          "connections": [
            "Sequential Dialogue Generation"
          ],
          "mechanisms": [
            "Generative Hierarchical Model"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross-Entropy Loss"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Shen2002_ModifiedHoughTransform",
      "label": "Modified Hough Transform",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Shen2002_ModifiedHoughTransform",
        "entity_id": "Shen2002_ModifiedHoughTransform",
        "name": "Modified Hough Transform",
        "title": "Corner detection based on modified Hough transform",
        "year": "2002",
        "authors": [
          "F. Shen",
          "H. Wang"
        ],
        "task": "[\"Corner Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Accumulator Array",
            "Edge Points"
          ],
          "connections": [
            "Edge Points -> Accumulator Array"
          ],
          "mechanisms": [
            "Peak Detection",
            "Quantization"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": [
            "Quantization Steps dθ and dρ"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Shi2015_CFGParser",
      "label": "CFG Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Shi2015_CFGParser",
        "entity_id": "Shi2015_CFGParser",
        "name": "CFG Parser",
        "title": "",
        "year": "2015",
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Algebra.com_2015",
          "YahooAnswers.com_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "CFG Grammar Rules",
            "Top-down Parser",
            "Earley Algorithm"
          ],
          "connections": [
            "Parsing NL Text to DOL Trees"
          ],
          "mechanisms": [
            "Context-Free Grammar",
            "Dynamic Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Semi-automatic Creation of Grammar Rules"
          ],
          "parameter_tuning": [
            "Type Compatibility Checking"
          ]
        },
        "feature_processing": [
          "Lexical String Handling",
          "Entity Variable Assignment"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Shi2015_DOL",
      "label": "DOL",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Shi2015_DOL",
        "entity_id": "Shi2015_DOL",
        "name": "DOL",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": "2015",
        "authors": [
          "Shi",
          "Wang",
          "Lin",
          "Liu",
          "Rui"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Semantic Parser",
            "CFG Parser"
          ],
          "connections": [
            "Context-Free Grammar"
          ],
          "mechanisms": [
            "Dependency Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Lexicon Construction"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Grammar Rules"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Shi2015_NumberWordProblems",
      "label": "Number Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Shi2015_NumberWordProblems",
        "entity_id": "Shi2015_NumberWordProblems",
        "name": "Number Word Problem Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "[\"Solving number word problems\"]",
        "dataset": [
          "Number word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Semantic parsing",
            "Reasoning"
          ],
          "connections": [
            "Parsing and reasoning"
          ],
          "mechanisms": [
            "Semantic analysis"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Semantic-based learning"
          ],
          "parameter_tuning": [
            "Semantic parameters"
          ]
        },
        "feature_processing": [
          "Semantic feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Shi2015_NumberWordProblemSolver",
      "label": "Number Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Shi2015_NumberWordProblemSolver",
        "entity_id": "Shi2015_NumberWordProblemSolver",
        "name": "Number Word Problem Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.-Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "[\"自动解决数学文字问题\"]",
        "dataset": [
          "Dolphin1878_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "语义解析模块",
            "推理模块"
          ],
          "connections": [
            "输入问题 -> 语义解析 -> 推理 -> 输出答案"
          ],
          "mechanisms": [
            "模式匹配",
            "动词分类"
          ]
        },
        "methodology": {
          "training_strategy": [
            "监督学习"
          ],
          "parameter_tuning": [
            "超参数调整"
          ]
        },
        "feature_processing": [
          "句子结构化",
          "方程推导"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Shi2015_ReasoningModule",
      "label": "Reasoning Module",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Shi2015_ReasoningModule",
        "entity_id": "Shi2015_ReasoningModule",
        "name": "Reasoning Module",
        "title": "",
        "year": "2015",
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Algebra.com_2015",
          "YahooAnswers.com_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "Math Expression Derivation",
            "Equation System Solver"
          ],
          "connections": [
            "Deriving Math Expressions from DOL Trees"
          ],
          "mechanisms": [
            "Semantic Interpretation of DOL Nodes"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Construction of Semantic Interpretations"
          ],
          "parameter_tuning": [
            "Handling Empty Parsing Results"
          ]
        },
        "feature_processing": [
          "Variable ID Assignment",
          "Lazy Variable ID Assignment"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Shi2015_SemanticParsingAndReasoning",
      "label": "Semantic Parsing and Reasoning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Shi2015_SemanticParsingAndReasoning",
        "entity_id": "Shi2015_SemanticParsingAndReasoning",
        "name": "Semantic Parsing and Reasoning",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": "2015",
        "authors": [
          "Shi, S.",
          "Wang, Y.",
          "Lin, C.-Y.",
          "Liu, X.",
          "Rui, Y."
        ],
        "task": "[\"Solving Math Word Problems\"]",
        "dataset": [
          "Algebra.com_2015",
          "YahooAnswers.com_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "Meaning Representation Language (DOL)",
            "CFG Parser",
            "Reasoning Module"
          ],
          "connections": [
            "NL Text -> DOL Trees -> Math Expressions"
          ],
          "mechanisms": [
            "Semantic Parsing",
            "Reasoning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CFG Grammar Rules",
            "Semantic Interpretation"
          ],
          "parameter_tuning": [
            "Type Compatibility Checking",
            "Score Calculation"
          ]
        },
        "feature_processing": [
          "Context-Free Grammar Parsing",
          "Entity Variable Assignment"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Shi2015_SigmaDolphin",
      "label": "SigmaDolphin",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Shi2015_SigmaDolphin",
        "entity_id": "Shi2015_SigmaDolphin",
        "name": "SigmaDolphin",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": "2015",
        "authors": [
          "Shi, Shuming",
          "Wang, Yuehui",
          "Lin, Chin-Yew",
          "Liu, Xiaojiang",
          "Rui, Yong"
        ],
        "task": "[\"Solving Number Word Problems\"]",
        "dataset": [
          "Algebra.com_2015",
          "Yahoo_Answers_2015"
        ],
        "metrics": [
          "Precision_Classification",
          "Recall_Classification",
          "F1_Classification"
        ],
        "architecture": {
          "components": [
            "CFG parser",
            "reasoning module",
            "DOL language"
          ],
          "connections": [
            "semantic parsing",
            "math expression derivation"
          ],
          "mechanisms": [
            "context-free grammar",
            "semantic interpretation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CFG rules",
            "semantic interpretation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "natural language sentences",
          "mathematical expressions"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "SIM2016_SimilarityBasedMethod",
      "label": "SIM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "SIM2016_SimilarityBasedMethod",
        "entity_id": "SIM2016_SimilarityBasedMethod",
        "name": "SIM",
        "title": "",
        "year": "2016",
        "authors": [
          "Huang, D.",
          "Shi, S.",
          "Lin, C.Y.",
          "Yin, J.",
          "Ma, W.Y."
        ],
        "task": "[\"自动数学应用题求解\"]",
        "dataset": [
          "Alg514_2014",
          "SingleEQ_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "相似度计算模块",
            "模板选择模块",
            "模板填充模块"
          ],
          "connections": [
            "问题句子相似度计算",
            "最相似问题模板选择",
            "模板填充"
          ],
          "mechanisms": [
            "基于相似度的方法",
            "问题句子解析"
          ]
        },
        "methodology": {
          "training_strategy": [
            "使用相似度进行训练"
          ],
          "parameter_tuning": [
            "相似度阈值"
          ]
        },
        "feature_processing": [
          "问题句子特征提取"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Singh2012_AlgebraProblemGenerator",
      "label": "Algebra Problem Generator",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Singh2012_AlgebraProblemGenerator",
        "entity_id": "Singh2012_AlgebraProblemGenerator",
        "name": "Algebra Problem Generator",
        "title": "",
        "year": "2012",
        "authors": [
          "Singh, R.",
          "Gulwani, S.",
          "Rajamani, S. K."
        ],
        "task": "[\"Algebra Problem Generation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Singley2002_AutomaticItemGeneration",
      "label": "Automatic Item Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Singley2002_AutomaticItemGeneration",
        "entity_id": "Singley2002_AutomaticItemGeneration",
        "name": "Automatic Item Generation",
        "title": "",
        "year": "2002",
        "authors": [
          "Singley, M. K.",
          "Bennett, R. E."
        ],
        "task": "[\"Mathematical Word Problem Generation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Template-based natural language generation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Siya2017_ArabicArithmeticWordProblemsSolver",
      "label": "Arabic Arithmetic Word Problems Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Siya2017_ArabicArithmeticWordProblemsSolver",
        "entity_id": "Siya2017_ArabicArithmeticWordProblemsSolver",
        "name": "Arabic Arithmetic Word Problems Solver",
        "title": "",
        "year": "2017",
        "authors": [
          "B. Siyam",
          "A. A. Saa",
          "O. Alqaryouti",
          "K. Shaalan"
        ],
        "task": "[\"Arabic Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Arabic Arithmetic Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Verb Categorization",
            "Syntactic Parser",
            "Named Entity Recognition"
          ],
          "connections": [
            "Text to Quantity Relations"
          ],
          "mechanisms": [
            "Semantic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Parameter Optimization"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Siyam2017_ArabicArithmetic",
      "label": "Arabic Arithmetic Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Siyam2017_ArabicArithmetic",
        "entity_id": "Siyam2017_ArabicArithmetic",
        "name": "Arabic Arithmetic Word Problem Solver",
        "title": "Solving Arabic Arithmetic Word Problems",
        "year": "2017",
        "authors": [
          "Siyam",
          "Saa",
          "Alqaryouti",
          "Shaalan"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Verb Categorization"
          ],
          "connections": [
            "Syntactic Parser",
            "Named Entity Recognition"
          ],
          "mechanisms": [
            "Customization for Arabic Language"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Verb Categorization",
          "Syntactic Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Siyam2017_ArabicArithmeticProblems",
      "label": "Arabic Arithmetic Problems Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Siyam2017_ArabicArithmeticProblems",
        "entity_id": "Siyam2017_ArabicArithmeticProblems",
        "name": "Arabic Arithmetic Problems Solver",
        "title": "",
        "year": "2017",
        "authors": [
          "Siyam, B.",
          "Saa, A. A.",
          "Alqaryouti, O.",
          "Shaalan, K."
        ],
        "task": "[\"Solving Arabic arithmetic word problems\"]",
        "dataset": [
          "Arabic arithmetic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Verb categorization"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Customization for Arabic language"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Siyam2017_ArabicArithmeticWordProblemSolver",
      "label": "Arabic Arithmetic Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Siyam2017_ArabicArithmeticWordProblemSolver",
        "entity_id": "Siyam2017_ArabicArithmeticWordProblemSolver",
        "name": "Arabic Arithmetic Word Problem Solver",
        "title": "",
        "year": "2017",
        "authors": [
          "Siyam, B.",
          "Saa, A. A.",
          "Alqaryouti, O.",
          "Shaalan, K."
        ],
        "task": "[\"Solving Arabic arithmetic word problems\"]",
        "dataset": [
          "Arabic arithmetic word problem datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Verb categorization"
          ],
          "connections": [
            "Syntactic parser and named entity recognition"
          ],
          "mechanisms": [
            "Customization for Arabic language"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Model training"
          ],
          "parameter_tuning": [
            "Hyperparameter tuning"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Siyam2017_AxiomaticKnowledge",
      "label": "AxiomaticKnowledge",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Siyam2017_AxiomaticKnowledge",
        "entity_id": "Siyam2017_AxiomaticKnowledge",
        "name": "AxiomaticKnowledge",
        "title": "From Textbooks to Knowledge: A Case Study in Harvesting Axiomatic Knowledge from Textbooks to Solve Geometry Problems",
        "year": "2017",
        "authors": [
          "Sachan",
          "Dubey",
          "Xing"
        ],
        "task": "[\"Geometry Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Axiomatic Knowledge Base",
            "Reasoning Engine"
          ],
          "connections": [
            "Knowledge Integration"
          ],
          "mechanisms": [
            "Logical Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Regularization Parameters"
          ]
        },
        "feature_processing": [
          "Axiomatic Knowledge Extraction",
          "Logical Inference"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Slagle1965_AdviceTaker",
      "label": "Advice Taker",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Slagle1965_AdviceTaker",
        "entity_id": "Slagle1965_AdviceTaker",
        "name": "Advice Taker",
        "title": "",
        "year": "1965",
        "authors": [
          "McCarthy, J."
        ],
        "task": "[\"Deductive reasoning and question answering\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Fact representation",
            "Inference rules"
          ],
          "connections": [
            "Logical deduction",
            "Predicate calculus"
          ],
          "mechanisms": [
            "Heuristic programming",
            "Educated guessing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based inference"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Logical transformations"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Slagle1965_DEDUCOM",
      "label": "DEDUCOM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Slagle1965_DEDUCOM",
        "entity_id": "Slagle1965_DEDUCOM",
        "name": "DEDUCOM",
        "title": "Experiments with a Deductive Question-Answering Program",
        "year": "1965",
        "authors": [
          "James R. Slagle"
        ],
        "task": "[\"Deductive Question-Answering\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Fact Interpreter",
            "Question Reducer",
            "Search Procedure"
          ],
          "connections": [
            "Fact Interpreter -> Question Reducer",
            "Question Reducer -> Search Procedure"
          ],
          "mechanisms": [
            "Depth-First Search",
            "Logical Deduction in Predicate Calculus"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Providing facts to the system"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Logical deduction rules",
          "Fact representation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Slagle1965_DepthFirstSearch",
      "label": "Depth-First Search",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Slagle1965_DepthFirstSearch",
        "entity_id": "Slagle1965_DepthFirstSearch",
        "name": "Depth-First Search",
        "title": "",
        "year": "1965",
        "authors": [
          "Slagle, J.R."
        ],
        "task": "[\"Search Procedure\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Nodes",
            "Branches"
          ],
          "connections": [
            "Traversal Order"
          ],
          "mechanisms": [
            "Backtracking"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Slagle1965_LISPInterpreterExtension",
      "label": "LISP Interpreter Extension",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Slagle1965_LISPInterpreterExtension",
        "entity_id": "Slagle1965_LISPInterpreterExtension",
        "name": "LISP Interpreter Extension",
        "title": "",
        "year": "1965",
        "authors": [
          "Slagle, J.R."
        ],
        "task": "[\"Deductive Question-Answering\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "LISP Interpreter",
            "Fact Processing Module",
            "Question Reduction Module"
          ],
          "connections": [
            "Fact Processing -> Question Reduction -> Answer Generation"
          ],
          "mechanisms": [
            "Recursive Question Reduction",
            "Fact Lookup"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Fact Representation",
          "Logical Deduction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Slagle1965_QuestionReduction",
      "label": "Question Reduction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Slagle1965_QuestionReduction",
        "entity_id": "Slagle1965_QuestionReduction",
        "name": "Question Reduction",
        "title": "",
        "year": "1965",
        "authors": [
          "Slagle, J.R."
        ],
        "task": "[\"Deductive Question-Answering\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Original Question",
            "Simpler Question",
            "Directly Answerable Question"
          ],
          "connections": [
            "Reduction Process"
          ],
          "mechanisms": [
            "Deduction Rules"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Slagle1965_SIRProgram",
      "label": "SIR Program",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Slagle1965_SIRProgram",
        "entity_id": "Slagle1965_SIRProgram",
        "name": "SIR Program",
        "title": "",
        "year": "1965",
        "authors": [
          "Raphael, B."
        ],
        "task": "[\"Question answering\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Fact representation",
            "Inference rules"
          ],
          "connections": [
            "Logical deduction",
            "Predicate calculus"
          ],
          "mechanisms": [
            "Heuristic programming",
            "Educated guessing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based inference"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Logical transformations"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Slagle1965_Valueans",
      "label": "Valueans",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Slagle1965_Valueans",
        "entity_id": "Slagle1965_Valueans",
        "name": "Valueans",
        "title": "",
        "year": "1965",
        "authors": [
          "Slagle, J.R."
        ],
        "task": "[\"Question Answering\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Valueans Function"
          ],
          "connections": [
            "Valueans to Answer Generation"
          ],
          "mechanisms": [
            "Logical Deduction"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sleator1993_LinkParser",
      "label": "Link Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sleator1993_LinkParser",
        "entity_id": "Sleator1993_LinkParser",
        "name": "Link Parser",
        "title": "",
        "year": "1993",
        "authors": [
          "Daniel D. Sleator",
          "Davy Temperley"
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "Dependency Accuracy"
        ],
        "architecture": {
          "components": [
            "Dependency Parsing"
          ],
          "connections": [
            "Dependency Extraction Rules"
          ],
          "mechanisms": [
            "Head Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Rule-Based"
          ]
        },
        "feature_processing": [
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_BerkeleyParser",
      "label": "Berkeley Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_BerkeleyParser",
        "entity_id": "Socher2013_BerkeleyParser",
        "name": "Berkeley Parser",
        "title": "",
        "year": "2013",
        "authors": [
          "Petrov, S.",
          "Klein, D."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Factored PCFGs"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Expectation Propagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_BottomUpBeamSearch",
      "label": "Bottom-Up Beam Search",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_BottomUpBeamSearch",
        "entity_id": "Socher2013_BottomUpBeamSearch",
        "name": "Bottom-Up Beam Search",
        "title": "",
        "year": "2013",
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing",
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "CKY Dynamic Programming"
          ],
          "connections": [
            "Tree Scoring",
            "Inference"
          ],
          "mechanisms": [
            "Efficient Approximation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-Pass Inference"
          ],
          "parameter_tuning": [
            "Beam Size k"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_CharniakJohnsonParser",
      "label": "Charniak-Johnson Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_CharniakJohnsonParser",
        "entity_id": "Socher2013_CharniakJohnsonParser",
        "name": "Charniak-Johnson Parser",
        "title": "",
        "year": "2013",
        "authors": [
          "Charniak, E.",
          "Johnson, M."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Self-trained",
            "Discriminatively re-ranked"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Combining multiple approaches"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_CharniakSelfTrainedParser",
      "label": "Charniak Self-Trained Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_CharniakSelfTrainedParser",
        "entity_id": "Socher2013_CharniakSelfTrainedParser",
        "name": "Charniak Self-Trained Parser",
        "title": "",
        "year": "2013",
        "authors": [
          "McClosky, D.",
          "Charniak, E.",
          "Johnson, M."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Self-training",
            "Re-ranking"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Bootstrapping",
            "Parsing additional large corpora"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_CollinsParser",
      "label": "Collins Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_CollinsParser",
        "entity_id": "Socher2013_CollinsParser",
        "name": "Collins Parser",
        "title": "",
        "year": "2013",
        "authors": [
          "Collins, M."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Head-driven statistical models"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Generative models"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_CompositionalVectorGrammar",
      "label": "Compositional Vector Grammar (CVG)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_CompositionalVectorGrammar",
        "entity_id": "Socher2013_CompositionalVectorGrammar",
        "name": "Compositional Vector Grammar (CVG)",
        "title": "Parsing with Compositional Vector Grammars",
        "year": "2013",
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "[\"自然语言解析\"]",
        "dataset": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1_Score_Parsing",
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "PCFG",
            "递归神经网络(RNN)",
            "分布式的词向量表示"
          ],
          "connections": [
            "PCFG与RNN结合",
            "RNN权重与句法类别条件相关"
          ],
          "mechanisms": [
            "软性头部词概念",
            "分布式的组合语义表示"
          ]
        },
        "methodology": {
          "training_strategy": [
            "最大间隔训练目标",
            "AdaGrad优化"
          ],
          "parameter_tuning": [
            "学习率调整",
            "矩阵初始化"
          ]
        },
        "feature_processing": [
          "词向量表示",
          "上下文窗口特征"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_CompositionalVectorGrammars",
      "label": "Compositional Vector Grammars",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_CompositionalVectorGrammars",
        "entity_id": "Socher2013_CompositionalVectorGrammars",
        "name": "Compositional Vector Grammars",
        "title": "",
        "year": "2013",
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C.D.",
          "Ng, A.Y."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Vector Grammars"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_FactoredPCFGs",
      "label": "Factored PCFGs",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_FactoredPCFGs",
        "entity_id": "Socher2013_FactoredPCFGs",
        "name": "Factored PCFGs",
        "title": "",
        "year": "2013",
        "authors": [
          "Hall, D.",
          "Klein, D."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Factored PCFGs"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Expectation Propagation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_MaxMarginTrainingObjective",
      "label": "Max-Margin Training Objective",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_MaxMarginTrainingObjective",
        "entity_id": "Socher2013_MaxMarginTrainingObjective",
        "name": "Max-Margin Training Objective",
        "title": "",
        "year": "2013",
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing",
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Structured Margin Loss",
            "Compositional Vector Grammar"
          ],
          "connections": [
            "Tree Scoring",
            "Inference"
          ],
          "mechanisms": [
            "Max-Margin Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Gradient Ascent",
            "Backpropagation Through Structure"
          ],
          "parameter_tuning": [
            "Regularization Parameter λ",
            "Learning Rate α"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_SimplifiedStanfordParser",
      "label": "Simplified Stanford Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_SimplifiedStanfordParser",
        "entity_id": "Socher2013_SimplifiedStanfordParser",
        "name": "Simplified Stanford Parser",
        "title": "",
        "year": "2013",
        "authors": [
          "Klein, D.",
          "Manning, C. D."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "PCFG"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "CKY dynamic programming"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_SSNParser",
      "label": "SSN Parser",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_SSNParser",
        "entity_id": "Socher2013_SSNParser",
        "name": "SSN Parser",
        "title": "",
        "year": "2013",
        "authors": [
          "Henderson, J."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Statistical Neural Network"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Discriminative training"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_StandardRecursiveNeuralNetwork",
      "label": "Standard Recursive Neural Network (RNN)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_StandardRecursiveNeuralNetwork",
        "entity_id": "Socher2013_StandardRecursiveNeuralNetwork",
        "name": "Standard Recursive Neural Network (RNN)",
        "title": "",
        "year": "2013",
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "[\"Syntactic Parsing\"]",
        "dataset": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score",
          "Labeled F1"
        ],
        "architecture": {
          "components": [
            "Recursive Neural Network"
          ],
          "connections": [
            "Fully tied weights across nodes"
          ],
          "mechanisms": [
            "Single composition function for all types of compositions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin training objective"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word vector representations"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_SubgradientMethodsAdaGrad",
      "label": "Subgradient Methods and AdaGrad",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_SubgradientMethodsAdaGrad",
        "entity_id": "Socher2013_SubgradientMethodsAdaGrad",
        "name": "Subgradient Methods and AdaGrad",
        "title": "",
        "year": "2013",
        "authors": [
          "Socher, R.",
          "Bauer, J.",
          "Manning, C. D.",
          "Ng, A. Y."
        ],
        "task": "[\"Optimization\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing",
          "Labeled_F1_Parsing"
        ],
        "architecture": {
          "components": [
            "Subgradient Method",
            "AdaGrad"
          ],
          "connections": [
            "Parameter Updates",
            "Minibatch Training"
          ],
          "mechanisms": [
            "Diagonal Variant of AdaGrad"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate α",
            "Mini-batch Size"
          ]
        },
        "feature_processing": [
          "Word Vector Representations",
          "POS Tags"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Socher2013_SyntacticallyUntiedRecursiveNeuralNetwork",
      "label": "Syntactically Untied Recursive Neural Network (SU-RNN)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Socher2013_SyntacticallyUntiedRecursiveNeuralNetwork",
        "entity_id": "Socher2013_SyntacticallyUntiedRecursiveNeuralNetwork",
        "name": "Syntactically Untied Recursive Neural Network (SU-RNN)",
        "title": "",
        "year": "2013",
        "authors": [
          "Richard Socher",
          "John Bauer",
          "Christopher D. Manning",
          "Andrew Y. Ng"
        ],
        "task": "[\"Syntactic Parsing\"]",
        "dataset": [
          "Penn Treebank WSJ"
        ],
        "metrics": [
          "F1 Score",
          "Labeled F1"
        ],
        "architecture": {
          "components": [
            "Recursive Neural Network",
            "Syntactically Untied Weights"
          ],
          "connections": [
            "Parent-child connections based on syntactic categories"
          ],
          "mechanisms": [
            "Composition function conditioned on syntactic categories"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin training objective",
            "Backpropagation through structure"
          ],
          "parameter_tuning": [
            "Subgradient methods",
            "AdaGrad"
          ]
        },
        "feature_processing": [
          "Word vector representations",
          "POS tags"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Srivastava2014_Dropout",
      "label": "Dropout",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Srivastava2014_Dropout",
        "entity_id": "Srivastava2014_Dropout",
        "name": "Dropout",
        "title": "",
        "year": "2014",
        "authors": [
          "Srivastava, N.",
          "Hinton, G.",
          "Krizhevsky, A.",
          "Sutskever, I.",
          "Salakhutdinov, R."
        ],
        "task": "[\"Regularization\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Dropout Layer"
          ],
          "connections": [
            "Randomly Dropping Units"
          ],
          "mechanisms": [
            "Preventing Overfitting"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "StackDecoder2019_StackDecoder",
      "label": "StackDecoder",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "StackDecoder2019_StackDecoder",
        "entity_id": "StackDecoder2019_StackDecoder",
        "name": "StackDecoder",
        "title": "",
        "year": "2019",
        "authors": [
          "Chiang, T.",
          "Chen, Y."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Stack"
          ],
          "connections": [
            "Encoder-Decoder"
          ],
          "mechanisms": [
            "Operand Tracking"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Model Parameters"
          ]
        },
        "feature_processing": [
          "Semantic Meaning Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Stanford2013_SieveModel",
      "label": "Stanford Sieve Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Stanford2013_SieveModel",
        "entity_id": "Stanford2013_SieveModel",
        "name": "Stanford Sieve Model",
        "title": "",
        "year": "2013",
        "authors": [
          "Lee, H.",
          "Raghunathan, K.",
          "Surdeanu, M.",
          "Jurafsky, D."
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE2004_NWIRE_2004",
          "CONLL2011_2011"
        ],
        "metrics": [
          "MUC_Coreference",
          "B3_Coreference",
          "Pairwise_Coreference"
        ],
        "architecture": {
          "components": [
            "mention detection",
            "cluster merging operations"
          ],
          "connections": [
            "deterministic rules",
            "sieves"
          ],
          "mechanisms": [
            "mention clustering",
            "coreference resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "pipeline of sieves"
          ],
          "parameter_tuning": [
            "mention detection",
            "cluster merging"
          ]
        },
        "feature_processing": [
          "noun phrases",
          "pronouns",
          "named entities"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Stenetorp2013_RecursiveNeuralNetworks",
      "label": "Recursive Neural Networks",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Stenetorp2013_RecursiveNeuralNetworks",
        "entity_id": "Stenetorp2013_RecursiveNeuralNetworks",
        "name": "Recursive Neural Networks",
        "title": "",
        "year": "2013",
        "authors": [
          "Stenetorp, P."
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Neural Networks"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sundaram2015_KnowledgeRepresentation",
      "label": "Knowledge Representation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sundaram2015_KnowledgeRepresentation",
        "entity_id": "Sundaram2015_KnowledgeRepresentation",
        "name": "Knowledge Representation",
        "title": "",
        "year": "2015",
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Temporal Schemas",
            "Common Sense Law of Inertia"
          ],
          "connections": [
            "Information Extraction -> Knowledge Representation"
          ],
          "mechanisms": [
            "Temporal Ordering",
            "Variable Substitution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Temporal Ordering",
          "Default Assumptions",
          "Heuristics"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sundaram2015_NaturalLanguageProcessor",
      "label": "Natural Language Processor",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sundaram2015_NaturalLanguageProcessor",
        "entity_id": "Sundaram2015_NaturalLanguageProcessor",
        "name": "Natural Language Processor",
        "title": "Natural Language Processing for Solving Simple Word Problems",
        "year": "2015",
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification",
          "ErrorRate_Classification"
        ],
        "architecture": {
          "components": [
            "Stanford CoreNLP Suite",
            "Dependency Parser",
            "Co-reference Resolver"
          ],
          "connections": [
            "Simplification Phase",
            "Analysis Phase"
          ],
          "mechanisms": [
            "Conjunction Resolution",
            "Currency Preprocessing",
            "Co-reference Resolution",
            "Entity Resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based parsing",
            "Heuristic-based reasoning"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Conjunction resolution",
          "Currency preprocessing",
          "Co-reference resolution",
          "Entity resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sundaram2015_SchemaBasedReasoning",
      "label": "Schema-Based Reasoning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sundaram2015_SchemaBasedReasoning",
        "entity_id": "Sundaram2015_SchemaBasedReasoning",
        "name": "Schema-Based Reasoning",
        "title": "",
        "year": "2015",
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "[\"Solving Addition/Subtraction Word Problems\"]",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Schemas",
            "Keyword Mapping"
          ],
          "connections": [
            "Schema Matching",
            "Event Update"
          ],
          "mechanisms": [
            "Change In",
            "Change Out",
            "Combine",
            "Compare Plus",
            "Compare Minus",
            "Increase",
            "Reduction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge Representation"
          ],
          "parameter_tuning": [
            "Schema Design"
          ]
        },
        "feature_processing": [
          "Keyword Extraction",
          "Entity Resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sundaram2015_SentenceSimplifier",
      "label": "Sentence Simplifier",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sundaram2015_SentenceSimplifier",
        "entity_id": "Sundaram2015_SentenceSimplifier",
        "name": "Sentence Simplifier",
        "title": "",
        "year": "2015",
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "[\"Natural Language Processing\"]",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Conjunction Resolver",
            "Currency Preprocessor",
            "Co-reference Resolver",
            "Entity Resolver"
          ],
          "connections": [
            "Simplification Phase -> Analysis Phase"
          ],
          "mechanisms": [
            "Dependency Parsing",
            "POS Tagging"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Conjunction Resolution",
          "Currency Preprocessing",
          "Co-reference Resolution",
          "Entity Resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sundaram2015_SimpleWordProblemSolver",
      "label": "Simple Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sundaram2015_SimpleWordProblemSolver",
        "entity_id": "Sundaram2015_SimpleWordProblemSolver",
        "name": "Simple Word Problem Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "[\"Solving simple arithmetic word problems\"]",
        "dataset": [
          "Hosseini2014_Dataset"
        ],
        "metrics": [
          "Accuracy_AnswerExtraction"
        ],
        "architecture": {
          "components": [
            "Natural Language Processor",
            "Knowledge Representation"
          ],
          "connections": [
            "Information Extraction",
            "Temporal Ordering"
          ],
          "mechanisms": [
            "Schema Matching",
            "Pronoun Resolution"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based",
            "Template-based"
          ],
          "parameter_tuning": [
            "Heuristics",
            "Default Assumptions"
          ]
        },
        "feature_processing": [
          "Dependency Parsing",
          "Co-reference Resolution",
          "Conjunction Resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sundaram2015_TemporalSchemas",
      "label": "Temporal Schemas",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sundaram2015_TemporalSchemas",
        "entity_id": "Sundaram2015_TemporalSchemas",
        "name": "Temporal Schemas",
        "title": "",
        "year": "2015",
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "[\"Solving Addition/Subtraction Word Problems\"]",
        "dataset": [
          "DS1_2014",
          "DS2_2014",
          "DS3_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Time Stamps",
            "Default Assumptions",
            "Heuristics"
          ],
          "connections": [
            "Temporal Ordering",
            "Event Matching"
          ],
          "mechanisms": [
            "Common Sense Law of Inertia"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Knowledge Representation"
          ],
          "parameter_tuning": [
            "Temporal Reasoning"
          ]
        },
        "feature_processing": [
          "Entity Resolution",
          "Temporal Event Handling"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sundaram2015_WordProblemSolver",
      "label": "Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sundaram2015_WordProblemSolver",
        "entity_id": "Sundaram2015_WordProblemSolver",
        "name": "Word Problem Solver",
        "title": "Natural Language Processing for Solving Simple Word Problems",
        "year": "2015",
        "authors": [
          "Sundaram, S. S.",
          "Khemani, D."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Simplification Phase",
            "Analysis Phase",
            "Knowledge Representation",
            "Temporal Schemas"
          ],
          "connections": [
            "Dependency Parsing",
            "Co-reference Resolution",
            "Conjunction Resolution"
          ],
          "mechanisms": [
            "Stanford CoreNLP Suite",
            "Common Sense Law of Inertia"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Conjunction Resolution",
          "Co-reference Resolution",
          "Entity Resolution"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sutskever2011_NeuralLanguageModel",
      "label": "Neural Language Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sutskever2011_NeuralLanguageModel",
        "entity_id": "Sutskever2011_NeuralLanguageModel",
        "name": "Neural Language Model",
        "title": "",
        "year": "2011",
        "authors": [
          "Sutskever, I.",
          "Martens, J.",
          "Hinton, G.E."
        ],
        "task": "[\"Text Generation\"]",
        "dataset": [
          "Various Text Corpora"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network (RNN)",
            "Softmax Layer"
          ],
          "connections": [
            "Sequential Word Generation"
          ],
          "mechanisms": [
            "Conditional Probability Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "Cross-Entropy Loss"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sutskever2014_BeamSearchDecoder",
      "label": "Beam Search Decoder",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sutskever2014_BeamSearchDecoder",
        "entity_id": "Sutskever2014_BeamSearchDecoder",
        "name": "Beam Search Decoder",
        "title": "",
        "year": "2014",
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q. V."
        ],
        "task": "[\"Sequence to Sequence Translation\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Beam Search",
            "Left-to-right decoding"
          ],
          "connections": [
            "Partial hypotheses",
            "Log probability"
          ],
          "mechanisms": [
            "Beam pruning",
            "End-of-sentence token"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Approximate decoding",
            "Simple implementation"
          ],
          "parameter_tuning": [
            "Beam size"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sutskever2014_DeepLSTM",
      "label": "Deep LSTM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sutskever2014_DeepLSTM",
        "entity_id": "Sutskever2014_DeepLSTM",
        "name": "Deep LSTM",
        "title": "",
        "year": "2014",
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q. V."
        ],
        "task": "[\"Sequence to Sequence Translation\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Input LSTM",
            "Output LSTM"
          ],
          "connections": [
            "Fixed-dimensional vector representation",
            "Recurrent connections"
          ],
          "mechanisms": [
            "Long Short-Term Memory",
            "Backpropagation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic Gradient Descent",
            "Fixed learning rate",
            "Batch normalization"
          ],
          "parameter_tuning": [
            "Learning rate decay",
            "Gradient clipping"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Reversed source sentences"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sutskever2014_SentenceRepresentation",
      "label": "Sentence Representation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sutskever2014_SentenceRepresentation",
        "entity_id": "Sutskever2014_SentenceRepresentation",
        "name": "Sentence Representation",
        "title": "",
        "year": "2014",
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q. V."
        ],
        "task": "[\"Sequence to Sequence Translation\"]",
        "dataset": [
          "WMT-14_English_to_French_2014"
        ],
        "metrics": [
          "BLEU_score_Translation"
        ],
        "architecture": {
          "components": [
            "Fixed-dimensional vector",
            "Hidden states"
          ],
          "connections": [
            "Input sequence",
            "Output sequence"
          ],
          "mechanisms": [
            "PCA projection",
            "Word order sensitivity"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mapping sequences to vectors",
            "Training on reversed sentences"
          ],
          "parameter_tuning": [
            "Vocabulary size"
          ]
        },
        "feature_processing": [
          "Word embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sutskever2014_Seq2Seq",
      "label": "Sequence to Sequence Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sutskever2014_Seq2Seq",
        "entity_id": "Sutskever2014_Seq2Seq",
        "name": "Sequence to Sequence Learning",
        "title": "",
        "year": "2014",
        "authors": [
          "Sutskever, Ilya",
          "Vinyals, Oriol",
          "Le, Quoc V."
        ],
        "task": "[\"Sequence Modeling\"]",
        "dataset": [
          "WMT'15 English-German Translation",
          "Penn Tree Bank Parsing",
          "High-Confidence Parsing Corpus",
          "Image Caption Generation"
        ],
        "metrics": [
          "BLEU",
          "F1",
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Recurrent Neural Networks",
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Conditional Probability Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Alternating Training",
            "Parameter Updates Allocation"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Mini-Batch Size",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embeddings",
          "Input Sequence Reversal"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sutskever2014_SequenceToSequence",
      "label": "Sequence-to-Sequence Learning with Neural Networks",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sutskever2014_SequenceToSequence",
        "entity_id": "Sutskever2014_SequenceToSequence",
        "name": "Sequence-to-Sequence Learning with Neural Networks",
        "title": "",
        "year": "2014",
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q.V."
        ],
        "task": "[\"Sequence Generation\"]",
        "dataset": [
          "Various"
        ],
        "metrics": [
          "Perplexity",
          "BLEU Score"
        ],
        "architecture": {
          "components": [
            "Encoder-Decoder",
            "RNN"
          ],
          "connections": [
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Conditional Language Modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Word-Level Cross-Entropy Loss"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sutskever2014_SequenceToSequenceLearning",
      "label": "Sequence to Sequence Learning with Neural Networks",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sutskever2014_SequenceToSequenceLearning",
        "entity_id": "Sutskever2014_SequenceToSequenceLearning",
        "name": "Sequence to Sequence Learning with Neural Networks",
        "title": "Sequence to Sequence Learning with Neural Networks",
        "year": "2014",
        "authors": [
          "Ilya Sutskever",
          "Oriol Vinyals",
          "Quoc V. Le"
        ],
        "task": "[\"Machine Translation\"]",
        "dataset": [
          "WMT-14 English to French"
        ],
        "metrics": [
          "BLEU score"
        ],
        "architecture": {
          "components": [
            "Multilayered LSTM",
            "Deep LSTM"
          ],
          "connections": [
            "Input sequence to fixed-dimensional vector",
            "Fixed-dimensional vector to output sequence"
          ],
          "mechanisms": [
            "Long Short-Term Memory",
            "Reversed source sentences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised backpropagation",
            "Left-to-right beam-search decoder"
          ],
          "parameter_tuning": [
            "4-layer LSTM",
            "1000 cells per layer",
            "1000-dimensional word embeddings",
            "Batch size of 128",
            "Fixed learning rate of 0.7"
          ]
        },
        "feature_processing": [
          "Reversing the order of words in source sentences"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Sutskever2014_SimpleLSTMApproach",
      "label": "Simple LSTM Approach",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Sutskever2014_SimpleLSTMApproach",
        "entity_id": "Sutskever2014_SimpleLSTMApproach",
        "name": "Simple LSTM Approach",
        "title": "",
        "year": "2014",
        "authors": [
          "Sutskever, I.",
          "Vinyals, O.",
          "Le, Q. V."
        ],
        "task": "[\"Machine Translation\"]",
        "dataset": [
          "WMT-14 English to French"
        ],
        "metrics": [
          "BLEU score"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder"
          ],
          "connections": [
            "Fixed-dimensional Vector Representation"
          ],
          "mechanisms": [
            "Reversed Input Sentences"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end Training"
          ],
          "parameter_tuning": [
            "Limited Vocabulary"
          ]
        },
        "feature_processing": [
          "Word Order Sensitivity",
          "Active/Passive Voice Invariance"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "T_RNN2019_TemplateBasedSolver",
      "label": "T-RNN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "T_RNN2019_TemplateBasedSolver",
        "entity_id": "T_RNN2019_TemplateBasedSolver",
        "name": "T-RNN",
        "title": "",
        "year": "2019",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Zhang, J.",
          "Xu, X.",
          "Gao, L.",
          "Dai, B.",
          "Shen, H.T."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2014"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Bi-LSTM",
            "Self-Attention",
            "Recursive Neural Networks"
          ],
          "connections": [
            "Seq2Seq"
          ],
          "mechanisms": [
            "Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "T-RNN2019_T-RNN",
      "label": "T-RNN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "T-RNN2019_T-RNN",
        "entity_id": "T-RNN2019_T-RNN",
        "name": "T-RNN",
        "title": "",
        "year": "2019",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Zhang, J.",
          "Xu, X.",
          "Gao, L.",
          "Dai, B.",
          "Shen, H.T."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Bi-LSTM",
            "Self-Attention",
            "Recursive Neural Network"
          ],
          "connections": [
            "Encoder-Decoder"
          ],
          "mechanisms": [
            "Template Representation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Model Parameters"
          ]
        },
        "feature_processing": [
          "Quantity Encoding",
          "Template Generation"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Tao2002_RectangleBuildingExtraction",
      "label": "Rectangle Building Extraction",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Tao2002_RectangleBuildingExtraction",
        "entity_id": "Tao2002_RectangleBuildingExtraction",
        "name": "Rectangle Building Extraction",
        "title": "",
        "year": "2002",
        "authors": [
          "W.-B. Tao",
          "J.-W. Tian",
          "J. Liu"
        ],
        "task": "[\"Building Extraction\"]",
        "dataset": [
          "AerialUrbanImages_2002"
        ],
        "metrics": [
          "DetectionAccuracy"
        ],
        "architecture": {
          "components": [
            "Edge Element Detection",
            "Linear Element Extraction"
          ],
          "connections": [
            "Start-Point, End-Point, Orientation"
          ],
          "mechanisms": [
            "Detecting Parallel Lines"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Not Applicable"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Tarski1926_EuclideanGeometryAxioms",
      "label": "Euclidean Geometry Axioms",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Tarski1926_EuclideanGeometryAxioms",
        "entity_id": "Tarski1926_EuclideanGeometryAxioms",
        "name": "Euclidean Geometry Axioms",
        "title": "",
        "year": "1926",
        "authors": [
          "Tarski, A."
        ],
        "task": "[\"Geometry Theorem Proving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Primitive relations: betweenness and equidistance"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Points only"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Taskar2004_MaxMarginParsing",
      "label": "Max-Margin Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Taskar2004_MaxMarginParsing",
        "entity_id": "Taskar2004_MaxMarginParsing",
        "name": "Max-Margin Parsing",
        "title": "",
        "year": "2004",
        "authors": [
          "Taskar, B.",
          "Klein, D.",
          "Collins, M.",
          "Koller, D.",
          "Manning, C."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "PennTreebank_WSJ_2013"
        ],
        "metrics": [
          "F1_Score_Parsing"
        ],
        "architecture": {
          "components": [
            "Structured Margin Loss",
            "Max-Margin Objective"
          ],
          "connections": [
            "Loss Function"
          ],
          "mechanisms": [
            "Structured Prediction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Optimization"
          ],
          "parameter_tuning": [
            "Margin Parameters"
          ]
        },
        "feature_processing": [
          "Feature Engineering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Tellex2011_ApproachingSymbolGrounding",
      "label": "Approaching the Symbol Grounding Problem",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Tellex2011_ApproachingSymbolGrounding",
        "entity_id": "Tellex2011_ApproachingSymbolGrounding",
        "name": "Approaching the Symbol Grounding Problem",
        "title": "",
        "year": "2011",
        "authors": [
          "Tellex, S.",
          "Kollar, T.",
          "Dickerson, S.",
          "Walter, M.",
          "Banerjee, A.",
          "Teller, S.",
          "Roy, N."
        ],
        "task": "[\"Symbol Grounding\"]",
        "dataset": [
          "AI Magazine_2011"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Symbol Grounding",
            "Probabilistic Graphical Models"
          ],
          "connections": [
            "Symbol Grounding",
            "Graphical Models"
          ],
          "mechanisms": [
            "Probabilistic Models"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic Models"
          ],
          "parameter_tuning": [
            "Symbol Grounding"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Thomaz2006_ReinforcementLearningWithTeachers",
      "label": "Reinforcement Learning with Human Teachers",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Thomaz2006_ReinforcementLearningWithTeachers",
        "entity_id": "Thomaz2006_ReinforcementLearningWithTeachers",
        "name": "Reinforcement Learning with Human Teachers",
        "title": "",
        "year": "2006",
        "authors": [
          "Thomaz, A.",
          "Breazeal, C."
        ],
        "task": "[\"Reinforcement Learning\"]",
        "dataset": [
          "AAAI_2006"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Reinforcement Learning",
            "Human Teachers"
          ],
          "connections": [
            "Human Interaction",
            "Reinforcement Learning"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Human Teachers"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Tian2014_ProbabilisticModelForMultiPrototypeWordEmbeddings",
      "label": "Probabilistic Model for Multi-Prototype Word Embeddings",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Tian2014_ProbabilisticModelForMultiPrototypeWordEmbeddings",
        "entity_id": "Tian2014_ProbabilisticModelForMultiPrototypeWordEmbeddings",
        "name": "Probabilistic Model for Multi-Prototype Word Embeddings",
        "title": "",
        "year": "2014",
        "authors": [
          "Fei Tian",
          "Hanjun Dai",
          "Jiang Bian",
          "Bin Gao",
          "Rui Zhang",
          "Enhong Chen",
          "Tie-Yan Liu"
        ],
        "task": "[\"Word Embedding\"]",
        "dataset": [
          "wiki2014"
        ],
        "metrics": [
          "Perplexity"
        ],
        "architecture": {
          "components": [
            "Probabilistic Model",
            "Multi-Prototype Embeddings"
          ],
          "connections": [
            "Word-Sense Pair Representation",
            "Contextual Information"
          ],
          "mechanisms": [
            "Probabilistic Inference",
            "Multi-Sense Clustering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic Learning",
            "Context Window Clustering"
          ],
          "parameter_tuning": [
            "Embedding Dimension",
            "Window Size",
            "Negative Sampling Count"
          ]
        },
        "feature_processing": [
          "Context Window Extraction",
          "TF-IDF Weighting"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Titov2007_GenerativeLatentVariableModel",
      "label": "Generative Latent Variable Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Titov2007_GenerativeLatentVariableModel",
        "entity_id": "Titov2007_GenerativeLatentVariableModel",
        "name": "Generative Latent Variable Model",
        "title": "",
        "year": "2007",
        "authors": [
          "Titov, I.",
          "Henderson, J."
        ],
        "task": "[\"Dependency Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Latent Variable Model"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Titov2007_IncrementalSigmoidBeliefNetworks",
      "label": "Incremental Sigmoid Belief Networks",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Titov2007_IncrementalSigmoidBeliefNetworks",
        "entity_id": "Titov2007_IncrementalSigmoidBeliefNetworks",
        "name": "Incremental Sigmoid Belief Networks",
        "title": "",
        "year": "2007",
        "authors": [
          "Titov, I.",
          "Henderson, J."
        ],
        "task": "[\"Constituency Parsing\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Belief Networks"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Ullman1984_UniversalVisualRoutines",
      "label": "Universal Visual Routines",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Ullman1984_UniversalVisualRoutines",
        "entity_id": "Ullman1984_UniversalVisualRoutines",
        "name": "Universal Visual Routines",
        "title": "",
        "year": "1984",
        "authors": [
          "Ullman, S."
        ],
        "task": "[\"Spatial Reasoning\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Low-level vision routines",
            "Intermediate-level vision routines"
          ],
          "connections": [],
          "mechanisms": [
            "Automatic detection of visual relations",
            "Domain-independent processing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None (not a learning algorithm)"
          ],
          "parameter_tuning": [
            "None (not a learning algorithm)"
          ]
        },
        "feature_processing": [
          "Detection of primitive visual elements",
          "Computation of visual relations"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "UnitDep2017_UnitDependencyGraph",
      "label": "Unit Dependency Graph",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "UnitDep2017_UnitDependencyGraph",
        "entity_id": "UnitDep2017_UnitDependencyGraph",
        "name": "Unit Dependency Graph",
        "title": "",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Unit Dependency Graph",
            "Rate Consistency"
          ],
          "connections": [
            "Graph Construction"
          ],
          "mechanisms": [
            "Node Classification",
            "Edge Classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Graph Parameters"
          ]
        },
        "feature_processing": [
          "Quantity Extraction",
          "Rate Detection"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Upadhyay2016_JointLearning",
      "label": "Joint Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Upadhyay2016_JointLearning",
        "entity_id": "Upadhyay2016_JointLearning",
        "name": "Joint Learning",
        "title": "",
        "year": "2016",
        "authors": [
          "Upadhyay, S.",
          "Chang, M.W.",
          "Chang, K.W.",
          "Yih, W.T."
        ],
        "task": "[\"Solving algebra word problems\"]",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Explicit and implicit supervision"
          ],
          "connections": [
            "Joint learning"
          ],
          "mechanisms": [
            "Supervision integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Joint learning"
          ],
          "parameter_tuning": [
            "Joint learning parameters"
          ]
        },
        "feature_processing": [
          "Supervision feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Upadhyay2016_LearningFromExplicitImplicitSupervision",
      "label": "Learning from Explicit and Implicit Supervision",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Upadhyay2016_LearningFromExplicitImplicitSupervision",
        "entity_id": "Upadhyay2016_LearningFromExplicitImplicitSupervision",
        "name": "Learning from Explicit and Implicit Supervision",
        "title": "",
        "year": "2016",
        "authors": [
          "S. Upadhyay",
          "M. Chang",
          "K. Chang",
          "W. Yih"
        ],
        "task": "[\"Algebraic Word Problem Solving\"]",
        "dataset": [
          "DRAW1K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "MixedSP Algorithm",
            "Log-Linear Model"
          ],
          "connections": [
            "Explicit and Implicit Supervision"
          ],
          "mechanisms": [
            "Max-Margin Objective"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Parameter Optimization"
          ]
        },
        "feature_processing": [
          "Feature Selection"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Upadhyay2016_MixedSP",
      "label": "MixedSP",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Upadhyay2016_MixedSP",
        "entity_id": "Upadhyay2016_MixedSP",
        "name": "MixedSP",
        "title": "",
        "year": "2016",
        "authors": [
          "Upadhyay, S.",
          "Chang, M.",
          "Chang, K.",
          "Yih, W."
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "ALG514_2014",
          "DRAW1K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Feature Representation",
            "Parameter Vector"
          ],
          "connections": [
            "Template Matching",
            "Feature Extraction"
          ],
          "mechanisms": [
            "Log-linear Model",
            "RankSVM"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Implicit Supervision Signals",
            "Explicit Supervised Examples"
          ],
          "parameter_tuning": [
            "Joint Learning"
          ]
        },
        "feature_processing": [
          "Lexical and Syntactic Features",
          "Dependency Path Between Slots"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Vaswani2017_Transformer",
      "label": "Transformer",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Vaswani2017_Transformer",
        "entity_id": "Vaswani2017_Transformer",
        "name": "Transformer",
        "title": "",
        "year": "2017",
        "authors": [
          "Ashish Vaswani",
          "Noam Shazeer",
          "Niki Parmar",
          "Jakob Uszkoreit",
          "Llion Jones",
          "Aidan N Gomez",
          "Łukasz Kaiser",
          "Illia Polosukhin"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Multi-Head Self-Attention",
            "Position-Wise Fully-Connected Feed-Forward Network"
          ],
          "connections": [
            "Stacked Layers"
          ],
          "mechanisms": [
            "Self-Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adam Optimizer",
            "Learning Rate Annealing"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Significant Number Identification",
          "Number Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Vendrov2015_1024DGRUEncodersWithSkipThoughtsPreTraining",
      "label": "1024D GRU encoders with SkipThoughts pre-training",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Vendrov2015_1024DGRUEncodersWithSkipThoughtsPreTraining",
        "entity_id": "Vendrov2015_1024DGRUEncodersWithSkipThoughtsPreTraining",
        "name": "1024D GRU encoders with SkipThoughts pre-training",
        "title": "",
        "year": "2015",
        "authors": [
          "Vendrov, I.",
          "Kiros, R.",
          "Fidler, S.",
          "Urtasun, R."
        ],
        "task": "[\"Textual Entailment\"]",
        "dataset": [
          "SNLI_dataset_2015"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "GRU"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Recurrent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised",
            "Pre-trained"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Vinyals2015_GrammarAsForeignLanguage",
      "label": "Grammar as a Foreign Language",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Vinyals2015_GrammarAsForeignLanguage",
        "entity_id": "Vinyals2015_GrammarAsForeignLanguage",
        "name": "Grammar as a Foreign Language",
        "title": "",
        "year": "2015",
        "authors": [
          "Vinyals, O.",
          "Kaiser, L.",
          "Koo, T.",
          "Petrov, S.",
          "Sutskever, I.",
          "Hinton, G."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [
          "Penn Treebank"
        ],
        "metrics": [
          "UAS",
          "LAS"
        ],
        "architecture": {
          "components": [
            "Encoder-Decoder Framework",
            "Attention Layer"
          ],
          "connections": [
            "Sequential Parsing"
          ],
          "mechanisms": [
            "Grammar Encoding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Cross-Entropy Loss"
          ]
        },
        "feature_processing": [
          "Word Embeddings"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Vogel2010_LearningToFollowDirections",
      "label": "Learning to Follow Navigational Directions",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Vogel2010_LearningToFollowDirections",
        "entity_id": "Vogel2010_LearningToFollowDirections",
        "name": "Learning to Follow Navigational Directions",
        "title": "",
        "year": "2010",
        "authors": [
          "Vogel, A.",
          "Jurafsky, D."
        ],
        "task": "[\"Navigational Directions\"]",
        "dataset": [
          "ACL_2010"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Navigational Directions",
            "Reinforcement Learning"
          ],
          "connections": [
            "Navigational Directions",
            "Reinforcement Learning"
          ],
          "mechanisms": [
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Navigational Directions"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_AnalogySolver",
      "label": "Analogy Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_AnalogySolver",
        "entity_id": "Wang2016_AnalogySolver",
        "name": "Analogy Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "[\"Analogy Question Answering\"]",
        "dataset": [
          "PublishedIQTestBooks_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Cosine Similarity Calculation"
          ],
          "connections": [
            "Word-Sense Pair Embedding"
          ],
          "mechanisms": [
            "Optimization Method"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Window Size"
          ]
        },
        "feature_processing": [
          "Word-Sense Pair Indexing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_AntonymSolver",
      "label": "Antonym Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_AntonymSolver",
        "entity_id": "Wang2016_AntonymSolver",
        "name": "Antonym Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "[\"Antonym Question Answering\"]",
        "dataset": [
          "PublishedIQTestBooks_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Distance Calculation",
            "Translation Distance Minimization"
          ],
          "connections": [
            "Word-Sense Pair Embedding"
          ],
          "mechanisms": [
            "Offset Vector Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Window Size"
          ]
        },
        "feature_processing": [
          "Word-Sense Pair Indexing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_ClassificationSolver",
      "label": "Classification Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_ClassificationSolver",
        "entity_id": "Wang2016_ClassificationSolver",
        "name": "Classification Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "[\"Classification Question Answering\"]",
        "dataset": [
          "PublishedIQTestBooks_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Mean Vector Calculation",
            "Distance Calculation"
          ],
          "connections": [
            "Word-Sense Pair Embedding"
          ],
          "mechanisms": [
            "Closest Mean Vector Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Window Size"
          ]
        },
        "feature_processing": [
          "Word-Sense Pair Indexing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_CoLearningWordSensePairRepresentations",
      "label": "Co-Learning Word-Sense Pair Representations and Relation Representations",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_CoLearningWordSensePairRepresentations",
        "entity_id": "Wang2016_CoLearningWordSensePairRepresentations",
        "name": "Co-Learning Word-Sense Pair Representations and Relation Representations",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "[\"Verbal Comprehension Question Answering\"]",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Skip-gram Objective Function",
            "Relational Knowledge Regularization"
          ],
          "connections": [
            "Word-Sense Pair Embedding",
            "Relation Embedding"
          ],
          "mechanisms": [
            "Margin-Based Regularization",
            "Translation Operations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Back Propagation Neural Networks"
          ],
          "parameter_tuning": [
            "Margin Hyper-parameter",
            "Combination Coefficient"
          ]
        },
        "feature_processing": [
          "Soft Norm Constraint"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_DimensionallyGuidedSynthesis",
      "label": "Dimensionally Guided Synthesis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_DimensionallyGuidedSynthesis",
        "entity_id": "Wang2016_DimensionallyGuidedSynthesis",
        "name": "Dimensionally Guided Synthesis",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, K.",
          "Su, Z."
        ],
        "task": "[\"Synthesizing mathematical word problems\"]",
        "dataset": [
          "Mathematical word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression tree"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Recursive synthesis"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Wang2016_EquationGenerator",
      "label": "Equation Generator",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_EquationGenerator",
        "entity_id": "Wang2016_EquationGenerator",
        "name": "Equation Generator",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, K.",
          "Su, Z."
        ],
        "task": "[\"Mathematical Word Problem Generation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Seed Equation Synthesis",
            "Variable Unrolling"
          ],
          "connections": [
            "Semantic Instantiation",
            "Operational Rules"
          ],
          "mechanisms": [
            "Dimensional Unit Assignment",
            "Binary Expression Tree"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Equation Generation"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dimensional Unit Handling"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_MultiSenseIdentification",
      "label": "Multi-Sense Identification",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_MultiSenseIdentification",
        "entity_id": "Wang2016_MultiSenseIdentification",
        "name": "Multi-Sense Identification",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "[\"Verbal Comprehension Question Answering\"]",
        "dataset": [
          "wiki2014_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Skip-gram",
            "Context Windows Clustering",
            "Dictionary Matching"
          ],
          "connections": [
            "Word-Sense Pair Labeling",
            "Cluster to Sense Matching"
          ],
          "mechanisms": [
            "TF-IDF Weighting",
            "Spherical k-means Clustering"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Unsupervised Learning"
          ],
          "parameter_tuning": [
            "Window Size",
            "Number of Clusters"
          ]
        },
        "feature_processing": [
          "Context Window Representation",
          "Weighted Average Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_MWPSynthesisApproach",
      "label": "MWPSynthesis Approach",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_MWPSynthesisApproach",
        "entity_id": "Wang2016_MWPSynthesisApproach",
        "name": "MWPSynthesis Approach",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, K.",
          "Su, Z."
        ],
        "task": "[\"Mathematical Word Problem Synthesis\"]",
        "dataset": [
          "Singapore Math Curriculum 2009"
        ],
        "metrics": [
          "Authenticity",
          "Error Rate",
          "Statistical Indistinguishability"
        ],
        "architecture": {
          "components": [
            "Equation Generator",
            "Narrative Generator"
          ],
          "connections": [
            "Equation to Story Conversion"
          ],
          "mechanisms": [
            "Dimensional Units",
            "Binary Expression Trees"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Random Equation Generation",
            "Dimensional Unit Assignment"
          ],
          "parameter_tuning": [
            "Arithmetic Operation Complexity",
            "Distraction Elements"
          ]
        },
        "feature_processing": [
          "Dimensional Unit Handling",
          "Natural Language Story Generation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_NarrativeGenerator",
      "label": "Narrative Generator",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_NarrativeGenerator",
        "entity_id": "Wang2016_NarrativeGenerator",
        "name": "Narrative Generator",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, K.",
          "Su, Z."
        ],
        "task": "[\"Mathematical Word Problem Generation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Binary Expression Tree",
            "Keyword Assignment",
            "Sub-story Generation"
          ],
          "connections": [
            "Atomic Expression Trees",
            "Postorder Traversal"
          ],
          "mechanisms": [
            "Verbal Templates",
            "Sub-story Concatenation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Recursive Story Construction"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Dimensional Unit Integration",
          "Keyword Selection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_ProbabilityProblemSolver",
      "label": "Probability Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_ProbabilityProblemSolver",
        "entity_id": "Wang2016_ProbabilityProblemSolver",
        "name": "Probability Problem Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Dries, A.",
          "Kimmig, A.",
          "Davis, J.",
          "Belle, V.",
          "Raedt, L. D."
        ],
        "task": "[\"Solving probability problems\"]",
        "dataset": [
          "Various probability datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Declarative language formulation",
            "ProbLog solver"
          ],
          "connections": [
            "Formulating questions in declarative language",
            "Computing answers using ProbLog"
          ],
          "mechanisms": [
            "Declarative language processing",
            "Probabilistic logic solving"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Not specified"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Wang2016_RandomGuessModel",
      "label": "Random Guess Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_RandomGuessModel",
        "entity_id": "Wang2016_RandomGuessModel",
        "name": "Random Guess Model",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "[\"Verbal Comprehension Questions\"]",
        "dataset": [
          "OnlineIQTestQuestions_2016"
        ],
        "metrics": [
          "OverallAccuracy_VerbalComprehension"
        ],
        "architecture": {
          "components": [],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_RelationKnowledgePoweredModel",
      "label": "Relation Knowledge Powered Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_RelationKnowledgePoweredModel",
        "entity_id": "Wang2016_RelationKnowledgePoweredModel",
        "name": "Relation Knowledge Powered Model",
        "title": "Solving Verbal Questions in IQ Test by Knowledge-Powered Word Embedding",
        "year": "2016",
        "authors": [
          "Huazheng Wang",
          "Fei Tian",
          "Bin Gao",
          "Chengjieren Zhu",
          "Jiang Bian",
          "Tie-Yan Liu"
        ],
        "task": "[\"Verbal Comprehension Questions in IQ Tests\"]",
        "dataset": [
          "wiki2014",
          "Published IQ Test Books"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Question Classifier",
            "Word-Sense and Relation Embedding",
            "Specific Solvers"
          ],
          "connections": [
            "Question Classifier -> Word-Sense and Relation Embedding -> Specific Solvers"
          ],
          "mechanisms": [
            "Multi-Sense Clustering",
            "Relational Knowledge Integration",
            "Co-Learning Word-Sense Pair Representations and Relation Representations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Learning",
            "Back Propagation Neural Networks"
          ],
          "parameter_tuning": [
            "Window Size",
            "Embedding Dimension",
            "Negative Sampling Count",
            "Epoch Number"
          ]
        },
        "feature_processing": [
          "TF-IDF Features",
          "Context Windows Clustering",
          "Dictionary-Based Relational Knowledge"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_SMTSolver",
      "label": "SMT Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_SMTSolver",
        "entity_id": "Wang2016_SMTSolver",
        "name": "SMT Solver",
        "title": "Dimensionally Guided Synthesis of Mathematical Word Problems",
        "year": "2016",
        "authors": [
          "Ke Wang",
          "Zhendong Su"
        ],
        "task": "[\"Mathematical Word Problem Generation\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Solver"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_SynonymSolver",
      "label": "Synonym Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_SynonymSolver",
        "entity_id": "Wang2016_SynonymSolver",
        "name": "Synonym Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "[\"Synonym Question Answering\"]",
        "dataset": [
          "PublishedIQTestBooks_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Distance Calculation",
            "Translation Distance Minimization"
          ],
          "connections": [
            "Word-Sense Pair Embedding"
          ],
          "mechanisms": [
            "Offset Vector Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization"
          ],
          "parameter_tuning": [
            "Window Size"
          ]
        },
        "feature_processing": [
          "Word-Sense Pair Indexing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_VerbalIQQuestions",
      "label": "Verbal IQ Questions Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_VerbalIQQuestions",
        "entity_id": "Wang2016_VerbalIQQuestions",
        "name": "Verbal IQ Questions Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Wang, H.",
          "Tian, F.",
          "Gao, B.",
          "Zhu, C.",
          "Bian, J.",
          "Liu, T."
        ],
        "task": "[\"Solving verbal IQ questions\"]",
        "dataset": [
          "IQ test questions"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Knowledge-powered word embedding"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Embedding words with knowledge"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Wang2017_DeepNeuralSolver",
      "label": "Deep Neural Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_DeepNeuralSolver",
        "entity_id": "Wang2017_DeepNeuralSolver",
        "name": "Deep Neural Solver",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network (RNN)"
          ],
          "connections": [
            "Equation Templates"
          ],
          "mechanisms": [
            "Direct Translation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_DNS",
      "label": "DNS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_DNS",
        "entity_id": "Wang2017_DNS",
        "name": "DNS",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ",
            "GRU",
            "LSTM"
          ],
          "connections": [
            "encoder-decoder"
          ],
          "mechanisms": [
            "attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "maximum likelihood estimation"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "number mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_DNSHybrid",
      "label": "DNS-Hybrid",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_DNSHybrid",
        "entity_id": "Wang2017_DNSHybrid",
        "name": "DNS-Hybrid",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ",
            "GRU",
            "LSTM",
            "retrieval-based solver"
          ],
          "connections": [
            "encoder-decoder"
          ],
          "mechanisms": [
            "attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "maximum likelihood estimation"
          ],
          "parameter_tuning": [
            "learning rate",
            "batch size"
          ]
        },
        "feature_processing": [
          "number mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_EquationTemplate",
      "label": "Equation Template",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_EquationTemplate",
        "entity_id": "Wang2017_EquationTemplate",
        "name": "Equation Template",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"数学文字问题求解\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "方程模板生成器"
          ],
          "connections": [
            "问题文本到方程模板的转换"
          ],
          "mechanisms": [
            "方程模板匹配"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习"
          ],
          "parameter_tuning": [
            "无"
          ]
        },
        "feature_processing": [
          "方程模板生成"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_GRU",
      "label": "GRU",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_GRU",
        "entity_id": "Wang2017_GRU",
        "name": "GRU",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Gated Recurrent Units"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Update gate",
            "Reset gate",
            "Hidden state"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Standard dropout"
          ],
          "parameter_tuning": [
            "Dropout probability 0.5"
          ]
        },
        "feature_processing": [
          "Number mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_HybridModel",
      "label": "Hybrid Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_HybridModel",
        "entity_id": "Wang2017_HybridModel",
        "name": "Hybrid Model",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "RNN-based Seq2Seq Model",
            "Retrieval Model"
          ],
          "connections": [
            "Threshold-based Selection"
          ],
          "mechanisms": [
            "Similarity-based Retrieval",
            "Seq2Seq Generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mini-batch",
            "Dropout"
          ],
          "parameter_tuning": [
            "Threshold",
            "Learning Rate",
            "Epochs"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_LSTM",
      "label": "LSTM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_LSTM",
        "entity_id": "Wang2017_LSTM",
        "name": "LSTM",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Long Short-Term Memory"
          ],
          "connections": [
            "Sequential"
          ],
          "mechanisms": [
            "Input gate",
            "Forget gate",
            "Output gate",
            "Hidden state"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Standard dropout"
          ],
          "parameter_tuning": [
            "Dropout probability 0.5"
          ]
        },
        "feature_processing": [
          "Number mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_MathDQN",
      "label": "MathDQN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_MathDQN",
        "entity_id": "Wang2017_MathDQN",
        "name": "MathDQN",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": "2017",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H.T."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Average Precision"
        ],
        "architecture": {
          "components": [
            "Deep Q-Network"
          ],
          "connections": [
            "State Representation",
            "Action Selection"
          ],
          "mechanisms": [
            "Reward Function"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Reinforcement Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_NumberMapping",
      "label": "Number Mapping",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_NumberMapping",
        "entity_id": "Wang2017_NumberMapping",
        "name": "Number Mapping",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"数学文字问题求解\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "映射模块",
            "变量替换"
          ],
          "connections": [
            "问题文本到方程模板的转换"
          ],
          "mechanisms": [
            "数字替换规则"
          ]
        },
        "methodology": {
          "training_strategy": [
            "无监督学习"
          ],
          "parameter_tuning": [
            "无"
          ]
        },
        "feature_processing": [
          "数字提取",
          "变量替换"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_ProblemToEquationMapping",
      "label": "Problem-to-Equation Mapping",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_ProblemToEquationMapping",
        "entity_id": "Wang2017_ProblemToEquationMapping",
        "name": "Problem-to-Equation Mapping",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ model"
          ],
          "connections": [
            "Maps problem text to equation templates"
          ],
          "mechanisms": [
            "Conditional probability maximization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximizes conditional probability P(Tp|P)"
          ],
          "parameter_tuning": [
            "Token-wise probabilities"
          ]
        },
        "feature_processing": [
          "Uses beam search for decoding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_RetrievalModel",
      "label": "Retrieval Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_RetrievalModel",
        "entity_id": "Wang2017_RetrievalModel",
        "name": "Retrieval Model",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "TF-IDF Vectorizer",
            "Jaccard Similarity"
          ],
          "connections": [
            "Vector Comparison"
          ],
          "mechanisms": [
            "Lexical Similarity Calculation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Similarity-Based Retrieval"
          ],
          "parameter_tuning": [
            "Threshold Setting"
          ]
        },
        "feature_processing": [
          "TF-IDF Scoring"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_RNNBasedSeq2SeqModel",
      "label": "RNN-based Seq2Seq Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_RNNBasedSeq2SeqModel",
        "entity_id": "Wang2017_RNNBasedSeq2SeqModel",
        "name": "RNN-based Seq2Seq Model",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "GRU",
            "LSTM"
          ],
          "connections": [
            "Encoder-Decoder"
          ],
          "mechanisms": [
            "Number Mapping",
            "Significant Number Identification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mini-batch",
            "Dropout"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Epochs"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_SemanticallyAligned",
      "label": "Semantically-Aligned Equation Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_SemanticallyAligned",
        "entity_id": "Wang2017_SemanticallyAligned",
        "name": "Semantically-Aligned Equation Generation",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": "2017",
        "authors": [
          "Chiang, T.R.",
          "Chen, Y.N."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder-Decoder Framework"
          ],
          "connections": [
            "Symbolic World",
            "Semantic World"
          ],
          "mechanisms": [
            "Stack Actions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_Seq2Seq",
      "label": "Seq2Seq Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_Seq2Seq",
        "entity_id": "Wang2017_Seq2Seq",
        "name": "Seq2Seq Model",
        "title": "Data-Driven Methods for Solving Algebra Word Problems",
        "year": "2018",
        "authors": [
          "Robaidek, Benjamin",
          "Koncel-Kedziorski, Rik",
          "Hajishirzi, Hannaneh"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "LSTM",
            "CNN"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_Seq2SeqAttn",
      "label": "Seq2SeqAttn",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_Seq2SeqAttn",
        "entity_id": "Wang2017_Seq2SeqAttn",
        "name": "Seq2SeqAttn",
        "title": "Deep Neural Model for Math Word Problem Solving",
        "year": "2017",
        "authors": [
          "Yan Wang",
          "Xiaojiang Liu",
          "Shuming Shi"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Attention"
          ],
          "mechanisms": [
            "Gated Recurrent Unit (GRU)"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximum Likelihood Estimation"
          ],
          "parameter_tuning": [
            "SGD Optimizer"
          ]
        },
        "feature_processing": [
          "Number Tokenization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_SEQ2SEQFramework",
      "label": "SEQ2SEQ Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_SEQ2SEQFramework",
        "entity_id": "Wang2017_SEQ2SEQFramework",
        "name": "SEQ2SEQ Framework",
        "title": "",
        "year": "2017",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder",
            "Attention Mechanism"
          ],
          "connections": [
            "Source Sequence",
            "Target Sequence"
          ],
          "mechanisms": [
            "Conditional Probability Maximization",
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-stage Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Significant Number Identification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_Seq2SeqModel",
      "label": "Seq2Seq Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_Seq2SeqModel",
        "entity_id": "Wang2017_Seq2SeqModel",
        "name": "Seq2Seq Model",
        "title": "",
        "year": "2017",
        "authors": [
          "Yan Wang",
          "Xiaojiang Liu",
          "Shuming Shi"
        ],
        "task": "[\"Solving Math Word Problems\"]",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "RNN",
            "GRU",
            "LSTM"
          ],
          "connections": [
            "attention mechanism"
          ],
          "mechanisms": [
            "sequence to sequence learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "beam search"
          ],
          "parameter_tuning": [
            "learning rate",
            "dropout rate"
          ]
        },
        "feature_processing": [
          "significant number identification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_SignificantNumberIdentification",
      "label": "Significant Number Identification",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_SignificantNumberIdentification",
        "entity_id": "Wang2017_SignificantNumberIdentification",
        "name": "Significant Number Identification",
        "title": "",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017",
          "Alg514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "LSTM"
          ],
          "connections": [
            "Binary Classification"
          ],
          "mechanisms": [
            "Context Window"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Mini-batch"
          ],
          "parameter_tuning": [
            "Nodes",
            "Window Size"
          ]
        },
        "feature_processing": [
          "Context Window"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_TemplateBased",
      "label": "Template-Based Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_TemplateBased",
        "entity_id": "Wang2017_TemplateBased",
        "name": "Template-Based Solver",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": "2017",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Zhang, J.",
          "Xu, X.",
          "Gao, L.",
          "Dai, B.T.",
          "Shen, H.T."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Recursive Neural Network"
          ],
          "connections": [
            "Tree-Structure Template"
          ],
          "mechanisms": [
            "Bottom-Up Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_TemplateBasedSolver",
      "label": "Template-Based Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_TemplateBasedSolver",
        "entity_id": "Wang2017_TemplateBasedSolver",
        "name": "Template-Based Solver",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": "2017",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Zhang, J.",
          "Xu, X.",
          "Gao, L.",
          "Dai, B.T.",
          "Shen, H.T."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Recursive Neural Network"
          ],
          "connections": [
            "Tree-Structure Template"
          ],
          "mechanisms": [
            "Bottom-Up Inference"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2017_TranslationModel",
      "label": "Translation Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2017_TranslationModel",
        "entity_id": "Wang2017_TranslationModel",
        "name": "Translation Model",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": "2017",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Expression Tree"
          ],
          "connections": [
            "Equation Normalization"
          ],
          "mechanisms": [
            "Maximum Likelihood Estimation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameters"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_BiLSTM",
      "label": "BiLSTM",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_BiLSTM",
        "entity_id": "Wang2018_BiLSTM",
        "name": "BiLSTM",
        "title": "",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Bidirectional LSTM",
            "Global Attention Mechanism"
          ],
          "connections": [
            "Encoder-Decoder"
          ],
          "mechanisms": [
            "Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adam Optimizer",
            "Early Stopping",
            "Learning Rate Annealing"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Significant Number Identification",
          "Number Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_BracketNormalization",
      "label": "Bracket Normalization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_BracketNormalization",
        "entity_id": "Wang2018_BracketNormalization",
        "name": "Bracket Normalization",
        "title": "",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Wang, Y.",
          "Cai, D.",
          "Zhang, D.",
          "Liu, X."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree"
          ],
          "connections": [
            "Equation Templates Transformation"
          ],
          "mechanisms": [
            "Bracket Elimination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Normalization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Bracket Handling"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_CASS",
      "label": "CASS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_CASS",
        "entity_id": "Wang2018_CASS",
        "name": "CASS",
        "title": "Neural Math Word Problem Solver with Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Huang, D.",
          "Liu, J.",
          "Lin, C.",
          "Yin, J."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Copy Mechanism",
            "Alignment Mechanism",
            "Sequence-to-Sequence Model"
          ],
          "connections": [
            "Reinforcement Learning"
          ],
          "mechanisms": [
            "Deep Q-Network"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Deep Q-Network"
          ]
        },
        "feature_processing": [
          "Copy Mechanism",
          "Alignment Mechanism"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_ConvS2S",
      "label": "ConvS2S",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_ConvS2S",
        "entity_id": "Wang2018_ConvS2S",
        "name": "ConvS2S",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Convolutional Layers"
          ],
          "connections": [
            "Gate Linear Units"
          ],
          "mechanisms": [
            "Convolutional Architecture"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Early Stopping",
            "Learning Rate Annealing"
          ],
          "parameter_tuning": [
            "Max-Epochs",
            "Hidden Size"
          ]
        },
        "feature_processing": [
          "Number Tokenization",
          "Equation Template Transformation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_DeepReinforcementLearningFramework",
      "label": "Deep Reinforcement Learning Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_DeepReinforcementLearningFramework",
        "entity_id": "Wang2018_DeepReinforcementLearningFramework",
        "name": "Deep Reinforcement Learning Framework",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Precision",
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "State Representation",
            "Action Selection",
            "Reward Function"
          ],
          "connections": [
            "State Transition",
            "Policy Update"
          ],
          "mechanisms": [
            "Q-Learning",
            "Experience Replay"
          ]
        },
        "methodology": {
          "training_strategy": [
            "ε-greedy Strategy",
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Discount Factor",
            "Learning Rate",
            "Mini-batch Size"
          ]
        },
        "feature_processing": [
          "Quantity Schema Features",
          "Pair Features",
          "Question Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_EnsembleModel",
      "label": "Ensemble Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_EnsembleModel",
        "entity_id": "Wang2018_EnsembleModel",
        "name": "Ensemble Model",
        "title": "",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "BiLSTM",
            "ConvS2S",
            "Transformer"
          ],
          "connections": [
            "Model Combination"
          ],
          "mechanisms": [
            "Ensemble"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Model Selection Based on Generation Probability"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Significant Number Identification",
          "Number Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_EquationNormalization",
      "label": "Equation Normalization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_EquationNormalization",
        "entity_id": "Wang2018_EquationNormalization",
        "name": "Equation Normalization",
        "title": "",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Expression Tree"
          ],
          "connections": [
            "Equation Templates"
          ],
          "mechanisms": [
            "Order Duplication Normalization",
            "Bracket Duplication Normalization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SEQ2SEQ Framework"
          ],
          "parameter_tuning": [
            "Beam Search"
          ]
        },
        "feature_processing": [
          "Significant Number Identification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_EquationNormalizationMethod",
      "label": "Equation Normalization Method",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_EquationNormalizationMethod",
        "entity_id": "Wang2018_EquationNormalizationMethod",
        "name": "Equation Normalization Method",
        "title": "",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "SEQ2SEQ Models"
          ],
          "connections": [
            "Equation Templates",
            "Postorder Traversal"
          ],
          "mechanisms": [
            "Order Duplication Normalization",
            "Bracket Duplication Normalization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SEQ2SEQ Framework"
          ],
          "parameter_tuning": [
            "Beam Search",
            "Adam Optimizer"
          ]
        },
        "feature_processing": [
          "Significant Number Identification",
          "Number Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_ErrorAnalysis",
      "label": "Error Analysis Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_ErrorAnalysis",
        "entity_id": "Wang2018_ErrorAnalysis",
        "name": "Error Analysis Framework",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Accuracy",
          "Precision"
        ],
        "architecture": {
          "components": [
            "Error Identification Module",
            "Reason Analysis Module"
          ],
          "connections": [
            "Error Identification -> Reason Analysis"
          ],
          "mechanisms": [
            "Missing Quantities Detection",
            "Relevance Classifier Evaluation",
            "Feature Limitation Analysis",
            "State Representation Evaluation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Exploration vs Exploitation"
          ],
          "parameter_tuning": [
            "ε-greedy Strategy"
          ]
        },
        "feature_processing": [
          "Quantity Schema Analysis",
          "Context Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_M1",
      "label": "M1",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_M1",
        "entity_id": "Wang2018_M1",
        "name": "M1",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "CC"
        ],
        "metrics": [
          "Precision"
        ],
        "architecture": {
          "components": [
            "Two-layer Feed-forward Neural Network"
          ],
          "connections": [
            "State Representation",
            "Action Selection",
            "Reward Function"
          ],
          "mechanisms": [
            "Sarsa",
            "Reinforcement Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "ε-greedy Strategy",
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Discount Factor",
            "Replay Memory Size"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Feature Concatenation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_M2",
      "label": "M2",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_M2",
        "entity_id": "Wang2018_M2",
        "name": "M2",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "CC"
        ],
        "metrics": [
          "Precision"
        ],
        "architecture": {
          "components": [
            "Two-layer Feed-forward Neural Network"
          ],
          "connections": [
            "Feature Extraction",
            "Operator Classification"
          ],
          "mechanisms": [
            "Neural Network Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Hidden Layer Dimensions"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Feature Concatenation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_MathDQN",
      "label": "MathDQN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_MathDQN",
        "entity_id": "Wang2018_MathDQN",
        "name": "MathDQN",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "[\"Solving arithmetic word problems\"]",
        "dataset": [
          "AI2_2014",
          "IL_2015",
          "CC_2015",
          "ArithS_2018",
          "ArithM_2018"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblem",
          "Precision_ArithmeticWordProblem"
        ],
        "architecture": {
          "components": [
            "Deep Q-Network",
            "Feed-forward neural network"
          ],
          "connections": [
            "State to action mapping",
            "Reward feedback loop"
          ],
          "mechanisms": [
            "Reinforcement learning",
            "Deep learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep reinforcement learning",
            "Experience replay",
            "ε-greedy strategy"
          ],
          "parameter_tuning": [
            "Discount factor γ",
            "Learning rate",
            "Mini-batch size"
          ]
        },
        "feature_processing": [
          "Quantity schema",
          "Verb categorization",
          "Unit dependency graph"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_MathDQNReorder",
      "label": "MathDQN-Reorder",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_MathDQNReorder",
        "entity_id": "Wang2018_MathDQNReorder",
        "name": "MathDQN-Reorder",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Precision"
        ],
        "architecture": {
          "components": [
            "Deep Q-Network",
            "Re-order Mechanism"
          ],
          "connections": [
            "State Representation",
            "Action Selection",
            "Reward Function"
          ],
          "mechanisms": [
            "Reinforcement Learning",
            "Deep Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "ε-greedy Strategy",
            "Mini-batch Gradient Descent"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Discount Factor",
            "Replay Memory Size"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction",
          "Feature Concatenation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_OrderNormalizationRule1",
      "label": "Order Normalization Rule 1",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_OrderNormalizationRule1",
        "entity_id": "Wang2018_OrderNormalizationRule1",
        "name": "Order Normalization Rule 1",
        "title": "",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Wang, Y.",
          "Cai, D.",
          "Zhang, D.",
          "Liu, X."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Normalization Rules"
          ],
          "connections": [
            "Equation Templates Transformation"
          ],
          "mechanisms": [
            "Shortest Template Selection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Normalization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Token Ordering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_OrderNormalizationRule2",
      "label": "Order Normalization Rule 2",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_OrderNormalizationRule2",
        "entity_id": "Wang2018_OrderNormalizationRule2",
        "name": "Order Normalization Rule 2",
        "title": "",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Wang, Y.",
          "Cai, D.",
          "Zhang, D.",
          "Liu, X."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Normalization Rules"
          ],
          "connections": [
            "Equation Templates Transformation"
          ],
          "mechanisms": [
            "Order Preservation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-Based Normalization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Number Token Ordering"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_ReorderMechanism",
      "label": "Reorder Mechanism",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_ReorderMechanism",
        "entity_id": "Wang2018_ReorderMechanism",
        "name": "Reorder Mechanism",
        "title": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Lianli Gao",
          "Jingkuan Song",
          "Long Guo",
          "Heng Tao Shen"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2",
          "IL",
          "CC"
        ],
        "metrics": [
          "Precision",
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quantity Schema",
            "Reorder Mechanism",
            "Expression Tree"
          ],
          "connections": [
            "Quantity Sorting",
            "Tree Construction"
          ],
          "mechanisms": [
            "Rate Unit Detection",
            "Priority Assignment"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Reinforcement Learning",
            "Two-layer Feed-forward Neural Network"
          ],
          "parameter_tuning": [
            "Discount Factor",
            "Learning Rate",
            "Mini-batch Size"
          ]
        },
        "feature_processing": [
          "Verb Categorization",
          "Rate Unit Detection",
          "Context Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_Seq2SeqFramework",
      "label": "SEQ2SEQ Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_Seq2SeqFramework",
        "entity_id": "Wang2018_Seq2SeqFramework",
        "name": "SEQ2SEQ Framework",
        "title": "",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Problem Text -> Source Sequence",
            "Equation Templates -> Target Sequence"
          ],
          "mechanisms": [
            "Beam Search",
            "Token-wise Probabilities"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Maximize Conditional Probability P(Tp|P)"
          ],
          "parameter_tuning": [
            "Beam Search Width"
          ]
        },
        "feature_processing": [
          "Significant Number Identification",
          "Number Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_Transformer",
      "label": "Transformer",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_Transformer",
        "entity_id": "Wang2018_Transformer",
        "name": "Transformer",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Multi-Head Self-Attention Module",
            "Position-Wise Fully-Connected Feed-Forward Network"
          ],
          "connections": [
            "Self-Attention"
          ],
          "mechanisms": [
            "Attention Mechanism"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Adam Optimizer",
            "Dropout"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Number of Heads",
            "Dimension of Keys",
            "Dimension of Values",
            "Output Dimension"
          ]
        },
        "feature_processing": [
          "Number Tokenization",
          "Equation Template Transformation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_TranslatingMathWordProblem",
      "label": "Translating Math Word Problem to Expression Tree",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_TranslatingMathWordProblem",
        "entity_id": "Wang2018_TranslatingMathWordProblem",
        "name": "Translating Math Word Problem to Expression Tree",
        "title": "",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Wang, Y.",
          "Cai, D.",
          "Zhang, D.",
          "Liu, X."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "EMNLP_2018"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Expression Tree"
          ],
          "connections": [
            "Mapping Problem Text to Expression Tree"
          ],
          "mechanisms": [
            "Deep Learning",
            "Sequence-to-Sequence"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Seq2Seq Training"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Dependency Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Wang2018_TranslationToExpressionTree",
      "label": "Translation to Expression Tree",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_TranslationToExpressionTree",
        "entity_id": "Wang2018_TranslationToExpressionTree",
        "name": "Translation to Expression Tree",
        "title": "Translating Math Word Problem to Expression Tree",
        "year": "2018",
        "authors": [
          "L. Wang",
          "Y. Wang",
          "D. Cai",
          "D. Zhang",
          "X. Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder",
            "Decoder"
          ],
          "connections": [
            "Beam Search"
          ],
          "mechanisms": [
            "Recurrent Neural Network"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss"
          ],
          "parameter_tuning": [
            "Adam"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Dependency Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Wang2018b_DeepReinforcementLearning",
      "label": "Deep Reinforcement Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018b_DeepReinforcementLearning",
        "entity_id": "Wang2018b_DeepReinforcementLearning",
        "name": "Deep Reinforcement Learning",
        "title": "",
        "year": "2018",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Song, J.",
          "Guo, L.",
          "Shen, H. T."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "MathDQN_Dataset"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Expression Tree"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2019_BiLSTMwithSelfAttention",
      "label": "Bi-LSTM with Self Attention",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2019_BiLSTMwithSelfAttention",
        "entity_id": "Wang2019_BiLSTMwithSelfAttention",
        "name": "Bi-LSTM with Self Attention",
        "title": "",
        "year": "2019",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bi-LSTM",
            "Self Attention"
          ],
          "connections": [
            "Bidirectional LSTM layers",
            "Attention mechanism"
          ],
          "mechanisms": [
            "Contextualized word embeddings",
            "Long-range dependencies modeling"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-layer Bi-LSTM",
            "Two-layer LSTM"
          ],
          "parameter_tuning": [
            "Adam optimizer",
            "SGD optimizer"
          ]
        },
        "feature_processing": [
          "Word embeddings",
          "Quantity extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2019_RecursiveNN",
      "label": "Recursive Neural Network (Recursive NN)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2019_RecursiveNN",
        "entity_id": "Wang2019_RecursiveNN",
        "name": "Recursive Neural Network (Recursive NN)",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": "2019",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Bi-LSTM",
            "Self Attention",
            "Recursive NN"
          ],
          "connections": [
            "Quantity Embedding Layer -> Bi-LSTM -> Self Attention -> Recursive NN"
          ],
          "mechanisms": [
            "Bottom-up Operator Inference",
            "Suffix Expression Processing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Minimizing Loss Function"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "SGD Optimizer"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Quantity Extraction",
          "Equation Normalization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2019_SemanticallyAligned",
      "label": "Semantically-Aligned Equation Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2019_SemanticallyAligned",
        "entity_id": "Wang2019_SemanticallyAligned",
        "name": "Semantically-Aligned Equation Generation",
        "title": "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
        "year": "2019",
        "authors": [
          "Ting-Rui Chiang",
          "Yun-Nung Chen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Encoder-Decoder Framework"
          ],
          "connections": [
            "Symbolic World",
            "Semantic World"
          ],
          "mechanisms": [
            "Stack Actions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Hyperparameters"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2019_Seq2SeqModel",
      "label": "Seq2Seq Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2019_Seq2SeqModel",
        "entity_id": "Wang2019_Seq2SeqModel",
        "name": "Seq2Seq Model",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": "2019",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Encoder (Bi-LSTM)",
            "Decoder (LSTM)",
            "Attention Layer"
          ],
          "connections": [
            "Input Sequence -> Encoder -> Decoder -> Output Sequence"
          ],
          "mechanisms": [
            "Conditional Probability Estimation",
            "Sequence-to-Sequence Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Minimizing Loss Function"
          ],
          "parameter_tuning": [
            "Adam Optimizer"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Suffix Expression Generation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2019_Seq2SeqTemplatePrediction",
      "label": "Seq2Seq Template Prediction Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2019_Seq2SeqTemplatePrediction",
        "entity_id": "Wang2019_Seq2SeqTemplatePrediction",
        "name": "Seq2Seq Template Prediction Model",
        "title": "",
        "year": "2019",
        "authors": [
          "Wang, L.",
          "Zhang, D.",
          "Gao, L.",
          "Dai, B.T.",
          "Shen, H.T."
        ],
        "task": "[\"Template Prediction\"]",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2016"
        ],
        "metrics": [
          "Accuracy_TemplatePrediction"
        ],
        "architecture": {
          "components": [
            "Encoder (Bi-LSTM)",
            "Decoder (LSTM)",
            "Attention Layer"
          ],
          "connections": [
            "Encoder-Decoder Connection",
            "Attention Mechanism"
          ],
          "mechanisms": [
            "Sequence-to-Sequence Translation",
            "Attention Scoring"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Teacher Forcing"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Positional Encoding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2019_T-RNN",
      "label": "T-RNN",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2019_T-RNN",
        "entity_id": "Wang2019_T-RNN",
        "name": "T-RNN",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": "2019",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "MAWPS_2016",
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_MathWordProblem",
          "Precision_MathWordProblem",
          "Recall_MathWordProblem"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Recursive Neural Network",
            "Bi-LSTM",
            "Self Attention"
          ],
          "connections": [
            "Template Prediction",
            "Answer Generation"
          ],
          "mechanisms": [
            "Equation Normalization",
            "Operator Encapsulation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning",
            "Deep Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "SGD Optimizer"
          ]
        },
        "feature_processing": [
          "Quantity Embedding",
          "Suffix Expression Serialization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2019_TemplateBased",
      "label": "Template-Based Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2019_TemplateBased",
        "entity_id": "Wang2019_TemplateBased",
        "name": "Template-Based Solver",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": "2019",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Tree-Structure Template"
          ],
          "connections": [
            "Recursive Neural Network"
          ],
          "mechanisms": [
            "Bi-LSTM",
            "Self Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameters"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2019_TemplateBasedSolver",
      "label": "Template-Based Math Word Problem Solver with Recursive Neural Networks",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2019_TemplateBasedSolver",
        "entity_id": "Wang2019_TemplateBasedSolver",
        "name": "Template-Based Math Word Problem Solver with Recursive Neural Networks",
        "title": "",
        "year": "2019",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K",
          "MAWPS"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Bi-LSTM",
            "Self Attention",
            "Recursive Neural Network"
          ],
          "connections": [
            "Seq2Seq Model -> Template Prediction",
            "Bi-LSTM -> Quantity Embedding",
            "Recursive Neural Network -> Operator Inference"
          ],
          "mechanisms": [
            "Tree Structure Template",
            "Suffix Expression",
            "Equation Normalization",
            "Operator Encapsulation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Two-stage Training",
            "Template Prediction",
            "Answer Generation"
          ],
          "parameter_tuning": [
            "Adam Optimizer",
            "SGD Optimizer",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Quantity Detection",
          "Equation Template Annotation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Watanabe1991_IntegrationFramework",
      "label": "Integration Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Watanabe1991_IntegrationFramework",
        "entity_id": "Watanabe1991_IntegrationFramework",
        "name": "Integration Framework",
        "title": "Diagram Understanding Using Integration of Layout Information and Textual Information",
        "year": "1991",
        "authors": [
          "Yasuhiko Watanabe",
          "Makoto Nagao"
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Layout Information",
            "Natural Language Information"
          ],
          "connections": [
            "Connection",
            "Adjacency"
          ],
          "mechanisms": [
            "Semantic Interpretation",
            "Clue Expressions"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Observation and Experiments"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Pattern/Layout Information",
          "Natural Language Information"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Watanabe1991_LayoutAndNaturalLanguageIntegration",
      "label": "Layout and Natural Language Integration Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Watanabe1991_LayoutAndNaturalLanguageIntegration",
        "entity_id": "Watanabe1991_LayoutAndNaturalLanguageIntegration",
        "name": "Layout and Natural Language Integration Framework",
        "title": "",
        "year": "1991",
        "authors": [
          "Watanabe, Y.",
          "Nagao, M."
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "PBF Diagrams"
        ],
        "metrics": [
          "Success Rate",
          "Failure Rate"
        ],
        "architecture": {
          "components": [
            "Layout Information",
            "Natural Language Information"
          ],
          "connections": [
            "Symbol Connection",
            "Spatial Adjacency"
          ],
          "mechanisms": [
            "Semantic Interpretation Rules",
            "Clue Expressions Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pattern Matching",
            "Japanese Morphological Analysis"
          ],
          "parameter_tuning": [
            "Expression Patterns Matching",
            "Spatial Relationship Detection"
          ]
        },
        "feature_processing": [
          "ID Number Assignment",
          "Element Correspondence Description"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Watanabe1991_PBFDiagramUnderstandingFramework",
      "label": "PBF Diagram Understanding Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Watanabe1991_PBFDiagramUnderstandingFramework",
        "entity_id": "Watanabe1991_PBFDiagramUnderstandingFramework",
        "name": "PBF Diagram Understanding Framework",
        "title": "Diagram Understanding Using Integration of Layout Information and Textual Information",
        "year": "1991",
        "authors": [
          "Yasuhiko Watanabe",
          "Makoto Nagao"
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [],
        "metrics": [
          "Accuracy",
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Layout Information Extraction",
            "Natural Language Information Extraction"
          ],
          "connections": [
            "Integration of Layout and Natural Language Information"
          ],
          "mechanisms": [
            "Semantic Interpretation Rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Pattern Matching",
            "Japanese Morphological Analysis"
          ],
          "parameter_tuning": [
            "Rule-based Classification"
          ]
        },
        "feature_processing": [
          "Symbol Detection",
          "Spatial Relationship Analysis",
          "Expression Pattern Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Watanabe1991_RuleBasedSemanticAnalysis",
      "label": "Rule-Based Semantic Analysis",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Watanabe1991_RuleBasedSemanticAnalysis",
        "entity_id": "Watanabe1991_RuleBasedSemanticAnalysis",
        "name": "Rule-Based Semantic Analysis",
        "title": "",
        "year": "1991",
        "authors": [
          "Watanabe, Y.",
          "Nagao, M."
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "PBF Diagrams"
        ],
        "metrics": [
          "Success Rate",
          "Failure Rate"
        ],
        "architecture": {
          "components": [
            "Rule 1",
            "Rule 2",
            "Rule 3",
            "Rule 4",
            "Rule 5",
            "Rule 6",
            "Rule 7"
          ],
          "connections": [
            "Layout Information",
            "Natural Language Information"
          ],
          "mechanisms": [
            "Symbol Connection",
            "Spatial Relationship",
            "Expression Patterns"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Annotation"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Japanese Morphological Analysis",
          "Pattern Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Watanabe1991_SemanticInterpretationFramework",
      "label": "Semantic Interpretation Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Watanabe1991_SemanticInterpretationFramework",
        "entity_id": "Watanabe1991_SemanticInterpretationFramework",
        "name": "Semantic Interpretation Framework",
        "title": "",
        "year": "1991",
        "authors": [
          "Yasuhiko Watanabe",
          "Makoto Nagao"
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [
          "PBF Diagrams"
        ],
        "metrics": [
          "Success Rate"
        ],
        "architecture": {
          "components": [
            "Layout Information",
            "Natural Language Information"
          ],
          "connections": [
            "Integration of Layout and Natural Language Information"
          ],
          "mechanisms": [
            "Symbol Connection",
            "Spatial Relationship Similarity",
            "Expression Patterns"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Manual Annotation of Diagram Elements"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Japanese Morphological Analysis",
          "Pattern Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Watanabe2014_PBFDiagramUnderstanding",
      "label": "PBF Diagram Understanding",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Watanabe2014_PBFDiagramUnderstanding",
        "entity_id": "Watanabe2014_PBFDiagramUnderstanding",
        "name": "PBF Diagram Understanding",
        "title": "",
        "year": "2014",
        "authors": [
          "Yasuhiko Watanabe",
          "Makoto Nagao"
        ],
        "task": "[\"Diagram Understanding\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "layout information",
            "natural language information"
          ],
          "connections": [
            "symbolic connections",
            "spatial adjacency"
          ],
          "mechanisms": [
            "semantic interpretation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "keyword extraction",
          "expression pattern matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Williams1992_REINFORCE",
      "label": "REINFORCE",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Williams1992_REINFORCE",
        "entity_id": "Williams1992_REINFORCE",
        "name": "REINFORCE",
        "title": "",
        "year": "1992",
        "authors": [
          "Williams, R.J."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Alg514",
          "NumWord",
          "Dolphin18K"
        ],
        "metrics": [
          "Solution Accuracy"
        ],
        "architecture": {
          "components": [
            "Policy Gradient",
            "Reward Function"
          ],
          "connections": [
            "Action Space",
            "State Space"
          ],
          "mechanisms": [
            "Expected Reward",
            "Gradient Descent"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Learning Rate Decay",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Number Extraction",
          "Token Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wiseman2016_BeamSearchOptimization",
      "label": "Beam Search Optimization (BSO)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wiseman2016_BeamSearchOptimization",
        "entity_id": "Wiseman2016_BeamSearchOptimization",
        "name": "Beam Search Optimization (BSO)",
        "title": "",
        "year": "2016",
        "authors": [
          "Sam Wiseman",
          "Alexander M. Rush"
        ],
        "task": "[\"Sequence-to-Sequence Learning\"]",
        "dataset": [
          "Word Ordering",
          "Dependency Parsing",
          "Machine Translation"
        ],
        "metrics": [
          "BLEU Score",
          "UAS",
          "LAS"
        ],
        "architecture": {
          "components": [
            "Recurrent Neural Network (RNN)",
            "Long Short-Term Memory (LSTM)",
            "Global Attention Model"
          ],
          "connections": [
            "Encoder-Decoder Architecture"
          ],
          "mechanisms": [
            "Beam Search",
            "LaSO Framework"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Training",
            "Curriculum Beam Strategy",
            "Pre-training with Cross-Entropy Loss"
          ],
          "parameter_tuning": [
            "Mini-batch Adagrad",
            "Gradient Renormalization",
            "Learning Rates"
          ]
        },
        "feature_processing": [
          "Input Feeding",
          "Dropout Regularization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wiseman2016_ConstrainedBeamSearchOptimization",
      "label": "Constrained Beam Search Optimization (ConBSO)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wiseman2016_ConstrainedBeamSearchOptimization",
        "entity_id": "Wiseman2016_ConstrainedBeamSearchOptimization",
        "name": "Constrained Beam Search Optimization (ConBSO)",
        "title": "",
        "year": "2016",
        "authors": [
          "Wiseman, S.",
          "Rush, A.M."
        ],
        "task": "[\"Sequence-to-Sequence Learning\"]",
        "dataset": [
          "PTB_2015",
          "IWSLT2014_GermanToEnglish"
        ],
        "metrics": [
          "BLEU_SentenceLevel",
          "UAS_Parsing",
          "LAS_Parsing"
        ],
        "architecture": {
          "components": [
            "LSTM Encoder",
            "LSTM Decoder",
            "Global Attention Model"
          ],
          "connections": [
            "Input Feeding",
            "Beam Search"
          ],
          "mechanisms": [
            "Hard Constraints",
            "Sequence-Level Scoring"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Beam Search Optimization",
            "Curriculum Beam Strategy"
          ],
          "parameter_tuning": [
            "Pre-training with Cross-Entropy Loss",
            "Mini-batch Adagrad",
            "Gradient Renormalization"
          ]
        },
        "feature_processing": [
          "Word Embeddings Initialization",
          "Digit Normalization",
          "Singleton Words Replacement"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wong2006_LearningSemanticParsing",
      "label": "Learning for Semantic Parsing",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wong2006_LearningSemanticParsing",
        "entity_id": "Wong2006_LearningSemanticParsing",
        "name": "Learning for Semantic Parsing",
        "title": "",
        "year": "2006",
        "authors": [
          "Wong, Y.",
          "Mooney, R."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "NAACL_2006"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Parsing",
            "Statistical Machine Translation"
          ],
          "connections": [
            "Semantic Parsing",
            "Translation"
          ],
          "mechanisms": [
            "Statistical Machine Translation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Statistical Machine Translation"
          ],
          "parameter_tuning": [
            "Semantic Parsing"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wong2007_LearningSynchronousGrammars",
      "label": "Learning Synchronous Grammars",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wong2007_LearningSynchronousGrammars",
        "entity_id": "Wong2007_LearningSynchronousGrammars",
        "name": "Learning Synchronous Grammars",
        "title": "",
        "year": "2007",
        "authors": [
          "Wong, Y.",
          "Mooney, R."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "ACL_2007"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Synchronous Grammars",
            "Lambda Calculus"
          ],
          "connections": [
            "Synchronous Grammars",
            "Semantic Parsing"
          ],
          "mechanisms": [
            "Lambda Calculus"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Lambda Calculus"
          ],
          "parameter_tuning": [
            "Synchronous Grammars"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Younger1967_RecognitionAlgorithm",
      "label": "Younger's Recognition Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Younger1967_RecognitionAlgorithm",
        "entity_id": "Younger1967_RecognitionAlgorithm",
        "name": "Younger's Recognition Algorithm",
        "title": "",
        "year": "1967",
        "authors": [
          "Younger, D.H."
        ],
        "task": "[\"Parsing\"]",
        "dataset": [],
        "metrics": [
          "TimeComplexity_Parsing",
          "SpaceComplexity_Parsing"
        ],
        "architecture": {
          "components": [
            "Parsing table",
            "Dynamic programming"
          ],
          "connections": [
            "State transitions"
          ],
          "mechanisms": [
            "Turing machine implementation"
          ]
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Yu2009_LearningStructuralSVMs",
      "label": "Learning Structural SVMs",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2009_LearningStructuralSVMs",
        "entity_id": "Yu2009_LearningStructuralSVMs",
        "name": "Learning Structural SVMs",
        "title": "",
        "year": "2009",
        "authors": [
          "Yu, C.",
          "Joachims, T."
        ],
        "task": "[\"Structural SVMs\"]",
        "dataset": [
          "ICML_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Structural SVMs",
            "Latent Variables"
          ],
          "connections": [
            "Structural SVMs",
            "Latent Variables"
          ],
          "mechanisms": [
            "Latent Variables"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Latent Variables"
          ],
          "parameter_tuning": [
            "Structural SVMs"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Yu2009_SpanningTree",
      "label": "Spanning Tree",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2009_SpanningTree",
        "entity_id": "Yu2009_SpanningTree",
        "name": "Spanning Tree",
        "title": "",
        "year": "2009",
        "authors": [
          "Yu and Joachims"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE_2004",
          "Ontonotes_2012"
        ],
        "metrics": [
          "MUC_Coreference",
          "BCUB_Coreference",
          "CEAF_EntityBased",
          "F1_Average"
        ],
        "architecture": {
          "components": [
            "Latent Spanning Forest"
          ],
          "connections": [
            "Mention Pair Scoring",
            "Clustering"
          ],
          "mechanisms": [
            "Latent Structure"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Prediction"
          ],
          "parameter_tuning": [
            "Loss-Based Margin"
          ]
        },
        "feature_processing": [
          "Pairwise Compatibility Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Yu2015_ChineseArithmeticProblems",
      "label": "Chinese Arithmetic Problems Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2015_ChineseArithmeticProblems",
        "entity_id": "Yu2015_ChineseArithmeticProblems",
        "name": "Chinese Arithmetic Problems Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Yu, X.",
          "Wang, M.",
          "Zeng, Z.",
          "Fan, J."
        ],
        "task": "[\"Solving directly-stated arithmetic word problems in Chinese\"]",
        "dataset": [
          "Chinese arithmetic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Syntax-semantics model"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Extracting quantity relations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Yu2015_ChineseEquationSet",
      "label": "Chinese Equation Set Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2015_ChineseEquationSet",
        "entity_id": "Yu2015_ChineseEquationSet",
        "name": "Chinese Equation Set Problem Solver",
        "title": "Solving Equation Set Problems in Chinese",
        "year": "2015",
        "authors": [
          "Yu",
          "Wang",
          "Zeng",
          "Fan"
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Syntax-Semantics Model"
          ],
          "connections": [
            "Keyword Structure",
            "POS Pattern"
          ],
          "mechanisms": [
            "Quantity Relation Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameter Tuning"
          ]
        },
        "feature_processing": [
          "Keyword Structure",
          "POS Tagging"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Yu2015_ChineseEquationSetSolver",
      "label": "Chinese Equation Set Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2015_ChineseEquationSetSolver",
        "entity_id": "Yu2015_ChineseEquationSetSolver",
        "name": "Chinese Equation Set Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Yu, X.",
          "Wang, M.",
          "Zeng, Z.",
          "Fan, J."
        ],
        "task": "[\"Solving Chinese equation set problems\"]",
        "dataset": [
          "Chinese equation set datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Syntax-semantics model"
          ],
          "connections": [
            "Quantity relation extraction"
          ],
          "mechanisms": [
            "Keyword structure, POS pattern, quantity relation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Model training"
          ],
          "parameter_tuning": [
            "Hyperparameter tuning"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Yu2015_SyntaxSemanticsModel",
      "label": "Syntax-Semantics Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2015_SyntaxSemanticsModel",
        "entity_id": "Yu2015_SyntaxSemanticsModel",
        "name": "Syntax-Semantics Model",
        "title": "",
        "year": "2015",
        "authors": [
          "X. Yu",
          "M. Wang",
          "Z. Zeng",
          "J. Fan"
        ],
        "task": "[\"Chinese Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Chinese Arithmetic Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Keyword Structure",
            "POS Pattern",
            "Quantity Relation"
          ],
          "connections": [
            "Text to Quantity Relations"
          ],
          "mechanisms": [
            "Semantic Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Parameter Optimization"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Yu2016_ChineseArithmeticWordProblemSolver",
      "label": "Chinese Arithmetic Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2016_ChineseArithmeticWordProblemSolver",
        "entity_id": "Yu2016_ChineseArithmeticWordProblemSolver",
        "name": "Chinese Arithmetic Word Problem Solver",
        "title": "",
        "year": "2016",
        "authors": [
          "Yu, X.",
          "Jian, P.",
          "Wang, M.",
          "Wu, S."
        ],
        "task": "[\"Solving Chinese arithmetic word problems\"]",
        "dataset": [
          "Chinese arithmetic word problem datasets"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Implicit quantity relation extraction"
          ],
          "connections": [
            "Quantity relation extraction"
          ],
          "mechanisms": [
            "Extracting implicit quantity relations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Model training"
          ],
          "parameter_tuning": [
            "Hyperparameter tuning"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Yu2016_ChinesePhraseParse",
      "label": "Chinese Phrase Parse",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2016_ChinesePhraseParse",
        "entity_id": "Yu2016_ChinesePhraseParse",
        "name": "Chinese Phrase Parse",
        "title": "",
        "year": "2016",
        "authors": [
          "Yu, X.",
          "Jian, P.",
          "Wang, M.",
          "Wu, S."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy"
        ],
        "architecture": {
          "components": [
            "ICTCLAS"
          ],
          "connections": [
            "Input Text -> ICTCLAS -> Annotated Text"
          ],
          "mechanisms": [
            "Part-of-Speech Tagging",
            "Phrase Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Preprocessing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Part-of-Speech Tagging",
          "Phrase Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Yu2016_ImplicitQuantityRelationExtractor",
      "label": "Implicit Quantity Relation Extractor",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2016_ImplicitQuantityRelationExtractor",
        "entity_id": "Yu2016_ImplicitQuantityRelationExtractor",
        "name": "Implicit Quantity Relation Extractor",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": "2016",
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": "[\"Extracting implicit quantity relations in arithmetic word problems\"]",
        "dataset": [
          "Elementary school arithmetic application problem_2011",
          "Suzhou Education Publishing House_dataset"
        ],
        "metrics": [
          "Classification Accuracy"
        ],
        "architecture": {
          "components": [
            "Chinese phrase parse",
            "SVM classification",
            "Instantiation method of required general implicit quantity relations"
          ],
          "connections": [
            "Chinese phrase parse -> SVM classification -> Instantiation method"
          ],
          "mechanisms": [
            "Semantic models",
            "Sequence alignment",
            "Equation construction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SVM with slack variable",
            "Bag of words feature extraction"
          ],
          "parameter_tuning": [
            "C (weight number for slack variable)"
          ]
        },
        "feature_processing": [
          "Bag of words",
          "Chinese phrase parse",
          "Normalization of common units"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Yu2016_ImplicitQuantityRelations",
      "label": "Implicit Quantity Relations Extractor",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2016_ImplicitQuantityRelations",
        "entity_id": "Yu2016_ImplicitQuantityRelations",
        "name": "Implicit Quantity Relations Extractor",
        "title": "",
        "year": "2016",
        "authors": [
          "Yu, X.",
          "Jian, P.",
          "Wang, M.",
          "Wu, S."
        ],
        "task": "[\"Extracting implicit quantity relations for arithmetic word problems in Chinese\"]",
        "dataset": [
          "Chinese arithmetic word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Syntax-semantics model"
          ],
          "connections": [
            "Not specified"
          ],
          "mechanisms": [
            "Extracting quantity relations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not specified"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Textual feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Yu2016_NormalizedCommonUnits",
      "label": "Normalized Common Units",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2016_NormalizedCommonUnits",
        "entity_id": "Yu2016_NormalizedCommonUnits",
        "name": "Normalized Common Units",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": "2016",
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": "[\"Normalization of units in arithmetic word problems\"]",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy"
        ],
        "architecture": {
          "components": [
            "Unit normalization module"
          ],
          "connections": [
            "Preprocessing step before Chinese phrase parse"
          ],
          "mechanisms": [
            "Unit conversion rules"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Rule-based normalization"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Unit unification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Yu2016_SemanticModelInstantiation",
      "label": "Semantic Model Instantiation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2016_SemanticModelInstantiation",
        "entity_id": "Yu2016_SemanticModelInstantiation",
        "name": "Semantic Model Instantiation",
        "title": "",
        "year": "2016",
        "authors": [
          "Yu, X.",
          "Jian, P.",
          "Wang, M.",
          "Wu, S."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy"
        ],
        "architecture": {
          "components": [
            "Semantic Models",
            "Equation Construction"
          ],
          "connections": [
            "Parsed Text -> Semantic Models -> Equations"
          ],
          "mechanisms": [
            "Mapping Variables",
            "Constructing Equations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Post-processing"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Variable Allocation",
          "Equation Formation"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Yu2016_SVMAlgorithm",
      "label": "SVM Algorithm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2016_SVMAlgorithm",
        "entity_id": "Yu2016_SVMAlgorithm",
        "name": "SVM Algorithm",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": "2016",
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy",
          "Classification_Error_Rate"
        ],
        "architecture": {
          "components": [
            "Kernel Function",
            "Slack Variable"
          ],
          "connections": [
            "Hyperplane Calculation",
            "Margin Maximization"
          ],
          "mechanisms": [
            "Support Vector Identification",
            "Classification Boundary"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-validation",
            "Grid Search"
          ],
          "parameter_tuning": [
            "C (Regularization Parameter)",
            "Gamma"
          ]
        },
        "feature_processing": [
          "Bag of Words",
          "TF-IDF"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Yu2016_SVMClassification",
      "label": "SVM Classification",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Yu2016_SVMClassification",
        "entity_id": "Yu2016_SVMClassification",
        "name": "SVM Classification",
        "title": "Extraction of Implicit Quantity Relations for Arithmetic Word Problems in Chinese",
        "year": "2016",
        "authors": [
          "Xinguo Yu",
          "Pengpeng Jian",
          "Mingshu Wang",
          "Shuang Wu"
        ],
        "task": "[\"Arithmetic Word Problem Classification\"]",
        "dataset": [
          "Elementary_school_arithmetic_application_problem_2011"
        ],
        "metrics": [
          "Classification_Accuracy"
        ],
        "architecture": {
          "components": [
            "SVM Classifier",
            "Slack Variable"
          ],
          "connections": [
            "Input Features -> SVM Classifier -> Output Classification"
          ],
          "mechanisms": [
            "Kernel Function",
            "Max Margin Hyperplane"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Cross-validation",
            "Grid Search"
          ],
          "parameter_tuning": [
            "C (Regularization Parameter)",
            "Kernel Type"
          ]
        },
        "feature_processing": [
          "Bag of Words",
          "Part-of-Speech Tagging"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "ZDC2015_ImprovedTemplateBasedStatisticalLearning",
      "label": "ZDC",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "ZDC2015_ImprovedTemplateBasedStatisticalLearning",
        "entity_id": "ZDC2015_ImprovedTemplateBasedStatisticalLearning",
        "name": "ZDC",
        "title": "",
        "year": "2015",
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "[\"自动解代数文字题\"]",
        "dataset": [
          "Alg514"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "问题句子映射到方程模板"
          ],
          "connections": [
            "问题句子与方程模板之间的映射"
          ],
          "mechanisms": [
            "减少名词短语与变量之间的对齐搜索空间"
          ]
        },
        "methodology": {
          "training_strategy": [
            "统计学习方法"
          ],
          "parameter_tuning": [
            "无"
          ]
        },
        "feature_processing": [
          "无"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zelle1996_LearningToParseDatabase",
      "label": "Learning to Parse Database Queries",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zelle1996_LearningToParseDatabase",
        "entity_id": "Zelle1996_LearningToParseDatabase",
        "name": "Learning to Parse Database Queries",
        "title": "",
        "year": "1996",
        "authors": [
          "Zelle, J.",
          "Mooney, R."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "AAAI_1996"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Semantic Parsing",
            "Database Queries"
          ],
          "connections": [
            "Semantic Parsing",
            "Database"
          ],
          "mechanisms": [
            "Inductive Logic Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Inductive Logic Programming"
          ],
          "parameter_tuning": [
            "Semantic Parsing"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zettlemoyer2005_LearningToMapSentences",
      "label": "Learning to Map Sentences to Logical Form",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zettlemoyer2005_LearningToMapSentences",
        "entity_id": "Zettlemoyer2005_LearningToMapSentences",
        "name": "Learning to Map Sentences to Logical Form",
        "title": "",
        "year": "2005",
        "authors": [
          "Zettlemoyer, L.",
          "Collins, M."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "UAI_2005"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Sentences Mapping",
            "Logical Form"
          ],
          "connections": [
            "Sentences",
            "Logical Form"
          ],
          "mechanisms": [
            "Probabilistic Categorial Grammars"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Probabilistic Categorial Grammars"
          ],
          "parameter_tuning": [
            "Sentences Mapping"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zettlemoyer2005_SentenceToLogicalForm",
      "label": "SentenceToLogicalForm",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zettlemoyer2005_SentenceToLogicalForm",
        "entity_id": "Zettlemoyer2005_SentenceToLogicalForm",
        "name": "SentenceToLogicalForm",
        "title": "",
        "year": "2005",
        "authors": [
          "Zettlemoyer, L.S.",
          "Collins, M."
        ],
        "task": "[\"Mapping sentences to logical form\"]",
        "dataset": [
          "None specified"
        ],
        "metrics": [
          "None specified"
        ],
        "architecture": {
          "components": [
            "Probabilistic Categorial Grammars"
          ],
          "connections": [
            "None specified"
          ],
          "mechanisms": [
            "Structured classification"
          ]
        },
        "methodology": {
          "training_strategy": [
            "None specified"
          ],
          "parameter_tuning": [
            "None specified"
          ]
        },
        "feature_processing": [
          "None specified"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zettlemoyer2007_OnlineLearningRelaxedCCG",
      "label": "Online Learning of Relaxed CCG Grammars",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zettlemoyer2007_OnlineLearningRelaxedCCG",
        "entity_id": "Zettlemoyer2007_OnlineLearningRelaxedCCG",
        "name": "Online Learning of Relaxed CCG Grammars",
        "title": "",
        "year": "2007",
        "authors": [
          "Zettlemoyer, L.",
          "Collins, M."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "CoNLL_2007"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Relaxed CCG Grammars",
            "Online Learning"
          ],
          "connections": [
            "Relaxed CCG Grammars",
            "Online Learning"
          ],
          "mechanisms": [
            "Online Learning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Online Learning"
          ],
          "parameter_tuning": [
            "Relaxed CCG Grammars"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zettlemoyer2009_LearningContextDependentMappings",
      "label": "Learning Context-Dependent Mappings",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zettlemoyer2009_LearningContextDependentMappings",
        "entity_id": "Zettlemoyer2009_LearningContextDependentMappings",
        "name": "Learning Context-Dependent Mappings",
        "title": "",
        "year": "2009",
        "authors": [
          "Zettlemoyer, L.",
          "Collins, M."
        ],
        "task": "[\"Semantic Parsing\"]",
        "dataset": [
          "ACL_2009"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Context-Dependent Mappings",
            "Sentences",
            "Logical Form"
          ],
          "connections": [
            "Context-Dependent Mappings",
            "Sentences",
            "Logical Form"
          ],
          "mechanisms": [
            "Context-Dependent Mappings"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Context-Dependent Mappings"
          ],
          "parameter_tuning": [
            "Sentences",
            "Logical Form"
          ]
        },
        "feature_processing": [
          "Lexical Features",
          "Syntactic Features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhang2015_ExpressionTree",
      "label": "ExpressionTree",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhang2015_ExpressionTree",
        "entity_id": "Zhang2015_ExpressionTree",
        "name": "ExpressionTree",
        "title": "The Gap of Semantic Parsing: A Survey on Automatic Math Word Problem Solvers",
        "year": "2015",
        "authors": [
          "Roy",
          "Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary Classifier",
            "Expression Tree"
          ],
          "connections": [
            "Beam Search"
          ],
          "mechanisms": [
            "Local Classifier"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Binary Classification"
          ],
          "parameter_tuning": [
            "Beam Search"
          ]
        },
        "feature_processing": [
          "Quantity Extraction",
          "Verb Categorization"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Zhang2016_Yin_and_Yang",
      "label": "Yin and Yang",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhang2016_Yin_and_Yang",
        "entity_id": "Zhang2016_Yin_and_Yang",
        "name": "Yin and Yang",
        "title": "Yin and Yang: Balancing and Answering Binary Visual Questions",
        "year": "2016",
        "authors": [
          "Zhang, P.",
          "Goyal, Y.",
          "Summers-Stay, D.",
          "Batra, D.",
          "Parikh, D."
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "VQA Abstract Scenes"
        ],
        "metrics": [
          "VQA Accuracy"
        ],
        "architecture": {
          "components": [
            "Binary Question Handling",
            "Clipart Scene Editing"
          ],
          "connections": [
            "Question-Image Pairing"
          ],
          "mechanisms": [
            "Answer Change Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Human Annotation"
          ],
          "parameter_tuning": [
            "None"
          ]
        },
        "feature_processing": [
          "Clipart Scene Modification"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhang2017_DeepNeuralSolver",
      "label": "Deep Neural Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhang2017_DeepNeuralSolver",
        "entity_id": "Zhang2017_DeepNeuralSolver",
        "name": "Deep Neural Solver",
        "title": "Deep Neural Solver for Math Word Problems",
        "year": "2017",
        "authors": [
          "Wang, Y.",
          "Liu, X.",
          "Shi, S."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "GRU",
            "Word Embedding"
          ],
          "connections": [
            "Seq2Seq"
          ],
          "mechanisms": [
            "Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "CrossEntropyLoss",
            "Normalization"
          ],
          "parameter_tuning": [
            "Adam",
            "Dropout"
          ]
        },
        "feature_processing": [
          "Tokenization",
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Zhang2019_DeepNeuralSolver",
      "label": "Deep Neural Solver (DNS)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhang2019_DeepNeuralSolver",
        "entity_id": "Zhang2019_DeepNeuralSolver",
        "name": "Deep Neural Solver (DNS)",
        "title": "",
        "year": "2017",
        "authors": [
          "Y. Wang",
          "X. Liu",
          "S. Shi"
        ],
        "task": "[\"Solving Math Word Problems\"]",
        "dataset": [
          "Math23K_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "GRU",
            "seq2seq model"
          ],
          "connections": [
            "encoder-decoder"
          ],
          "mechanisms": [
            "word embedding",
            "validity constraints"
          ]
        },
        "methodology": {
          "training_strategy": [
            "sequence-to-sequence learning"
          ],
          "parameter_tuning": [
            "pre-defined rules"
          ]
        },
        "feature_processing": [
          "word embedding"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Zhou2015_ConstraintGeneration",
      "label": "Constraint Generation",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_ConstraintGeneration",
        "entity_id": "Zhou2015_ConstraintGeneration",
        "name": "Constraint Generation",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": "2015",
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Log-linear Model",
            "Quadratic Programming"
          ],
          "connections": [
            "Max-margin Objective",
            "Slack Variable"
          ],
          "mechanisms": [
            "Constraint Generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Initial Model Training",
            "Constraint Checking",
            "False Derivation Collection"
          ],
          "parameter_tuning": [
            "Parameter C"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_EnhancedTemplate",
      "label": "EnhancedTemplate",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_EnhancedTemplate",
        "entity_id": "Zhou2015_EnhancedTemplate",
        "name": "EnhancedTemplate",
        "title": "Enhanced Algorithm for Template-Based Learning Framework",
        "year": "2015",
        "authors": [
          "Zhou",
          "et al."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Template Matching",
            "RankSVM"
          ],
          "connections": [
            "Canonicalized Ordering"
          ],
          "mechanisms": [
            "Beam Search"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Objective"
          ],
          "parameter_tuning": [
            "Beam Size"
          ]
        },
        "feature_processing": [
          "Number Slot Assignment",
          "Unknown Slot Alignment"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Zhou2015_EnhancedTemplateBasedSolver",
      "label": "Enhanced Template-Based Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_EnhancedTemplateBasedSolver",
        "entity_id": "Zhou2015_EnhancedTemplateBasedSolver",
        "name": "Enhanced Template-Based Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "ALG514_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Equation Templates",
            "Feature Representation",
            "Parameter Vector"
          ],
          "connections": [
            "Template Matching",
            "Feature Extraction"
          ],
          "mechanisms": [
            "Log-linear Model",
            "Max-Margin Objective",
            "RankSVM"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Objective",
            "Constraint Generation Algorithm"
          ],
          "parameter_tuning": [
            "QP Problem"
          ]
        },
        "feature_processing": [
          "Lexical and Syntactic Features",
          "Dependency Path Between Slots"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Zhou2015_ImprovedTemplateBasedStatisticalLearning",
      "label": "ZDC",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_ImprovedTemplateBasedStatisticalLearning",
        "entity_id": "Zhou2015_ImprovedTemplateBasedStatisticalLearning",
        "name": "ZDC",
        "title": "",
        "year": "2015",
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "[\"自动求解数学文字题\"]",
        "dataset": [
          "Alg514_2014",
          "Dolphin18K_2016"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "改进的模板匹配",
            "句子推理"
          ],
          "connections": [
            "问题句子到模板映射"
          ],
          "mechanisms": [
            "统计学习"
          ]
        },
        "methodology": {
          "training_strategy": [
            "减少名词短语与变量的对齐建模"
          ],
          "parameter_tuning": [
            "模板定义"
          ]
        },
        "feature_processing": [
          "问题句子建模"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_LogLinearModel",
      "label": "Log-Linear Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_LogLinearModel",
        "entity_id": "Zhou2015_LogLinearModel",
        "name": "Log-Linear Model",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": "2015",
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Feature Function",
            "Parameter Vector"
          ],
          "connections": [
            "Template Selection",
            "Number Assignment"
          ],
          "mechanisms": [
            "Max-Margin Objective"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-Margin Objective",
            "Quadratic Programming"
          ],
          "parameter_tuning": [
            "Parameter Vector θ"
          ]
        },
        "feature_processing": [
          "Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_LogLinearModelForEquationMapping",
      "label": "Log-Linear Model for Equation Mapping",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_LogLinearModelForEquationMapping",
        "entity_id": "Zhou2015_LogLinearModelForEquationMapping",
        "name": "Log-Linear Model for Equation Mapping",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": "2015",
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Log-linear model",
            "Equation system templates"
          ],
          "connections": [
            "Mapping from word problems to equation systems"
          ],
          "mechanisms": [
            "Max-margin objective",
            "Quadratic Programming"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin objective",
            "Constraint generation"
          ],
          "parameter_tuning": [
            "Parameter C"
          ]
        },
        "feature_processing": [
          "Single slot features",
          "Slot pair features",
          "Solution features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_MaxMarginObjective",
      "label": "Max-Margin Objective",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_MaxMarginObjective",
        "entity_id": "Zhou2015_MaxMarginObjective",
        "name": "Max-Margin Objective",
        "title": "",
        "year": "2015",
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "Max-Margin Objective"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_QuadraticProgramming",
      "label": "Quadratic Programming Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_QuadraticProgramming",
        "entity_id": "Zhou2015_QuadraticProgramming",
        "name": "Quadratic Programming Solver",
        "title": "",
        "year": "2015",
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "[\"Solving algebra word problems\"]",
        "dataset": [
          "Algebra word problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Quadratic programming"
          ],
          "connections": [
            "Optimization"
          ],
          "mechanisms": [
            "Quadratic optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Optimization-based learning"
          ],
          "parameter_tuning": [
            "Optimization parameters"
          ]
        },
        "feature_processing": [
          "Optimization feature extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_QuadraticProgrammingSolver",
      "label": "Quadratic Programming Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_QuadraticProgrammingSolver",
        "entity_id": "Zhou2015_QuadraticProgrammingSolver",
        "name": "Quadratic Programming Solver",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": "2015",
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "[\"Solving Algebra Word Problems\"]",
        "dataset": [
          "Kushman2014_Dataset"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Log-linear model",
            "Quadratic Programming"
          ],
          "connections": [
            "Max-margin objective",
            "Constraint generation"
          ],
          "mechanisms": [
            "Feature extraction",
            "Template matching"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Max-margin objective",
            "Constraint generation"
          ],
          "parameter_tuning": [
            "Parameter C"
          ]
        },
        "feature_processing": [
          "Single slot features",
          "Slot pair features",
          "Solution features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_QuadraticProgrammingWordProblemSolver",
      "label": "Quadratic Programming Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_QuadraticProgrammingWordProblemSolver",
        "entity_id": "Zhou2015_QuadraticProgrammingWordProblemSolver",
        "name": "Quadratic Programming Word Problem Solver",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": "2015",
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "[\"Solving Algebra Word Problems\"]",
        "dataset": [
          "Kushman2014_Dataset"
        ],
        "metrics": [
          "Accuracy_AnswerExtraction"
        ],
        "architecture": {
          "components": [
            "log-linear model",
            "quadratic programming"
          ],
          "connections": [
            "template selection",
            "number assignment"
          ],
          "mechanisms": [
            "max-margin objective",
            "constraint generation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "max-margin objective",
            "constraint generation"
          ],
          "parameter_tuning": [
            "C parameter for regularization"
          ]
        },
        "feature_processing": [
          "single slot features",
          "slot pair features",
          "solution features"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_SingleSlotFeatures",
      "label": "Single Slot Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_SingleSlotFeatures",
        "entity_id": "Zhou2015_SingleSlotFeatures",
        "name": "Single Slot Features",
        "title": "",
        "year": "2015",
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Relation between numbers and the question sentence",
            "Position of a number w.r.t a comparative word",
            "Context of a number",
            "Is one or two?",
            "Is a multiplier?",
            "Is between 0 and 1?"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Relation between numbers and the question sentence",
          "Position of a number w.r.t a comparative word",
          "Context of a number",
          "Is one or two?",
          "Is a multiplier?",
          "Is between 0 and 1?"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_SlotPairFeatures",
      "label": "Slot Pair Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_SlotPairFeatures",
        "entity_id": "Zhou2015_SlotPairFeatures",
        "name": "Slot Pair Features",
        "title": "",
        "year": "2015",
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Relation between two numbers",
            "Context similarity between two numbers",
            "Coreference relationship",
            "Both multipliers",
            "Same sentence or continuous sentences",
            "Raw path and dependency path",
            "One number is larger than another"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Relation between two numbers",
          "Context similarity between two numbers",
          "Coreference relationship",
          "Both multipliers",
          "Same sentence or continuous sentences",
          "Raw path and dependency path",
          "One number is larger than another"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_SolutionFeatures",
      "label": "Solution Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_SolutionFeatures",
        "entity_id": "Zhou2015_SolutionFeatures",
        "name": "Solution Features",
        "title": "",
        "year": "2015",
        "authors": [
          "Lipu Zhou",
          "Shuaixiang Dai",
          "Liwei Chen"
        ],
        "task": "[\"Algebra Word Problem Solving\"]",
        "dataset": [
          "Kushman2014_Dataset_2014"
        ],
        "metrics": [
          "Accuracy_Classification"
        ],
        "architecture": {
          "components": [
            "Is integer solution?",
            "Is positive solution?",
            "Is between 0 and 1?"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [
          "Is integer solution?",
          "Is positive solution?",
          "Is between 0 and 1?"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_StructuredOutput",
      "label": "Structured-Output Learning Framework",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_StructuredOutput",
        "entity_id": "Zhou2015_StructuredOutput",
        "name": "Structured-Output Learning Framework",
        "title": "",
        "year": "2015",
        "authors": [
          "Zhou, L.",
          "Dai, S.",
          "Chen, L."
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "Dolphin_2016"
        ],
        "metrics": [
          "Precision_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Structured-Output Learning",
            "Explicit and Implicit Signals"
          ],
          "connections": [
            "Joint Learning of Signals"
          ],
          "mechanisms": [
            "Signal Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Signal Learning Parameters"
          ]
        },
        "feature_processing": [
          "Signal Extraction",
          "Joint Learning"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhou2015_ZDC",
      "label": "ZDC",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhou2015_ZDC",
        "entity_id": "Zhou2015_ZDC",
        "name": "ZDC",
        "title": "Learn to Solve Algebra Word Problems Using Quadratic Programming",
        "year": "2015",
        "authors": [
          "Zhou",
          "Dai",
          "Chen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Improved Template-based Statistical Learning"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [
            "Reduced Search Space"
          ],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhu2003_AutomaticParticleDetection",
      "label": "Automatic Particle Detection",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhu2003_AutomaticParticleDetection",
        "entity_id": "Zhu2003_AutomaticParticleDetection",
        "name": "Automatic Particle Detection",
        "title": "",
        "year": "2003",
        "authors": [
          "Y. Zhu",
          "B. Carragher",
          "F. Mouche",
          "C. Potter"
        ],
        "task": "[\"Particle Detection\"]",
        "dataset": [
          "CryoElectronMicroscopyImages_2003"
        ],
        "metrics": [
          "DetectionAccuracy"
        ],
        "architecture": {
          "components": [
            "Rectangular Hough Transform"
          ],
          "connections": [
            "Accumulator Array"
          ],
          "mechanisms": [
            "Detecting Center and Orientation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Not Applicable"
          ]
        },
        "feature_processing": [
          "Edge Detection"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zhu2003_RectangularHoughTransform",
      "label": "Rectangular Hough Transform (RHT)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zhu2003_RectangularHoughTransform",
        "entity_id": "Zhu2003_RectangularHoughTransform",
        "name": "Rectangular Hough Transform (RHT)",
        "title": "Automatic Particle Detection through Efficient Hough Transforms",
        "year": "2003",
        "authors": [
          "Y. Zhu",
          "B. Carragher",
          "F. Mouche",
          "C. Potter"
        ],
        "task": "[\"Particle Detection\"]",
        "dataset": [],
        "metrics": [],
        "architecture": {
          "components": [
            "2D Accumulator Array"
          ],
          "connections": [],
          "mechanisms": []
        },
        "methodology": {
          "training_strategy": [],
          "parameter_tuning": []
        },
        "feature_processing": [],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Zou2013_BilingualEmbedding",
      "label": "Bilingual Embedding",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Zou2013_BilingualEmbedding",
        "entity_id": "Zou2013_BilingualEmbedding",
        "name": "Bilingual Embedding",
        "title": "",
        "year": "2013",
        "authors": [
          "Zou, W.Y.",
          "Socher, R.",
          "Cer, D.M.",
          "Manning, C.D."
        ],
        "task": "[\"Phrase Pair Scoring\"]",
        "dataset": [
          "WMT14_EnglishFrench_2014"
        ],
        "metrics": [
          "BLEU_Translation"
        ],
        "architecture": {
          "components": [
            "Input Layer",
            "Hidden Layers",
            "Output Layer"
          ],
          "connections": [
            "Fully Connected"
          ],
          "mechanisms": [
            "Bilingual Embedding"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Backpropagation"
          ]
        },
        "feature_processing": [
          "Word Embedding"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "CASS2018_ReinforcementLearning",
      "label": "CASS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "CASS2018_ReinforcementLearning",
        "entity_id": "CASS2018_ReinforcementLearning",
        "name": "CASS",
        "title": "",
        "year": "2018",
        "authors": [
          "Huang, D.",
          "Liu, J.",
          "Lin, C.",
          "Yin, J."
        ],
        "task": "[\"Equation Set Problem Solving\"]",
        "dataset": [
          "Dolphin18K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Copy Mechanism",
            "Alignment Mechanism"
          ],
          "connections": [
            "Policy Gradient",
            "Reinforcement Learning"
          ],
          "mechanisms": [
            "Copy and Alignment",
            "Policy Gradient Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Reinforcement Learning"
          ],
          "parameter_tuning": [
            "Policy Gradient"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Number Mapping"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2015_QuantityPairFeatures",
      "label": "Quantity-pair Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_QuantityPairFeatures",
        "entity_id": "Roy2015_QuantityPairFeatures",
        "name": "Quantity-pair Features",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_2014",
          "IL_2014",
          "CC_2014"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Quantity-pair Features"
          ],
          "connections": [
            "Context Similarity",
            "Numeric Relation"
          ],
          "mechanisms": [
            "Dependency Path",
            "Same Sentence Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Dependency Path Extraction",
          "Context Window Analysis"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2015_ContextFeatures",
      "label": "Context-related Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_ContextFeatures",
        "entity_id": "Roy2015_ContextFeatures",
        "name": "Context-related Features",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_2014",
          "IL_2014",
          "CC_2014"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Context-related Features"
          ],
          "connections": [
            "Word Lemmas",
            "POS Tags",
            "Dependence Types"
          ],
          "mechanisms": [
            "Comparative Adverbs Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Text Window Analysis",
          "POS Tagging"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2015_QuestionFeatures",
      "label": "Question-related Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_QuestionFeatures",
        "entity_id": "Roy2015_QuestionFeatures",
        "name": "Question-related Features",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_2014",
          "IL_2014",
          "CC_2014"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Question-related Features"
          ],
          "connections": [
            "Matching Tokens",
            "Rate Indicators",
            "Comparison Indicators"
          ],
          "mechanisms": [
            "Question Parsing"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Token Matching",
          "Question Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2015_VerbFeatures",
      "label": "Verb-related Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_VerbFeatures",
        "entity_id": "Roy2015_VerbFeatures",
        "name": "Verb-related Features",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_2014",
          "IL_2014",
          "CC_2014"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Verb-related Features"
          ],
          "connections": [
            "Dependent Verbs",
            "Distance Vectors"
          ],
          "mechanisms": [
            "Verb Dependency Detection"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Verb Dependency Parsing",
          "Distance Vector Calculation"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2015_GlobalFeatures",
      "label": "Global Features",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2015_GlobalFeatures",
        "entity_id": "Roy2015_GlobalFeatures",
        "name": "Global Features",
        "title": "",
        "year": "2015",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "AI2_2014",
          "IL_2014",
          "CC_2014"
        ],
        "metrics": [
          "Accuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Global Features"
          ],
          "connections": [
            "Quantity Count",
            "Unigrams",
            "Bigrams"
          ],
          "mechanisms": [
            "Sentence-Level Feature Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Feature Selection"
          ]
        },
        "feature_processing": [
          "Sentence-Level Feature Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Seo2014_GEOS",
      "label": "GEOS",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Seo2014_GEOS",
        "entity_id": "Seo2014_GEOS",
        "name": "GEOS",
        "title": "",
        "year": "2015",
        "authors": [
          "Seo, M. J.",
          "Hajishirzi, H.",
          "Farhadi, A.",
          "Etzioni, O.",
          "Malcolm, C."
        ],
        "task": "[\"Solving Geometry Problems\"]",
        "dataset": [
          "Geometry Word Problems"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Text Parsing",
            "Diagram Parsing",
            "Logical Expression Generation"
          ],
          "connections": [
            "Text-Diagram Alignment"
          ],
          "mechanisms": [
            "Primitive Detection",
            "Logical Expression Optimization"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Not Applicable"
          ],
          "parameter_tuning": [
            "Not Applicable"
          ]
        },
        "feature_processing": [
          "Logical Expression Confidence Scores"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Huang2016_SemanticParsingAndReasoning",
      "label": "Semantic Parsing and Reasoning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Huang2016_SemanticParsingAndReasoning",
        "entity_id": "Huang2016_SemanticParsingAndReasoning",
        "name": "Semantic Parsing and Reasoning",
        "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning",
        "year": "2016",
        "authors": [
          "Shuming Shi",
          "Yuehui Wang",
          "Chin-Yew Lin",
          "Xiaojiang Liu",
          "Yong Rui"
        ],
        "task": "[\"Solving Math Word Problems\"]",
        "dataset": [
          "ACE_2013"
        ],
        "metrics": [
          "F1_Score_Classification",
          "Precision_Classification"
        ],
        "architecture": {
          "components": [
            "CFG Parser",
            "Meaning Representation Language"
          ],
          "connections": [
            "Natural Language Text",
            "Math Expressions"
          ],
          "mechanisms": [
            "Semantic Parsing",
            "Reasoning"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Grammar Rules"
          ]
        },
        "feature_processing": [
          "Pattern Matching",
          "Verb Categorization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Chang2013_ConstrainedLatentVariableModel",
      "label": "Constrained Latent Variable Model (CL3M)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Chang2013_ConstrainedLatentVariableModel",
        "entity_id": "Chang2013_ConstrainedLatentVariableModel",
        "name": "Constrained Latent Variable Model (CL3M)",
        "title": "A Constrained Latent Variable Model for Coreference Resolution",
        "year": "2013",
        "authors": [
          "Kai-Wei Chang",
          "Rajhans Samdani",
          "Dan Roth"
        ],
        "task": "[\"Coreference Resolution\"]",
        "dataset": [
          "ACE",
          "Ontonotes"
        ],
        "metrics": [
          "F1 Score"
        ],
        "architecture": {
          "components": [
            "Latent Left Linking Model (L3M)",
            "Knowledge-based constraints"
          ],
          "connections": [
            "Latent structured prediction",
            "Efficient inference"
          ],
          "mechanisms": [
            "Stochastic gradient learning",
            "Constraint augmentation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Stochastic gradient descent"
          ],
          "parameter_tuning": [
            "Learning rate",
            "Regularization parameters"
          ]
        },
        "feature_processing": [
          "Pairwise mention features",
          "Higher-order interactions"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2016_UnitDependencyGraph",
      "label": "Unit Dependency Graph",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2016_UnitDependencyGraph",
        "entity_id": "Roy2016_UnitDependencyGraph",
        "name": "Unit Dependency Graph",
        "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
        "year": "2016",
        "authors": [
          "Subhro Roy",
          "Dan Roth"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "BenchmarkArithmeticWordProblems_2015"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "Unit Extraction",
            "Dependency Graph Construction"
          ],
          "connections": [
            "Unit Relationships",
            "Question Dependencies"
          ],
          "mechanisms": [
            "Global Reasoning",
            "Domain Knowledge Integration"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Structured Prediction",
            "Decomposed Model"
          ],
          "parameter_tuning": [
            "Unit Compatibility Parameters"
          ]
        },
        "feature_processing": [
          "Rate Detection",
          "Unit Matching"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_TemplateBasedSolver",
      "label": "Template-Based Math Word Problem Solver",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_TemplateBasedSolver",
        "entity_id": "Wang2018_TemplateBasedSolver",
        "name": "Template-Based Math Word Problem Solver",
        "title": "Template-Based Math Word Problem Solvers with Recursive Neural Networks",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Dongxiang Zhang",
          "Jipeng Zhang",
          "Xing Xu",
          "Lianli Gao",
          "Bing Tian Dai",
          "Heng Tao Shen"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017",
          "MAWPS_2017"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "Seq2Seq Model",
            "Recursive Neural Network",
            "Bi-LSTM",
            "Self Attention"
          ],
          "connections": [
            "Template Prediction",
            "Quantity Encoding"
          ],
          "mechanisms": [
            "Bottom-Up Inference",
            "Tree Structure Template"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Recursive Neural Network Training",
            "Template-Based Approach"
          ],
          "parameter_tuning": [
            "Template Space Reduction",
            "Equation Normalization"
          ]
        },
        "feature_processing": [
          "Quantity Embedding",
          "Operator Inference"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_EquationNormalization",
      "label": "Equation Normalization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_EquationNormalization",
        "entity_id": "Wang2016_EquationNormalization",
        "name": "Equation Normalization",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": "2016",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2017"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "SEQ2SEQ Model"
          ],
          "connections": [
            "Equation Duplication Handling",
            "Ensemble Model"
          ],
          "mechanisms": [
            "Uniqueness of Expression Tree",
            "Model Combination"
          ]
        },
        "methodology": {
          "training_strategy": [
            "SEQ2SEQ Framework",
            "Ensemble Learning"
          ],
          "parameter_tuning": [
            "Equation Normalization Parameters"
          ]
        },
        "feature_processing": [
          "Equation Duplication Handling",
          "Model Ensemble Techniques"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "DNS2014_DeepLearningModel",
      "label": "Deep Learning Model",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "DNS2014_DeepLearningModel",
        "entity_id": "DNS2014_DeepLearningModel",
        "name": "Deep Learning Model",
        "title": "",
        "year": "2014",
        "authors": [
          "D. Huang",
          "S. Shi",
          "C. Lin",
          "J. Yin",
          "W. Ma"
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Dolphin18K",
          "Math23K"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Neural Networks",
            "Sequence-to-Sequence Models"
          ],
          "connections": [
            "Encoder-Decoder"
          ],
          "mechanisms": [
            "Attention Mechanism",
            "Recurrent Neural Networks"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-End Training"
          ],
          "parameter_tuning": [
            "Hyperparameter Optimization"
          ]
        },
        "feature_processing": [
          "Word Embedding",
          "Syntactic Parsing"
        ],
        "entity_type": "Algorithm",
        "source": "综述"
      }
    },
    {
      "id": "Roy2016_ExpressionTree",
      "label": "Expression Tree",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2016_ExpressionTree",
        "entity_id": "Roy2016_ExpressionTree",
        "name": "Expression Tree",
        "title": "Solving General Arithmetic Word Problems",
        "year": "2016",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "StandardPrimarySchoolTestQuestions_2015"
        ],
        "metrics": [
          "ProblemSolvingAccuracy_Arithmetic"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Constrained Inference Framework"
          ],
          "connections": [
            "Decomposition of Arithmetic Expressions",
            "Combination of World Knowledge"
          ],
          "mechanisms": [
            "Classification Problems",
            "Quantity Schemas"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Decomposition of Target Arithmetic Problem"
          ],
          "parameter_tuning": [
            "Not specified"
          ]
        },
        "feature_processing": [
          "Quantity Extraction",
          "Feature Extraction from Quantity Schemas"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2018_DeepReinforcementLearning",
      "label": "Deep Reinforcement Learning",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2018_DeepReinforcementLearning",
        "entity_id": "Wang2018_DeepReinforcementLearning",
        "name": "Deep Reinforcement Learning",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": "2018",
        "authors": [
          "Lei Wang",
          "Yan Wang",
          "Deng Cai",
          "Dongxiang Zhang",
          "Xiaojiang Liu"
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "Math23K_2018"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "Deep Neural Networks",
            "Recurrent Encoder-Decoder",
            "Convolutional SEQ2SEQ",
            "Transformer"
          ],
          "connections": [
            "Sequence-to-Sequence Mapping",
            "Expression Tree Construction"
          ],
          "mechanisms": [
            "Recursive Neural Network",
            "Bi-LSTM",
            "Self Attention"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Deep Reinforcement Learning"
          ],
          "parameter_tuning": [
            "No Hand-crafted Features"
          ]
        },
        "feature_processing": [
          "Number Mapping",
          "Equation Normalization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_QuantitySchema",
      "label": "Quantity Schema",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_QuantitySchema",
        "entity_id": "Roy2017_QuantitySchema",
        "name": "Quantity Schema",
        "title": "Solving General Arithmetic Word Problems",
        "year": "2017",
        "authors": [
          "Roy, S.",
          "Roth, D."
        ],
        "task": "[\"Arithmetic Word Problem Solving\"]",
        "dataset": [
          "BenchmarkArithmeticWordProblems_2016"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "Expression Tree",
            "Constrained Inference Framework"
          ],
          "connections": [
            "Decomposition of Arithmetic Problem",
            "Combination with World Knowledge"
          ],
          "mechanisms": [
            "Classification Problems",
            "Feature Extraction"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameters for Classifiers"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2019_EquationNormalization",
      "label": "Equation Normalization",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2019_EquationNormalization",
        "entity_id": "Wang2019_EquationNormalization",
        "name": "Equation Normalization",
        "title": "Translating a Math Word Problem to an Expression Tree",
        "year": "2019",
        "authors": [
          "Wang, L.",
          "Wang, Y.",
          "Cai, D.",
          "Zhang, D.",
          "Liu, X."
        ],
        "task": "[\"Math Word Problem Solving\"]",
        "dataset": [
          "Math23K_2018"
        ],
        "metrics": [
          "Accuracy_ArithmeticWordProblems"
        ],
        "architecture": {
          "components": [
            "SEQ2SEQ Model",
            "Expression Tree"
          ],
          "connections": [
            "Equation Duplication Handling",
            "Ensemble Model"
          ],
          "mechanisms": [
            "Suffix Expression",
            "Operator Encapsulation"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Supervised Learning"
          ],
          "parameter_tuning": [
            "Hyperparameters for SEQ2SEQ"
          ]
        },
        "feature_processing": [
          "Equation Normalization"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Roy2017_VisualQuestionAnswering",
      "label": "Visual Question Answering (VQA)",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Roy2017_VisualQuestionAnswering",
        "entity_id": "Roy2017_VisualQuestionAnswering",
        "name": "Visual Question Answering (VQA)",
        "title": "VQA: Visual Question Answering",
        "year": "2017",
        "authors": [
          "Stanislaw Antol",
          "Aishwarya Agrawal",
          "Jiasen Lu",
          "Margaret Mitchell",
          "Dhruv Batra",
          "C. Lawrence Zitnick",
          "Devi Parikh"
        ],
        "task": "[\"Visual Question Answering\"]",
        "dataset": [
          "MS COCO_2014",
          "Abstract Scene Dataset_2017"
        ],
        "metrics": [
          "Accuracy_VQA",
          "MultipleChoiceAccuracy_VQA"
        ],
        "architecture": {
          "components": [
            "CNN",
            "LSTM",
            "Attention Mechanism"
          ],
          "connections": [
            "Image Feature Extraction",
            "Question Encoding",
            "Answer Generation"
          ],
          "mechanisms": [
            "Attention",
            "Multi-modal Fusion"
          ]
        },
        "methodology": {
          "training_strategy": [
            "End-to-end Training",
            "Transfer Learning"
          ],
          "parameter_tuning": [
            "Learning Rate",
            "Batch Size",
            "Dropout Rate"
          ]
        },
        "feature_processing": [
          "Image Preprocessing",
          "Question Tokenization",
          "Answer Post-processing"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Wang2016_KnowledgePoweredWordEmbedding",
      "label": "Knowledge-Powered Word Embedding",
      "type": "Algorithm",
      "entity_type": "Algorithm",
      "data": {
        "algorithm_id": "Wang2016_KnowledgePoweredWordEmbedding",
        "entity_id": "Wang2016_KnowledgePoweredWordEmbedding",
        "name": "Knowledge-Powered Word Embedding",
        "title": "Solving Verbal Questions in IQ Test by Knowledge-Powered Word Embedding",
        "year": "2016",
        "authors": [
          "Huazheng Wang",
          "Fei Tian",
          "Bin Gao",
          "Chengjieren Zhu",
          "Jiang Bian",
          "Tie-Yan Liu"
        ],
        "task": "[\"Verbal Comprehension in IQ Tests\"]",
        "dataset": [
          "Verbal IQ Test Questions"
        ],
        "metrics": [
          "Accuracy"
        ],
        "architecture": {
          "components": [
            "Improved Word Embedding",
            "Multi-sense Nature of Words",
            "Relational Information"
          ],
          "connections": [
            "Word-Sense Representations",
            "Relation Representations"
          ],
          "mechanisms": [
            "Classifier for Question Type",
            "Distributed Representations of Words and Relations"
          ]
        },
        "methodology": {
          "training_strategy": [
            "Jointly Considering Multi-sense Nature and Relational Knowledge"
          ],
          "parameter_tuning": [
            "Not Specified"
          ]
        },
        "feature_processing": [
          "Quantity Schema Extraction"
        ],
        "entity_type": "Algorithm",
        "source": "引文"
      }
    },
    {
      "id": "Abstract_Scenes_2015",
      "label": "Abstract Scenes",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Abstract_Scenes_2015",
        "name": "Abstract Scenes",
        "description": "Dataset of abstract scenes for VQA",
        "domain": "Computer Vision",
        "size": 50000,
        "year": "2015",
        "creators": "[\"Stanislaw Antol\", \"Aishwarya Agrawal\", \"Jiasen Lu\", \"Margaret Mitchell\", \"Dhruv Batra\", \"C. Lawrence Zitnick\", \"Devi Parikh\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Abstract_Scenes_2015"
      }
    },
    {
      "id": "ACE_2004",
      "label": "ACE 2004",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE_2004",
        "name": "ACE 2004",
        "description": "Automatic Content Extraction 2004 dataset",
        "domain": "Natural Language Processing",
        "size": 443,
        "year": "2004",
        "creators": "[\"NIST\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "ACE_2004"
      }
    },
    {
      "id": "ACE_2004_GoldMentions",
      "label": "ACE 2004 Gold Mentions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE_2004_GoldMentions",
        "name": "ACE 2004 Gold Mentions",
        "description": "Gold mentions from ACE 2004 dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2004",
        "creators": "[\"NIST\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ACE_2004_GoldMentions"
      }
    },
    {
      "id": "ACE_2004_GoldMentions_2004",
      "label": "ACE 2004 Gold Mentions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE_2004_GoldMentions_2004",
        "name": "ACE 2004 Gold Mentions",
        "description": "Contains 443 documents used for coreference resolution.",
        "domain": "Natural Language Processing",
        "size": 443,
        "year": "2004",
        "creators": "[\"NIST\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "ACE_2004_GoldMentions_2004"
      }
    },
    {
      "id": "ACE_2013",
      "label": "ACE",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE_2013",
        "name": "ACE",
        "description": "A dataset for Automatic Content Extraction tasks",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2013",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "引文",
        "entity_id": "ACE_2013"
      }
    },
    {
      "id": "ACE2004",
      "label": "ACE 2004",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004",
        "name": "ACE 2004",
        "description": "A dataset for coreference resolution containing 443 documents.",
        "domain": "Natural Language Processing",
        "size": 443,
        "year": "2004",
        "creators": "[\"NIST\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "ACE2004"
      }
    },
    {
      "id": "ACE2004_2004",
      "label": "ACE2004",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004_2004",
        "name": "ACE2004",
        "description": "Automatic Content Extraction 2004 corpus used for coreference resolution.",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2004",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ACE2004_2004"
      }
    },
    {
      "id": "ACE2004_NWIRE_2004",
      "label": "ACE 2004 Newswire",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004_NWIRE_2004",
        "name": "ACE 2004 Newswire",
        "description": "Newswire subset of the ACE 2004 corpus",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": "2004",
        "creators": "[\"NIST\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ACE2004_NWIRE_2004"
      }
    },
    {
      "id": "ACE2004_NWIRE_NEL_2004",
      "label": "ACE2004-NWIRE-NEL",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004_NWIRE_NEL_2004",
        "name": "ACE2004-NWIRE-NEL",
        "description": "A subset of ACE 2004 newswire data annotated with gold-standard entity links.",
        "domain": "Natural Language Processing",
        "size": 12,
        "year": "2004",
        "creators": "[\"NIST\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ACE2004_NWIRE_NEL_2004"
      }
    },
    {
      "id": "ACE2004_NWIRE_NEL_Gold_2004",
      "label": "ACE2004-NWIRE-NEL (Gold)",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004_NWIRE_NEL_Gold_2004",
        "name": "ACE2004-NWIRE-NEL (Gold)",
        "description": "A subset of ACE 2004 newswire data with gold-standard entity links.",
        "domain": "Natural Language Processing",
        "size": 12,
        "year": "2004",
        "creators": "[\"NIST\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ACE2004_NWIRE_NEL_Gold_2004"
      }
    },
    {
      "id": "ACE2004-CULOTTA-TEST_2004",
      "label": "ACE2004-CULOTTA-TEST",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004-CULOTTA-TEST_2004",
        "name": "ACE2004-CULOTTA-TEST",
        "description": "Partition of ACE 2004 corpus reserved for testing",
        "domain": "Natural Language Processing",
        "size": 107,
        "year": "2004",
        "creators": "[\"Culotta et al.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "ACE2004-CULOTTA-TEST_2004"
      }
    },
    {
      "id": "ACE2004-CULOTTA-TEST_2009",
      "label": "ACE2004-CULOTTA-TEST",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004-CULOTTA-TEST_2009",
        "name": "ACE2004-CULOTTA-TEST",
        "description": "Test set split of the ACE 2004 training set",
        "domain": "Natural Language Processing",
        "size": 107,
        "year": "2009",
        "creators": "[\"Culotta et al.\", \"Bengston and Roth\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ACE2004-CULOTTA-TEST_2009"
      }
    },
    {
      "id": "ACE2004-NWIRE_2004",
      "label": "ACE2004-NWIRE",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004-NWIRE_2004",
        "name": "ACE2004-NWIRE",
        "description": "Newswire subset of the ACE 2004 corpus",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": "2004",
        "creators": "[\"Poon and Domingos\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "ACE2004-NWIRE_2004"
      }
    },
    {
      "id": "ACE2004-NWIRE_2009",
      "label": "ACE2004-NWIRE",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004-NWIRE_2009",
        "name": "ACE2004-NWIRE",
        "description": "ACE 2004 Newswire set",
        "domain": "Natural Language Processing",
        "size": 128,
        "year": "2009",
        "creators": "[\"Poon and Domingos\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ACE2004-NWIRE_2009"
      }
    },
    {
      "id": "ACE2004-ROTH-DEV_2004",
      "label": "ACE2004-ROTH-DEV",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004-ROTH-DEV_2004",
        "name": "ACE2004-ROTH-DEV",
        "description": "Development split of Bengston and Roth (2008)",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": "2004",
        "creators": "[\"Bengston and Roth\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "ACE2004-ROTH-DEV_2004"
      }
    },
    {
      "id": "ACE2004-ROTH-DEV_2009",
      "label": "ACE2004-ROTH-DEV",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004-ROTH-DEV_2009",
        "name": "ACE2004-ROTH-DEV",
        "description": "Development set split of the ACE 2004 training set",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": "2009",
        "creators": "[\"Bengston and Roth\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ACE2004-ROTH-DEV_2009"
      }
    },
    {
      "id": "ACE2004-ROTH-DEV2_2004",
      "label": "ACE2004-ROTH-DEV2",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ACE2004-ROTH-DEV2_2004",
        "name": "ACE2004-ROTH-DEV2",
        "description": "Development split of Bengston and Roth(2008) from the 2004 Automatic Content Extraction (ACE) evaluation",
        "domain": "Natural Language Processing",
        "size": 68,
        "year": "2004",
        "creators": "[\"Bengston and Roth\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ACE2004-ROTH-DEV2_2004"
      }
    },
    {
      "id": "AddingProblem_1997",
      "label": "Adding Problem",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AddingProblem_1997",
        "name": "Adding Problem",
        "description": "A dataset for evaluating models on summing specific elements in a sequence",
        "domain": "Sequence prediction",
        "size": 0,
        "year": "1997",
        "creators": "[\"Hochreiter, S.\", \"Schmidhuber, J.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "AddingProblem_1997"
      }
    },
    {
      "id": "ADDSUB_2014",
      "label": "ADDSUB",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ADDSUB_2014",
        "name": "ADDSUB",
        "description": "Contains addition and subtraction word problems",
        "domain": "Mathematics",
        "size": 395,
        "year": "2014",
        "creators": "[\"Mohammad Javad Hosseini\", \"Hannaneh Hajishirzi\", \"Oren Etzioni\", \"Nate Kushman\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "ADDSUB_2014"
      }
    },
    {
      "id": "AddSub_2014",
      "label": "ADDSUB",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AddSub_2014",
        "name": "ADDSUB",
        "description": "Addition and subtraction word problems with irrelevant distractor quantities",
        "domain": "Elementary Mathematics",
        "size": 0,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "AddSub_2014"
      }
    },
    {
      "id": "AerialImages_2004",
      "label": "Aerial Images",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AerialImages_2004",
        "name": "Aerial Images",
        "description": "Aerial imagery used for detecting rectangular structures such as buildings and vehicles.",
        "domain": "Remote Sensing",
        "size": 0,
        "year": "2004",
        "creators": "[\"Various sources\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "AerialImages_2004"
      }
    },
    {
      "id": "AerialUrbanImages_2002",
      "label": "Aerial Urban Images",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AerialUrbanImages_2002",
        "name": "Aerial Urban Images",
        "description": "Aerial images of urban areas used for building detection",
        "domain": "Remote Sensing",
        "size": 0,
        "year": "2002",
        "creators": "[\"W.-B. Tao\", \"J.-W. Tian\", \"J. Liu\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "AerialUrbanImages_2002"
      }
    },
    {
      "id": "Age_Dataset_2017",
      "label": "Age Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Age_Dataset_2017",
        "name": "Age Dataset",
        "description": "Twitter tweets in English, Spanish, and Dutch with age and gender information",
        "domain": "Natural Language Processing",
        "size": 68485,
        "year": "2017",
        "creators": "[\"IBM Watson\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Age_Dataset_2017"
      }
    },
    {
      "id": "Aggregate_2018",
      "label": "Aggregate",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Aggregate_2018",
        "name": "Aggregate",
        "description": "Combined dataset of AllArith and Perturb",
        "domain": "Natural Language Processing",
        "size": 1492,
        "year": "2018",
        "creators": "[\"Roy, S.\", \"Roth, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Aggregate_2018"
      }
    },
    {
      "id": "AI2_2014",
      "label": "AI2",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AI2_2014",
        "name": "AI2",
        "description": "Arithmetic word problems for third, fourth, and fifth graders",
        "domain": "Mathematics",
        "size": 395,
        "year": "2014",
        "creators": "[\"M. J. Hosseini\", \"H. Hajishirzi\", \"O. Etzioni\", \"N. Kushman\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "AI2_2014"
      }
    },
    {
      "id": "AI2_2015",
      "label": "AI2",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AI2_2015",
        "name": "AI2",
        "description": "Dataset for arithmetic word problems",
        "domain": "Mathematical word problems",
        "size": 395,
        "year": "2015",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "综述",
        "entity_id": "AI2_2015"
      }
    },
    {
      "id": "AI2_Dataset_2014",
      "label": "AI2 Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AI2_Dataset_2014",
        "name": "AI2 Dataset",
        "description": "A collection of 395 addition and subtraction problems",
        "domain": "Arithmetic Word Problems",
        "size": 395,
        "year": "2014",
        "creators": "[\"M. J. Hosseini\", \"H. Hajishirzi\", \"O. Etzioni\", \"N. Kushman\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "AI2_Dataset_2014"
      }
    },
    {
      "id": "ALG514_2014",
      "label": "ALG514",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ALG514_2014",
        "name": "ALG514",
        "description": "Crowd-sourced tutoring website dataset for algebra problems",
        "domain": "Mathematical Word Problems",
        "size": 514,
        "year": "2014",
        "creators": "[\"Kushman, N.\", \"Zettlemoyer, L.\", \"Barzilay, R.\", \"Artzi, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "ALG514_2014"
      }
    },
    {
      "id": "Alg514_2014",
      "label": "Alg514",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Alg514_2014",
        "name": "Alg514",
        "description": "包含514个代数文字题的数据集",
        "domain": "数学教育",
        "size": 514,
        "year": "2014",
        "creators": "[\"Kushman, N.\", \"Artzi, Y.\", \"Zettlemoyer, L.\", \"Barzilay, R.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Alg514_2014"
      }
    },
    {
      "id": "Algebra_com_2015",
      "label": "Algebra.com",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Algebra_com_2015",
        "name": "Algebra.com",
        "description": "Website for users to post math problems and get help from tutors",
        "domain": "Mathematics",
        "size": 0,
        "year": "2015",
        "creators": "[\"Algebra.com\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Algebra_com_2015"
      }
    },
    {
      "id": "Algebra_com_Dataset_2014",
      "label": "Algebra.com数据集",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Algebra_com_Dataset_2014",
        "name": "Algebra.com数据集",
        "description": "从Algebra.com收集的代数文字题数据集",
        "domain": "数学问题",
        "size": 514,
        "year": "2014",
        "creators": "[\"Nate Kushman\", \"Yoav Artzi\", \"Luke Zettlemoyer\", \"Regina Barzilay\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Algebra_com_Dataset_2014"
      }
    },
    {
      "id": "Algebra.com_2014",
      "label": "Algebra.com",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Algebra.com_2014",
        "name": "Algebra.com",
        "description": "A crowdsourced tutoring website dataset of algebra word problems",
        "domain": "Mathematics",
        "size": 514,
        "year": "2014",
        "creators": "[\"Nate Kushman\", \"Yoav Artzi\", \"Luke Zettlemoyer\", \"Regina Barzilay\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Algebra.com_2014"
      }
    },
    {
      "id": "Algebra.com_2015",
      "label": "Algebra.com",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Algebra.com_2015",
        "name": "Algebra.com",
        "description": "一个用户发布数学问题并获得导师帮助的网站",
        "domain": "数学教育",
        "size": 1878,
        "year": "2015",
        "creators": "[\"Various Contributors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Algebra.com_2015"
      }
    },
    {
      "id": "Algebra.com_Dataset_2014",
      "label": "Algebra.com Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Algebra.com_Dataset_2014",
        "name": "Algebra.com Dataset",
        "description": "A dataset of algebra word problems collected from Algebra.com",
        "domain": "Natural Language Processing, Algebra",
        "size": 514,
        "year": "2014",
        "creators": "[\"Nate Kushman\", \"Yoav Artzi\", \"Luke Zettlemoyer\", \"Regina Barzilay\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "Algebra.com_Dataset_2014"
      }
    },
    {
      "id": "AlgebraCom_Dataset_2014",
      "label": "Algebra.com Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AlgebraCom_Dataset_2014",
        "name": "Algebra.com Dataset",
        "description": "Crowdsourced tutoring website dataset for algebra word problems",
        "domain": "Natural Language Processing",
        "size": 514,
        "year": "2014",
        "creators": "[\"Nate Kushman\", \"Yoav Artzi\", \"Luke Zettlemoyer\", \"Regina Barzilay\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "AlgebraCom_Dataset_2014"
      }
    },
    {
      "id": "AlgebraWordProblems_2014",
      "label": "Algebra Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AlgebraWordProblems_2014",
        "name": "Algebra Word Problems",
        "description": "A dataset of algebra word problems collected from Algebra.com",
        "domain": "Mathematics",
        "size": 514,
        "year": "2014",
        "creators": "[\"Nate Kushman\", \"Yoav Artzi\", \"Luke Zettlemoyer\", \"Regina Barzilay\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "AlgebraWordProblems_2014"
      }
    },
    {
      "id": "AllArith_2016",
      "label": "AllArith",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AllArith_2016",
        "name": "AllArith",
        "description": "混合了多个来源的算术问题数据集",
        "domain": "数学问题求解",
        "size": 831,
        "year": "2016",
        "creators": "[\"未提供\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "AllArith_2016"
      }
    },
    {
      "id": "AllArith_2017",
      "label": "AllArith",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AllArith_2017",
        "name": "AllArith",
        "description": "A dataset of arithmetic word problems",
        "domain": "Mathematics",
        "size": 831,
        "year": "2017",
        "creators": "[\"Roy, S.\", \"Roth, D.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "AllArith_2017"
      }
    },
    {
      "id": "AllArith_2018",
      "label": "AllArith",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AllArith_2018",
        "name": "AllArith",
        "description": "Arithmetic word problem dataset",
        "domain": "Mathematics",
        "size": 831,
        "year": "2018",
        "creators": "[\"Subhro Roy\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "AllArith_2018"
      }
    },
    {
      "id": "AllArithLex_2017",
      "label": "AllArithLex",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AllArithLex_2017",
        "name": "AllArithLex",
        "description": "AllArith数据集的子集，具有低词汇重叠。",
        "domain": "算术文字题求解",
        "size": 415,
        "year": "2017",
        "creators": "[\"Subhro Roy\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "AllArithLex_2017"
      }
    },
    {
      "id": "AllArithLex_2018",
      "label": "AllArithLex",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AllArithLex_2018",
        "name": "AllArithLex",
        "description": "Subset of AllArith for testing robustness to new vocabulary",
        "domain": "Mathematics",
        "size": 831,
        "year": "2018",
        "creators": "[\"Subhro Roy\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "AllArithLex_2018"
      }
    },
    {
      "id": "AllArithTmpl_2017",
      "label": "AllArithTmpl",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AllArithTmpl_2017",
        "name": "AllArithTmpl",
        "description": "AllArith数据集的子集，具有低模板重叠。",
        "domain": "算术文字题求解",
        "size": 415,
        "year": "2017",
        "creators": "[\"Subhro Roy\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "AllArithTmpl_2017"
      }
    },
    {
      "id": "AllArithTmpl_2018",
      "label": "AllArithTmpl",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AllArithTmpl_2018",
        "name": "AllArithTmpl",
        "description": "Subset of AllArith for testing robustness to new equation forms",
        "domain": "Mathematics",
        "size": 831,
        "year": "2018",
        "creators": "[\"Subhro Roy\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "AllArithTmpl_2018"
      }
    },
    {
      "id": "AlpinoDependencyTreebank_2002",
      "label": "Alpino Dependency Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AlpinoDependencyTreebank_2002",
        "name": "Alpino Dependency Treebank",
        "description": "Dutch dependency treebank",
        "domain": "Computational Linguistics",
        "size": 0,
        "year": "2002",
        "creators": "[\"Leonoor van der Beek\", \"Gosse Bouma\", \"Robert Malouf\", \"Gertjan van Noord\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "AlpinoDependencyTreebank_2002"
      }
    },
    {
      "id": "AmazonMechanicalTurkWorkers_2016",
      "label": "Amazon Mechanical Turk Workers",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AmazonMechanicalTurkWorkers_2016",
        "name": "Amazon Mechanical Turk Workers",
        "description": "Crowdsourced human responses to IQ test questions",
        "domain": "Human Intelligence",
        "size": 0,
        "year": "2016",
        "creators": "[\"Wang, H.\", \"Tian, F.\", \"Gao, B.\", \"Zhu, C.\", \"Bian, J.\", \"Liu, T.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "AmazonMechanicalTurkWorkers_2016"
      }
    },
    {
      "id": "AQuA_2017",
      "label": "AQuA",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AQuA_2017",
        "name": "AQuA",
        "description": "Contains 100,000 math word problems with rationales",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2017",
        "creators": "[]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "AQuA_2017"
      }
    },
    {
      "id": "ARIS_Dataset_2014",
      "label": "ARIS Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ARIS_Dataset_2014",
        "name": "ARIS Dataset",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ARIS_Dataset_2014"
      }
    },
    {
      "id": "ArithM_2018",
      "label": "ArithM",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ArithM_2018",
        "name": "ArithM",
        "description": "Collected from AI2, IL, and CC containing multi-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 667,
        "year": "2018",
        "creators": "[\"Lei Wang\", \"Dongxiang Zhang\", \"Lianli Gao\", \"Jingkuan Song\", \"Long Guo\", \"Heng Tao Shen\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ArithM_2018"
      }
    },
    {
      "id": "ArithmeticWordProblems_2014",
      "label": "Arithmetic Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ArithmeticWordProblems_2014",
        "name": "Arithmetic Word Problems",
        "description": "A corpus of arithmetic word problems focusing on addition and subtraction.",
        "domain": "Natural Language Processing",
        "size": 395,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ArithmeticWordProblems_2014"
      }
    },
    {
      "id": "ArithmeticWordProblems_2015",
      "label": "Arithmetic Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ArithmeticWordProblems_2015",
        "name": "Arithmetic Word Problems",
        "description": "A dataset of arithmetic word problems",
        "domain": "Arithmetic",
        "size": 1000,
        "year": "2015",
        "creators": "[\"Roy, S.\", \"Roth, D.\"]",
        "entity_type": "Dataset",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "entity_id": "ArithmeticWordProblems_2015"
      }
    },
    {
      "id": "ArithS_2018",
      "label": "ArithS",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ArithS_2018",
        "name": "ArithS",
        "description": "Subset of AI2, IL, and CC containing single-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 890,
        "year": "2018",
        "creators": "[\"Lei Wang\", \"Dongxiang Zhang\", \"Lianli Gao\", \"Jingkuan Song\", \"Long Guo\", \"Heng Tao Shen\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ArithS_2018"
      }
    },
    {
      "id": "Baseline_SMT_System_2014",
      "label": "Baseline SMT System",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Baseline_SMT_System_2014",
        "name": "Baseline SMT System",
        "description": "A phrase-based statistical machine translation system used as a baseline for comparison.",
        "domain": "Machine Translation",
        "size": 0,
        "year": "2014",
        "creators": "[\"Schwenk, H.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Baseline_SMT_System_2014"
      }
    },
    {
      "id": "BidirectionalLSTM_Dataset_2018",
      "label": "Bidirectional LSTM Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "BidirectionalLSTM_Dataset_2018",
        "name": "Bidirectional LSTM Dataset",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2018",
        "creators": "[\"Robaidek, B.\", \"Koncel-Kedziorski, R.\", \"Hajishirzi, H.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "BidirectionalLSTM_Dataset_2018"
      }
    },
    {
      "id": "BLIPP_2009",
      "label": "BLIPP",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "BLIPP_2009",
        "name": "BLIPP",
        "description": "1.8 million sentences of newswire parsed with the Charniak parser",
        "domain": "Natural Language Processing",
        "size": 1800000,
        "year": "2009",
        "creators": "[]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "BLIPP_2009"
      }
    },
    {
      "id": "BoxImage_1972",
      "label": "Box Image",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "BoxImage_1972",
        "name": "Box Image",
        "description": "Digitized version of a television monitor view of a box",
        "domain": "Computer Vision",
        "size": 0,
        "year": "1972",
        "creators": "[\"Duda, R.O.\", \"Hart, P.E.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "BoxImage_1972"
      }
    },
    {
      "id": "BrownCorpus_1964",
      "label": "Brown Corpus",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "BrownCorpus_1964",
        "name": "Brown Corpus",
        "description": "A standard corpus of present-day edited American English",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "1964",
        "creators": "[\"Henry Kučera\", \"W. Nelson Francis\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "BrownCorpus_1964"
      }
    },
    {
      "id": "Caltech101_2004",
      "label": "Caltech101",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Caltech101_2004",
        "name": "Caltech101",
        "description": "一个包含101个类别的图像数据集，每个类别大约有40到800张图像。",
        "domain": "计算机视觉",
        "size": 9146,
        "year": "2004",
        "creators": "[\"Fei-Fei, L.\", \"Fergus, R.\", \"Perona, P.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Caltech101_2004"
      }
    },
    {
      "id": "Caltech256_2007",
      "label": "Caltech256",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Caltech256_2007",
        "name": "Caltech256",
        "description": "一个包含256个类别的图像数据集，每个类别大约有80张图像。",
        "domain": "计算机视觉",
        "size": 30607,
        "year": "2007",
        "creators": "[\"Griffin, G.\", \"Holub, A.\", \"Perona, P.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Caltech256_2007"
      }
    },
    {
      "id": "Carroll1999_GrevalTestSuite",
      "label": "Greval Test Suite",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Carroll1999_GrevalTestSuite",
        "name": "Greval Test Suite",
        "description": "A test suite for evaluating parser performance",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "1999",
        "creators": "[]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Carroll1999_GrevalTestSuite"
      }
    },
    {
      "id": "CC_2014",
      "label": "CC",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CC_2014",
        "name": "CC",
        "description": "Multi-step math problems without irrelevant quantities",
        "domain": "Mathematics",
        "size": 600,
        "year": "2014",
        "creators": "[\"S. Roy\", \"D. Roth\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "CC_2014"
      }
    },
    {
      "id": "CC_2015",
      "label": "CC",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CC_2015",
        "name": "CC",
        "description": "Multi-step problems without irrelevant quantities, harvested from commoncoresheets",
        "domain": "Arithmetic word problems",
        "size": 600,
        "year": "2015",
        "creators": "[\"Roy and Roth\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "CC_2015"
      }
    },
    {
      "id": "Chinese_Penn_Treebank_2014",
      "label": "Chinese Penn Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Chinese_Penn_Treebank_2014",
        "name": "Chinese Penn Treebank",
        "description": "Standard dataset for dependency parsing",
        "domain": "Natural Language Processing",
        "size": 16091,
        "year": "2014",
        "creators": "[\"Stanford University\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Chinese_Penn_Treebank_2014"
      }
    },
    {
      "id": "ChineseElementarySchoolTextbooks_2010",
      "label": "Chinese Elementary School Textbooks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ChineseElementarySchoolTextbooks_2010",
        "name": "Chinese Elementary School Textbooks",
        "description": "Word problems gathered from four publishers in Chinese (one book from People’s Education Press, one book from Beijing Normal University Press, and two books from DONGBEI Normal University Press)",
        "domain": "Mathematics Education",
        "size": 0,
        "year": "2010",
        "creators": "[\"Various Publishers\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ChineseElementarySchoolTextbooks_2010"
      }
    },
    {
      "id": "ChineseElementarySchoolWordProblems_2010",
      "label": "Chinese Elementary School Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ChineseElementarySchoolWordProblems_2010",
        "name": "Chinese Elementary School Word Problems",
        "description": "Word problems collected from Chinese elementary school textbooks",
        "domain": "Education",
        "size": 0,
        "year": "2010",
        "creators": "[\"People’s Education Press\", \"Beijing Normal University Press\", \"DONGBEI Normal University Press\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "ChineseElementarySchoolWordProblems_2010"
      }
    },
    {
      "id": "ChineseTextbooks_2010",
      "label": "Chinese Textbooks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ChineseTextbooks_2010",
        "name": "Chinese Textbooks",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2010",
        "creators": "[\"People’s Education Press\", \"Beijing Normal University Press\", \"DONGBEI Normal University Press\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ChineseTextbooks_2010"
      }
    },
    {
      "id": "COADiagrams_Military",
      "label": "COA Diagrams",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "COADiagrams_Military",
        "name": "COA Diagrams",
        "description": "Set of Course of Action diagrams used by the military for tasks such as troop movement planning",
        "domain": "Military Planning",
        "size": 0,
        "year": "1999",
        "creators": "[\"Ferguson, R. W.\", \"Forbus, K. D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "COADiagrams_Military"
      }
    },
    {
      "id": "COCO_2014",
      "label": "COCO",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "COCO_2014",
        "name": "COCO",
        "description": "Common Objects in Context",
        "domain": "计算机视觉",
        "size": 204000,
        "year": "2014",
        "creators": "[\"Lin, T.-Y.\", \"Maire, M.\", \"Belongie, S.\", \"Hays, J.\", \"Perona, P.\", \"Ramanan, D.\", \"Dolla´r, P.\", \"Zitnick, C. L.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "COCO_2014"
      }
    },
    {
      "id": "CollegeLevelPhysicsTextbooks_1988",
      "label": "College-Level Physics Textbooks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CollegeLevelPhysicsTextbooks_1988",
        "name": "College-Level Physics Textbooks",
        "description": "Collections of ready-made test cases in the form of college-level textbooks",
        "domain": "Physics Education",
        "size": 0,
        "year": "1988",
        "creators": "[\"Various Authors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CollegeLevelPhysicsTextbooks_1988"
      }
    },
    {
      "id": "Combined_Dataset_2014",
      "label": "Combined Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Combined_Dataset_2014",
        "name": "Combined Dataset",
        "description": "A combined dataset of arithmetic word problems from MA1, IXL, and MA2",
        "domain": "Natural Language Processing",
        "size": 395,
        "year": "2014",
        "creators": "[\"Mohammad Javad Hosseini\", \"Hannaneh Hajishirzi\", \"Oren Etzioni\", \"Nate Kushman\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Combined_Dataset_2014"
      }
    },
    {
      "id": "Commoncore_2016",
      "label": "Commoncore",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Commoncore_2016",
        "name": "Commoncore",
        "description": "A dataset of multi-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 600,
        "year": "2016",
        "creators": "[\"Subhro Roy\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Commoncore_2016"
      }
    },
    {
      "id": "Commoncore_Dataset_2016",
      "label": "Commoncore Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Commoncore_Dataset_2016",
        "name": "Commoncore Dataset",
        "description": "A new dataset of multi-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 600,
        "year": "2016",
        "creators": "[\"Subhro Roy\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Commoncore_Dataset_2016"
      }
    },
    {
      "id": "CoNLL_2006_Shared_Task",
      "label": "CoNLL 2006 Shared Task",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL_2006_Shared_Task",
        "name": "CoNLL 2006 Shared Task",
        "description": "Multilingual dependency parsing dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2006",
        "creators": "[\"CoNLL organizers\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CoNLL_2006_Shared_Task"
      }
    },
    {
      "id": "CoNLL_2007_English_dataset_2007",
      "label": "CoNLL 2007 English dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL_2007_English_dataset_2007",
        "name": "CoNLL 2007 English dataset",
        "description": "Dataset for dependency parsing derived from WSJ Treebank",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2007",
        "creators": "[\"CoNLL Shared Task\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "CoNLL_2007_English_dataset_2007"
      }
    },
    {
      "id": "CoNLL_2007_English_dataset_2010",
      "label": "CoNLL 2007 English dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL_2007_English_dataset_2010",
        "name": "CoNLL 2007 English dataset",
        "description": "English dataset from the CoNLL 2007 shared task",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2010",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "CoNLL_2007_English_dataset_2010"
      }
    },
    {
      "id": "CoNLL_2007_English_test_set_2010",
      "label": "CoNLL 2007 English test set",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL_2007_English_test_set_2010",
        "name": "CoNLL 2007 English test set",
        "description": "English dataset from the CoNLL 2007 shared task",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2010",
        "creators": "[\"CoNLL 2007 shared task organizers\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CoNLL_2007_English_test_set_2010"
      }
    },
    {
      "id": "CoNLL_2008",
      "label": "CoNLL",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL_2008",
        "name": "CoNLL",
        "description": "Conference on Computational Natural Language Learning dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2008",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CoNLL_2008"
      }
    },
    {
      "id": "CoNLL_2012",
      "label": "CoNLL",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL_2012",
        "name": "CoNLL",
        "description": "A dataset for coreference resolution and dependency parsing",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2012",
        "creators": "[\"Pradhan, S.\", \"Moschitti, A.\", \"Xue, N.\", \"Uryupina, O.\", \"Zhang, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "CoNLL_2012"
      }
    },
    {
      "id": "CoNLL_Dependencies_2014",
      "label": "CoNLL Syntactic Dependencies",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL_Dependencies_2014",
        "name": "CoNLL Syntactic Dependencies",
        "description": "A dataset for syntactic dependencies derived from the Penn Treebank.",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Johansson, R.\", \"Nugues, P.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CoNLL_Dependencies_2014"
      }
    },
    {
      "id": "CoNLL_SharedTask_2011",
      "label": "CoNLL Shared Task 2011",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL_SharedTask_2011",
        "name": "CoNLL Shared Task 2011",
        "description": "Shared task for coreference resolution",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2011",
        "creators": "[\"Pradhan et al.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CoNLL_SharedTask_2011"
      }
    },
    {
      "id": "CoNLL_SharedTask_2012",
      "label": "CoNLL Shared Task 2012",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL_SharedTask_2012",
        "name": "CoNLL Shared Task 2012",
        "description": "Shared task for coreference resolution",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2012",
        "creators": "[\"Pradhan et al.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CoNLL_SharedTask_2012"
      }
    },
    {
      "id": "CoNLL2003_NER",
      "label": "CoNLL-2003",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL2003_NER",
        "name": "CoNLL-2003",
        "description": "Named Entity Recognition benchmark dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2003",
        "creators": "[\"Tjong Kim Sang, E.F.\", \"De Meulder, F.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CoNLL2003_NER"
      }
    },
    {
      "id": "CoNLL2011_2011",
      "label": "CoNLL2011",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoNLL2011_2011",
        "name": "CoNLL2011",
        "description": "Coreference dataset from five different domains",
        "domain": "Natural Language Processing",
        "size": 625,
        "year": "2011",
        "creators": "[\"Pradhan et al.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "CoNLL2011_2011"
      }
    },
    {
      "id": "CONLL2011_2011",
      "label": "CoNLL 2011",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CONLL2011_2011",
        "name": "CoNLL 2011",
        "description": "Coreference dataset from five different domains: broadcast conversation, broadcast news, magazine, newswire, and web data",
        "domain": "Natural Language Processing",
        "size": 625,
        "year": "2011",
        "creators": "[\"Pradhan et al.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CONLL2011_2011"
      }
    },
    {
      "id": "CoRR_2018",
      "label": "CoRR",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CoRR_2018",
        "name": "CoRR",
        "description": "ArXiv preprint dataset for arithmetic word problems.",
        "domain": "Mathematical Word Problems",
        "size": 0,
        "year": "2018",
        "creators": "[\"Chiang, T.\", \"Chen, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "CoRR_2018"
      }
    },
    {
      "id": "CrawledCorpora_2014",
      "label": "爬取语料库",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CrawledCorpora_2014",
        "name": "爬取语料库",
        "description": "从网络爬取的语料库",
        "domain": "机器翻译",
        "size": 870000000,
        "year": "2014",
        "creators": "[\"Kyunghyun Cho\", \"Bart van Merrienboer\", \"Caglar Gulcehre\", \"Dzmitry Bahdanau\", \"Fethi Bougares\", \"Holger Schwenk\", \"Yoshua Bengio\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "CrawledCorpora_2014"
      }
    },
    {
      "id": "CryoElectronMicroscopyImages_2003",
      "label": "Cryo-Electron Microscopy Images",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "CryoElectronMicroscopyImages_2003",
        "name": "Cryo-Electron Microscopy Images",
        "description": "Images used for detecting particles in cryo-electron microscopy",
        "domain": "Cryo-Electron Microscopy",
        "size": 0,
        "year": "2003",
        "creators": "[\"Y. Zhu\", \"B. Carragher\", \"F. Mouche\", \"C. Potter\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "CryoElectronMicroscopyImages_2003"
      }
    },
    {
      "id": "Custom_Arithmetic_Problems_1986",
      "label": "自定义算术问题数据集",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Custom_Arithmetic_Problems_1986",
        "name": "自定义算术问题数据集",
        "description": "由作者创建的用于测试WORDPRO系统的算术问题数据集",
        "domain": "教育心理学",
        "size": 0,
        "year": "1986",
        "creators": "[\"Fletcher, C. R.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Custom_Arithmetic_Problems_1986"
      }
    },
    {
      "id": "Custom_Word_Problems_2023",
      "label": "Custom Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Custom_Word_Problems_2023",
        "name": "Custom Word Problems",
        "description": "A collection of multi-step arithmetic word problems with extraneous information.",
        "domain": "Arithmetic Problem Solving",
        "size": 0,
        "year": "2023",
        "creators": "[\"Bakman, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "Custom_Word_Problems_2023"
      }
    },
    {
      "id": "DanishDependencyTreebank_2003",
      "label": "Danish Dependency Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DanishDependencyTreebank_2003",
        "name": "Danish Dependency Treebank",
        "description": "Danish dependency treebank",
        "domain": "Computational Linguistics",
        "size": 0,
        "year": "2003",
        "creators": "[\"Matthias T. Kromann\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "DanishDependencyTreebank_2003"
      }
    },
    {
      "id": "DevSet_2015",
      "label": "Development Set",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DevSet_2015",
        "name": "Development Set",
        "description": "包含374个数学文字题的开发集",
        "domain": "数学文字题求解",
        "size": 374,
        "year": "2015",
        "creators": "[\"Shi, S.\", \"Wang, Y.\", \"Lin, C.Y.\", \"Liu, X.\", \"Rui, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "DevSet_2015"
      }
    },
    {
      "id": "DimensionalUnits_2016",
      "label": "Dimensional Units",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DimensionalUnits_2016",
        "name": "Dimensional Units",
        "description": "A set of dimensional units used for generating mathematical word problems.",
        "domain": "Mathematics Education",
        "size": 43,
        "year": "2016",
        "creators": "[\"Ke Wang\", \"Zhendong Su\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "DimensionalUnits_2016"
      }
    },
    {
      "id": "DNS_Dataset_2017",
      "label": "DNS",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DNS_Dataset_2017",
        "name": "DNS",
        "description": "Dataset used for arithmetic word problem solving",
        "domain": "Natural Language Processing",
        "size": 60000,
        "year": "2017",
        "creators": "[\"Lei Wang\", \"Dongxiang Zhang\", \"Jipeng Zhang\", \"Xing Xu\", \"Lianli Gao\", \"Bing Tian Dai\", \"Heng Tao Shen\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "DNS_Dataset_2017"
      }
    },
    {
      "id": "Dolphin_2016",
      "label": "Dolphin",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Dolphin_2016",
        "name": "Dolphin",
        "description": "Harvested from community question-answering web pages",
        "domain": "Arithmetic Word Problems",
        "size": 0,
        "year": "2016",
        "creators": "[]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Dolphin_2016"
      }
    },
    {
      "id": "Dolphin_S_2017",
      "label": "Dolphin-S",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Dolphin_S_2017",
        "name": "Dolphin-S",
        "description": "Subset of Dolphin18K with one or multiple equations",
        "domain": "Mathematics",
        "size": 7070,
        "year": "2017",
        "creators": "[\"Authors of the paper\"]",
        "entity_type": "Dataset",
        "task_id": "94afd1a4-87cf-461f-bf45-7e59af553b6e",
        "source": "综述",
        "entity_id": "Dolphin_S_2017"
      }
    },
    {
      "id": "Dolphin-S_2016",
      "label": "Dolphin-S",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Dolphin-S_2016",
        "name": "Dolphin-S",
        "description": "Dolphin18K的一个子集，包含单步和多步算术问题",
        "domain": "数学问题求解",
        "size": 7070,
        "year": "2016",
        "creators": "[\"未提供\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "Dolphin-S_2016"
      }
    },
    {
      "id": "Dolphin-S_2017",
      "label": "Dolphin-S",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Dolphin-S_2017",
        "name": "Dolphin-S",
        "description": "Subset of Dolphin18K with single and multi-step operations",
        "domain": "Mathematics",
        "size": 7070,
        "year": "2017",
        "creators": "[\"Huang\"]",
        "entity_type": "Dataset",
        "task_id": "e6a5c6e0-87b5-49cf-a7c1-5ae80b441cb7",
        "source": "综述",
        "entity_id": "Dolphin-S_2017"
      }
    },
    {
      "id": "Dolphin1878_2015",
      "label": "Dolphin1878",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Dolphin1878_2015",
        "name": "Dolphin1878",
        "description": "A dataset of 1,878 number word problems",
        "domain": "Mathematics",
        "size": 1878,
        "year": "2015",
        "creators": "[\"Shi, S.\", \"Wang, Y.\", \"Lin, C.-Y.\", \"Liu, X.\", \"Rui, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Dolphin1878_2015"
      }
    },
    {
      "id": "Dolphin18K_2015",
      "label": "Dolphin18K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Dolphin18K_2015",
        "name": "Dolphin18K",
        "description": "Contains 18,460 math word problems with logical forms",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2015",
        "creators": "[]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Dolphin18K_2015"
      }
    },
    {
      "id": "Dolphin18K_2016",
      "label": "Dolphin18K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Dolphin18K_2016",
        "name": "Dolphin18K",
        "description": "Contains 18,460 math problems and 5,871 templates with one or multiple equations.",
        "domain": "Mathematical Word Problems",
        "size": 18460,
        "year": "2016",
        "creators": "[\"Huang, D.\", \"Shi, S.\", \"Lin, C.\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "Dolphin18K_2016"
      }
    },
    {
      "id": "DRAW_2015",
      "label": "DRAW",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DRAW_2015",
        "name": "DRAW",
        "description": "A dataset of 1,000 algebra word problems",
        "domain": "Mathematics",
        "size": 1000,
        "year": "2015",
        "creators": "[\"Upadhyay, S.\", \"Chang, M.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "DRAW_2015"
      }
    },
    {
      "id": "DRAW_2016",
      "label": "DRAW",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DRAW_2016",
        "name": "DRAW",
        "description": "",
        "domain": "Math Word Problems",
        "size": 1000,
        "year": "2016",
        "creators": "[\"Shyam Upadhyay\", \"Ming-Wei Chang\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "DRAW_2016"
      }
    },
    {
      "id": "DRAW1K_2016",
      "label": "DRAW1K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DRAW1K_2016",
        "name": "DRAW1K",
        "description": "Dataset for linear equation problems with diverse vocabularies and equation systems",
        "domain": "Mathematical Word Problems",
        "size": 1000,
        "year": "2016",
        "creators": "[\"Upadhyay, S.\", \"Chang, M.\", \"Chang, K.\", \"Yih, W.\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "DRAW1K_2016"
      }
    },
    {
      "id": "DRAW1K_2017",
      "label": "DRAW-1K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DRAW1K_2017",
        "name": "DRAW-1K",
        "description": "Algebra, linear, one-VAR problems",
        "domain": "Math Word Problem Solving",
        "size": 1000,
        "year": "2017",
        "creators": "[\"Shyam, U.\", \"Ming-Wei, C.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "DRAW1K_2017"
      }
    },
    {
      "id": "DS1_2014",
      "label": "DS1",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DS1_2014",
        "name": "DS1",
        "description": "Dataset with simple arithmetic word problems",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "DS1_2014"
      }
    },
    {
      "id": "DS2_2014",
      "label": "DS2",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DS2_2014",
        "name": "DS2",
        "description": "Dataset with arithmetic word problems containing irrelevant information",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "DS2_2014"
      }
    },
    {
      "id": "DS3_2014",
      "label": "DS3",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "DS3_2014",
        "name": "DS3",
        "description": "Dataset with complex arithmetic word problems",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "DS3_2014"
      }
    },
    {
      "id": "Elementary_Math_Word_Problems_2015",
      "label": "Elementary Math Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Elementary_Math_Word_Problems_2015",
        "name": "Elementary Math Word Problems",
        "description": "Math word problems for elementary school students",
        "domain": "Natural Language Processing",
        "size": 869,
        "year": "2015",
        "creators": "[\"Subhro Roy\", \"Tim Vieira\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Elementary_Math_Word_Problems_2015"
      }
    },
    {
      "id": "Elementary_school_arithmetic_application_problem_2011",
      "label": "Elementary school arithmetic application problem",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Elementary_school_arithmetic_application_problem_2011",
        "name": "Elementary school arithmetic application problem",
        "description": "Arithmetic word problems from People's Education Press, 2011",
        "domain": "Education",
        "size": 627,
        "year": "2011",
        "creators": "[\"People's Education Press\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Elementary_school_arithmetic_application_problem_2011"
      }
    },
    {
      "id": "Elementary_Science_Corpus_2016",
      "label": "Elementary Science Corpus",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Elementary_Science_Corpus_2016",
        "name": "Elementary Science Corpus",
        "description": "Corpus of 80k sentences about elementary science",
        "domain": "Elementary Education",
        "size": 80000,
        "year": "2016",
        "creators": "[\"Clark, P.\", \"Etzioni, O.\", \"Khot, T.\", \"Sabharwal, A.\", \"Tafjord, O.\", \"Turney, P.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Elementary_Science_Corpus_2016"
      }
    },
    {
      "id": "ElementarySchoolArithmeticApplicationProblem_2011",
      "label": "Elementary school arithmetic application problem",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ElementarySchoolArithmeticApplicationProblem_2011",
        "name": "Elementary school arithmetic application problem",
        "description": "Arithmetic word problems for elementary school students",
        "domain": "Education",
        "size": 627,
        "year": "2011",
        "creators": "[\"People's Education Press\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "ElementarySchoolArithmeticApplicationProblem_2011"
      }
    },
    {
      "id": "EmbeddedReberGrammar_1997",
      "label": "Embedded Reber Grammar",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "EmbeddedReberGrammar_1997",
        "name": "Embedded Reber Grammar",
        "description": "A synthetic dataset for evaluating sequence prediction models",
        "domain": "Natural language processing",
        "size": 0,
        "year": "1997",
        "creators": "[\"Sepp Hochreiter\", \"Jürgen Schmidhuber\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "EmbeddedReberGrammar_1997"
      }
    },
    {
      "id": "EMNLP_2018",
      "label": "EMNLP",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "EMNLP_2018",
        "name": "EMNLP",
        "description": "Conference proceedings dataset for arithmetic word problems.",
        "domain": "Mathematical Word Problems",
        "size": 0,
        "year": "2018",
        "creators": "[\"Wang, L.\", \"Wang, Y.\", \"Cai, D.\", \"Zhang, D.\", \"Liu, X.\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "EMNLP_2018"
      }
    },
    {
      "id": "EMNLP_Corpora_2014",
      "label": "EMNLP Corpora",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "EMNLP_Corpora_2014",
        "name": "EMNLP Corpora",
        "description": "Corpora used in EMNLP conference papers",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Various authors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "EMNLP_Corpora_2014"
      }
    },
    {
      "id": "English_Penn_Treebank_2014",
      "label": "English Penn Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "English_Penn_Treebank_2014",
        "name": "English Penn Treebank",
        "description": "Standard dataset for dependency parsing",
        "domain": "Natural Language Processing",
        "size": 39832,
        "year": "2014",
        "creators": "[\"Stanford University\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "English_Penn_Treebank_2014"
      }
    },
    {
      "id": "EnglishFrenchTranslationTask_2014",
      "label": "English-French Translation Task",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "EnglishFrenchTranslationTask_2014",
        "name": "English-French Translation Task",
        "description": "Dataset for English to French translation",
        "domain": "Machine Translation",
        "size": 514,
        "year": "2014",
        "creators": "[\"Kyunghyun Cho\", \"Bart van Merrienboer\", \"Caglar Gulcehre\", \"Dzmitry Bahdanau\", \"Fethi Bougares\", \"Holger Schwenk\", \"Yoshua Bengio\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "EnglishFrenchTranslationTask_2014"
      }
    },
    {
      "id": "ESP_2004",
      "label": "ESP",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ESP_2004",
        "name": "ESP",
        "description": "通过在线游戏收集的图像标签数据集。",
        "domain": "计算机视觉",
        "size": 60000,
        "year": "2004",
        "creators": "[\"von Ahn, L.\", \"Dabbish, L.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "ESP_2004"
      }
    },
    {
      "id": "ESP_dataset_2004",
      "label": "ESP dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ESP_dataset_2004",
        "name": "ESP dataset",
        "description": "通过在线游戏ESP Game收集的图像数据集，玩家独立为同一张图片提供标签，目标是在规定时间内匹配尽可能多的词汇。",
        "domain": "计算机视觉",
        "size": 60000,
        "year": "2004",
        "creators": "[\"von Ahn, L.\", \"Dabbish, L.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ESP_dataset_2004"
      }
    },
    {
      "id": "Europarl_2005",
      "label": "Europarl",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Europarl_2005",
        "name": "Europarl",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 61000000,
        "year": "2005",
        "creators": "[\"Koehn, P.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Europarl_2005"
      }
    },
    {
      "id": "Europarl_2014",
      "label": "Europarl",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Europarl_2014",
        "name": "Europarl",
        "description": "欧洲议会平行语料库",
        "domain": "机器翻译",
        "size": 61000000,
        "year": "2014",
        "creators": "[\"Kyunghyun Cho\", \"Bart van Merrienboer\", \"Caglar Gulcehre\", \"Dzmitry Bahdanau\", \"Fethi Bougares\", \"Holger Schwenk\", \"Yoshua Bengio\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Europarl_2014"
      }
    },
    {
      "id": "ExpressionTree_Dataset_2015",
      "label": "Expression Tree Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ExpressionTree_Dataset_2015",
        "name": "Expression Tree Dataset",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2015",
        "creators": "[\"Roy, S.\", \"Roth, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ExpressionTree_Dataset_2015"
      }
    },
    {
      "id": "FERET_Faces_1998",
      "label": "FERET Faces",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "FERET_Faces_1998",
        "name": "FERET Faces",
        "description": "Face recognition database",
        "domain": "Computer Vision",
        "size": 14000,
        "year": "1998",
        "creators": "[\"Phillips, P.\", \"Wechsler, H.\", \"Huang, J.\", \"Rauss, P.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "FERET_Faces_1998"
      }
    },
    {
      "id": "Figures_from_geometry_textbooks_2014",
      "label": "Figures from geometry textbooks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Figures_from_geometry_textbooks_2014",
        "name": "Figures from geometry textbooks",
        "description": "A set of 110 geometric figures taken from standard mathematics textbooks",
        "domain": "High School Geometry",
        "size": 110,
        "year": "2014",
        "creators": "[\"Chris Alvin\", \"Sumit Gulwani\", \"Rupak Majumdar\", \"Supratik Mukhopadhyay\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Figures_from_geometry_textbooks_2014"
      }
    },
    {
      "id": "FiguresFromGeometryTextbooks_2014",
      "label": "Figures from Geometry Textbooks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "FiguresFromGeometryTextbooks_2014",
        "name": "Figures from Geometry Textbooks",
        "description": "A collection of 110 geometric figures taken from standard mathematics textbooks in India and the United States.",
        "domain": "High School Geometry",
        "size": 110,
        "year": "2014",
        "creators": "[\"Alvin, C.\", \"Gulwani, S.\", \"Majumdar, R.\", \"Mukhopadhyay, S.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "FiguresFromGeometryTextbooks_2014"
      }
    },
    {
      "id": "Formula_Dataset_2016",
      "label": "Formula Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Formula_Dataset_2016",
        "name": "Formula Dataset",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2016",
        "creators": "[\"Mitra, A.\", \"Baral, C.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Formula_Dataset_2016"
      }
    },
    {
      "id": "Freebase_2015",
      "label": "Freebase",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Freebase_2015",
        "name": "Freebase",
        "description": "",
        "domain": "General Knowledge",
        "size": 0,
        "year": "2015",
        "creators": "[]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Freebase_2015"
      }
    },
    {
      "id": "Freebase_QA_2013",
      "label": "Freebase QA",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Freebase_QA_2013",
        "name": "Freebase QA",
        "description": "Freebase问答数据集，用于语义解析任务",
        "domain": "自然语言处理",
        "size": 0,
        "year": "2013",
        "creators": "[\"未提及\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Freebase_QA_2013"
      }
    },
    {
      "id": "FreebaseQA_2013",
      "label": "Freebase QA",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "FreebaseQA_2013",
        "name": "Freebase QA",
        "description": "A large community-authored database that spans many sub-domains, containing 917 questions labeled with logical form meaning representations for querying Freebase.",
        "domain": "Open-domain Question Answering",
        "size": 0,
        "year": "2013",
        "creators": "[\"Cai, Q.\", \"Yates, A.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "FreebaseQA_2013"
      }
    },
    {
      "id": "GAOKAO_2016",
      "label": "GAOKAO",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "GAOKAO_2016",
        "name": "GAOKAO",
        "description": "Chinese college entrance exam dataset",
        "domain": "Education",
        "size": 0,
        "year": "2016",
        "creators": "[\"Cheng, G.\", \"Zhu, W.\", \"Wang, Z.\", \"Chen, J.\", \"Qu, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "GAOKAO_2016"
      }
    },
    {
      "id": "Gaokao_2016",
      "label": "Gaokao",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Gaokao_2016",
        "name": "Gaokao",
        "description": "Dataset for Gaokao questions",
        "domain": "Chinese college entrance exam",
        "size": 0,
        "year": "2016",
        "creators": "[\"Cheng, G.\", \"Zhu, W.\", \"Wang, Z.\", \"Chen, J.\", \"Qu, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "综述",
        "entity_id": "Gaokao_2016"
      }
    },
    {
      "id": "Geo880_2014",
      "label": "Geo880",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Geo880_2014",
        "name": "Geo880",
        "description": "Geographical queries dataset",
        "domain": "Natural Language Processing",
        "size": 880,
        "year": "2014",
        "creators": "[\"Zelle, J.\", \"Mooney, R.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Geo880_2014"
      }
    },
    {
      "id": "Geometry Questions Dataset_2014",
      "label": "Geometry Questions Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Geometry Questions Dataset_2014",
        "name": "Geometry Questions Dataset",
        "description": "A dataset of geometry questions including textual descriptions and diagrams",
        "domain": "Geometry",
        "size": 100,
        "year": "2014",
        "creators": "[\"Min Joon Seo\", \"Hannaneh Hajishirzi\", \"Ali Farhadi\", \"Oren Etzioni\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Geometry Questions Dataset_2014"
      }
    },
    {
      "id": "Geometry_Questions_Dataset_2014",
      "label": "Geometry Questions Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Geometry_Questions_Dataset_2014",
        "name": "Geometry Questions Dataset",
        "description": "A dataset of geometry questions with textual descriptions and diagrams",
        "domain": "Geometry Questions",
        "size": 100,
        "year": "2014",
        "creators": "[\"Seo, M.\", \"Hajishirzi, H.\", \"Farhadi, A.\", \"Etzioni, O.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Geometry_Questions_Dataset_2014"
      }
    },
    {
      "id": "Geoquery_1996",
      "label": "GeoQuery",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Geoquery_1996",
        "name": "GeoQuery",
        "description": "A geography database with a small ontology and questions with relatively complex, compositional structure.",
        "domain": "Geography",
        "size": 0,
        "year": "1996",
        "creators": "[\"Zelle, J.\", \"Mooney, R.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Geoquery_1996"
      }
    },
    {
      "id": "GeoQuery_2013",
      "label": "GeoQuery",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "GeoQuery_2013",
        "name": "GeoQuery",
        "description": "地理查询数据集，用于语义解析任务",
        "domain": "自然语言处理",
        "size": 0,
        "year": "2013",
        "creators": "[\"未提及\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "GeoQuery_2013"
      }
    },
    {
      "id": "Geoquery_2014",
      "label": "Geoquery",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Geoquery_2014",
        "name": "Geoquery",
        "description": "Database consisting of U.S. geographical information and natural language queries",
        "domain": "Natural Language Processing",
        "size": 500,
        "year": "2014",
        "creators": "[\"Zelle and Mooney\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Geoquery_2014"
      }
    },
    {
      "id": "GeoTutor_2014",
      "label": "GeoTutor",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "GeoTutor_2014",
        "name": "GeoTutor",
        "description": "Dataset for generating geometry proof problems for high school students",
        "domain": "Education",
        "size": 0,
        "year": "2014",
        "creators": "[\"Singhal, R.\", \"Henz, M.\", \"McGee, K.\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "GeoTutor_2014"
      }
    },
    {
      "id": "GrammarExamples_1970",
      "label": "Grammar Examples",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "GrammarExamples_1970",
        "name": "Grammar Examples",
        "description": "Examples of context-free grammars used for testing parsing algorithms",
        "domain": "Formal Language Theory",
        "size": 0,
        "year": "1970",
        "creators": "[\"Earley, J.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "GrammarExamples_1970"
      }
    },
    {
      "id": "GREGrammar_1970",
      "label": "GRE Grammar",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "GREGrammar_1970",
        "name": "GRE Grammar",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "1970",
        "creators": "[\"Griffiths, T.\", \"Petrick, S.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "GREGrammar_1970"
      }
    },
    {
      "id": "HighConfidenceCorpus_2015",
      "label": "High-Confidence Corpus",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "HighConfidenceCorpus_2015",
        "name": "High-Confidence Corpus",
        "description": "高置信度解析树数据集",
        "domain": "自然语言处理",
        "size": 11000000,
        "year": "2015",
        "creators": "[\"Vinyals, Oriol\", \"Kaiser, Lukasz\", \"Koo, Terry\", \"Petrov, Slav\", \"Sutskever, Ilya\", \"Hinton, Geoffrey\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "HighConfidenceCorpus_2015"
      }
    },
    {
      "id": "HighConfidenceCorpusParsing_2015",
      "label": "High-Confidence Corpus Parsing",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "HighConfidenceCorpusParsing_2015",
        "name": "High-Confidence Corpus Parsing",
        "description": "Large corpus for syntactic parsing",
        "domain": "Natural Language Processing",
        "size": 11000000,
        "year": "2015",
        "creators": "[\"Vinyals et al.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "HighConfidenceCorpusParsing_2015"
      }
    },
    {
      "id": "HighConfidenceParsingCorpus_2015",
      "label": "High-confidence parsing corpus",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "HighConfidenceParsingCorpus_2015",
        "name": "High-confidence parsing corpus",
        "description": "Large corpus for syntactic parsing",
        "domain": "constituency parsing",
        "size": 11000000,
        "year": "2015",
        "creators": "[\"Vinyals, Oriol\", \"Kaiser, Lukasz\", \"Koo, Terry\", \"Petrov, Slav\", \"Sutskever, Ilya\", \"Hinton, Geoffrey\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "HighConfidenceParsingCorpus_2015"
      }
    },
    {
      "id": "HighSchoolGeometryProblems_2015",
      "label": "High School Geometry Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "HighSchoolGeometryProblems_2015",
        "name": "High School Geometry Problems",
        "description": "A corpus of high school geometry problems from standard geometry textbooks",
        "domain": "Education",
        "size": 155,
        "year": "2015",
        "creators": "[\"Chris Alvin\", \"Sumit Gulwani\", \"Rupak Majumdar\", \"Supratik Mukhopadhyay\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "HighSchoolGeometryProblems_2015"
      }
    },
    {
      "id": "HighSchoolGeometryQuestions_2014",
      "label": "High School Geometry Questions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "HighSchoolGeometryQuestions_2014",
        "name": "High School Geometry Questions",
        "description": "Dataset of high school plane geometry questions with textual descriptions and diagrams.",
        "domain": "Geometry",
        "size": 100,
        "year": "2014",
        "creators": "[\"Seo, M. J.\", \"Hajishirzi, H.\", \"Farhadi, A.\", \"Etzioni, O.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "HighSchoolGeometryQuestions_2014"
      }
    },
    {
      "id": "HighSchoolPlaneGeometryQuestions_2014",
      "label": "High School Plane Geometry Questions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "HighSchoolPlaneGeometryQuestions_2014",
        "name": "High School Plane Geometry Questions",
        "description": "A dataset of high school plane geometry questions with textual descriptions and accompanying diagrams.",
        "domain": "Geometry",
        "size": 100,
        "year": "2014",
        "creators": "[\"Seo, M. J.\", \"Hajishirzi, H.\", \"Farhadi, A.\", \"Etzioni, O.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "HighSchoolPlaneGeometryQuestions_2014"
      }
    },
    {
      "id": "HighSchoolTextbooks_1959",
      "label": "High School Textbooks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "HighSchoolTextbooks_1959",
        "name": "High School Textbooks",
        "description": "高中几何教科书中的定理",
        "domain": "几何学",
        "size": 0,
        "year": "1959",
        "creators": "[\"Gelernter, H.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "HighSchoolTextbooks_1959"
      }
    },
    {
      "id": "Hosseini2014_AdditionSubtraction",
      "label": "Addition Subtraction Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Hosseini2014_AdditionSubtraction",
        "name": "Addition Subtraction Problems",
        "description": "Dataset for addition and subtraction word problems",
        "domain": "Arithmetic Word Problem Solving",
        "size": 0,
        "year": "2014",
        "creators": "[\"Mohammad Javad Hosseini\", \"Hannaneh Hajishirzi\", \"Oren Etzioni\", \"Nate Kushman\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Hosseini2014_AdditionSubtraction"
      }
    },
    {
      "id": "Hosseini2014_Dataset_2014",
      "label": "Hosseini2014_Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Hosseini2014_Dataset_2014",
        "name": "Hosseini2014_Dataset",
        "description": "Arithmetic word problems dataset",
        "domain": "Natural Language Processing",
        "size": 394,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Hosseini2014_Dataset_2014"
      }
    },
    {
      "id": "Hosseini2014_Datasets",
      "label": "Hosseini et al. datasets",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Hosseini2014_Datasets",
        "name": "Hosseini et al. datasets",
        "description": "Three datasets (DS1, DS2, DS3) with increasing difficulty in terms of natural language and irrelevant information.",
        "domain": "Arithmetic word problems",
        "size": 0,
        "year": "2014",
        "creators": "[\"Hosseini, M.J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Hosseini2014_Datasets"
      }
    },
    {
      "id": "Hosseini2014_DS1",
      "label": "DS1",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Hosseini2014_DS1",
        "name": "DS1",
        "description": "Dataset with simple word problems",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "Hosseini2014_DS1"
      }
    },
    {
      "id": "Hosseini2014_DS2",
      "label": "DS2",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Hosseini2014_DS2",
        "name": "DS2",
        "description": "Dataset with moderate complexity word problems",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "Hosseini2014_DS2"
      }
    },
    {
      "id": "Hosseini2014_DS3",
      "label": "DS3",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Hosseini2014_DS3",
        "name": "DS3",
        "description": "Dataset with complex word problems",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "Hosseini2014_DS3"
      }
    },
    {
      "id": "IL_2014",
      "label": "IL",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IL_2014",
        "name": "IL",
        "description": "Single-step word problems with one operator",
        "domain": "Mathematics",
        "size": 562,
        "year": "2014",
        "creators": "[\"S. Roy\", \"D. Roth\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "IL_2014"
      }
    },
    {
      "id": "IL_2015",
      "label": "IL",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IL_2015",
        "name": "IL",
        "description": "Single-step word problems with one operator, including addition, subtraction, multiplication, and division",
        "domain": "Arithmetic word problems",
        "size": 562,
        "year": "2015",
        "creators": "[\"Roy et al.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "IL_2015"
      }
    },
    {
      "id": "IL_Dataset_2015",
      "label": "IL Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IL_Dataset_2015",
        "name": "IL Dataset",
        "description": "A collection of arithmetic problems that can be solved by performing one operation",
        "domain": "Arithmetic Word Problems",
        "size": 562,
        "year": "2015",
        "creators": "[\"S. Roy\", \"T. Vieira\", \"D. Roth\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "IL_Dataset_2015"
      }
    },
    {
      "id": "ImageCaptionGeneration_2015",
      "label": "image caption generation",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ImageCaptionGeneration_2015",
        "name": "image caption generation",
        "description": "Dataset of image and caption pairs",
        "domain": "image captioning",
        "size": 596000,
        "year": "2015",
        "creators": "[\"Vinyals, Oriol\", \"Toshev, Alexander\", \"Bengio, Samy\", \"Erhan, Dumitru\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ImageCaptionGeneration_2015"
      }
    },
    {
      "id": "ImageCaptioning_2015",
      "label": "Image Captioning",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ImageCaptioning_2015",
        "name": "Image Captioning",
        "description": "图像和字幕对的数据集",
        "domain": "计算机视觉与自然语言处理",
        "size": 596000,
        "year": "2015",
        "creators": "[\"Vinyals, Oriol\", \"Toshev, Alexander\", \"Bengio, Samy\", \"Erhan, Dumitru\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "ImageCaptioning_2015"
      }
    },
    {
      "id": "ImageCaptioningDataset_2015",
      "label": "Image Captioning Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ImageCaptioningDataset_2015",
        "name": "Image Captioning Dataset",
        "description": "Dataset of image-caption pairs",
        "domain": "Computer Vision",
        "size": 596000,
        "year": "2015",
        "creators": "[\"Vinyals et al.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "ImageCaptioningDataset_2015"
      }
    },
    {
      "id": "ImageNet_2009",
      "label": "ImageNet",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ImageNet_2009",
        "name": "ImageNet",
        "description": "一个大规模的层次化图像数据库，基于WordNet结构构建。",
        "domain": "计算机视觉",
        "size": 3200000,
        "year": "2009",
        "creators": "[\"Jia Deng\", \"Wei Dong\", \"Richard Socher\", \"Li-Jia Li\", \"Kai Li\", \"Li Fei-Fei\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ImageNet_2009"
      }
    },
    {
      "id": "ImageNet_2011",
      "label": "ImageNet",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ImageNet_2011",
        "name": "ImageNet",
        "description": "A large-scale hierarchical image database",
        "domain": "Computer Vision",
        "size": 50000000,
        "year": "2011",
        "creators": "[\"Jia Deng\", \"Wei Dong\", \"Richard Socher\", \"Li-Jia Li\", \"Kai Li\", \"Li Fei-Fei\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "ImageNet_2011"
      }
    },
    {
      "id": "IndianMathTextbooks_2006",
      "label": "Indian Math Textbooks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IndianMathTextbooks_2006",
        "name": "Indian Math Textbooks",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2006",
        "creators": "[\"Sinclair, D.\", \"Dikshit, et al.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "IndianMathTextbooks_2006"
      }
    },
    {
      "id": "IntegerLinearProgramming_Dataset_2015",
      "label": "Integer Linear Programming Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IntegerLinearProgramming_Dataset_2015",
        "name": "Integer Linear Programming Dataset",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2015",
        "creators": "[\"Koncel-Kedziorski, R.\", \"Hajishirzi, H.\", \"Sabharwal, A.\", \"Etzioni, O.\", \"Ang, S. D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "IntegerLinearProgramming_Dataset_2015"
      }
    },
    {
      "id": "IQTestSet_2016",
      "label": "IQ Test Set",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IQTestSet_2016",
        "name": "IQ Test Set",
        "description": "Verbal comprehension questions from published IQ test books",
        "domain": "Intelligence Testing",
        "size": 232,
        "year": "2016",
        "creators": "[\"Various Authors of IQ Test Books\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "IQTestSet_2016"
      }
    },
    {
      "id": "IWSLT2014_German_to_English_2016",
      "label": "IWSLT 2014 German-to-English",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IWSLT2014_German_to_English_2016",
        "name": "IWSLT 2014 German-to-English",
        "description": "Dataset from the IWSLT 2014 machine translation evaluation campaign",
        "domain": "Machine Translation",
        "size": 0,
        "year": "2016",
        "creators": "[\"Cettolo, M.\", \"Niehues, J.\", \"Stüker, S.\", \"Bentivogli, L.\", \"Federico, M.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "IWSLT2014_German_to_English_2016"
      }
    },
    {
      "id": "IWSLT2014_GermanToEnglish",
      "label": "IWSLT 2014 German-to-English",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IWSLT2014_GermanToEnglish",
        "name": "IWSLT 2014 German-to-English",
        "description": "Dataset for machine translation from German to English",
        "domain": "Machine Translation",
        "size": 0,
        "year": "2014",
        "creators": "[\"Cettolo, M.\", \"Niehues, J.\", \"Stüker, S.\", \"Bentivogli, L.\", \"Federico, M.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "IWSLT2014_GermanToEnglish"
      }
    },
    {
      "id": "IWSLT2014_TEDTalks",
      "label": "IWSLT 2014 TED Talks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IWSLT2014_TEDTalks",
        "name": "IWSLT 2014 TED Talks",
        "description": "Dataset from translated TED talks for German-to-English machine translation",
        "domain": "Machine Translation",
        "size": 0,
        "year": "2014",
        "creators": "[\"Cettolo, M.\", \"Niehues, J.\", \"Stüker, S.\", \"Bentivogli, L.\", \"Federico, M.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "IWSLT2014_TEDTalks"
      }
    },
    {
      "id": "IXL_2014",
      "label": "IXL",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "IXL_2014",
        "name": "IXL",
        "description": "Math word problems with more information gaps",
        "domain": "Math Word Problem Solving",
        "size": 395,
        "year": "2014",
        "creators": "[\"Hosseini et al.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "IXL_2014"
      }
    },
    {
      "id": "Kushman2014_Dataset_2014",
      "label": "Kushman2014_Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Kushman2014_Dataset_2014",
        "name": "Kushman2014_Dataset",
        "description": "Benchmark dataset for algebra word problems",
        "domain": "Natural Language Processing",
        "size": 1024,
        "year": "2014",
        "creators": "[\"Nate Kushman\", \"Yoav Artzi\", \"Luke Zettlemoyer\", \"Regina Barzilay\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Kushman2014_Dataset_2014"
      }
    },
    {
      "id": "Labeled_Faces_in_the_Wild_2007",
      "label": "Labeled Faces in the Wild",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Labeled_Faces_in_the_Wild_2007",
        "name": "Labeled Faces in the Wild",
        "description": "Unconstrained face recognition database",
        "domain": "Computer Vision",
        "size": 13000,
        "year": "2007",
        "creators": "[\"Huang, G.\", \"Ramesh, M.\", \"Berg, T.\", \"Learned-Miller, E.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Labeled_Faces_in_the_Wild_2007"
      }
    },
    {
      "id": "LabelMe_2008",
      "label": "LabelMe",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "LabelMe_2008",
        "name": "LabelMe",
        "description": "一个包含30,000张标注和分割的图像数据集。",
        "domain": "计算机视觉",
        "size": 30000,
        "year": "2008",
        "creators": "[\"Russell, B.\", \"Torralba, A.\", \"Murphy, K.\", \"Freeman, W.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "LabelMe_2008"
      }
    },
    {
      "id": "LinearSubset_NumWord_2015",
      "label": "Linear Subset of NumWord",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "LinearSubset_NumWord_2015",
        "name": "Linear Subset of NumWord",
        "description": "A subset of the NumWord dataset containing linear problems.",
        "domain": "Math Word Problems",
        "size": 986,
        "year": "2015",
        "creators": "[\"Shi, S.\", \"Yuehui, W.\", \"Lin, C.-Y.\", \"Liu, X.\", \"Rui, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "LinearSubset_NumWord_2015"
      }
    },
    {
      "id": "LinearT2_2015",
      "label": "LinearT2",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "LinearT2_2015",
        "name": "LinearT2",
        "description": "Subset of problems with linear equations and at least two problems for each equation template",
        "domain": "Math Word Problem Solving",
        "size": 0,
        "year": "2015",
        "creators": "[\"Shi, S.\", \"Wang, Y.\", \"Lin, C.Y.\", \"Liu, X.\", \"Rui, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "LinearT2_2015"
      }
    },
    {
      "id": "LinearT6_2015",
      "label": "LinearT6",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "LinearT6_2015",
        "name": "LinearT6",
        "description": "Subset of problems with linear equations and at least six problems for each equation template",
        "domain": "Math Word Problem Solving",
        "size": 0,
        "year": "2015",
        "creators": "[\"Shi, S.\", \"Wang, Y.\", \"Lin, C.Y.\", \"Liu, X.\", \"Rui, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "LinearT6_2015"
      }
    },
    {
      "id": "Lotus_Hill_2007",
      "label": "Lotus Hill",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Lotus_Hill_2007",
        "name": "Lotus Hill",
        "description": "一个包含50,000张标注和分割的图像数据集，以及587,000帧视频。",
        "domain": "计算机视觉",
        "size": 50000,
        "year": "2007",
        "creators": "[\"Yao, B.\", \"Yang, X.\", \"Zhu, S.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Lotus_Hill_2007"
      }
    },
    {
      "id": "LotusHill_2007",
      "label": "Lotus Hill",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "LotusHill_2007",
        "name": "Lotus Hill",
        "description": "一个包含50000张带标注和分割的图像数据集。",
        "domain": "计算机视觉",
        "size": 50000,
        "year": "2007",
        "creators": "[\"Yao, B.\", \"Yang, X.\", \"Zhu, S.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "LotusHill_2007"
      }
    },
    {
      "id": "MA1_2014",
      "label": "MA1",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MA1_2014",
        "name": "MA1",
        "description": "Simple math word problems on addition and subtraction for third, fourth, and fifth graders",
        "domain": "Math Word Problem Solving",
        "size": 395,
        "year": "2014",
        "creators": "[\"Hosseini et al.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "MA1_2014"
      }
    },
    {
      "id": "MA2_2014",
      "label": "MA2",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MA2_2014",
        "name": "MA2",
        "description": "Math word problems with more irrelevant information",
        "domain": "Math Word Problem Solving",
        "size": 395,
        "year": "2014",
        "creators": "[\"Hosseini et al.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "MA2_2014"
      }
    },
    {
      "id": "Math23K_2014",
      "label": "Math23K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Math23K_2014",
        "name": "Math23K",
        "description": "Chinese math word problems for elementary school students",
        "domain": "Mathematics",
        "size": 23162,
        "year": "2014",
        "creators": "[\"Y. Wang\", \"X. Liu\", \"S. Shi\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "综述",
        "entity_id": "Math23K_2014"
      }
    },
    {
      "id": "Math23K_2015",
      "label": "Math23K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Math23K_2015",
        "name": "Math23K",
        "description": "Large-scale dataset for arithmetic word problems",
        "domain": "Mathematics",
        "size": 23000,
        "year": "2015",
        "creators": "[\"Kushman et al.\"]",
        "entity_type": "Dataset",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "entity_id": "Math23K_2015"
      }
    },
    {
      "id": "Math23K_2016",
      "label": "Math23K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Math23K_2016",
        "name": "Math23K",
        "description": "A large-scale dataset for arithmetic word problems",
        "domain": "Natural Language Processing",
        "size": 23000,
        "year": "2016",
        "creators": "[\"Lei Wang\", \"Dongxiang Zhang\", \"Lianli Gao\", \"Jingkuan Song\", \"Long Guo\", \"Heng Tao Shen\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "引文",
        "entity_id": "Math23K_2016"
      }
    },
    {
      "id": "Math23K_2017",
      "label": "Math23K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Math23K_2017",
        "name": "Math23K",
        "description": "",
        "domain": "Math Word Problems",
        "size": 23161,
        "year": "2017",
        "creators": "[\"Yan Wang\", \"Xiaojiang Liu\", \"Shuming Shi\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Math23K_2017"
      }
    },
    {
      "id": "MathDQN_Dataset_2018",
      "label": "MathDQN Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MathDQN_Dataset_2018",
        "name": "MathDQN Dataset",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2018",
        "creators": "[\"Wang, L.\", \"Zhang, D.\", \"Gao, L.\", \"Song, J.\", \"Guo, L.\", \"Shen, H. T.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MathDQN_Dataset_2018"
      }
    },
    {
      "id": "MathematicalWordProblems_2017",
      "label": "Mathematical Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MathematicalWordProblems_2017",
        "name": "Mathematical Word Problems",
        "description": "A dataset of mathematical word problems",
        "domain": "Mathematics",
        "size": 1000,
        "year": "2017",
        "creators": "[\"Wang, K.\", \"Su, Z.\"]",
        "entity_type": "Dataset",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "entity_id": "MathematicalWordProblems_2017"
      }
    },
    {
      "id": "MAWPS_2016",
      "label": "MAWPS",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MAWPS_2016",
        "name": "MAWPS",
        "description": "包含一元未知数的算术问题数据集",
        "domain": "数学问题求解",
        "size": 2373,
        "year": "2016",
        "creators": "[\"未提供\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "MAWPS_2016"
      }
    },
    {
      "id": "MAWPS_S_2016",
      "label": "MAWPS-S",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MAWPS_S_2016",
        "name": "MAWPS-S",
        "description": "Dataset for arithmetic word problems with one unknown variable",
        "domain": "Mathematics",
        "size": 2373,
        "year": "2016",
        "creators": "[\"Authors of the paper\"]",
        "entity_type": "Dataset",
        "task_id": "94afd1a4-87cf-461f-bf45-7e59af553b6e",
        "source": "综述",
        "entity_id": "MAWPS_S_2016"
      }
    },
    {
      "id": "MAWPS-S_2016",
      "label": "MAWPS-S",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MAWPS-S_2016",
        "name": "MAWPS-S",
        "description": "A dataset of varying complexity from different websites",
        "domain": "Arithmetic Word Problem Solving",
        "size": 2373,
        "year": "2016",
        "creators": "[\"Koncel-Kedziorski, R.\", \"Roy, S.\", \"Amini, A.\", \"Kushman, N.\", \"Hajishirzi, H.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "综述",
        "entity_id": "MAWPS-S_2016"
      }
    },
    {
      "id": "MC_1991",
      "label": "MC",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MC_1991",
        "name": "MC",
        "description": "Miller and Charles word similarity dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "1991",
        "creators": "[\"Miller, G.A.\", \"Charles, W.G.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MC_1991"
      }
    },
    {
      "id": "MilitaryCOADiagrams_1999",
      "label": "Military Course of Action (COA) Diagrams",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MilitaryCOADiagrams_1999",
        "name": "Military Course of Action (COA) Diagrams",
        "description": "Diagrams used by the military for tasks such as troop movement planning",
        "domain": "Military Planning",
        "size": 0,
        "year": "1999",
        "creators": "[\"DARPA\", \"Northwestern University\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MilitaryCOADiagrams_1999"
      }
    },
    {
      "id": "MonolingualCorpora_2015",
      "label": "Monolingual Corpora",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MonolingualCorpora_2015",
        "name": "Monolingual Corpora",
        "description": "Monolingual corpora used for unsupervised learning tasks.",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2015",
        "creators": "[\"WMT'15 Contributors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MonolingualCorpora_2015"
      }
    },
    {
      "id": "MS_COCO_2014",
      "label": "MS COCO",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MS_COCO_2014",
        "name": "MS COCO",
        "description": "Microsoft Common Objects in Context dataset",
        "domain": "Computer Vision",
        "size": 204721,
        "year": "2014",
        "creators": "[\"T.-Y. Lin\", \"M. Maire\", \"S. Belongie\", \"J. Hays\", \"P. Perona\", \"D. Ramanan\", \"P. Dollar\", \"C. L. Zitnick\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MS_COCO_2014"
      }
    },
    {
      "id": "MS_COCO_Images_2014",
      "label": "MS COCO Images",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MS_COCO_Images_2014",
        "name": "MS COCO Images",
        "description": "Dataset containing 123,287 training and validation images and 81,434 test images.",
        "domain": "Computer Vision",
        "size": 204721,
        "year": "2014",
        "creators": "[\"Lin, T.-Y.\", \"Maire, M.\", \"Belongie, S.\", \"Hays, J.\", \"Perona, P.\", \"Ramanan, D.\", \"Dolla´r, P.\", \"Zitnick, C. L.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MS_COCO_Images_2014"
      }
    },
    {
      "id": "MSRC_2006",
      "label": "MSRC",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MSRC_2006",
        "name": "MSRC",
        "description": "一个包含24个类别的图像分割数据集。",
        "domain": "计算机视觉",
        "size": 591,
        "year": "2006",
        "creators": "[\"Shotton, J.\", \"Winn, J.\", \"Rother, C.\", \"Criminisi, A.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MSRC_2006"
      }
    },
    {
      "id": "MUC-6-TEST_2009",
      "label": "MUC-6-TEST",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MUC-6-TEST_2009",
        "name": "MUC-6-TEST",
        "description": "MUC6 formal evaluation set",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": "2009",
        "creators": "[]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MUC-6-TEST_2009"
      }
    },
    {
      "id": "MUC6_1995",
      "label": "MUC6",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MUC6_1995",
        "name": "MUC6",
        "description": "Message Understanding Conference 6 test corpus used for coreference resolution.",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "1995",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MUC6_1995"
      }
    },
    {
      "id": "MUC6-TEST_1995",
      "label": "MUC6-TEST",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MUC6-TEST_1995",
        "name": "MUC6-TEST",
        "description": "Test corpus from the sixth Message Understanding Conference (MUC-6) evaluation",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": "1995",
        "creators": "[\"Vilain et al.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MUC6-TEST_1995"
      }
    },
    {
      "id": "MUC6-TEST_2006",
      "label": "MUC6-TEST",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MUC6-TEST_2006",
        "name": "MUC6-TEST",
        "description": "Test corpus from the sixth Message Understanding Conference",
        "domain": "Natural Language Processing",
        "size": 30,
        "year": "2006",
        "creators": "[\"Message Understanding Conference\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "MUC6-TEST_2006"
      }
    },
    {
      "id": "MultiplicationProblem_1997",
      "label": "Multiplication Problem",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MultiplicationProblem_1997",
        "name": "Multiplication Problem",
        "description": "A dataset for evaluating models on multiplying specific elements in a sequence",
        "domain": "Sequence prediction",
        "size": 0,
        "year": "1997",
        "creators": "[\"Hochreiter, S.\", \"Schmidhuber, J.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "MultiplicationProblem_1997"
      }
    },
    {
      "id": "MultiStep_Word_Problems_2013",
      "label": "Multi-Step Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MultiStep_Word_Problems_2013",
        "name": "Multi-Step Word Problems",
        "description": "多步骤算术文字题数据集，包含无关信息",
        "domain": "自然语言处理",
        "size": 0,
        "year": "2013",
        "creators": "[\"未提及\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "MultiStep_Word_Problems_2013"
      }
    },
    {
      "id": "Natural_Images_2004",
      "label": "Natural Images",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Natural_Images_2004",
        "name": "Natural Images",
        "description": "自然图像数据集，用于矩形检测任务",
        "domain": "计算机视觉",
        "size": 0,
        "year": "2004",
        "creators": "[\"未提及\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Natural_Images_2004"
      }
    },
    {
      "id": "NaturalImages_2004",
      "label": "Natural images",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "NaturalImages_2004",
        "name": "Natural images",
        "description": "Real-world images for testing rectangle detection algorithms",
        "domain": "Computer Vision",
        "size": 0,
        "year": "2004",
        "creators": "[\"Claudio Rosito Jung\", \"Rodrigo Schramm\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "NaturalImages_2004"
      }
    },
    {
      "id": "NewsArticles_2013",
      "label": "News Articles",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "NewsArticles_2013",
        "name": "News Articles",
        "description": "A large dataset consisting of various news articles",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": "2013",
        "creators": "[\"Google Inc.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "NewsArticles_2013"
      }
    },
    {
      "id": "NewsArticlesDataset_2013",
      "label": "News Articles Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "NewsArticlesDataset_2013",
        "name": "News Articles Dataset",
        "description": "A large dataset consisting of various news articles",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": "2013",
        "creators": "[\"Google Inc.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "NewsArticlesDataset_2013"
      }
    },
    {
      "id": "NewsCommentary_2014",
      "label": "新闻评论",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "NewsCommentary_2014",
        "name": "新闻评论",
        "description": "新闻评论语料库",
        "domain": "机器翻译",
        "size": 5500000,
        "year": "2014",
        "creators": "[\"Kyunghyun Cho\", \"Bart van Merrienboer\", \"Caglar Gulcehre\", \"Dzmitry Bahdanau\", \"Fethi Bougares\", \"Holger Schwenk\", \"Yoshua Bengio\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "NewsCommentary_2014"
      }
    },
    {
      "id": "Newswire_Text_2015",
      "label": "Newswire Text",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Newswire_Text_2015",
        "name": "Newswire Text",
        "description": "新闻电讯文本数据集，用于数量推理任务",
        "domain": "自然语言处理",
        "size": 0,
        "year": "2015",
        "creators": "[\"未提及\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Newswire_Text_2015"
      }
    },
    {
      "id": "NSEGrammar_1970",
      "label": "NSE Grammar",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "NSEGrammar_1970",
        "name": "NSE Grammar",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "1970",
        "creators": "[\"Griffiths, T.\", \"Petrick, S.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "NSEGrammar_1970"
      }
    },
    {
      "id": "NumberWordProblem_2015",
      "label": "Number Word Problem",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "NumberWordProblem_2015",
        "name": "Number Word Problem",
        "description": "Verbally expressed number word problems",
        "domain": "Math Word Problem Solving",
        "size": 2871,
        "year": "2015",
        "creators": "[\"Shi, Shuming\", \"Wang, Yuehui\", \"Lin, Chin-Yew\", \"Liu, Xiaojiang\", \"Rui, Yong\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "NumberWordProblem_2015"
      }
    },
    {
      "id": "NumberWordProblems_2015",
      "label": "Number Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "NumberWordProblems_2015",
        "name": "Number Word Problems",
        "description": "A collection of math word problems focusing on number-related problems",
        "domain": "Mathematics",
        "size": 1878,
        "year": "2015",
        "creators": "[\"Shi, S.\", \"Wang, Y.\", \"Lin, C.-Y.\", \"Liu, X.\", \"Rui, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "NumberWordProblems_2015"
      }
    },
    {
      "id": "NumWord_2015",
      "label": "Number Word Problem",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "NumWord_2015",
        "name": "Number Word Problem",
        "description": "Contains 2,871 number word problems with 1,183 templates",
        "domain": "Mathematics",
        "size": 2871,
        "year": "2015",
        "creators": "[\"Shuming Shi\", \"Yuehui Wang\", \"Chin-Yew Lin\", \"Xiaojiang Liu\", \"Yong Rui\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "NumWord_2015"
      }
    },
    {
      "id": "NY_Regents_Science_Exam_2016",
      "label": "NY Regents Science Exam",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "NY_Regents_Science_Exam_2016",
        "name": "NY Regents Science Exam",
        "description": "Real exam questions from the NY Regents 4th Grade Science exams",
        "domain": "Elementary Science",
        "size": 0,
        "year": "2016",
        "creators": "[\"NY Regents\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "NY_Regents_Science_Exam_2016"
      }
    },
    {
      "id": "OnlineIQTestQuestions_2016",
      "label": "Online IQ Test Questions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "OnlineIQTestQuestions_2016",
        "name": "Online IQ Test Questions",
        "description": "Verbal comprehension questions collected from online IQ test websites",
        "domain": "Natural Language Processing",
        "size": 150,
        "year": "2016",
        "creators": "[\"Wang, H.\", \"Tian, F.\", \"Gao, B.\", \"Zhu, C.\", \"Bian, J.\", \"Liu, T.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "OnlineIQTestQuestions_2016"
      }
    },
    {
      "id": "Ontonotes_2012",
      "label": "Ontonotes-5.0",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Ontonotes_2012",
        "name": "Ontonotes-5.0",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2012",
        "creators": "[\"Pradhan et al.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Ontonotes_2012"
      }
    },
    {
      "id": "Ontonotes_2013",
      "label": "Ontonotes",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Ontonotes_2013",
        "name": "Ontonotes",
        "description": "A large-scale dataset for coreference resolution and other NLP tasks",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2013",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "引文",
        "entity_id": "Ontonotes_2013"
      }
    },
    {
      "id": "Ontonotes_5.0_GoldMentions",
      "label": "Ontonotes-5.0 Gold Mentions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Ontonotes_5.0_GoldMentions",
        "name": "Ontonotes-5.0 Gold Mentions",
        "description": "Gold mentions from Ontonotes-5.0 dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2012",
        "creators": "[\"Pradhan et al.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Ontonotes_5.0_GoldMentions"
      }
    },
    {
      "id": "Ontonotes-5.0_2012",
      "label": "Ontonotes 5.0",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Ontonotes-5.0_2012",
        "name": "Ontonotes 5.0",
        "description": "Large annotated corpus for coreference resolution",
        "domain": "Natural Language Processing",
        "size": 3145,
        "year": "2012",
        "creators": "[\"Pradhan et al.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Ontonotes-5.0_2012"
      }
    },
    {
      "id": "Ontonotes-5.0_GoldMentions_2012",
      "label": "Ontonotes-5.0 Gold Mentions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Ontonotes-5.0_GoldMentions_2012",
        "name": "Ontonotes-5.0 Gold Mentions",
        "description": "Largest annotated corpus on coreference, containing 3,145 annotated documents from various sources.",
        "domain": "Natural Language Processing",
        "size": 3145,
        "year": "2012",
        "creators": "[\"Pradhan et al.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Ontonotes-5.0_GoldMentions_2012"
      }
    },
    {
      "id": "Ontonotes5_2012",
      "label": "Ontonotes-5.0",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Ontonotes5_2012",
        "name": "Ontonotes-5.0",
        "description": "A large annotated corpus for coreference resolution containing 3,145 documents from various sources.",
        "domain": "Natural Language Processing",
        "size": 3145,
        "year": "2012",
        "creators": "[\"Pradhan et al.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "Ontonotes5_2012"
      }
    },
    {
      "id": "PASCAL_2008",
      "label": "PASCAL",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PASCAL_2008",
        "name": "PASCAL",
        "description": "一个包含20个类别的图像分割和物体检测数据集。",
        "domain": "计算机视觉",
        "size": 10000,
        "year": "2008",
        "creators": "[\"Everingham, M.\", \"Van Gool, L.\", \"Williams, C. K. I.\", \"Winn, J.\", \"Zisserman, A.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PASCAL_2008"
      }
    },
    {
      "id": "PBF_Diagrams_1991",
      "label": "PBF Diagrams",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PBF_Diagrams_1991",
        "name": "PBF Diagrams",
        "description": "Diagrams from Pictorial Book of Flora (PBF) in Japanese",
        "domain": "Botanical Illustrations",
        "size": 31,
        "year": "1991",
        "creators": "[\"Yasuhiko Watanabe\", \"Makoto Nagao\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PBF_Diagrams_1991"
      }
    },
    {
      "id": "PBF_Diagrams_2014",
      "label": "PBF Diagrams",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PBF_Diagrams_2014",
        "name": "PBF Diagrams",
        "description": "Diagrams from a pictorial book of flora with accompanying textual descriptions",
        "domain": "Pictorial Books of Flora",
        "size": 31,
        "year": "2014",
        "creators": "[\"Watanabe, Y.\", \"Nagao, M.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "PBF_Diagrams_2014"
      }
    },
    {
      "id": "Penn_Treebank_2010",
      "label": "Penn Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Penn_Treebank_2010",
        "name": "Penn Treebank",
        "description": "A large annotated corpus of English text",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2010",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Penn_Treebank_2010"
      }
    },
    {
      "id": "Penn_Treebank_WSJ_2013",
      "label": "Penn Treebank WSJ",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Penn_Treebank_WSJ_2013",
        "name": "Penn Treebank WSJ",
        "description": "华尔街日报语料库，用于语法解析任务",
        "domain": "自然语言处理",
        "size": 0,
        "year": "2013",
        "creators": "[\"未提及\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Penn_Treebank_WSJ_2013"
      }
    },
    {
      "id": "Penn2Malt_Conversion_Program_2010",
      "label": "Penn2Malt Conversion Program",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Penn2Malt_Conversion_Program_2010",
        "name": "Penn2Malt Conversion Program",
        "description": "Program used to convert constituency trees to dependency structures",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2010",
        "creators": "[\"Yamada, H.\", \"Matsumoto, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Penn2Malt_Conversion_Program_2010"
      }
    },
    {
      "id": "PennTreeBank_1993",
      "label": "Penn Tree Bank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PennTreeBank_1993",
        "name": "Penn Tree Bank",
        "description": "广泛使用的句法树库",
        "domain": "自然语言处理",
        "size": 40000,
        "year": "1993",
        "creators": "[\"Marcus, Mitchell P.\", \"Marcinkiewicz, Mary Ann\", \"Santorini, Beatrice\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "PennTreeBank_1993"
      }
    },
    {
      "id": "PennTreebank_1999",
      "label": "Penn Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PennTreebank_1999",
        "name": "Penn Treebank",
        "description": "A large annotated corpus of English text",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "1999",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PennTreebank_1999"
      }
    },
    {
      "id": "PennTreebank_2013",
      "label": "Penn Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PennTreebank_2013",
        "name": "Penn Treebank",
        "description": "A dataset of syntactically annotated English text",
        "domain": "Natural Language Processing",
        "size": 40000,
        "year": "2013",
        "creators": "[\"Marcus, M.\", \"Marcinkiewicz, M.\", \"Santorini, B.\"]",
        "entity_type": "Dataset",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "entity_id": "PennTreebank_2013"
      }
    },
    {
      "id": "PennTreebank_WSJ_2013",
      "label": "Penn Treebank WSJ",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PennTreebank_WSJ_2013",
        "name": "Penn Treebank WSJ",
        "description": "A widely used dataset for syntactic parsing, containing Wall Street Journal articles.",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2013",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PennTreebank_WSJ_2013"
      }
    },
    {
      "id": "PennTreeBankParsing_1993",
      "label": "Penn Tree Bank parsing",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PennTreeBankParsing_1993",
        "name": "Penn Tree Bank parsing",
        "description": "Corpus for syntactic parsing",
        "domain": "constituency parsing",
        "size": 40000,
        "year": "1993",
        "creators": "[\"Marcus, Mitchell P.\", \"Marcinkiewicz, Mary Ann\", \"Santorini, Beatrice\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PennTreeBankParsing_1993"
      }
    },
    {
      "id": "Perturb_2018",
      "label": "Perturb",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Perturb_2018",
        "name": "Perturb",
        "description": "New dataset created by perturbing original problems",
        "domain": "Natural Language Processing",
        "size": 661,
        "year": "2018",
        "creators": "[\"Roy, S.\", \"Roth, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Perturb_2018"
      }
    },
    {
      "id": "PhraseAnalogyDataset_2013",
      "label": "Phrase Analogy Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PhraseAnalogyDataset_2013",
        "name": "Phrase Analogy Dataset",
        "description": "Dataset for evaluating phrase-based analogical reasoning",
        "domain": "Natural Language Processing",
        "size": 3218,
        "year": "2013",
        "creators": "[\"Tomas Mikolov\", \"Ilya Sutskever\", \"Kai Chen\", \"Greg Corrado\", \"Jeffrey Dean\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PhraseAnalogyDataset_2013"
      }
    },
    {
      "id": "PhysicsProblems_1990",
      "label": "Physics Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PhysicsProblems_1990",
        "name": "Physics Problems",
        "description": "Textbook physics problems with accompanying diagrams",
        "domain": "Physics Education",
        "size": 0,
        "year": "1990",
        "creators": "[\"Novak, G. S.\", \"Bulko, W.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PhysicsProblems_1990"
      }
    },
    {
      "id": "PolygonFigures_1996",
      "label": "Polygon Figures",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PolygonFigures_1996",
        "name": "Polygon Figures",
        "description": "Set of randomly generated polygons used for symmetry detection experiments",
        "domain": "Psychological Experiments",
        "size": 240,
        "year": "1996",
        "creators": "[\"Ferguson, R. W.\", \"Aminoff, A.\", \"Gentner, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PolygonFigures_1996"
      }
    },
    {
      "id": "PropositionalCalculusGrammar_1970",
      "label": "Propositional Calculus Grammar",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PropositionalCalculusGrammar_1970",
        "name": "Propositional Calculus Grammar",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "1970",
        "creators": "[\"Griffiths, T.\", \"Petrick, S.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PropositionalCalculusGrammar_1970"
      }
    },
    {
      "id": "PropositionalRepresentations_1985",
      "label": "Propositional Representations",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PropositionalRepresentations_1985",
        "name": "Propositional Representations",
        "description": "Propositional representations for 14 texts used in WORDPRO",
        "domain": "Arithmetic Word Problems",
        "size": 14,
        "year": "1985",
        "creators": "[\"Fletcher, C. R.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PropositionalRepresentations_1985"
      }
    },
    {
      "id": "PTB_2015",
      "label": "Penn Treebank (PTB)",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PTB_2015",
        "name": "Penn Treebank (PTB)",
        "description": "Standard dataset for parsing and word ordering tasks",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2015",
        "creators": "[\"Zhang, Y.\", \"Clark, S.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PTB_2015"
      }
    },
    {
      "id": "PTB_2015_WordOrdering",
      "label": "PTB Word Ordering",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PTB_2015_WordOrdering",
        "name": "PTB Word Ordering",
        "description": "Penn Treebank dataset used for word ordering experiments",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2015",
        "creators": "[\"Zhang, Y.\", \"Clark, S.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PTB_2015_WordOrdering"
      }
    },
    {
      "id": "PTB_2016",
      "label": "PTB",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PTB_2016",
        "name": "PTB",
        "description": "Penn Treebank dataset for word ordering and dependency parsing tasks",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2016",
        "creators": "[\"Zhang, Y.\", \"Clark, S.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "PTB_2016"
      }
    },
    {
      "id": "PublishedIQTestBooks_2016",
      "label": "Published IQ Test Books",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PublishedIQTestBooks_2016",
        "name": "Published IQ Test Books",
        "description": "Verbal comprehension questions associated with correct answers from published IQ test books",
        "domain": "Intelligence Testing",
        "size": 232,
        "year": "2016",
        "creators": "[\"Philip Carter\", \"Dan Pape\", \"Ken Russell\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "PublishedIQTestBooks_2016"
      }
    },
    {
      "id": "RG_1965",
      "label": "RG",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "RG_1965",
        "name": "RG",
        "description": "Rubenstein and Goodenough word similarity dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "1965",
        "creators": "[\"Rubenstein, H.\", \"Goodenough, J.B.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "RG_1965"
      }
    },
    {
      "id": "RTE_Datasets_2006",
      "label": "RTE Datasets",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "RTE_Datasets_2006",
        "name": "RTE Datasets",
        "description": "Textual Entailment datasets from RTE2 to RTE4",
        "domain": "Natural Language Processing",
        "size": 384,
        "year": "2006",
        "creators": "[\"Dagan, I.\", \"Glickman, O.\", \"Magnini, B.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "RTE_Datasets_2006"
      }
    },
    {
      "id": "RTE_Datasets_2015",
      "label": "RTE Datasets",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "RTE_Datasets_2015",
        "name": "RTE Datasets",
        "description": "文本蕴含数据集，用于数量推理任务",
        "domain": "自然语言处理",
        "size": 0,
        "year": "2015",
        "creators": "[\"未提及\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "RTE_Datasets_2015"
      }
    },
    {
      "id": "RTE2_Dataset_2006",
      "label": "RTE2 Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "RTE2_Dataset_2006",
        "name": "RTE2 Dataset",
        "description": "Recognizing Textual Entailment Dataset",
        "domain": "Natural Language Processing",
        "size": 800,
        "year": "2006",
        "creators": "[\"Dagan, I.\", \"Glickman, O.\", \"Magnini, B.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "RTE2_Dataset_2006"
      }
    },
    {
      "id": "RTE3_Dataset_2006",
      "label": "RTE3 Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "RTE3_Dataset_2006",
        "name": "RTE3 Dataset",
        "description": "Recognizing Textual Entailment Dataset",
        "domain": "Natural Language Processing",
        "size": 800,
        "year": "2006",
        "creators": "[\"Dagan, I.\", \"Glickman, O.\", \"Magnini, B.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "RTE3_Dataset_2006"
      }
    },
    {
      "id": "RTE4_Dataset_2006",
      "label": "RTE4 Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "RTE4_Dataset_2006",
        "name": "RTE4 Dataset",
        "description": "Recognizing Textual Entailment Dataset",
        "domain": "Natural Language Processing",
        "size": 800,
        "year": "2006",
        "creators": "[\"Dagan, I.\", \"Glickman, O.\", \"Magnini, B.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "RTE4_Dataset_2006"
      }
    },
    {
      "id": "RW_2013",
      "label": "RW",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "RW_2013",
        "name": "RW",
        "description": "Rare Words dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2013",
        "creators": "[\"Luong, M.T.\", \"Socher, R.\", \"Manning, C.D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "RW_2013"
      }
    },
    {
      "id": "SampleWordProblems_1985",
      "label": "Sample Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SampleWordProblems_1985",
        "name": "Sample Word Problems",
        "description": "A set of arithmetic word problems designed for third-grade children.",
        "domain": "Education",
        "size": 0,
        "year": "1985",
        "creators": "[\"Fletcher, C. R.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "SampleWordProblems_1985"
      }
    },
    {
      "id": "SAT_Geometry_2015",
      "label": "SAT Geometry",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SAT_Geometry_2015",
        "name": "SAT Geometry",
        "description": "A dataset of SAT plane geometry questions",
        "domain": "Geometry",
        "size": 186,
        "year": "2015",
        "creators": "[\"Minjoon Seo\", \"Hannaneh Hajishirzi\", \"Ali Farhadi\", \"Oren Etzioni\", \"Clint Malcolm\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "SAT_Geometry_2015"
      }
    },
    {
      "id": "SAT_Geometry_Questions_2015",
      "label": "SAT Geometry Questions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SAT_Geometry_Questions_2015",
        "name": "SAT Geometry Questions",
        "description": "A dataset of SAT plane geometry questions with textual descriptions and diagrams",
        "domain": "Geometry",
        "size": 186,
        "year": "2015",
        "creators": "[\"Minjoon Seo\", \"Hannaneh Hajishirzi\", \"Ali Farhadi\", \"Oren Etzioni\", \"Clint Malcolm\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "SAT_Geometry_Questions_2015"
      }
    },
    {
      "id": "SATGeometryQuestions_2015",
      "label": "SAT Geometry Questions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SATGeometryQuestions_2015",
        "name": "SAT Geometry Questions",
        "description": "A dataset of SAT-level geometry problems with text and diagrams",
        "domain": "Geometry",
        "size": 110,
        "year": "2015",
        "creators": "[\"Seo, M.\", \"Hajishirzi, H.\", \"Farhadi, A.\", \"Etzioni, O.\", \"Malcolm, C.\"]",
        "entity_type": "Dataset",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "entity_id": "SATGeometryQuestions_2015"
      }
    },
    {
      "id": "SCWS_2012",
      "label": "SCWS",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SCWS_2012",
        "name": "SCWS",
        "description": "Sentences Containing Word Similarities",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2012",
        "creators": "[\"Huang, E.H.\", \"Socher, R.\", \"Manning, C.D.\", \"Ng, A.Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "SCWS_2012"
      }
    },
    {
      "id": "SimplifiedDiagrams_PhysicalPhenomena",
      "label": "Simplified Diagrams of Physical Phenomena",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SimplifiedDiagrams_PhysicalPhenomena",
        "name": "Simplified Diagrams of Physical Phenomena",
        "description": "Set of simplified diagrams used to critique physical phenomena",
        "domain": "Physics Education",
        "size": 0,
        "year": "1999",
        "creators": "[\"Ferguson, R. W.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "SimplifiedDiagrams_PhysicalPhenomena"
      }
    },
    {
      "id": "SingaporeMathCurriculum_2009",
      "label": "Singapore Math Curriculum",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SingaporeMathCurriculum_2009",
        "name": "Singapore Math Curriculum",
        "description": "Collection of mathematical word problems used in Singapore schools",
        "domain": "Education",
        "size": 24,
        "year": "2009",
        "creators": "[\"Frank Schaffer Publications\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "SingaporeMathCurriculum_2009"
      }
    },
    {
      "id": "SingleEQ_2015",
      "label": "SINGLEEQ",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SingleEQ_2015",
        "name": "SINGLEEQ",
        "description": "Consists of 508 single-variable algebra word problems",
        "domain": "Mathematics",
        "size": 508,
        "year": "2015",
        "creators": "[\"Rik Koncel-Kedziorski\", \"Hannaneh Hajishirzi\", \"Ashish Sabharwal\", \"Oren Etzioni\", \"Siena Dumas Ang\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "SingleEQ_2015"
      }
    },
    {
      "id": "SingleEQ_2016",
      "label": "SingleEQ",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SingleEQ_2016",
        "name": "SingleEQ",
        "description": "包含单步和多步算术问题的数据集",
        "domain": "数学问题求解",
        "size": 508,
        "year": "2016",
        "creators": "[\"未提供\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "综述",
        "entity_id": "SingleEQ_2016"
      }
    },
    {
      "id": "Small01_2016",
      "label": "Small.01",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Small01_2016",
        "name": "Small.01",
        "description": "从All.Linear中选择对应于Alg514中的28个模板的问题",
        "domain": "数学文字问题",
        "size": 2021,
        "year": "2016",
        "creators": "[\"Huang, D.\", \"Shi, S.\", \"Lin, C.-Y.\", \"Yin, J.\", \"Ma, W.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Small01_2016"
      }
    },
    {
      "id": "Small02_2016",
      "label": "Small.02",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Small02_2016",
        "name": "Small.02",
        "description": "从Small.01中随机移除问题，使得每个模板包含与Alg514相似数量的问题",
        "domain": "数学文字问题",
        "size": 0,
        "year": "2016",
        "creators": "[\"Huang, D.\", \"Shi, S.\", \"Lin, C.-Y.\", \"Yin, J.\", \"Ma, W.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Small02_2016"
      }
    },
    {
      "id": "SNLI_Corpus_2015",
      "label": "SNLI Corpus",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SNLI_Corpus_2015",
        "name": "SNLI Corpus",
        "description": "570k human-written English sentence pairs manually labeled for entailment, contradiction, and neutral",
        "domain": "Natural Language Processing",
        "size": 570000,
        "year": "2015",
        "creators": "[\"Bowman et al.\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "SNLI_Corpus_2015"
      }
    },
    {
      "id": "SNLI_Dataset_2015",
      "label": "SNLI Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SNLI_Dataset_2015",
        "name": "SNLI Dataset",
        "description": "Collection of 570k human-written English sentence pairs for textual entailment",
        "domain": "Natural Language Processing",
        "size": 570000,
        "year": "2015",
        "creators": "[\"Bowman et al.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "SNLI_Dataset_2015"
      }
    },
    {
      "id": "SNLI_dataset_2015",
      "label": "SNLI dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SNLI_dataset_2015",
        "name": "SNLI dataset",
        "description": "570k human-written English sentence pairs manually labeled for entailment, contradiction, and neutral",
        "domain": "Textual Entailment",
        "size": 570000,
        "year": "2015",
        "creators": "[\"Bowman et al.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "SNLI_dataset_2015"
      }
    },
    {
      "id": "SolitaireCardGame_2014",
      "label": "Solitaire Card Game",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SolitaireCardGame_2014",
        "name": "Solitaire Card Game",
        "description": "Instructions and rules for various solitaire card games",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Goldwasser, D.\", \"Roth, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "SolitaireCardGame_2014"
      }
    },
    {
      "id": "SolitaireCardGameRules_2014",
      "label": "Solitaire Card Game Rules",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SolitaireCardGameRules_2014",
        "name": "Solitaire Card Game Rules",
        "description": "自然语言指令描述的纸牌游戏规则",
        "domain": "自然语言处理",
        "size": 0,
        "year": "2014",
        "creators": "[\"Dan Goldwasser\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "SolitaireCardGameRules_2014"
      }
    },
    {
      "id": "StandardMathTextbooks_2006",
      "label": "Standard Math Textbooks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "StandardMathTextbooks_2006",
        "name": "Standard Math Textbooks",
        "description": "Collection of standard mathematics textbooks for grades IX and X",
        "domain": "Education",
        "size": 110,
        "year": "2006",
        "creators": "[\"Sinclair, D.\", \"Dikshit, et al.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "StandardMathTextbooks_2006"
      }
    },
    {
      "id": "StandardPrimarySchoolTestQuestions_2015",
      "label": "Standard Primary School Test Questions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "StandardPrimarySchoolTestQuestions_2015",
        "name": "Standard Primary School Test Questions",
        "description": "A dataset of arithmetic word problems from primary school exams",
        "domain": "Arithmetic Word Problem Solving",
        "size": 0,
        "year": "2015",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "3bd4a30a-8625-4ec9-8d37-c4497808b0e2",
        "source": "引文",
        "entity_id": "StandardPrimarySchoolTestQuestions_2015"
      }
    },
    {
      "id": "Stanford_Basic_Dependencies_2014",
      "label": "Stanford Basic Dependencies",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Stanford_Basic_Dependencies_2014",
        "name": "Stanford Basic Dependencies",
        "description": "A dataset for basic dependencies derived from the Penn Treebank.",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"de Marneffe, M.-C.\", \"MacCartney, B.\", \"Manning, C. D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Stanford_Basic_Dependencies_2014"
      }
    },
    {
      "id": "Stanford_Dependency_Parser_2014",
      "label": "Stanford Dependency Parser",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Stanford_Dependency_Parser_2014",
        "name": "Stanford Dependency Parser",
        "description": "A dependency parser for syntactic analysis",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Chen, Danqi\", \"Manning, Christopher D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Stanford_Dependency_Parser_2014"
      }
    },
    {
      "id": "StanfordCoreNLPSuite_2014",
      "label": "Stanford CoreNLP Suite",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "StanfordCoreNLPSuite_2014",
        "name": "Stanford CoreNLP Suite",
        "description": "A set of tools for natural language processing",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Manning, C. D.\", \"Surdeanu, M.\", \"Bauer, J.\", \"Finkel, J.\", \"Bethard, S. J.\", \"McClosky, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "StanfordCoreNLPSuite_2014"
      }
    },
    {
      "id": "StanfordDependencies_2014",
      "label": "Stanford Dependencies",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "StanfordDependencies_2014",
        "name": "Stanford Dependencies",
        "description": "Dependency parsing dataset with Stanford dependency labels",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Chen, D.\", \"Manning, C.D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "StanfordDependencies_2014"
      }
    },
    {
      "id": "Suzhou_Education_Publishing_House_dataset",
      "label": "Suzhou Education Publishing House dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Suzhou_Education_Publishing_House_dataset",
        "name": "Suzhou Education Publishing House dataset",
        "description": "Training dataset containing different types of arithmetic word problems",
        "domain": "Education",
        "size": 283,
        "year": "2016",
        "creators": "[\"Suzhou Education Publishing House\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Suzhou_Education_Publishing_House_dataset"
      }
    },
    {
      "id": "SuzhouEducationPublishingHouse_2016",
      "label": "Suzhou Education Publishing House",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SuzhouEducationPublishingHouse_2016",
        "name": "Suzhou Education Publishing House",
        "description": "Arithmetic word problems for training",
        "domain": "Education",
        "size": 0,
        "year": "2016",
        "creators": "[\"Suzhou Education Publishing House\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "SuzhouEducationPublishingHouse_2016"
      }
    },
    {
      "id": "Synthesized_MWPs_2016",
      "label": "Synthesized MWPs",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Synthesized_MWPs_2016",
        "name": "Synthesized MWPs",
        "description": "Automatically generated mathematical word problems",
        "domain": "Mathematics",
        "size": 48,
        "year": "2016",
        "creators": "[\"Wang, K.\", \"Su, Z.\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Synthesized_MWPs_2016"
      }
    },
    {
      "id": "Synthetic_Images_2004",
      "label": "Synthetic Images",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Synthetic_Images_2004",
        "name": "Synthetic Images",
        "description": "合成图像数据集，用于矩形检测任务",
        "domain": "计算机视觉",
        "size": 0,
        "year": "2004",
        "creators": "[\"未提及\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Synthetic_Images_2004"
      }
    },
    {
      "id": "SyntheticImages_2004",
      "label": "Synthetic images",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SyntheticImages_2004",
        "name": "Synthetic images",
        "description": "Synthetic images containing geometric objects for testing rectangle detection algorithms",
        "domain": "Computer Vision",
        "size": 0,
        "year": "2004",
        "creators": "[\"Claudio Rosito Jung\", \"Rodrigo Schramm\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "SyntheticImages_2004"
      }
    },
    {
      "id": "T6_2018",
      "label": "T6",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "T6_2018",
        "name": "T6",
        "description": "A subset setting representing problems for which the associated template appeared equal to or more than six times in the subset.",
        "domain": "Math Word Problems",
        "size": 0,
        "year": "2018",
        "creators": "[\"Huang, D.\", \"Liu, J.\", \"Lin, C.-Y.\", \"Yin, J.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "T6_2018"
      }
    },
    {
      "id": "TagBased_Dataset_2016",
      "label": "Tag-Based Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "TagBased_Dataset_2016",
        "name": "Tag-Based Dataset",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2016",
        "creators": "[\"Liang, C.\", \"Hsu, K.\", \"Huang, C.\", \"Li, C.\", \"Miao, S.\", \"Su, K.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "TagBased_Dataset_2016"
      }
    },
    {
      "id": "Targeting_classification_dataset_2011",
      "label": "Targeting Classification Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Targeting_classification_dataset_2011",
        "name": "Targeting Classification Dataset",
        "description": "Arithmetic word problems for classification",
        "domain": "Education",
        "size": 627,
        "year": "2011",
        "creators": "[\"People's Education Press\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Targeting_classification_dataset_2011"
      }
    },
    {
      "id": "TestSet_newstest2012_2014",
      "label": "newstest2012",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "TestSet_newstest2012_2014",
        "name": "newstest2012",
        "description": "",
        "domain": "Machine Translation",
        "size": 70000,
        "year": "2014",
        "creators": "[\"WMT'14 workshop\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "TestSet_newstest2012_2014"
      }
    },
    {
      "id": "TestSet_newstest2013_2014",
      "label": "newstest2013",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "TestSet_newstest2013_2014",
        "name": "newstest2013",
        "description": "",
        "domain": "Machine Translation",
        "size": 70000,
        "year": "2014",
        "creators": "[\"WMT'14 workshop\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "TestSet_newstest2013_2014"
      }
    },
    {
      "id": "TestSet_newstest2014_2014",
      "label": "newstest2014",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "TestSet_newstest2014_2014",
        "name": "newstest2014",
        "description": "",
        "domain": "Machine Translation",
        "size": 70000,
        "year": "2014",
        "creators": "[\"WMT'14 workshop\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "TestSet_newstest2014_2014"
      }
    },
    {
      "id": "TestSetAll_2015",
      "label": "Test Set All",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "TestSetAll_2015",
        "name": "Test Set All",
        "description": "包含1504个数学文字题的测试集",
        "domain": "数学文字题求解",
        "size": 1504,
        "year": "2015",
        "creators": "[\"Shi, S.\", \"Wang, Y.\", \"Lin, C.Y.\", \"Liu, X.\", \"Rui, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "TestSetAll_2015"
      }
    },
    {
      "id": "TextbookPhysicsProblems_1985",
      "label": "Textbook Physics Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "TextbookPhysicsProblems_1985",
        "name": "Textbook Physics Problems",
        "description": "A dataset of physics problems with text and diagrams",
        "domain": "Physics",
        "size": 100,
        "year": "1985",
        "creators": "[\"Novak, G.\"]",
        "entity_type": "Dataset",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "entity_id": "TextbookPhysicsProblems_1985"
      }
    },
    {
      "id": "TinyImage_2008",
      "label": "TinyImage",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "TinyImage_2008",
        "name": "TinyImage",
        "description": "一个包含8000万张32x32低分辨率图像的数据集，通过将WordNet中的所有单词作为查询发送到图像搜索引擎收集。",
        "domain": "计算机视觉",
        "size": 80000000,
        "year": "2008",
        "creators": "[\"Torralba, A.\", \"Fergus, R.\", \"Freeman, W.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "TinyImage_2008"
      }
    },
    {
      "id": "Top10Templates_Math23K",
      "label": "Top 10 Most Frequent Templates in Math23K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Top10Templates_Math23K",
        "name": "Top 10 Most Frequent Templates in Math23K",
        "description": "Dataset containing the top 10 most frequent templates in the Math23K dataset",
        "domain": "Arithmetic Word Problems",
        "size": 10,
        "year": "2019",
        "creators": "[\"Wang, L.\", \"Zhang, D.\", \"Gao, L.\", \"Dai, B.T.\", \"Shen, H.T.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Top10Templates_Math23K"
      }
    },
    {
      "id": "Tufte1990_EnvisioningInformation",
      "label": "Envisioning Information",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Tufte1990_EnvisioningInformation",
        "name": "Envisioning Information",
        "description": "关于信息可视化的书籍",
        "domain": "信息可视化",
        "size": 0,
        "year": "1990",
        "creators": "[\"Tufte, E. R.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Tufte1990_EnvisioningInformation"
      }
    },
    {
      "id": "TwoSequenceProblem_1994",
      "label": "2-sequence problem",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "TwoSequenceProblem_1994",
        "name": "2-sequence problem",
        "description": "A dataset for evaluating sequence prediction models",
        "domain": "Sequence prediction",
        "size": 0,
        "year": "1994",
        "creators": "[\"Bengio, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "TwoSequenceProblem_1994"
      }
    },
    {
      "id": "UN_2014",
      "label": "联合国语料库",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "UN_2014",
        "name": "联合国语料库",
        "description": "联合国多语言语料库",
        "domain": "机器翻译",
        "size": 421000000,
        "year": "2014",
        "creators": "[\"Kyunghyun Cho\", \"Bart van Merrienboer\", \"Caglar Gulcehre\", \"Dzmitry Bahdanau\", \"Fethi Bougares\", \"Holger Schwenk\", \"Yoshua Bengio\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "UN_2014"
      }
    },
    {
      "id": "UNCorpus_2014",
      "label": "UN Corpus",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "UNCorpus_2014",
        "name": "UN Corpus",
        "description": "Parallel corpus for statistical machine translation",
        "domain": "Machine Translation",
        "size": 421000000,
        "year": "2014",
        "creators": "[\"UN\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "UNCorpus_2014"
      }
    },
    {
      "id": "UnitDependencyGraph_Dataset_2017",
      "label": "Unit Dependency Graph Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "UnitDependencyGraph_Dataset_2017",
        "name": "Unit Dependency Graph Dataset",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2017",
        "creators": "[\"Roy, S.\", \"Roth, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "UnitDependencyGraph_Dataset_2017"
      }
    },
    {
      "id": "USMathTextbooks_2006",
      "label": "US Math Textbooks",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "USMathTextbooks_2006",
        "name": "US Math Textbooks",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2006",
        "creators": "[\"Boyd, et al.\", \"Larson, et al.\", \"Jurgensen, Brown, and Jurgensen\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "USMathTextbooks_2006"
      }
    },
    {
      "id": "Verb395_2014",
      "label": "Verb395",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Verb395_2014",
        "name": "Verb395",
        "description": "Collection of addition/subtraction problems",
        "domain": "Mathematics",
        "size": 395,
        "year": "2014",
        "creators": "[\"Hosseini, M. J.\", \"Hajishirzi, H.\", \"Etzioni, O.\", \"Kushman, N.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Verb395_2014"
      }
    },
    {
      "id": "VQA_Abstract_Scenes_2016",
      "label": "VQA Abstract Scenes",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "VQA_Abstract_Scenes_2016",
        "name": "VQA Abstract Scenes",
        "description": "A dataset of abstract scenes made from clipart for visual question answering.",
        "domain": "Computer Vision",
        "size": 0,
        "year": "2016",
        "creators": "[\"Zhang, P.\", \"Goyal, Y.\", \"Summers-Stay, D.\", \"Batra, D.\", \"Parikh, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "VQA_Abstract_Scenes_2016"
      }
    },
    {
      "id": "VQA_Dataset_2015",
      "label": "VQA Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "VQA_Dataset_2015",
        "name": "VQA Dataset",
        "description": "包含超过250K张图像、760K个问题和约10M个答案的数据集",
        "domain": "计算机视觉与自然语言处理",
        "size": 250000,
        "year": "2015",
        "creators": "[\"Antol, S.\", \"Agrawal, A.\", \"Lu, J.\", \"Mitchell, M.\", \"Batra, D.\", \"Zitnick, C. L.\", \"Parikh, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "VQA_Dataset_2015"
      }
    },
    {
      "id": "VQA_TrainVal_2015",
      "label": "VQA TrainVal",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "VQA_TrainVal_2015",
        "name": "VQA TrainVal",
        "description": "Dataset used for training and validation of VQA models",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 204721,
        "year": "2015",
        "creators": "[\"Antol, S.\", \"Agrawal, A.\", \"Lu, J.\", \"Mitchell, M.\", \"Batra, D.\", \"Zitnick, C. L.\", \"Parikh, D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "VQA_TrainVal_2015"
      }
    },
    {
      "id": "VQA_v2.0_2016",
      "label": "VQA v2.0",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "VQA_v2.0_2016",
        "name": "VQA v2.0",
        "description": "Balanced Visual Question Answering dataset with complementary images",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 1100000,
        "year": "2016",
        "creators": "[\"Yash Goyal\", \"Tejas Khot\", \"Douglas Summers-Stay\", \"Dhruv Batra\", \"Devi Parikh\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "VQA_v2.0_2016"
      }
    },
    {
      "id": "VQA_v2.0_2017",
      "label": "VQA_v2.0",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "VQA_v2.0_2017",
        "name": "VQA_v2.0",
        "description": "Balanced Visual Question Answering dataset",
        "domain": "Computer Vision and Natural Language Processing",
        "size": 1100000,
        "year": "2017",
        "creators": "[\"Yash Goyal\", \"Tejas Khot\", \"Douglas Summers-Stay\", \"Dhruv Batra\", \"Devi Parikh\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "VQA_v2.0_2017"
      }
    },
    {
      "id": "VQADataset_2015",
      "label": "VQA Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "VQADataset_2015",
        "name": "VQA Dataset",
        "description": "A dataset for visual question answering",
        "domain": "Vision and Language",
        "size": 250000,
        "year": "2015",
        "creators": "[\"Antol, S.\", \"Agrawal, A.\", \"Lu, J.\", \"Mitchell, M.\", \"Batra, D.\", \"Zitnick, C.\", \"Parikh, D.\"]",
        "entity_type": "Dataset",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "entity_id": "VQADataset_2015"
      }
    },
    {
      "id": "WIKI_2009",
      "label": "WIKI",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WIKI_2009",
        "name": "WIKI",
        "description": "25k articles of English Wikipedia abstracts parsed by the Klein and Manning parser",
        "domain": "Natural Language Processing",
        "size": 25000,
        "year": "2009",
        "creators": "[]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WIKI_2009"
      }
    },
    {
      "id": "Wikipedia_2010",
      "label": "Wikipedia 2010",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Wikipedia_2010",
        "name": "Wikipedia 2010",
        "description": "A 2010 Wikipedia dump with 1 billion tokens",
        "domain": "Natural Language Processing",
        "size": 1000000000,
        "year": "2010",
        "creators": "[\"Stanford University\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Wikipedia_2010"
      }
    },
    {
      "id": "Wikipedia_2014",
      "label": "Wikipedia 2014",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Wikipedia_2014",
        "name": "Wikipedia 2014",
        "description": "A 2014 Wikipedia dump with 1.6 billion tokens",
        "domain": "Natural Language Processing",
        "size": 1600000000,
        "year": "2014",
        "creators": "[\"Stanford University\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "Wikipedia_2014"
      }
    },
    {
      "id": "WMT-14_English_to_French_2014",
      "label": "WMT-14 English to French",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WMT-14_English_to_French_2014",
        "name": "WMT-14 English to French",
        "description": "A dataset for English to French translation task",
        "domain": "Natural Language Processing",
        "size": 12000000,
        "year": "2014",
        "creators": "[\"WMT\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WMT-14_English_to_French_2014"
      }
    },
    {
      "id": "WMT14_English_to_French",
      "label": "WMT'14 English to French",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WMT14_English_to_French",
        "name": "WMT'14 English to French",
        "description": "A dataset for English to French translation used in the WMT'14 evaluation campaign.",
        "domain": "Natural Language Processing",
        "size": 12000000,
        "year": "2014",
        "creators": "[\"WMT'14\"]",
        "entity_type": "Dataset",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "entity_id": "WMT14_English_to_French"
      }
    },
    {
      "id": "WMT14_EnglishFrench_2014",
      "label": "English/French translation task of the WMT’14 workshop",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WMT14_EnglishFrench_2014",
        "name": "English/French translation task of the WMT’14 workshop",
        "description": "Large bilingual corpora for English/French translation including Europarl, news commentary, UN, and crawled corpora.",
        "domain": "Machine Translation",
        "size": 0,
        "year": "2014",
        "creators": "[\"WMT’14 workshop organizers\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WMT14_EnglishFrench_2014"
      }
    },
    {
      "id": "WMT14EnglishFrench_2014",
      "label": "WMT-14 English-French",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WMT14EnglishFrench_2014",
        "name": "WMT-14 English-French",
        "description": "A dataset for English-to-French translation",
        "domain": "Machine Translation",
        "size": 3000000,
        "year": "2014",
        "creators": "[\"WMT\"]",
        "entity_type": "Dataset",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "entity_id": "WMT14EnglishFrench_2014"
      }
    },
    {
      "id": "WMT15_EnglishGerman",
      "label": "WMT'15 English-German",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WMT15_EnglishGerman",
        "name": "WMT'15 English-German",
        "description": "Parallel corpus for English-German translation",
        "domain": "Machine Translation",
        "size": 4500000,
        "year": "2015",
        "creators": "[\"Bojar, Ondřej\", \"Chatterjee, Rajen\", \"Federmann, Christian\", \"Haddow, Barry\", \"Huck, Matthias\", \"Hokamp, Chris\", \"Koehn, Philipp\", \"Logacheva, Varvara\", \"Monz, Christof\", \"Negri, Matteo\", \"Post, Matt\", \"Scarton, Carolina\", \"Specia, Lucia\", \"Turchi, Marco\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "WMT15_EnglishGerman"
      }
    },
    {
      "id": "WMT15_EnglishGerman_2015",
      "label": "WMT'15 English-German",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WMT15_EnglishGerman_2015",
        "name": "WMT'15 English-German",
        "description": "英语到德语的翻译数据集",
        "domain": "自然语言处理",
        "size": 4500000,
        "year": "2015",
        "creators": "[\"Bojar, Ondřej\", \"Chatterjee, Rajen\", \"Federmann, Christian\", \"Haddow, Barry\", \"Huck, Matthias\", \"Hokamp, Chris\", \"Koehn, Philipp\", \"Logacheva, Varvara\", \"Monz, Christof\", \"Negri, Matteo\", \"Post, Matt\", \"Scarton, Carolina\", \"Specia, Lucia\", \"Turchi, Marco\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "WMT15_EnglishGerman_2015"
      }
    },
    {
      "id": "WMT15_EnglishGermanTranslation_2015",
      "label": "WMT'15 English-German translation",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WMT15_EnglishGermanTranslation_2015",
        "name": "WMT'15 English-German translation",
        "description": "Parallel corpus for English-German translation",
        "domain": "machine translation",
        "size": 4500000,
        "year": "2015",
        "creators": "[\"Bojar, Ondřej\", \"Chatterjee, Rajen\", \"Federmann, Christian\", \"Haddow, Barry\", \"Huck, Matthias\", \"Hokamp, Chris\", \"Koehn, Philipp\", \"Logacheva, Varvara\", \"Monz, Christof\", \"Negri, Matteo\", \"Post, Matt\", \"Scarton, Carolina\", \"Specia, Lucia\", \"Turchi, Marco\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WMT15_EnglishGermanTranslation_2015"
      }
    },
    {
      "id": "WordNet_1998",
      "label": "WordNet",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WordNet_1998",
        "name": "WordNet",
        "description": "A large lexical database of English",
        "domain": "Natural Language Processing",
        "size": 80000,
        "year": "1998",
        "creators": "[\"Fellbaum, C.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WordNet_1998"
      }
    },
    {
      "id": "WordProblems_2023",
      "label": "Word Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WordProblems_2023",
        "name": "Word Problems",
        "description": "A collection of multi-step arithmetic word problems with extraneous information",
        "domain": "Arithmetic problem solving",
        "size": 0,
        "year": "2023",
        "creators": "[\"Bakman, Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WordProblems_2023"
      }
    },
    {
      "id": "WordRep_2014",
      "label": "WordRep",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WordRep_2014",
        "name": "WordRep",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2014",
        "creators": "[\"Gao, B.\", \"Bian, J.\", \"Liu, T.-Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WordRep_2014"
      }
    },
    {
      "id": "WordSim353_2001",
      "label": "WordSim-353",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WordSim353_2001",
        "name": "WordSim-353",
        "description": "Word similarity dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2001",
        "creators": "[\"Finkelstein, L.\", \"Gabrilovich, E.\", \"Matias, Y.\", \"Rivlin, E.\", \"Solan, Z.\", \"Wolfman, G.\", \"Ruppin, E.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WordSim353_2001"
      }
    },
    {
      "id": "WSJ_Section22_2013",
      "label": "WSJ Section 22",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WSJ_Section22_2013",
        "name": "WSJ Section 22",
        "description": "Development set used for cross-validation and hyperparameter tuning",
        "domain": "Natural Language Processing",
        "size": 1700,
        "year": "2013",
        "creators": "[\"Various contributors to the Penn Treebank\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WSJ_Section22_2013"
      }
    },
    {
      "id": "WSJ_Section22_DevSet_2013",
      "label": "WSJ Section 22 Dev Set",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WSJ_Section22_DevSet_2013",
        "name": "WSJ Section 22 Dev Set",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2013",
        "creators": "[\"Socher, R.\", \"Bauer, J.\", \"Manning, C. D.\", \"Ng, A. Y.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WSJ_Section22_DevSet_2013"
      }
    },
    {
      "id": "WSJ_Section23_2013",
      "label": "WSJ Section 23",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WSJ_Section23_2013",
        "name": "WSJ Section 23",
        "description": "Final test set used for evaluating the model",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2013",
        "creators": "[\"Various contributors to the Penn Treebank\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WSJ_Section23_2013"
      }
    },
    {
      "id": "WSJ_Treebank_2010",
      "label": "WSJ Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WSJ_Treebank_2010",
        "name": "WSJ Treebank",
        "description": "Wall Street Journal Treebank for dependency parsing",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2010",
        "creators": "[\"Penn Treebank\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "WSJ_Treebank_2010"
      }
    },
    {
      "id": "WSJSection_PennTreebank_1999",
      "label": "Wall Street Journal Section of Penn Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WSJSection_PennTreebank_1999",
        "name": "Wall Street Journal Section of Penn Treebank",
        "description": "A section of the Penn Treebank containing news articles from the Wall Street Journal.",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "1999",
        "creators": "[\"Klein, Dan\", \"Manning, Christopher D.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "WSJSection_PennTreebank_1999"
      }
    },
    {
      "id": "Yahoo_Answers_2008",
      "label": "Yahoo! Answers",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Yahoo_Answers_2008",
        "name": "Yahoo! Answers",
        "description": "Community question-answering web pages containing math word problems and their solutions.",
        "domain": "Mathematics",
        "size": 0,
        "year": "2008",
        "creators": "[\"Yahoo!\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Yahoo_Answers_2008"
      }
    },
    {
      "id": "Yahoo_Answers_2015",
      "label": "Yahoo Answers",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Yahoo_Answers_2015",
        "name": "Yahoo Answers",
        "description": "Website for users to ask and answer questions",
        "domain": "Mathematics",
        "size": 0,
        "year": "2015",
        "creators": "[\"Yahoo\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Yahoo_Answers_2015"
      }
    },
    {
      "id": "YahooAnswers_2016",
      "label": "Yahoo! Answers",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "YahooAnswers_2016",
        "name": "Yahoo! Answers",
        "description": "Community question-answering web pages",
        "domain": "Mathematics",
        "size": 1000000,
        "year": "2016",
        "creators": "[\"Danqing Huang\", \"Shuming Shi\", \"Chin-Yew Lin\", \"Jian Yin\", \"Wei-Ying Ma\"]",
        "entity_type": "Dataset",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "entity_id": "YahooAnswers_2016"
      }
    },
    {
      "id": "YahooAnswers_MathPosts_2016",
      "label": "Yahoo! Answers Math Posts",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "YahooAnswers_MathPosts_2016",
        "name": "Yahoo! Answers Math Posts",
        "description": "Mathematics category posts from Yahoo! Answers, containing raw problem text and answer text.",
        "domain": "Mathematical Problem Solving",
        "size": 1000000,
        "year": "2016",
        "creators": "[\"Danqing Huang\", \"Shuming Shi\", \"Chin-Yew Lin\", \"Jian Yin\", \"Wei-Ying Ma\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "YahooAnswers_MathPosts_2016"
      }
    },
    {
      "id": "YahooAnswers.com_2015",
      "label": "Yahoo Answers",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "YahooAnswers.com_2015",
        "name": "Yahoo Answers",
        "description": "一个用户提问并获得答案的问答平台",
        "domain": "数学教育",
        "size": 1878,
        "year": "2015",
        "creators": "[\"Various Contributors\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "YahooAnswers.com_2015"
      }
    },
    {
      "id": "Yelp_Dataset_2017",
      "label": "Yelp Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Yelp_Dataset_2017",
        "name": "Yelp Dataset",
        "description": "2.7M Yelp reviews for sentiment analysis",
        "domain": "Natural Language Processing",
        "size": 2700000,
        "year": "2017",
        "creators": "[\"Yelp\"]",
        "entity_type": "Dataset",
        "task_id": "6a5f4ffd-b05f-4b77-80b0-39665cfba97d",
        "source": "引文",
        "entity_id": "Yelp_Dataset_2017"
      }
    },
    {
      "id": "YouTube2Text_2013",
      "label": "YouTube2Text",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "YouTube2Text_2013",
        "name": "YouTube2Text",
        "description": "Dataset for recognizing and describing arbitrary activities using semantic hierarchies and zero-shot recognition",
        "domain": "Video Captioning",
        "size": 15,
        "year": "2013",
        "creators": "[\"Guadarrama, S.\", \"Krishnamoorthy, N.\", \"Malkarnenkar, G.\", \"Venugopalan, S.\", \"Mooney, R.\", \"Darrell, T.\", \"Saenko, K.\"]",
        "entity_type": "Dataset",
        "task_id": "acd5234f-5909-41af-89e0-9ada88e1200a",
        "source": "引文",
        "entity_id": "YouTube2Text_2013"
      }
    },
    {
      "id": "SingleEQ_2014",
      "label": "SingleEQ",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "SingleEQ_2014",
        "name": "SingleEQ",
        "description": "Contains single-step and multi-step arithmetic problems",
        "domain": "Arithmetic Word Problems",
        "size": 508,
        "year": "2014",
        "creators": "[\"Koncel-Kedziorski, R.\", \"Hajishirzi, H.\", \"Sabharwal, A.\", \"Etzioni, O.\", \"Ang, S.D.\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "综述",
        "entity_id": "SingleEQ_2014"
      }
    },
    {
      "id": "AllArith_2014",
      "label": "AllArith",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "AllArith_2014",
        "name": "AllArith",
        "description": "A mixture of data from AI2, IL, CC and SingleEQ",
        "domain": "Arithmetic Word Problems",
        "size": 831,
        "year": "2014",
        "creators": "[\"Koncel-Kedziorski, R.\", \"Hajishirzi, H.\", \"Sabharwal, A.\", \"Etzioni, O.\", \"Ang, S.D.\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "综述",
        "entity_id": "AllArith_2014"
      }
    },
    {
      "id": "MAWPS-S_2014",
      "label": "MAWPS-S",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MAWPS-S_2014",
        "name": "MAWPS-S",
        "description": "A dataset of varying complexity from different websites",
        "domain": "Arithmetic Word Problems",
        "size": 2373,
        "year": "2014",
        "creators": "[\"Koncel-Kedziorski, R.\", \"Roy, S.\", \"Amini, A.\", \"Kushman, N.\", \"Hajishirzi, H.\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "综述",
        "entity_id": "MAWPS-S_2014"
      }
    },
    {
      "id": "Dolphin-S_2014",
      "label": "Dolphin-S",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Dolphin-S_2014",
        "name": "Dolphin-S",
        "description": "Subset of Dolphin18K with one or multiple equations",
        "domain": "Arithmetic Word Problems",
        "size": 7070,
        "year": "2014",
        "creators": "[\"Huang, D.\", \"Shi, S.\", \"Lin, C.\", \"Yin, J.\", \"Ma, W.\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "综述",
        "entity_id": "Dolphin-S_2014"
      }
    },
    {
      "id": "LargeDataset_2017",
      "label": "Large Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "LargeDataset_2017",
        "name": "Large Dataset",
        "description": "A large dataset of math word problems",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2017",
        "creators": "[\"Yan Wang\", \"Xiaojiang Liu\", \"Shuming Shi\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "LargeDataset_2017"
      }
    },
    {
      "id": "EnglishPennTreebank_2014",
      "label": "English Penn Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "EnglishPennTreebank_2014",
        "name": "English Penn Treebank",
        "description": "A widely used dataset for parsing tasks",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "EnglishPennTreebank_2014"
      }
    },
    {
      "id": "Ontonotes_2010",
      "label": "Ontonotes",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Ontonotes_2010",
        "name": "Ontonotes",
        "description": "A large-scale dataset for coreference resolution and other NLP tasks",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2010",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "Ontonotes_2010"
      }
    },
    {
      "id": "Alg514_2015",
      "label": "Alg514",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Alg514_2015",
        "name": "Alg514",
        "description": "A dataset containing 514 algebra problems",
        "domain": "Mathematics",
        "size": 514,
        "year": "2015",
        "creators": "[\"Koncel-Kedziorski, R.\", \"Hajishirzi, H.\", \"Sabharwal, A.\", \"Etzioni, O.\", \"Ang, S.D.\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "Alg514_2015"
      }
    },
    {
      "id": "WMT_2014",
      "label": "WMT",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "WMT_2014",
        "name": "WMT",
        "description": "Web-scale Machine Translation dataset",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"WMT Community\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "WMT_2014"
      }
    },
    {
      "id": "PennTreebank_2014",
      "label": "Penn Treebank",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "PennTreebank_2014",
        "name": "Penn Treebank",
        "description": "Corpus of syntactically annotated English text",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Marcus, Mitchell P.\", \"Marcinkiewicz, Mary Ann\", \"Santorini, Beatrice\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "PennTreebank_2014"
      }
    },
    {
      "id": "MSCOCO_2014",
      "label": "MS COCO",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MSCOCO_2014",
        "name": "MS COCO",
        "description": "Common Objects in Context dataset",
        "domain": "Computer Vision",
        "size": 0,
        "year": "2014",
        "creators": "[\"Lin, Tsung-Yi\", \"Maire, Michael\", \"Belongie, Serge\", \"Hays, James\", \"Perona, Pietro\", \"Ramanan, Deva\", \"Dollár, Piotr\", \"Zitnick, C. Lawrence\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "MSCOCO_2014"
      }
    },
    {
      "id": "GeometryQuestionsDataset_2014",
      "label": "Geometry Questions Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "GeometryQuestionsDataset_2014",
        "name": "Geometry Questions Dataset",
        "description": "Dataset of geometry questions with textual descriptions and diagrams",
        "domain": "Geometry Education",
        "size": 0,
        "year": "2014",
        "creators": "[\"Min Joon Seo\", \"Hannaneh Hajishirzi\", \"Ali Farhadi\", \"Oren Etzioni\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "GeometryQuestionsDataset_2014"
      }
    },
    {
      "id": "EnglishFrenchTranslationDataset_2014",
      "label": "English-French translation dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "EnglishFrenchTranslationDataset_2014",
        "name": "English-French translation dataset",
        "description": "Dataset for translating English to French",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2014",
        "creators": "[\"Not specified\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "EnglishFrenchTranslationDataset_2014"
      }
    },
    {
      "id": "BenchmarkArithmeticWordProblems_2015",
      "label": "Benchmark datasets of arithmetic word problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "BenchmarkArithmeticWordProblems_2015",
        "name": "Benchmark datasets of arithmetic word problems",
        "description": "",
        "domain": "",
        "size": 0,
        "year": "2015",
        "creators": "[\"Roy, S.\", \"Roth, D.\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "BenchmarkArithmeticWordProblems_2015"
      }
    },
    {
      "id": "MAWPS_2017",
      "label": "MAWPS",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MAWPS_2017",
        "name": "MAWPS",
        "description": "Dataset of arithmetic word problems",
        "domain": "Mathematics",
        "size": 2373,
        "year": "2017",
        "creators": "[\"Lei Wang\", \"Dongxiang Zhang\", \"Jipeng Zhang\", \"Xing Xu\", \"Lianli Gao\", \"Bing Tian Dai\", \"Heng Tao Shen\"]",
        "entity_type": "Dataset",
        "task_id": "e73f8a48-aefd-44b0-8021-38c2d3432ee1",
        "source": "引文",
        "entity_id": "MAWPS_2017"
      }
    },
    {
      "id": "Ontonotes-5.0_2013",
      "label": "Ontonotes-5.0",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Ontonotes-5.0_2013",
        "name": "Ontonotes-5.0",
        "description": "A large-scale dataset for coreference resolution and other NLP tasks",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2013",
        "creators": "[\"Various contributors\"]",
        "entity_type": "Dataset",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "entity_id": "Ontonotes-5.0_2013"
      }
    },
    {
      "id": "ALGEBRA_PROBLEMS_2015",
      "label": "Algebra Problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "ALGEBRA_PROBLEMS_2015",
        "name": "Algebra Problems",
        "description": "A dataset of algebraic word problems",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2015",
        "creators": "[\"Koncel-Kedziorski, R.\", \"Hajishirzi, H.\", \"Sabharwal, A.\", \"Etzioni, O.\", \"Ang, S.D.\"]",
        "entity_type": "Dataset",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "entity_id": "ALGEBRA_PROBLEMS_2015"
      }
    },
    {
      "id": "BenchmarkArithmeticWordProblems_2016",
      "label": "Benchmark datasets of arithmetic word problems",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "BenchmarkArithmeticWordProblems_2016",
        "name": "Benchmark datasets of arithmetic word problems",
        "description": "Benchmark datasets used for evaluating arithmetic word problem solving algorithms",
        "domain": "Natural Language Processing",
        "size": 0,
        "year": "2016",
        "creators": "[\"Subhro Roy\", \"Dan Roth\"]",
        "entity_type": "Dataset",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "entity_id": "BenchmarkArithmeticWordProblems_2016"
      }
    },
    {
      "id": "Math23K_2018",
      "label": "Math23K",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Math23K_2018",
        "name": "Math23K",
        "description": "Large dataset for arithmetic word problems",
        "domain": "Mathematics",
        "size": 23164,
        "year": "2018",
        "creators": "[\"Lei Wang\", \"Dongxiang Zhang\", \"Jipeng Zhang\", \"Xing Xu\", \"Lianli Gao\", \"Bing Tian Dai\", \"Heng Tao Shen\"]",
        "entity_type": "Dataset",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "entity_id": "Math23K_2018"
      }
    },
    {
      "id": "MAWPS_2018",
      "label": "MAWPS",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "MAWPS_2018",
        "name": "MAWPS",
        "description": "Dataset for arithmetic word problems",
        "domain": "Mathematics",
        "size": 2373,
        "year": "2018",
        "creators": "[\"Lei Wang\", \"Dongxiang Zhang\", \"Jipeng Zhang\", \"Xing Xu\", \"Lianli Gao\", \"Bing Tian Dai\", \"Heng Tao Shen\"]",
        "entity_type": "Dataset",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "entity_id": "MAWPS_2018"
      }
    },
    {
      "id": "Abstract_Scene_Dataset_2017",
      "label": "Abstract Scene Dataset",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "Abstract_Scene_Dataset_2017",
        "name": "Abstract Scene Dataset",
        "description": "A dataset of realistic abstract scenes to enable research focused on high-level reasoning required for VQA.",
        "domain": "Visual Question Answering",
        "size": 50000,
        "year": "2017",
        "creators": "[\"Stanislaw Antol\", \"Aishwarya Agrawal\", \"Jiasen Lu\", \"Margaret Mitchell\", \"Dhruv Batra\", \"C. Lawrence Zitnick\", \"Devi Parikh\"]",
        "entity_type": "Dataset",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "entity_id": "Abstract_Scene_Dataset_2017"
      }
    },
    {
      "id": "VerbalIQTestQuestions_2016",
      "label": "Verbal IQ Test Questions",
      "type": "Dataset",
      "entity_type": "Dataset",
      "data": {
        "dataset_id": "VerbalIQTestQuestions_2016",
        "name": "Verbal IQ Test Questions",
        "description": "Verbal comprehension questions in IQ tests",
        "domain": "Psychology, Education, Career Development",
        "size": 0,
        "year": "2016",
        "creators": "[\"Huazheng Wang\", \"Fei Tian\", \"Bin Gao\", \"Chengjieren Zhu\", \"Jiang Bian\", \"Tie-Yan Liu\"]",
        "entity_type": "Dataset",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "entity_id": "VerbalIQTestQuestions_2016"
      }
    },
    {
      "id": "Accuracy_Arithmetic",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_Arithmetic",
        "name": "Accuracy",
        "description": "Proportion of correctly solved arithmetic word problems",
        "category": "Arithmetic Word Problem Solving",
        "formula": "Correctly solved problems / Total problems",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "综述",
        "tasks": null,
        "entity_id": "Accuracy_Arithmetic"
      }
    },
    {
      "id": "Accuracy_ArithmeticWordProblems",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_ArithmeticWordProblems",
        "name": "Accuracy",
        "description": "Accuracy of solving arithmetic word problems",
        "category": "Arithmetic Word Problem Solving",
        "formula": "Correctly solved problems / Total problems",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "Accuracy_ArithmeticWordProblems"
      }
    },
    {
      "id": "Accuracy_Classification",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_Classification",
        "name": "Accuracy",
        "description": "Classification accuracy",
        "category": "Classification Evaluation",
        "formula": "Correct classifications / Total classifications",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "Accuracy_Classification"
      }
    },
    {
      "id": "Accuracy_Dependency_Parsing",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_Dependency_Parsing",
        "name": "Accuracy",
        "description": "Accuracy of dependency parsing in matching dependency parse structures to ground truth annotations.",
        "category": "Dependency Parsing",
        "formula": "Number of Correct Structures / Total Number of Structures",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Accuracy_Dependency_Parsing"
      }
    },
    {
      "id": "Accuracy_Detection",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_Detection",
        "name": "Accuracy",
        "description": "Detection accuracy",
        "category": "Detection Evaluation",
        "formula": "Correct detections / Total detections",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Accuracy_Detection"
      }
    },
    {
      "id": "Accuracy_EquationSet",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_EquationSet",
        "name": "Accuracy",
        "description": "方程组问题求解的准确率",
        "category": "分类评估",
        "formula": "正确分类样本数/总样本数",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "综述",
        "tasks": "[]",
        "entity_id": "Accuracy_EquationSet"
      }
    },
    {
      "id": "Accuracy_Geometry",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_Geometry",
        "name": "Accuracy",
        "description": "Proportion of correctly solved geometry problems",
        "category": "Geometry Problem Solving",
        "formula": "Correctly Solved Problems / Total Problems",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "Accuracy_Geometry"
      }
    },
    {
      "id": "Accuracy_Math",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_Math",
        "name": "Accuracy",
        "description": "Accuracy of the generated mathematical word problems",
        "category": "Math Problem Generation",
        "formula": "Number of Correct Problems / Total Number of Generated Problems",
        "entity_type": "Metric",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "tasks": null,
        "entity_id": "Accuracy_Math"
      }
    },
    {
      "id": "Accuracy_Math_Word_Problems",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_Math_Word_Problems",
        "name": "Accuracy",
        "description": "Proportion of correct answers",
        "category": "Math Word Problem Solving",
        "formula": "Correct Answers / Total Questions",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Accuracy_Math_Word_Problems"
      }
    },
    {
      "id": "Accuracy_MathProblemSolving",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_MathProblemSolving",
        "name": "Accuracy",
        "description": "Proportion of correctly solved math word problems",
        "category": "Math Word Problem Solving",
        "formula": "Number of Correct Solutions / Total Number of Problems",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Accuracy_MathProblemSolving"
      }
    },
    {
      "id": "Accuracy_Multiple-Choice",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_Multiple-Choice",
        "name": "Accuracy",
        "description": "Accuracy for multiple-choice task",
        "category": "Classification Evaluation",
        "formula": "Number of correct answers / Total number of questions",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Accuracy_Multiple-Choice"
      }
    },
    {
      "id": "Accuracy_Open-Answer",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_Open-Answer",
        "name": "Accuracy",
        "description": "Accuracy for open-answer task",
        "category": "Classification Evaluation",
        "formula": "min(# humans that provided that answer / 3, 1)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Accuracy_Open-Answer"
      }
    },
    {
      "id": "Accuracy_SymmetryJudgment",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_SymmetryJudgment",
        "name": "Accuracy",
        "description": "Accuracy of symmetry judgment in polygon figures",
        "category": "Symmetry Detection",
        "formula": "Correctly identified symmetric polygons / Total number of polygons",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Accuracy_SymmetryJudgment"
      }
    },
    {
      "id": "Accuracy_VerbalComprehension",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_VerbalComprehension",
        "name": "Accuracy",
        "description": "Accuracy of solving verbal comprehension questions",
        "category": "Classification",
        "formula": "Correctly Solved Questions / Total Questions",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "Accuracy_VerbalComprehension"
      }
    },
    {
      "id": "Accuracy_VQA",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_VQA",
        "name": "Accuracy",
        "description": "The proportion of correctly answered questions.",
        "category": "VQA Evaluation",
        "formula": "Correct Answers / Total Questions",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "Accuracy_VQA"
      }
    },
    {
      "id": "Accuracy_WordAnalogy",
      "label": "Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Accuracy_WordAnalogy",
        "name": "Accuracy",
        "description": "Accuracy on the word analogy task",
        "category": "Word Analogy Evaluation",
        "formula": "Correct answers / Total questions",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Accuracy_WordAnalogy"
      }
    },
    {
      "id": "Answer_Accuracy",
      "label": "Answer Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Answer_Accuracy",
        "name": "Answer Accuracy",
        "description": "Evaluates how often the generated numerical answer is correct",
        "category": "Numerical Answer Evaluation",
        "formula": "Number of Correct Answers / Total Number of Answers",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Answer_Accuracy"
      }
    },
    {
      "id": "AUC_ROC",
      "label": "AUC",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "AUC_ROC",
        "name": "AUC",
        "description": "ROC曲线下面积",
        "category": "分类评估",
        "formula": "ROC曲线下的面积",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "AUC_ROC"
      }
    },
    {
      "id": "B-Cubed_F_Score",
      "label": "B-Cubed F-Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "B-Cubed_F_Score",
        "name": "B-Cubed F-Score",
        "description": "F-score variant for coreference resolution",
        "category": "Coreference Resolution",
        "formula": "2 * (precision * recall) / (precision + recall)",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "B-Cubed_F_Score"
      }
    },
    {
      "id": "B-Cubed_F_Score_Coreference",
      "label": "B-Cubed F-Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "B-Cubed_F_Score_Coreference",
        "name": "B-Cubed F-Score",
        "description": "F-Score for coreference resolution",
        "category": "Coreference Resolution",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "B-Cubed_F_Score_Coreference"
      }
    },
    {
      "id": "B-Cubed_F-Score_Coreference",
      "label": "B-Cubed F-Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "B-Cubed_F-Score_Coreference",
        "name": "B-Cubed F-Score",
        "description": "A measure of the overlap of predicted clusters and true clusters",
        "category": "Coreference Evaluation",
        "formula": "Harmonic mean of precision and recall",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "B-Cubed_F-Score_Coreference"
      }
    },
    {
      "id": "B3_Coreference",
      "label": "b3",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "B3_Coreference",
        "name": "b3",
        "description": "For each mention, form the intersection between the predicted cluster and the true cluster for that mention",
        "category": "Coreference Evaluation",
        "formula": "F1 = 2 * (precision * recall) / (precision + recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "B3_Coreference"
      }
    },
    {
      "id": "B3_Scoring",
      "label": "B3",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "B3_Scoring",
        "name": "B3",
        "description": "Uses the intersection between predicted and gold clusters for a given mention to mark correct mentions and the sizes of the predicted and gold clusters as denominators for precision and recall",
        "category": "Coreference Resolution",
        "formula": "Not specified in the paper",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "B3_Scoring"
      }
    },
    {
      "id": "BCUB_Coreference",
      "label": "BCUB",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "BCUB_Coreference",
        "name": "BCUB",
        "description": "A metric for evaluating coreference resolution systems.",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "BCUB_Coreference"
      }
    },
    {
      "id": "BLEU_Translation",
      "label": "BLEU",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "BLEU_Translation",
        "name": "BLEU",
        "description": "Bilingual Evaluation Understudy",
        "category": "Machine Translation Evaluation",
        "formula": "Exponential of the weighted sum of modified n-gram precision and brevity penalty",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "BLEU_Translation"
      }
    },
    {
      "id": "BLEUScore_Translation",
      "label": "BLEU Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "BLEUScore_Translation",
        "name": "BLEU Score",
        "description": "Bilingual Evaluation Understudy Score",
        "category": "Translation Evaluation",
        "formula": "BP * exp(sum_{n=1}^N w_n log p_n)",
        "entity_type": "Metric",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "tasks": null,
        "entity_id": "BLEUScore_Translation"
      }
    },
    {
      "id": "CEAF_Coreference",
      "label": "CEAF",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "CEAF_Coreference",
        "name": "CEAF",
        "description": "Scores the best match between true and predicted clusters using a similarity function",
        "category": "Coreference Evaluation",
        "formula": "Best match using φ3 similarity function",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "CEAF_Coreference"
      }
    },
    {
      "id": "CEAF_EntityBased",
      "label": "Entity-based CEAF",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "CEAF_EntityBased",
        "name": "Entity-based CEAF",
        "description": "A metric for evaluating coreference resolution systems.",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "CEAF_EntityBased"
      }
    },
    {
      "id": "Complete_Correct_Parse",
      "label": "Complete",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Complete_Correct_Parse",
        "name": "Complete",
        "description": "Percentage of sentences in which all tokens were assigned their correct parent",
        "category": "Dependency Parsing Evaluation",
        "formula": "Sentences with all correct token assignments / Total sentences",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Complete_Correct_Parse"
      }
    },
    {
      "id": "Correct_Solution_Rate_Understanding",
      "label": "Correct Solution Rate",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Correct_Solution_Rate_Understanding",
        "name": "Correct Solution Rate",
        "description": "The proportion of correctly solved word problems.",
        "category": "Problem Solving Performance",
        "formula": "Number of Correct Solutions / Total Number of Problems",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Correct_Solution_Rate_Understanding"
      }
    },
    {
      "id": "Correctness_Completeness",
      "label": "Correctness and Completeness",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Correctness_Completeness",
        "name": "Correctness and Completeness",
        "description": "Validation of the model's correctness and completeness when supplied as input to a physics problem-solving program",
        "category": "Model Validation",
        "formula": "",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Correctness_Completeness"
      }
    },
    {
      "id": "Correctness_Physics",
      "label": "Correctness",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Correctness_Physics",
        "name": "Correctness",
        "description": "Correctness of the model's solution to physics problems",
        "category": "Physics Problem Solving",
        "formula": "Number of Correct Solutions / Total Number of Problems",
        "entity_type": "Metric",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "tasks": null,
        "entity_id": "Correctness_Physics"
      }
    },
    {
      "id": "CorrectnessOfSolution_ProblemSolving",
      "label": "Correctness of Solution",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "CorrectnessOfSolution_ProblemSolving",
        "name": "Correctness of Solution",
        "description": "Whether the multi-step addition and subtraction word problems are correctly solved",
        "category": "Problem Solving Evaluation",
        "formula": "Number of Correct Solutions / Total Number of Problems",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "CorrectnessOfSolution_ProblemSolving"
      }
    },
    {
      "id": "Count_ColinearPoints",
      "label": "Count of Colinear Points",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Count_ColinearPoints",
        "name": "Count of Colinear Points",
        "description": "Number of colinear points detected by the Hough Transformation",
        "category": "Line Detection",
        "formula": "k figure points lie along the line whose normal parameters are (θ, p)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Count_ColinearPoints"
      }
    },
    {
      "id": "DeductiveSteps_Classification",
      "label": "Deductive Steps",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "DeductiveSteps_Classification",
        "name": "Deductive Steps",
        "description": "The number of hyperedges in the problem hypergraph.",
        "category": "Classification Assessment",
        "formula": "Number of hyperedges",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "DeductiveSteps_Classification"
      }
    },
    {
      "id": "DependencyAccuracy_Classification",
      "label": "Dependency Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "DependencyAccuracy_Classification",
        "name": "Dependency Accuracy",
        "description": "Measures the accuracy of dependency relations in a parse.",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly parsed dependencies / Total dependencies",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "DependencyAccuracy_Classification"
      }
    },
    {
      "id": "Efficiency_GeometryRuleApplications",
      "label": "Efficiency",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Efficiency_GeometryRuleApplications",
        "name": "Efficiency",
        "description": "Efficiency of Geometry Rule Applications",
        "category": "Search Space Evaluation",
        "formula": "Number of Inferences per Layer",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Efficiency_GeometryRuleApplications"
      }
    },
    {
      "id": "Entropy_AnswerDistribution",
      "label": "Entropy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Entropy_AnswerDistribution",
        "name": "Entropy",
        "description": "Measure of uncertainty in the answer distribution",
        "category": "Distribution Analysis",
        "formula": "-sum(p(x) * log(p(x)))",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Entropy_AnswerDistribution"
      }
    },
    {
      "id": "Equation_Accuracy",
      "label": "Equation Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Equation_Accuracy",
        "name": "Equation Accuracy",
        "description": "Measures how often the system generates the correct equation system",
        "category": "Equation Generation",
        "formula": "Number of Correct Equation Systems / Total Number of Equation Systems",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Equation_Accuracy"
      }
    },
    {
      "id": "EquationLikelihood",
      "label": "Equation Likelihood",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "EquationLikelihood",
        "name": "Equation Likelihood",
        "description": "The likelihood of an equation being correct",
        "category": "Equation Evaluation",
        "formula": "Not specified",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "EquationLikelihood"
      }
    },
    {
      "id": "ErrorRate_Difficulty",
      "label": "Error Rate",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "ErrorRate_Difficulty",
        "name": "Error Rate",
        "description": "Measure of the difficulty level of generated problems",
        "category": "Difficulty Evaluation",
        "formula": "Percentage of incorrect answers",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "ErrorRate_Difficulty"
      }
    },
    {
      "id": "ErrorSignalStability_ErrorFlow",
      "label": "Error Signal Stability",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "ErrorSignalStability_ErrorFlow",
        "name": "Error Signal Stability",
        "description": "Stability of error signals over time.",
        "category": "Error Flow Evaluation",
        "formula": "Magnitude of error signals over time",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "ErrorSignalStability_ErrorFlow"
      }
    },
    {
      "id": "F1_Evaluation",
      "label": "F1",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Evaluation",
        "name": "F1",
        "description": "The harmonic mean of precision and recall",
        "category": "Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1_Evaluation"
      }
    },
    {
      "id": "F1_NEL",
      "label": "F1",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_NEL",
        "name": "F1",
        "description": "Harmonic mean of precision and recall",
        "category": "Named-entity linking evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1_NEL"
      }
    },
    {
      "id": "F1_Score",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Classification Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "综述",
        "tasks": null,
        "entity_id": "F1_Score"
      }
    },
    {
      "id": "F1_Score_Aligning_Visual_Elements",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_Aligning_Visual_Elements",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Alignment Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1_Score_Aligning_Visual_Elements"
      }
    },
    {
      "id": "F1_Score_Classification",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_Classification",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Classification Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "94afd1a4-87cf-461f-bf45-7e59af553b6e",
        "source": "综述",
        "tasks": null,
        "entity_id": "F1_Score_Classification"
      }
    },
    {
      "id": "F1_Score_Coreference",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_Coreference",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Coreference Resolution",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "F1_Score_Coreference"
      }
    },
    {
      "id": "F1_Score_EquationSet",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_EquationSet",
        "name": "F1 Score",
        "description": "方程组问题求解的F1分数",
        "category": "分类评估",
        "formula": "2 * (精确率 * 召回率) / (精确率 + 召回率)",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "综述",
        "tasks": "[]",
        "entity_id": "F1_Score_EquationSet"
      }
    },
    {
      "id": "F1_Score_Identifying_Primitives",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_Identifying_Primitives",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Classification Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1_Score_Identifying_Primitives"
      }
    },
    {
      "id": "F1_Score_NER",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_NER",
        "name": "F1 Score",
        "description": "F1 score on the named entity recognition task",
        "category": "Named Entity Recognition Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1_Score_NER"
      }
    },
    {
      "id": "F1_Score_Parsing",
      "label": "F1分数",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_Parsing",
        "name": "F1分数",
        "description": "综合考虑精确率和召回率的评估指标",
        "category": "解析评估",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "F1_Score_Parsing"
      }
    },
    {
      "id": "F1_Score_QA",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_QA",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall.",
        "category": "Question Answering Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1_Score_QA"
      }
    },
    {
      "id": "F1_Score_Quantitative_Reasoning",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_Quantitative_Reasoning",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Quantitative Reasoning",
        "formula": "2 * (precision * recall) / (precision + recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1_Score_Quantitative_Reasoning"
      }
    },
    {
      "id": "F1_Score_Text_Interpretation",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1_Score_Text_Interpretation",
        "name": "F1 Score",
        "description": "F1 score of text interpretation in deriving literals for geometry question texts.",
        "category": "Text Interpretation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1_Score_Text_Interpretation"
      }
    },
    {
      "id": "F1Score_Classification",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1Score_Classification",
        "name": "F1 Score",
        "description": "F1得分",
        "category": "分类评估",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1Score_Classification"
      }
    },
    {
      "id": "F1Score_Parsing",
      "label": "F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "F1Score_Parsing",
        "name": "F1 Score",
        "description": "Harmonic mean of precision and recall",
        "category": "Parsing Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "F1Score_Parsing"
      }
    },
    {
      "id": "Labeled_F1_Score_Parsing",
      "label": "Labeled F1 Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Labeled_F1_Score_Parsing",
        "name": "Labeled F1 Score",
        "description": "F1 score for labeled syntactic parsing",
        "category": "Syntactic Parsing Evaluation",
        "formula": "2 * (Precision * Recall) / (Precision + Recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Labeled_F1_Score_Parsing"
      }
    },
    {
      "id": "LabeledAttachmentScore_Parsing",
      "label": "Labeled Attachment Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "LabeledAttachmentScore_Parsing",
        "name": "Labeled Attachment Score",
        "description": "Dependency parsing score with labels",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correct Labeled Arcs / Total Arcs",
        "entity_type": "Metric",
        "task_id": "94afd1a4-87cf-461f-bf45-7e59af553b6e",
        "source": "引文",
        "tasks": null,
        "entity_id": "LabeledAttachmentScore_Parsing"
      }
    },
    {
      "id": "LAS_Parsing",
      "label": "Labeled Attachment Score (LAS)",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "LAS_Parsing",
        "name": "Labeled Attachment Score (LAS)",
        "description": "The proportion of words that are attached to their correct heads and have the correct label",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly attached and labeled words / Total words",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "LAS_Parsing"
      }
    },
    {
      "id": "MUC_Coreference",
      "label": "MUC",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "MUC_Coreference",
        "name": "MUC",
        "description": "A metric for evaluating coreference resolution systems.",
        "category": "Coreference Evaluation",
        "formula": "Not explicitly defined in the paper",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "MUC_Coreference"
      }
    },
    {
      "id": "MUC_F-Score_Coreference",
      "label": "MUC F-Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "MUC_F-Score_Coreference",
        "name": "MUC F-Score",
        "description": "Official MUC scoring algorithm",
        "category": "Coreference Evaluation",
        "formula": "Harmonic mean of precision and recall, counting precision errors by computing the minimum number of links that must be added and recall errors by the number of links that must be removed",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "MUC_F-Score_Coreference"
      }
    },
    {
      "id": "MUC_Scoring",
      "label": "MUC",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "MUC_Scoring",
        "name": "MUC",
        "description": "Measures how many predicted clusters need to be merged to cover the gold clusters",
        "category": "Coreference Resolution",
        "formula": "Not specified in the paper",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "MUC_Scoring"
      }
    },
    {
      "id": "MultipleChoiceAccuracy_VQA",
      "label": "Multiple Choice Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "MultipleChoiceAccuracy_VQA",
        "name": "Multiple Choice Accuracy",
        "description": "The proportion of correctly answered multiple-choice questions.",
        "category": "VQA Evaluation",
        "formula": "Correct Multiple Choice Answers / Total Multiple Choice Questions",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "MultipleChoiceAccuracy_VQA"
      }
    },
    {
      "id": "NumberOfGeneratedProblems_Generation",
      "label": "Number of Generated Problems",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "NumberOfGeneratedProblems_Generation",
        "name": "Number of Generated Problems",
        "description": "The number of geometry proof problems generated per figure.",
        "category": "Problem Generation Evaluation",
        "formula": "Total number of problems / Number of figures",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "NumberOfGeneratedProblems_Generation"
      }
    },
    {
      "id": "Pairwise_Coreference",
      "label": "Pairwise",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Pairwise_Coreference",
        "name": "Pairwise",
        "description": "Measures the accuracy of predicting pairs of mentions as coreferent",
        "category": "Coreference evaluation",
        "formula": "Correctly predicted pairs / Total pairs",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Pairwise_Coreference"
      }
    },
    {
      "id": "Pairwise_F1_Coreference",
      "label": "Pairwise F1",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Pairwise_F1_Coreference",
        "name": "Pairwise F1",
        "description": "Computed over mention pairs in the same entity cluster",
        "category": "Coreference Resolution",
        "formula": "2 * (precision * recall) / (precision + recall)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Pairwise_F1_Coreference"
      }
    },
    {
      "id": "Perplexity_LanguageModeling",
      "label": "Perplexity",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Perplexity_LanguageModeling",
        "name": "Perplexity",
        "description": "Measure of how well a probability distribution predicts a sample",
        "category": "Language Modeling Evaluation",
        "formula": "exp(-1/N * sum(log p(x_i))",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Perplexity_LanguageModeling"
      }
    },
    {
      "id": "Precision_Classification",
      "label": "Precision",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Precision_Classification",
        "name": "Precision",
        "description": "精确率",
        "category": "分类评估",
        "formula": "真正例 / （真正例 + 假正例）",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Precision_Classification"
      }
    },
    {
      "id": "Precision_EquationSet",
      "label": "Precision",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Precision_EquationSet",
        "name": "Precision",
        "description": "方程组问题求解的精确率",
        "category": "分类评估",
        "formula": "真正例/(真正例+假正例)",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "综述",
        "tasks": "[]",
        "entity_id": "Precision_EquationSet"
      }
    },
    {
      "id": "Precision_Evaluation",
      "label": "Precision",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Precision_Evaluation",
        "name": "Precision",
        "description": "The proportion of true positive results among the total predicted positives",
        "category": "Evaluation",
        "formula": "True Positives / (True Positives + False Positives)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Precision_Evaluation"
      }
    },
    {
      "id": "Precision_QA",
      "label": "Precision",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Precision_QA",
        "name": "Precision",
        "description": "Percentage of produced queries with correct answers.",
        "category": "Question Answering Evaluation",
        "formula": "Correctly answered queries / Produced queries",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Precision_QA"
      }
    },
    {
      "id": "Precision_Quantitative_Reasoning",
      "label": "Precision",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Precision_Quantitative_Reasoning",
        "name": "Precision",
        "description": "Proportion of true positive predictions",
        "category": "Quantitative Reasoning",
        "formula": "True Positives / (True Positives + False Positives)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Precision_Quantitative_Reasoning"
      }
    },
    {
      "id": "Precision_Text_Interpretation",
      "label": "Precision",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Precision_Text_Interpretation",
        "name": "Precision",
        "description": "Precision of text interpretation in deriving literals for geometry question texts.",
        "category": "Text Interpretation",
        "formula": "True Positives / (True Positives + False Positives)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Precision_Text_Interpretation"
      }
    },
    {
      "id": "ProblemSolvingAccuracy_Arithmetic",
      "label": "Problem Solving Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "ProblemSolvingAccuracy_Arithmetic",
        "name": "Problem Solving Accuracy",
        "description": "Accuracy of solving arithmetic word problems",
        "category": "Arithmetic Problem Solving",
        "formula": "Correctly solved problems / Total problems",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "ProblemSolvingAccuracy_Arithmetic"
      }
    },
    {
      "id": "ProofLength_Classification",
      "label": "Proof Length",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "ProofLength_Classification",
        "name": "Proof Length",
        "description": "The diameter of the problem hypergraph.",
        "category": "Classification Assessment",
        "formula": "Diameter of the hypergraph",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "ProofLength_Classification"
      }
    },
    {
      "id": "ProofWidth_Classification",
      "label": "Proof Width",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "ProofWidth_Classification",
        "name": "Proof Width",
        "description": "The width of the problem hypergraph.",
        "category": "Classification Assessment",
        "formula": "Width of the hypergraph",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "ProofWidth_Classification"
      }
    },
    {
      "id": "QualitativeFactors_SymmetryJudgment",
      "label": "Qualitative Factors",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "QualitativeFactors_SymmetryJudgment",
        "name": "Qualitative Factors",
        "description": "Effect of qualitative visual structure on symmetry judgment",
        "category": "Symmetry Detection",
        "formula": "Significant effect of qualitative factors on accuracy",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "QualitativeFactors_SymmetryJudgment"
      }
    },
    {
      "id": "Recall_Classification",
      "label": "Recall",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Recall_Classification",
        "name": "Recall",
        "description": "召回率",
        "category": "分类评估",
        "formula": "真正例 / （真正例 + 假负例）",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Recall_Classification"
      }
    },
    {
      "id": "Recall_EquationSet",
      "label": "Recall",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Recall_EquationSet",
        "name": "Recall",
        "description": "方程组问题求解的召回率",
        "category": "分类评估",
        "formula": "真正例/(真正例+假负例)",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "综述",
        "tasks": "[]",
        "entity_id": "Recall_EquationSet"
      }
    },
    {
      "id": "Recall_Evaluation",
      "label": "Recall",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Recall_Evaluation",
        "name": "Recall",
        "description": "The proportion of true positive results among the total actual positives",
        "category": "Evaluation",
        "formula": "True Positives / (True Positives + False Negatives)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Recall_Evaluation"
      }
    },
    {
      "id": "Recall_QA",
      "label": "Recall",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Recall_QA",
        "name": "Recall",
        "description": "Percentage of total questions answered correctly.",
        "category": "Question Answering Evaluation",
        "formula": "Correctly answered questions / Total questions",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Recall_QA"
      }
    },
    {
      "id": "Recall_Quantitative_Reasoning",
      "label": "Recall",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Recall_Quantitative_Reasoning",
        "name": "Recall",
        "description": "Proportion of actual positives that are correctly identified",
        "category": "Quantitative Reasoning",
        "formula": "True Positives / (True Positives + False Negatives)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Recall_Quantitative_Reasoning"
      }
    },
    {
      "id": "Recall_Text_Interpretation",
      "label": "Recall",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Recall_Text_Interpretation",
        "name": "Recall",
        "description": "Recall of text interpretation in deriving literals for geometry question texts.",
        "category": "Text Interpretation",
        "formula": "True Positives / (True Positives + False Negatives)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Recall_Text_Interpretation"
      }
    },
    {
      "id": "Relax_Accuracy",
      "label": "Relax Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Relax_Accuracy",
        "name": "Relax Accuracy",
        "description": "Fraction of quantities or quantity pairs correctly predicted",
        "category": "Partial Evaluation",
        "formula": "Correct Predictions / Total Predictions",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Relax_Accuracy"
      }
    },
    {
      "id": "Root_Prediction",
      "label": "Root",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Root_Prediction",
        "name": "Root",
        "description": "Percentage of sentences in which the ROOT attachment is correct",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correct ROOT attachments / Total sentences",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Root_Prediction"
      }
    },
    {
      "id": "RunTimeStatistics_ProblemSolving",
      "label": "Run-Time Statistics",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "RunTimeStatistics_ProblemSolving",
        "name": "Run-Time Statistics",
        "description": "Statistics collected during the execution of the program, including number of production rules fired, number of conversions, number of LTM searches, and maximum number of chunks held over.",
        "category": "Program Performance Evaluation",
        "formula": "Not explicitly defined, but includes counts of various operations",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "RunTimeStatistics_ProblemSolving"
      }
    },
    {
      "id": "SAT_Score_Geometry",
      "label": "SAT Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "SAT_Score_Geometry",
        "name": "SAT Score",
        "description": "Score achieved on SAT geometry questions, penalized for wrong answers.",
        "category": "Test Performance",
        "formula": "Correctly answered questions - 0.25 * Incorrectly answered questions",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "SAT_Score_Geometry"
      }
    },
    {
      "id": "Score_GEOS",
      "label": "Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Score_GEOS",
        "name": "Score",
        "description": "Score on SAT geometry questions",
        "category": "Geometry Problem Solving",
        "formula": "Number of Correct Answers / Total Number of Questions",
        "entity_type": "Metric",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "tasks": null,
        "entity_id": "Score_GEOS"
      }
    },
    {
      "id": "SemanticAccuracy_Classification",
      "label": "Semantic Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "SemanticAccuracy_Classification",
        "name": "Semantic Accuracy",
        "description": "Accuracy on semantic analogical reasoning",
        "category": "Classification Evaluation",
        "formula": "Correct Semantic Analogies / Total Semantic Analogies",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "SemanticAccuracy_Classification"
      }
    },
    {
      "id": "Solution_Accuracy",
      "label": "Solution Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Solution_Accuracy",
        "name": "Solution Accuracy",
        "description": "Accuracy of the final solution to the math word problem",
        "category": "Math Word Problem Solving Evaluation",
        "formula": "Number of correctly solved problems / Total number of problems",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Solution_Accuracy"
      }
    },
    {
      "id": "Solution_Type_Accuracy",
      "label": "Solution Type Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Solution_Type_Accuracy",
        "name": "Solution Type Accuracy",
        "description": "Accuracy of identifying the correct solution type",
        "category": "Classification evaluation",
        "formula": "Correctly identified solution types / Total solution types",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Solution_Type_Accuracy"
      }
    },
    {
      "id": "SolutionAccuracy",
      "label": "Solution Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "SolutionAccuracy",
        "name": "Solution Accuracy",
        "description": "The accuracy of the solution to the algebraic word problem",
        "category": "Solution Evaluation",
        "formula": "Correct solutions / Total solutions",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "SolutionAccuracy"
      }
    },
    {
      "id": "SolutionAccuracy_Arithmetic",
      "label": "Solution Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "SolutionAccuracy_Arithmetic",
        "name": "Solution Accuracy",
        "description": "Accuracy of the solution provided by the model",
        "category": "Arithmetic Problem Solving",
        "formula": "Correct Solutions / Total Problems",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "SolutionAccuracy_Arithmetic"
      }
    },
    {
      "id": "SolutionAccuracy_Math",
      "label": "Solution Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "SolutionAccuracy_Math",
        "name": "Solution Accuracy",
        "description": "Accuracy of the solution to math word problems",
        "category": "Math Problem Solving",
        "formula": "Number of Correct Solutions / Total Number of Problems",
        "entity_type": "Metric",
        "task_id": "46c68399-2fb2-454a-8e02-858feecbdac0",
        "source": "引文",
        "tasks": null,
        "entity_id": "SolutionAccuracy_Math"
      }
    },
    {
      "id": "SpaceComplexity_Parsing",
      "label": "Space Complexity",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "SpaceComplexity_Parsing",
        "name": "Space Complexity",
        "description": "The memory required to parse a string using the algorithm",
        "category": "Algorithm Performance",
        "formula": "O(n^2)",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "SpaceComplexity_Parsing"
      }
    },
    {
      "id": "SpearmanRankCorrelation_WordSimilarity",
      "label": "Spearman Rank Correlation",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "SpearmanRankCorrelation_WordSimilarity",
        "name": "Spearman Rank Correlation",
        "description": "Spearman rank correlation on word similarity tasks",
        "category": "Word Similarity Evaluation",
        "formula": "Correlation between ranked word similarities and human judgments",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "SpearmanRankCorrelation_WordSimilarity"
      }
    },
    {
      "id": "StatisticalIndistinguishability_Authenticity",
      "label": "Statistical Indistinguishability",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "StatisticalIndistinguishability_Authenticity",
        "name": "Statistical Indistinguishability",
        "description": "Measure of whether generated problems are statistically indistinguishable from textbook problems",
        "category": "Authenticity Evaluation",
        "formula": "Paired t-test and Chi-square test of independence",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "StatisticalIndistinguishability_Authenticity"
      }
    },
    {
      "id": "Strict_Accuracy",
      "label": "Strict Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Strict_Accuracy",
        "name": "Strict Accuracy",
        "description": "Fraction of problems where all quantities or quantity pairs were correctly classified",
        "category": "Complete Evaluation",
        "formula": "Fully Correct Problems / Total Problems",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Strict_Accuracy"
      }
    },
    {
      "id": "Success_Rate_Semantic_Analysis",
      "label": "Success Rate",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "Success_Rate_Semantic_Analysis",
        "name": "Success Rate",
        "description": "Rate of successful semantic interpretation of diagram elements.",
        "category": "Semantic Analysis Evaluation",
        "formula": "Successful Interpretations / Total Interpretations",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "Success_Rate_Semantic_Analysis"
      }
    },
    {
      "id": "SuccessRate_Classification",
      "label": "Success Rate",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "SuccessRate_Classification",
        "name": "Success Rate",
        "description": "Percentage of successful trials in classification tasks.",
        "category": "Classification Evaluation",
        "formula": "Number of successful trials / Total number of trials",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "SuccessRate_Classification"
      }
    },
    {
      "id": "SyntacticAccuracy_Classification",
      "label": "Syntactic Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "SyntacticAccuracy_Classification",
        "name": "Syntactic Accuracy",
        "description": "Accuracy on syntactic analogical reasoning",
        "category": "Classification Evaluation",
        "formula": "Correct Syntactic Analogies / Total Syntactic Analogies",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "SyntacticAccuracy_Classification"
      }
    },
    {
      "id": "TimeComplexity_Parsing",
      "label": "Time Complexity",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "TimeComplexity_Parsing",
        "name": "Time Complexity",
        "description": "The time required to parse a string using the algorithm",
        "category": "Algorithm Performance",
        "formula": "O(n^3) for general context-free grammars, O(n^2) for unambiguous grammars, O(n) for bounded state grammars",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "TimeComplexity_Parsing"
      }
    },
    {
      "id": "TimeTakenToGenerateProblems_Efficiency",
      "label": "Time Taken to Generate Problems",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "TimeTakenToGenerateProblems_Efficiency",
        "name": "Time Taken to Generate Problems",
        "description": "The average time taken to generate problems per figure.",
        "category": "Efficiency Evaluation",
        "formula": "Total time / Number of figures",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "TimeTakenToGenerateProblems_Efficiency"
      }
    },
    {
      "id": "TrainingTime_Performance",
      "label": "Training Time",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "TrainingTime_Performance",
        "name": "Training Time",
        "description": "Time required to train the model successfully.",
        "category": "Performance Evaluation",
        "formula": "Total time taken to achieve stopping criterion",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "TrainingTime_Performance"
      }
    },
    {
      "id": "UAS_Parsing",
      "label": "Unlabeled Attachment Score (UAS)",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "UAS_Parsing",
        "name": "Unlabeled Attachment Score (UAS)",
        "description": "The proportion of words that are attached to their correct heads, ignoring labels",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correctly attached words / Total words",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "UAS_Parsing"
      }
    },
    {
      "id": "UnifiedModel_Accuracy",
      "label": "Unified Model Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "UnifiedModel_Accuracy",
        "name": "Unified Model Accuracy",
        "description": "Accuracy of the unified model that combines information from both text and diagram",
        "category": "Model Evaluation",
        "formula": "",
        "entity_type": "Metric",
        "task_id": "dba6b51f-5d11-43f0-9528-026f36379e88",
        "source": "引文",
        "tasks": null,
        "entity_id": "UnifiedModel_Accuracy"
      }
    },
    {
      "id": "UnlabeledAttachmentScore_Parsing",
      "label": "Unlabeled Attachment Score",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "UnlabeledAttachmentScore_Parsing",
        "name": "Unlabeled Attachment Score",
        "description": "Dependency parsing score without labels",
        "category": "Dependency Parsing Evaluation",
        "formula": "Correct Arcs / Total Arcs",
        "entity_type": "Metric",
        "task_id": "94afd1a4-87cf-461f-bf45-7e59af553b6e",
        "source": "引文",
        "tasks": null,
        "entity_id": "UnlabeledAttachmentScore_Parsing"
      }
    },
    {
      "id": "VerbCategorizationAccuracy_Arithmetic",
      "label": "Verb Categorization Accuracy",
      "type": "Metric",
      "entity_type": "Metric",
      "data": {
        "metric_id": "VerbCategorizationAccuracy_Arithmetic",
        "name": "Verb Categorization Accuracy",
        "description": "Accuracy of categorizing verbs in arithmetic word problems",
        "category": "Natural Language Processing",
        "formula": "Correctly categorized verbs / Total verbs",
        "entity_type": "Metric",
        "task_id": "c870287d-a749-4441-8981-57bcdec13778",
        "source": "引文",
        "tasks": "[]",
        "entity_id": "VerbCategorizationAccuracy_Arithmetic"
      }
    },
    {
      "id": "Huang2018_NeuralMathWordProblemSolver",
      "label": "Huang2018_NeuralMathWordProblemSolver",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Huang2018_NeuralMathWordProblemSolver",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Sachan2017_TextbookKnowledge",
      "label": "Sachan2017_TextbookKnowledge",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Sachan2017_TextbookKnowledge",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Roth2004_LinearProgrammingFormulation",
      "label": "Roth2004_LinearProgrammingFormulation",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Roth2004_LinearProgrammingFormulation",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Soon2001",
      "label": "Soon2001",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Soon2001",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "McDonald2005_MSTParser",
      "label": "McDonald2005_MSTParser",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "McDonald2005_MSTParser",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Sagae2006b_ParserCombination",
      "label": "Sagae2006b_ParserCombination",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Sagae2006b_ParserCombination",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "CL3M",
      "label": "CL3M",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "CL3M",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "MAWPS-S",
      "label": "MAWPS-S",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "MAWPS-S",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "SingleEQ",
      "label": "SingleEQ",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "SingleEQ",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "DosSantos2016_AttentivePoolingNetworks",
      "label": "DosSantos2016_AttentivePoolingNetworks",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "DosSantos2016_AttentivePoolingNetworks",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Ng2002_PairwiseModel",
      "label": "Ng2002_PairwiseModel",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Ng2002_PairwiseModel",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "High-ConfidenceCorpus_2015",
      "label": "High-ConfidenceCorpus_2015",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "High-ConfidenceCorpus_2015",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Henderson2007_SigmoidBeliefNetworks",
      "label": "Henderson2007_SigmoidBeliefNetworks",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Henderson2007_SigmoidBeliefNetworks",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Collins2003_HeadDrivenModel",
      "label": "Collins2003_HeadDrivenModel",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Collins2003_HeadDrivenModel",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "CEAF",
      "label": "CEAF",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "CEAF",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Collins2002_DiscriminativeTraining",
      "label": "Collins2002_DiscriminativeTraining",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Collins2002_DiscriminativeTraining",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "SATGeometryQuestions",
      "label": "SATGeometryQuestions",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "SATGeometryQuestions",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Geometry_Textbooks",
      "label": "Geometry_Textbooks",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Geometry_Textbooks",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Chinese_Arithmetic_Problems",
      "label": "Chinese_Arithmetic_Problems",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Chinese_Arithmetic_Problems",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Koo2008_HigherOrderFeatures",
      "label": "Koo2008_HigherOrderFeatures",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Koo2008_HigherOrderFeatures",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Collobert2011_DeepLearningParsing",
      "label": "Collobert2011_DeepLearningParsing",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Collobert2011_DeepLearningParsing",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "MathDQN",
      "label": "MathDQN",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "MathDQN",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Yu2009_StructuralSVM",
      "label": "Yu2009_StructuralSVM",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Yu2009_StructuralSVM",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Shen2007_BidirectionalIncrementalConstruction",
      "label": "Shen2007_BidirectionalIncrementalConstruction",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Shen2007_BidirectionalIncrementalConstruction",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Math23K",
      "label": "Math23K",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Math23K",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Koncel2015_ExpressionTree",
      "label": "Koncel2015_ExpressionTree",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Koncel2015_ExpressionTree",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "MUC",
      "label": "MUC",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "MUC",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Dolphin-S",
      "label": "Dolphin-S",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Dolphin-S",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Nivre2007_SharedTask",
      "label": "Nivre2007_SharedTask",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Nivre2007_SharedTask",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Hill2016_LearningDistributedRepresentations",
      "label": "Hill2016_LearningDistributedRepresentations",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Hill2016_LearningDistributedRepresentations",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Duchi2011_AdaptiveSubgradient",
      "label": "Duchi2011_AdaptiveSubgradient",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Duchi2011_AdaptiveSubgradient",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Soon2001_PairwiseModel",
      "label": "Soon2001_PairwiseModel",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Soon2001_PairwiseModel",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "CL3M_2013",
      "label": "CL3M_2013",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "CL3M_2013",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Carreras2007_ProjectivizationProcedure",
      "label": "Carreras2007_ProjectivizationProcedure",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Carreras2007_ProjectivizationProcedure",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Munkhdalai2016_NeuralTreeIndexers",
      "label": "Munkhdalai2016_NeuralTreeIndexers",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Munkhdalai2016_NeuralTreeIndexers",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Garg2011_TemporalRestrictedBoltzmanMachine",
      "label": "Garg2011_TemporalRestrictedBoltzmanMachine",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Garg2011_TemporalRestrictedBoltzmanMachine",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Chinese_Math_Problems",
      "label": "Chinese_Math_Problems",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Chinese_Math_Problems",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "DRAW1K_2015",
      "label": "DRAW1K_2015",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "DRAW1K_2015",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Chinese_Arithmetic_Word_Problems_2015",
      "label": "Chinese_Arithmetic_Word_Problems_2015",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Chinese_Arithmetic_Word_Problems_2015",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "MSTParser",
      "label": "MSTParser",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "MSTParser",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Sagae2006a_BestFirstProbabilisticParser",
      "label": "Sagae2006a_BestFirstProbabilisticParser",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Sagae2006a_BestFirstProbabilisticParser",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "AI2_Translated_to_Arabic",
      "label": "AI2_Translated_to_Arabic",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "AI2_Translated_to_Arabic",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Bowman2016_FastUnifiedModel",
      "label": "Bowman2016_FastUnifiedModel",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Bowman2016_FastUnifiedModel",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "AllArith",
      "label": "AllArith",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "AllArith",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Nivre2006_MaltParser",
      "label": "Nivre2006_MaltParser",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Nivre2006_MaltParser",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Lee2016_SequentialShortTextClassification",
      "label": "Lee2016_SequentialShortTextClassification",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Lee2016_SequentialShortTextClassification",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "ACE",
      "label": "ACE",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "ACE",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Roth2010_MultiPassSieve",
      "label": "Roth2010_MultiPassSieve",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Roth2010_MultiPassSieve",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Yamada2003_HeadFindingRules",
      "label": "Yamada2003_HeadFindingRules",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Yamada2003_HeadFindingRules",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Ng2002",
      "label": "Ng2002",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Ng2002",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Huang2009_BilinguallyConstrainedParsing",
      "label": "Huang2009_BilinguallyConstrainedParsing",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Huang2009_BilinguallyConstrainedParsing",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "ALGES_2015",
      "label": "ALGES_2015",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "ALGES_2015",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "BCUB",
      "label": "BCUB",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "BCUB",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "DosSantos2014_DeepConvolutionalNeuralNetworks",
      "label": "DosSantos2014_DeepConvolutionalNeuralNetworks",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "DosSantos2014_DeepConvolutionalNeuralNetworks",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "MaltParser",
      "label": "MaltParser",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "MaltParser",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Bengtson2008_FeatureSelection",
      "label": "Bengtson2008_FeatureSelection",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Bengtson2008_FeatureSelection",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "F1 Score",
      "label": "F1 Score",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "F1 Score",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Palangi2016_DeepSentenceEmbedding",
      "label": "Palangi2016_DeepSentenceEmbedding",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Palangi2016_DeepSentenceEmbedding",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Koo2008_SimpleSemiSupervised",
      "label": "Koo2008_SimpleSemiSupervised",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Koo2008_SimpleSemiSupervised",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Fernandes2012",
      "label": "Fernandes2012",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Fernandes2012",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "MALT",
      "label": "MALT",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "MALT",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Feng2015_ApplyingDeepLearning",
      "label": "Feng2015_ApplyingDeepLearning",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Feng2015_ApplyingDeepLearning",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "MST",
      "label": "MST",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "MST",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Zhang2008_BeamSearchParser",
      "label": "Zhang2008_BeamSearchParser",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Zhang2008_BeamSearchParser",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Huang2013_FeatureSelection",
      "label": "Huang2013_FeatureSelection",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Huang2013_FeatureSelection",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "EnhancedTemplateBasedSolver_2015",
      "label": "EnhancedTemplateBasedSolver_2015",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "EnhancedTemplateBasedSolver_2015",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Zhang2011_TransitionBasedParser",
      "label": "Zhang2011_TransitionBasedParser",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Zhang2011_TransitionBasedParser",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Tan2016_ImprovedRepresentationLearning",
      "label": "Tan2016_ImprovedRepresentationLearning",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Tan2016_ImprovedRepresentationLearning",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "MathDQN_2018",
      "label": "MathDQN_2018",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "MathDQN_2018",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Arabic_Arithmetic_Problems",
      "label": "Arabic_Arithmetic_Problems",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Arabic_Arithmetic_Problems",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Ontonotes",
      "label": "Ontonotes",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Ontonotes",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "YahooAnswers",
      "label": "YahooAnswers",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "YahooAnswers",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Henderson2004_NeuralNetworkParser",
      "label": "Henderson2004_NeuralNetworkParser",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Henderson2004_NeuralNetworkParser",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "LinearT6",
      "label": "LinearT6",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "LinearT6",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Charniak1969_ComputerSolution",
      "label": "Charniak1969_ComputerSolution",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Charniak1969_ComputerSolution",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "BLEU_Score_Translation",
      "label": "BLEU_Score_Translation",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "BLEU_Score_Translation",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "LinearT2",
      "label": "LinearT2",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "LinearT2",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Kushman2014_AlgebraSolver",
      "label": "Kushman2014_AlgebraSolver",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Kushman2014_AlgebraSolver",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Dolphin18K",
      "label": "Dolphin18K",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Dolphin18K",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "StandardPrimarySchoolTestQuestions",
      "label": "StandardPrimarySchoolTestQuestions",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "StandardPrimarySchoolTestQuestions",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "VQADataset",
      "label": "VQADataset",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "VQADataset",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Munkhdalai2016_NeuralSemanticEncoders",
      "label": "Munkhdalai2016_NeuralSemanticEncoders",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Munkhdalai2016_NeuralSemanticEncoders",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Hinton2012_Dropout",
      "label": "Hinton2012_Dropout",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Hinton2012_Dropout",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Accuracy",
      "label": "Accuracy",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Accuracy",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Bowman2015_LargeAnnotatedCorpus",
      "label": "Bowman2015_LargeAnnotatedCorpus",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Bowman2015_LargeAnnotatedCorpus",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Geometry_Problems",
      "label": "Geometry_Problems",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Geometry_Problems",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Nivre2004_ArcStandardSystem",
      "label": "Nivre2004_ArcStandardSystem",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Nivre2004_ArcStandardSystem",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    },
    {
      "id": "Stanford_CoreNLP",
      "label": "Stanford_CoreNLP",
      "type": "Unknown",
      "entity_type": "Unknown",
      "data": {
        "name": "Stanford_CoreNLP",
        "placeholder": true,
        "entity_type": "Unknown"
      }
    }
  ],
  "edges": [
    {
      "id": "edge_0",
      "source": "Roy2015_ExpressionTree",
      "target": "Wang2018_TranslatingMathWordProblem",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanism",
            "detail": "Expression Tree mechanism extended with Seq2Seq Model and Beam Search",
            "problem_addressed": "",
            "evidence": "Seq2SeqET extended the idea of DNS by using expression tree as the output sequence. In other words, it applied seq2seq model to convert the problem text into an expression tree, which can be viewed as a template.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_1",
      "source": "KoncelKedziorski2015_ALGES",
      "target": "Wang2018_TranslatingMathWordProblem",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Mechanism",
            "detail": "Optimized equation tree construction with Seq2Seq model",
            "problem_addressed": "",
            "evidence": "ALGES adopts a more brutal-force manner to exploit all the possible equation trees, which incurs higher computation cost. Wang et al. (2018) optimized this with Seq2Seq model.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_2",
      "source": "Huang2017_FGExpression",
      "target": "Zhang2019_DeepNeuralSolver",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Components",
            "detail": "Improved template parsing with deep learning",
            "problem_addressed": "",
            "evidence": "FG-Expression parses an equation template into fine-grained units, while DNS uses deep learning to avoid non-trivial feature engineering (Wang et al., 2017).",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_3",
      "source": "Wang2018_MathDQN",
      "target": "Zhang2019_DeepNeuralSolver",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology.Training_Strategy",
            "detail": "Extended MathDQN's reinforcement learning with deep Q-network",
            "problem_addressed": "",
            "evidence": "MathDQN models the tree construction as Markov Decision Process and leverages the strengths of deep Q-network (Wang et al., 2018). DNS further extends this with a seq2seq model.",
            "confidence": 0.89
          }
        ]
      }
    },
    {
      "id": "edge_4",
      "source": "Huang2018_NeuralMathWordProblemSolver",
      "target": "Zhang2019_DeepNeuralSolver",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Mechanism",
            "detail": "Optimized neural architecture with gated recurrent units",
            "problem_addressed": "",
            "evidence": "Neural Math Word Problem Solver uses GRU for efficient training, while DNS uses LSTM and GRU for better performance (Huang et al., 2018).",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_5",
      "source": "Roy2017_UnitDependencyGraph",
      "target": "Zhang2019_DeepNeuralSolver",
      "label": "Replace",
      "relation_type": "Replace",
      "data": {
        "relations": [
          {
            "type": "Replace",
            "structure": "Feature_Processing",
            "detail": "Replaced unit dependency graph with deep learning",
            "problem_addressed": "",
            "evidence": "UnitDep requires additional annotation overhead to induce UDGs, while DNS uses deep learning to automatically learn features (Roy et al., 2017).",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_6",
      "source": "Chiang2018_SemanticallyAlignedEquationGeneration",
      "target": "Zhang2019_DeepNeuralSolver",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Connections",
            "detail": "Extended semantically-aligned equation generation with deep learning",
            "problem_addressed": "",
            "evidence": "Semantically-Aligned Equation Generation uses LSTM and self-attention, while DNS extends this with a seq2seq model (Chiang et al., 2018).",
            "confidence": 0.87
          }
        ]
      }
    },
    {
      "id": "edge_7",
      "source": "AI2_2014",
      "target": "Math23K_2017",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Extended AI2 dataset with more complex problems",
            "problem_addressed": "",
            "evidence": "Math23K contains Chinese math word problems for elementary school students, extending the scope of AI2 (Wang et al., 2017).",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_8",
      "source": "IL_2015",
      "target": "Math23K_2017",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Extended IL dataset with more complex problems",
            "problem_addressed": "",
            "evidence": "Math23K contains Chinese math word problems for elementary school students, extending the scope of IL (Wang et al., 2017).",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_9",
      "source": "CC_2015",
      "target": "Math23K_2017",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Extended CC dataset with more complex problems",
            "problem_addressed": "",
            "evidence": "Math23K contains Chinese math word problems for elementary school students, extending the scope of CC (Wang et al., 2017).",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_10",
      "source": "Zhang2019_DeepNeuralSolver",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Deep Neural Solver (DNS) uses Math23K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "DNS is evaluated on Math23K, a large-scale dataset containing Chinese math word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_11",
      "source": "Wang2018_TranslatingMathWordProblem",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Math23K for evaluation",
            "problem_addressed": "",
            "evidence": "Translating Math Word Problem to Expression Tree was evaluated on the large-scale Math23K dataset (Wang et al., 2018).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_12",
      "source": "Wang2018_MathDQN",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Math23K for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the large-scale Math23K dataset (Wang et al., 2018).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_13",
      "source": "Huang2018_NeuralMathWordProblemSolver",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Math23K for evaluation",
            "problem_addressed": "",
            "evidence": "Neural Math Word Problem Solver was evaluated on the large-scale Math23K dataset (Huang et al., 2018).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_14",
      "source": "Zhang2019_DeepNeuralSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Deep Neural Solver (DNS) uses Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The accuracy of DNS is reported on various datasets.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_15",
      "source": "Wang2018_TranslatingMathWordProblem",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Used Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_16",
      "source": "Wang2018_MathDQN",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Used Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_17",
      "source": "Huang2018_NeuralMathWordProblemSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Use",
            "detail": "Used Accuracy for evaluation",
            "problem_addressed": "",
            "evidence": "Neural Math Word Problem Solver reports accuracy on various datasets (Huang et al., 2018).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_18",
      "source": "Seo2014_GeoSolver",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Dolphin18K for evaluation",
            "problem_addressed": "",
            "evidence": "GEOS was evaluated on the large-scale Dolphin18K dataset (Seo et al., 2015).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_19",
      "source": "Seo2015_GEOS",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "GEOS uses Dolphin18K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "GEOS is evaluated on Dolphin18K, a large-scale dataset for math word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_20",
      "source": "Huang2017_FGExpression",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Dolphin18K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The accuracies of existing approaches for equation set problems degrade sharply to less than 25%.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_21",
      "source": "Seo2014_DiagramUnderstanding",
      "target": "Seo2015_GEOS",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "Extended diagram understanding with text-parser",
            "problem_addressed": "",
            "evidence": "Diagram Understanding was extended to GEOS, which combines text and diagram parsing (Seo et al., 2015).",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_22",
      "source": "Seo2015_GEOS",
      "target": "Sachan2017_TextbookKnowledge",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Methodology.Training_Strategy",
            "detail": "Improved reasoning engine with axiomatic knowledge",
            "problem_addressed": "",
            "evidence": "GEOS was improved by harvesting axiomatic knowledge from textbooks (Sachan et al., 2017).",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_23",
      "source": "Seo2015_GEOS",
      "target": "Alvin2017_GeoShader",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "Extended with hypergraph for shaded area reasoning",
            "problem_addressed": "",
            "evidence": "GEOS was extended to GeoShader, which handles shaded area problems using hypergraph (Alvin et al., 2017).",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_24",
      "source": "AI2_2014",
      "target": "Dolphin18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Dolphin18K extends AI2 with a larger and more diverse dataset",
            "problem_addressed": "",
            "evidence": "Dolphin18K is so far the largest one, with 18,460 problems and 5,871 equation templates.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_25",
      "source": "IL_2015",
      "target": "Dolphin18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Extended IL dataset with more complex problems",
            "problem_addressed": "",
            "evidence": "Dolphin18K contains a large number of problems and templates, extending the scope of IL (Huang et al., 2016).",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_26",
      "source": "CC_2015",
      "target": "Dolphin18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Extended CC dataset with more complex problems",
            "problem_addressed": "",
            "evidence": "Dolphin18K contains a large number of problems and templates, extending the scope of CC (Huang et al., 2016).",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_27",
      "source": "ALG514_2014",
      "target": "Dolphin18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Dolphin18K extends ALG514 with a larger and more diverse dataset",
            "problem_addressed": "",
            "evidence": "Dolphin18K is so far the largest one, with 18,460 problems and 5,871 equation templates.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_28",
      "source": "Dolphin1878_2015",
      "target": "Dolphin18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Dolphin18K extends Dolphin1878 by including more problems and templates",
            "problem_addressed": "",
            "evidence": "Dolphin18K contains 18,460 problems and 5,871 templates, expanding the scope and diversity beyond Dolphin1878.",
            "confidence": 0.94
          }
        ]
      }
    },
    {
      "id": "edge_29",
      "source": "DRAW1K_2016",
      "target": "Dolphin18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Extended DRAW1K dataset with more complex problems",
            "problem_addressed": "",
            "evidence": "Dolphin18K contains a large number of problems and templates, extending the scope of DRAW1K (Huang et al., 2016).",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_30",
      "source": "Roy2015_ExpressionTree",
      "target": "Zhang2017_DeepNeuralSolver",
      "label": "Replace",
      "relation_type": "Replace",
      "data": {
        "relations": [
          {
            "type": "Replace",
            "structure": "Architecture.Mechanism",
            "detail": "Expression Tree's rule-based and tree-based approach replaced by Deep Neural Solver's neural sequence-to-sequence model",
            "problem_addressed": "",
            "evidence": "Deep Neural Solver (DNS) is the first deep learning based algorithm that does not rely on hand-crafted features... This is a milestone contribution because all the previous methods (including MathDQN) require human intelligence to help extract features that are effective.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_31",
      "source": "KoncelKedziorski2015_ALGES",
      "target": "Zhang2017_DeepNeuralSolver",
      "label": "Replace",
      "relation_type": "Replace",
      "data": {
        "relations": [
          {
            "type": "Replace",
            "structure": "Architecture.Mechanism",
            "detail": "ALGES's Integer Linear Programming and Beam Search replaced by DNS's neural sequence-to-sequence model",
            "problem_addressed": "",
            "evidence": "Deep Neural Solver (DNS) is the first deep learning based algorithm that does not rely on hand-crafted features... This is a milestone contribution because all the previous methods (including MathDQN) require human intelligence to help extract features that are effective.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_32",
      "source": "Huang2017_FGExpression",
      "target": "Zhang2017_DeepNeuralSolver",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Feature_Processing",
            "detail": "FG-Expression's fine-grained feature extraction optimized by DNS's end-to-end neural model",
            "problem_addressed": "",
            "evidence": "This is a milestone contribution because all the previous methods (including MathDQN) require human intelligence to help extract features that are effective.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_33",
      "source": "Wang2018_MathDQN",
      "target": "Zhang2017_DeepNeuralSolver",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology.Training_Strategy",
            "detail": "MathDQN extends DNS by incorporating deep reinforcement learning for arithmetic word problems",
            "problem_addressed": "",
            "evidence": "MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning... It formulates the expression tree construction as a Markov Decision Process and leverages the strengths of deep Q-network (DQN).",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_34",
      "source": "Seo2015_GEOS",
      "target": "Zhang2017_DeepNeuralSolver",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Task.Domain",
            "detail": "GEOS extends DNS by focusing on geometry word problems requiring text and diagram interpretation",
            "problem_addressed": "",
            "evidence": "GEOS: Solving Geometry Problems: Combining Text and Diagram Interpretation... It combines text and diagram interpretation to solve geometry word problems.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_35",
      "source": "Roy2015_ExpressionTree",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Expression Tree uses AI2 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "Expression Tree was evaluated on the AI2 dataset, which contains arithmetic word problems for third, fourth, and fifth graders.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_36",
      "source": "KoncelKedziorski2015_ALGES",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "ALGES uses AI2 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_37",
      "source": "Wang2018_MathDQN",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used AI2 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN is evaluated on AI2, IL, and CC datasets.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_38",
      "source": "Wang2018_MathDQN",
      "target": "IL_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "MathDQN evaluated on IL dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_39",
      "source": "Wang2018_MathDQN",
      "target": "CC_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "MathDQN evaluated on CC dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_40",
      "source": "Wang2018_MathDQN",
      "target": "SingleEQ_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MathDQN uses SingleEQ dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_41",
      "source": "Wang2018_MathDQN",
      "target": "AllArith_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MathDQN uses AllArith dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_42",
      "source": "Wang2018_MathDQN",
      "target": "Dolphin-S_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MathDQN uses Dolphin-S dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_43",
      "source": "Wang2018_MathDQN",
      "target": "MAWPS-S_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MathDQN uses MAWPS-S dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_44",
      "source": "Zhang2017_DeepNeuralSolver",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Deep Neural Solver uses Math23K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "Math23K is another large-scale dataset which contains Chinese math word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_45",
      "source": "Upadhyay2016_MixedSP",
      "target": "ALG514_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MixedSP uses ALG514 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_46",
      "source": "Upadhyay2016_MixedSP",
      "target": "DRAW1K_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MixedSP uses DRAW1K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_47",
      "source": "Yu2015_SyntaxSemanticsModel",
      "target": "Chinese_Arithmetic_Word_Problems_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Syntax-Semantics Model uses Chinese Arithmetic Word Problems dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_48",
      "source": "Zhang2017_DeepNeuralSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Use",
            "detail": "Deep Neural Solver uses Accuracy as an evaluation metric",
            "problem_addressed": "",
            "evidence": "The accuracies of existing approaches for equation set problems degrade sharply to less than 25%.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_49",
      "source": "Roy2015_ExpressionTree",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Use",
            "detail": "Expression Tree uses Accuracy as an evaluation metric",
            "problem_addressed": "",
            "evidence": "The accuracies of existing approaches for equation set problems degrade sharply to less than 25%.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_50",
      "source": "KoncelKedziorski2015_ALGES",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Use",
            "detail": "ALGES uses Accuracy as an evaluation metric",
            "problem_addressed": "",
            "evidence": "The accuracies of existing approaches for equation set problems degrade sharply to less than 25%.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_51",
      "source": "Huang2017_FGExpression",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Used Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_52",
      "source": "Seo2015_GEOS",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "GEOS uses Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The accuracy of GEOS is reported on Dolphin18K.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_53",
      "source": "Upadhyay2016_MixedSP",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "MixedSP uses Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The accuracy of MixedSP is reported on DRAW1K.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_54",
      "source": "Roy2015_ExpressionTree",
      "target": "Wang2018_TranslationToExpressionTree",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Connections",
            "detail": "Beam Search replaces Bottom-Up Construction",
            "problem_addressed": "",
            "evidence": "ExpressionTree uses beam search for efficiency concerns, while Wang2018_TranslationToExpressionTree employs a seq2seq model with beam search for better performance.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_55",
      "source": "ALGES2015_EquationTree",
      "target": "Wang2018_TranslationToExpressionTree",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "Expression Tree extended to Equation Tree",
            "problem_addressed": "",
            "evidence": "ALGES constructs equation trees, while Wang2018_TranslationToExpressionTree extends this idea to translate math word problems into expression trees.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_56",
      "source": "UnitDep2017_UnitDependencyGraph",
      "target": "Wang2018_TranslationToExpressionTree",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "Uses Unit Dependency Graph for feature extraction",
            "problem_addressed": "",
            "evidence": "UnitDep introduces unit dependency graphs for feature extraction, which Wang2018_TranslationToExpressionTree can utilize.",
            "confidence": 0.82
          }
        ]
      }
    },
    {
      "id": "edge_57",
      "source": "DNS2017_DeepNeuralSolver",
      "target": "Huang2017_NeuralMathWordProblemSolver",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanisms",
            "detail": "Adds fine-grained expressions and policy gradient",
            "problem_addressed": "",
            "evidence": "DNS2017_DeepNeuralSolver uses a seq2seq model, while Huang2017_NeuralMathWordProblemSolver extends this with fine-grained expressions and policy gradient for reinforcement learning.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_58",
      "source": "DNS2017_DeepNeuralSolver",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Deep Neural Solver uses Math23K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "DNS is evaluated on Math23K, a large-scale dataset containing Chinese math word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_59",
      "source": "Math23K_2017",
      "target": "Dolphin18K",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Dolphin18K is a larger and more diverse dataset",
            "problem_addressed": "",
            "evidence": "Dolphin18K contains 18,460 problems, expanding on the 23,162 problems in Math23K.",
            "confidence": 0.87
          }
        ]
      }
    },
    {
      "id": "edge_60",
      "source": "Huang2017_NeuralMathWordProblemSolver",
      "target": "Dolphin18K",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on Dolphin18K dataset",
            "problem_addressed": "",
            "evidence": "Huang2017_NeuralMathWordProblemSolver evaluates its performance on the Dolphin18K dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_61",
      "source": "Wang2018_MathDQN",
      "target": "MathDQN",
      "label": "Replace",
      "relation_type": "Replace",
      "data": {
        "relations": [
          {
            "type": "Replace",
            "structure": "Architecture.Mechanisms",
            "detail": "Replaces traditional methods with deep reinforcement learning",
            "problem_addressed": "",
            "evidence": "Wang2018_MathDQN uses deep Q-networks and reinforcement learning to solve arithmetic word problems, replacing traditional methods.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_62",
      "source": "CASS2018_ReinforcementLearningSolver",
      "target": "MathDQN",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Connections",
            "detail": "Introduces copy and alignment mechanisms",
            "problem_addressed": "",
            "evidence": "CASS2018_ReinforcementLearningSolver extends MathDQN by introducing copy and alignment mechanisms.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_63",
      "source": "Roy2015_ExpressionTree",
      "target": "IL_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on IL dataset",
            "problem_addressed": "",
            "evidence": "Roy2015_ExpressionTree evaluates its performance on the IL dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_64",
      "source": "Roy2015_ExpressionTree",
      "target": "CC_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on CC dataset",
            "problem_addressed": "",
            "evidence": "Roy2015_ExpressionTree evaluates its performance on the CC dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_65",
      "source": "ALGES2015_EquationTree",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on AI2 dataset",
            "problem_addressed": "",
            "evidence": "ALGES2015_EquationTree evaluates its performance on the AI2 dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_66",
      "source": "ALGES2015_EquationTree",
      "target": "IL_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on IL dataset",
            "problem_addressed": "",
            "evidence": "ALGES2015_EquationTree evaluates its performance on the IL dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_67",
      "source": "ALGES2015_EquationTree",
      "target": "CC_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on CC dataset",
            "problem_addressed": "",
            "evidence": "ALGES2015_EquationTree evaluates its performance on the CC dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_68",
      "source": "UnitDep2017_UnitDependencyGraph",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on AI2 dataset",
            "problem_addressed": "",
            "evidence": "UnitDep2017_UnitDependencyGraph evaluates its performance on the AI2 dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_69",
      "source": "UnitDep2017_UnitDependencyGraph",
      "target": "IL_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on IL dataset",
            "problem_addressed": "",
            "evidence": "UnitDep2017_UnitDependencyGraph evaluates its performance on the IL dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_70",
      "source": "UnitDep2017_UnitDependencyGraph",
      "target": "CC_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on CC dataset",
            "problem_addressed": "",
            "evidence": "UnitDep2017_UnitDependencyGraph evaluates its performance on the CC dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_71",
      "source": "CASS2018_ReinforcementLearningSolver",
      "target": "Dolphin18K",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on Dolphin18K dataset",
            "problem_addressed": "",
            "evidence": "CASS2018_ReinforcementLearningSolver evaluates its performance on the Dolphin18K dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_72",
      "source": "Wang2018_TranslationToExpressionTree",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on AI2 dataset",
            "problem_addressed": "",
            "evidence": "Wang2018_TranslationToExpressionTree evaluates its performance on the AI2 dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_73",
      "source": "Wang2018_TranslationToExpressionTree",
      "target": "IL_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on IL dataset",
            "problem_addressed": "",
            "evidence": "Wang2018_TranslationToExpressionTree evaluates its performance on the IL dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_74",
      "source": "Wang2018_TranslationToExpressionTree",
      "target": "CC_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Evaluates on CC dataset",
            "problem_addressed": "",
            "evidence": "Wang2018_TranslationToExpressionTree evaluates its performance on the CC dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_75",
      "source": "Chiang2018_SemanticallyAlignedEquationGeneration",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used AI2 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_76",
      "source": "Chiang2018_SemanticallyAlignedEquationGeneration",
      "target": "IL_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Semantically-Aligned Equation Generation evaluated on IL dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_77",
      "source": "Chiang2018_SemanticallyAlignedEquationGeneration",
      "target": "CC_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Semantically-Aligned Equation Generation evaluated on CC dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_78",
      "source": "AI2_2014",
      "target": "Dolphin18K",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Dolphin18K extends AI2 with a larger and more diverse dataset",
            "problem_addressed": "",
            "evidence": "Dolphin18K contains 18,460 problems and 5,871 templates, making it a larger and more diversified dataset compared to AI2.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_79",
      "source": "IL_2015",
      "target": "Dolphin18K",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Dolphin18K extends IL with a larger and more diverse dataset",
            "problem_addressed": "",
            "evidence": "Dolphin18K contains 18,460 problems and 5,871 templates, making it a larger and more diversified dataset compared to IL.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_80",
      "source": "CC_2015",
      "target": "Dolphin18K",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Dolphin18K extends CC with a larger and more diverse dataset",
            "problem_addressed": "",
            "evidence": "Dolphin18K contains 18,460 problems and 5,871 templates, making it a larger and more diversified dataset compared to CC.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_81",
      "source": "Huang2017_NeuralMathWordProblemSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "Neural Math Word Problem Solver evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Classification accuracy is a common metric for evaluating the performance of algorithms.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_82",
      "source": "Wang2018_TranslationToExpressionTree",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "Evaluates using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Wang2018_TranslationToExpressionTree reports accuracy on the AI2, IL, and CC datasets.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_83",
      "source": "Chiang2018_SemanticallyAlignedEquationGeneration",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Used Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_84",
      "source": "CASS2018_ReinforcementLearningSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "Evaluates using Accuracy metric",
            "problem_addressed": "",
            "evidence": "CASS2018_ReinforcementLearningSolver reports accuracy on the Dolphin18K dataset.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_85",
      "source": "Chang2013_L3M",
      "target": "Raghunathan2010_MultiPassSieve",
      "label": "Improve, Optimize",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "L3M model introduces latent variables and constraints to improve coreference resolution",
            "problem_addressed": "",
            "evidence": "We show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches as well as some structured prediction models proposed in the literature.",
            "confidence": 0.88
          },
          {
            "type": "Optimize",
            "structure": "Architecture.Connections",
            "detail": "L3M incorporates knowledge-based constraints into the coreference resolution process, enhancing the precision of the Multi-Pass Sieve approach",
            "problem_addressed": "",
            "evidence": "We show that L3M admits efficient inference and can be augmented with knowledge-based constraints; we also present a fast stochastic gradient based learning.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_86",
      "source": "Chen2014_NeuralParser",
      "target": "Roy2015_ARIS",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Task.Dataset",
            "detail": "Neural Dependency Parser is used for dependency parsing in the ARIS system",
            "problem_addressed": "",
            "evidence": "Our system, ARIS, analyzes each of the sentences in the problem statement to identify the relevant variables and their values.",
            "confidence": 0.75
          }
        ]
      }
    },
    {
      "id": "edge_87",
      "source": "Roy2015_ARIS",
      "target": "StandardPrimarySchoolTestQuestions",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Task.Dataset",
            "detail": "ARIS is evaluated on a corpus of standard primary school test questions",
            "problem_addressed": "",
            "evidence": "We report the first learning results on this task without reliance on pre-defined templates and make our data publicly available.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_88",
      "source": "Huang2016_LargeScaleDataset",
      "target": "YahooAnswers",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Task.Dataset",
            "detail": "Ranking SVM Model is evaluated on Yahoo! Answers dataset",
            "problem_addressed": "",
            "evidence": "Problems in the dataset are semi-automatically obtained from community question-answering (CQA) web pages.",
            "confidence": 0.89
          }
        ]
      }
    },
    {
      "id": "edge_89",
      "source": "Roy2018_DeclarativeKnowledge",
      "target": "Roy2015_ARIS",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Declarative Knowledge Mapping extends ARIS by incorporating declarative rules",
            "problem_addressed": "",
            "evidence": "Our method learns to map arithmetic word problem text to math expressions, by learning to select the relevant declarative knowledge for each operation of the solution expression.",
            "confidence": 0.87
          }
        ]
      }
    },
    {
      "id": "edge_90",
      "source": "Wang2017_DeepNeuralSolver",
      "target": "Roy2015_ARIS",
      "label": "Replace",
      "relation_type": "Replace",
      "data": {
        "relations": [
          {
            "type": "Replace",
            "structure": "Architecture.Mechanism",
            "detail": "Deep Neural Solver replaces ARIS with a neural sequence-to-sequence architecture",
            "problem_addressed": "",
            "evidence": "In contrast to previous statistical learning approaches, we directly translate math word problems to equation templates using a recurrent neural network (RNN) model.",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_91",
      "source": "Zhou2015_QuadraticProgramming",
      "target": "Kushman2014_AlgebraSolver",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Quadratic Programming improves upon Kushman et al.'s algebra solver by using a log-linear model",
            "problem_addressed": "",
            "evidence": "Experimental results show that our algorithm achieves 79.7% accuracy, about 10% higher than the state-of-the-art baseline (Kushman et al., 2014).",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_92",
      "source": "Roy2015_GeneralArithmetic",
      "target": "Roy2018_DeclarativeKnowledge",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "General Arithmetic Solver is extended by incorporating declarative knowledge",
            "problem_addressed": "",
            "evidence": "This paper presents a novel approach to automatically solving arithmetic word problems. This is the first algorithmic approach that can handle arithmetic problems with multiple steps and operations.",
            "confidence": 0.86
          }
        ]
      }
    },
    {
      "id": "edge_93",
      "source": "Seo2015_GEOS",
      "target": "SATGeometryQuestions",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Task.Dataset",
            "detail": "GEOS is evaluated on SAT geometry questions",
            "problem_addressed": "",
            "evidence": "In our experiments, GEOS achieves a 49% score on official SAT questions, and a score of 61% on practice questions.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_94",
      "source": "Wang2017_MathDQN",
      "target": "Roy2015_ARIS",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Mechanism",
            "detail": "MathDQN optimizes ARIS by using deep reinforcement learning",
            "problem_addressed": "",
            "evidence": "In this paper, we make the first attempt of applying deep reinforcement learning to solve arithmetic word problems.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_95",
      "source": "Roy2018_UnitDependencyGraph",
      "target": "Roy2015_ARIS",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Unit Dependency Graph extends ARIS by introducing a new component for handling units",
            "problem_addressed": "",
            "evidence": "This paper proposes a principled way to capture and reason about units and shows how it can benefit an arithmetic word problem solver.",
            "confidence": 0.89
          }
        ]
      }
    },
    {
      "id": "edge_96",
      "source": "Wang2019_SemanticallyAligned",
      "target": "Wang2017_DeepNeuralSolver",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Semantically-Aligned Equation Generation improves upon Deep Neural Solver by bridging symbolic and semantic worlds",
            "problem_addressed": "",
            "evidence": "Our model significantly outperforms both the state-of-the-art single model and the best non-retrieval-based model over about 10% accuracy.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_97",
      "source": "Wang2019_TemplateBased",
      "target": "Wang2017_DeepNeuralSolver",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Template-Based Solver extends Deep Neural Solver by using a tree-structure template",
            "problem_addressed": "",
            "evidence": "To reduce the number of templates and improve the accuracy of template prediction, we proposed equation normalization and operator encapsulation.",
            "confidence": 0.87
          }
        ]
      }
    },
    {
      "id": "edge_98",
      "source": "Wang2017_TranslationModel",
      "target": "Wang2017_DeepNeuralSolver",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Mechanism",
            "detail": "Translation Model optimizes Deep Neural Solver by normalizing equations",
            "problem_addressed": "",
            "evidence": "By considering the uniqueness of expression tree, we propose an equation normalization method to normalize the duplicated equations.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_99",
      "source": "Antol2015_VQA",
      "target": "VQADataset",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Task.Dataset",
            "detail": "VQA is evaluated on VQA Dataset",
            "problem_addressed": "",
            "evidence": "We provide a dataset containing ∼0.25M images, ∼0.76M questions, and ∼10M answers (www.visualqa.org), and discuss the information it provides.",
            "confidence": 0.94
          }
        ]
      }
    },
    {
      "id": "edge_100",
      "source": "Roy2015_ExpressionTree",
      "target": "MathDQN",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Mechanism",
            "detail": "ExpressionTree's beam search replaced by MathDQN's reinforcement learning",
            "problem_addressed": "",
            "evidence": "MathDQN models the tree construction as Markov Decision Process and leverages the strengths of deep Q-network (DQN). By using a two-layer feed-forward neural network as the deep Q-network to approximate the Q-value function, the framework learns model parameters from the reward feedback of the environment.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_101",
      "source": "Huang2017_FineGrainedExpressions",
      "target": "MathDQN",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology.Training_Strategy",
            "detail": "Fine-Grained Expressions' log-linear model extended by MathDQN's reinforcement learning",
            "problem_addressed": "",
            "evidence": "MathDQN uses reinforcement learning to improve the accuracy of solving arithmetic word problems, which can be seen as an extension of the log-linear model used in Fine-Grained Expressions.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_102",
      "source": "Wang2017_DeepNeuralSolver",
      "target": "MathDQN",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Connections",
            "detail": "Deep Neural Solver's seq2seq model optimized by MathDQN's deep Q-network",
            "problem_addressed": "",
            "evidence": "MathDQN iteratively picks the best operator for two selected quantities, which can be viewed as beam search with k=1 when exploiting candidate expression trees. Its deep Q-network acts as the operator classifier and guides the model to select the most promising operator for tree construction.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_103",
      "source": "Zhang2015_ExpressionTree",
      "target": "MathDQN",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Connections",
            "detail": "ExpressionTree's beam search replaced by MathDQN's reinforcement learning mechanism",
            "problem_addressed": "",
            "evidence": "MathDQN iteratively picks the best operator for two selected quantities, which can be viewed as beam search with k=1. Its deep Q-network acts as the operator classifier and guides the model to select the most promising operator for tree construction.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_104",
      "source": "Huang2017_FGExpression",
      "target": "Zhang2015_ExpressionTree",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Feature_Processing",
            "detail": "FG-Expression introduces fine-grained units and template fragments to enhance feature extraction",
            "problem_addressed": "",
            "evidence": "FG-Expression parses an equation template into fine-grained units, called template fragment. Each template is represented in a tree structure and each fragment represents a sub-tree rooted at an internal node.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_105",
      "source": "Wang2018_MathDQN",
      "target": "Zhang2015_ExpressionTree",
      "label": "Replace",
      "relation_type": "Replace",
      "data": {
        "relations": [
          {
            "type": "Replace",
            "structure": "Architecture.Mechanism",
            "detail": "MathDQN replaces ExpressionTree's binary classifier with a deep Q-network",
            "problem_addressed": "",
            "evidence": "MathDQN models the tree construction as Markov Decision Process and leverages the strengths of deep Q-network (DQN). By using a two-layer feed-forward neural network as the deep Q-network to approximate the Q-value function, the framework learns model parameters from the reward feedback of the environment.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_106",
      "source": "Roy2015_ALGES",
      "target": "Zhang2015_ExpressionTree",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "ALGES extends ExpressionTree by incorporating integer linear programming for syntactic validity",
            "problem_addressed": "",
            "evidence": "ALGES does not discard irrelevant quantities but enumerates all syntactically valid trees. Integer Linear Programming (ILP) is applied to enforce syntactic validity, type consistency, and domain-specific simplicity considerations.",
            "confidence": 0.89
          }
        ]
      }
    },
    {
      "id": "edge_107",
      "source": "Shi2015_DOL",
      "target": "Roy2015_ALGES",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "DOL extends ALGES by introducing a meaning representation language and CFG parser",
            "problem_addressed": "",
            "evidence": "DOL designs a meaning representation language called DOL and uses a context-free grammar (CFG) parser to transform textual sentences into DOL trees.",
            "confidence": 0.87
          }
        ]
      }
    },
    {
      "id": "edge_108",
      "source": "Upadhyay2016_MixedSP",
      "target": "Roy2015_ALGES",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Methodology.Training_Strategy",
            "detail": "MixedSP optimizes ALGES by using joint training with explicit and implicit supervision",
            "problem_addressed": "",
            "evidence": "MixedSP leverages a large number of algebra word problems with noisy and implicit supervision signals to improve a strong solver trained by fully annotated data.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_109",
      "source": "Seo2014_GeoSolver",
      "target": "Seo2015_GEOS",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Connections",
            "detail": "GeoSolver's diagram parser extended in GEOS to handle text and diagram interpretation",
            "problem_addressed": "",
            "evidence": "GEOS combines text and diagram interpretation to solve geometry problems, extending the capabilities of GeoSolver.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_110",
      "source": "Wang2017_DeepNeuralSolver",
      "target": "Zhang2015_ExpressionTree",
      "label": "Replace",
      "relation_type": "Replace",
      "data": {
        "relations": [
          {
            "type": "Replace",
            "structure": "Architecture.Components",
            "detail": "Deep Neural Solver replaces ExpressionTree's components with a GRU encoder and seq2seq model",
            "problem_addressed": "",
            "evidence": "Deep Neural Solver uses a GRU encoder and seq2seq model to translate math word problems into equation templates, reducing the need for hand-crafted features.",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_111",
      "source": "Yu2015_ChineseEquationSet",
      "target": "Zhang2015_ExpressionTree",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "Chinese Equation Set Problem Solver extends ExpressionTree for Chinese language",
            "problem_addressed": "",
            "evidence": "The Syntax-Semantics (S2) model extracts quantity relations from Chinese problems, allowing for better handling of Chinese language nuances.",
            "confidence": 0.86
          }
        ]
      }
    },
    {
      "id": "edge_112",
      "source": "Siyam2017_ArabicArithmetic",
      "target": "Zhang2015_ExpressionTree",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "Arabic Arithmetic Word Problem Solver extends ExpressionTree for Arabic language",
            "problem_addressed": "",
            "evidence": "The proposed techniques rely on verb categorization and syntactic parser customization for the Arabic language.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_113",
      "source": "Accuracy_Classification",
      "target": "F1_Score_Classification",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Metric.Category",
            "detail": "F1 Score extends Accuracy by considering both precision and recall",
            "problem_addressed": "",
            "evidence": "F1 Score is the harmonic mean of precision and recall, providing a more balanced evaluation metric.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_114",
      "source": "Precision_Classification",
      "target": "F1_Score_Classification",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Metric.Category",
            "detail": "F1 Score extends Precision by considering recall",
            "problem_addressed": "",
            "evidence": "F1 Score is the harmonic mean of precision and recall, providing a more balanced evaluation metric.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_115",
      "source": "Recall_Classification",
      "target": "F1_Score_Classification",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Metric.Category",
            "detail": "F1 Score extends Recall by considering precision",
            "problem_addressed": "",
            "evidence": "F1 Score is the harmonic mean of precision and recall, providing a more balanced evaluation metric.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_116",
      "source": "Zhang2015_ExpressionTree",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "ExpressionTree uses AI2 for evaluation",
            "problem_addressed": "",
            "evidence": "ExpressionTree was evaluated on the AI2 dataset, which contains 395 arithmetic word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_117",
      "source": "Zhang2015_ExpressionTree",
      "target": "IL_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "ExpressionTree uses IL for evaluation",
            "problem_addressed": "",
            "evidence": "ExpressionTree was evaluated on the IL dataset, which contains 562 single-step word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_118",
      "source": "Zhang2015_ExpressionTree",
      "target": "CC_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "ExpressionTree uses CC for evaluation",
            "problem_addressed": "",
            "evidence": "ExpressionTree was evaluated on the CC dataset, which contains 600 multi-step math problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_119",
      "source": "MathDQN",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MathDQN uses AI2 for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the AI2 dataset, which contains 395 arithmetic word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_120",
      "source": "MathDQN",
      "target": "IL_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MathDQN uses IL for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the IL dataset, which contains 562 single-step word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_121",
      "source": "MathDQN",
      "target": "CC_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MathDQN uses CC for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the CC dataset, which contains 600 multi-step math problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_122",
      "source": "Huang2017_FGExpression",
      "target": "Dolphin18K",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "FG-Expression uses Dolphin18K for evaluation",
            "problem_addressed": "",
            "evidence": "FG-Expression was evaluated on the Dolphin18K dataset, which contains 18,460 problems and 5,871 templates.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_123",
      "source": "Wang2017_DeepNeuralSolver",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Deep Neural Solver uses Math23K for evaluation",
            "problem_addressed": "",
            "evidence": "Deep Neural Solver was evaluated on the Math23K dataset, which contains 23,162 Chinese math word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_124",
      "source": "Seo2015_GEOS",
      "target": "Geometry_Problems",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "GEOS uses Geometry Problems for evaluation",
            "problem_addressed": "",
            "evidence": "GEOS was evaluated on a dataset of geometry problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_125",
      "source": "Chiang2018_SemanticallyAligned",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Semantically-Aligned Equation Generation uses Math23K for evaluation",
            "problem_addressed": "",
            "evidence": "Semantically-Aligned Equation Generation was evaluated on the Math23K dataset, which contains 23,162 Chinese math word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_126",
      "source": "Yu2015_ChineseEquationSet",
      "target": "Chinese_Math_Problems",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Chinese Equation Set Problem Solver uses Chinese Math Problems for evaluation",
            "problem_addressed": "",
            "evidence": "The Chinese Equation Set Problem Solver was evaluated on a dataset of Chinese math problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_127",
      "source": "Siyam2017_ArabicArithmetic",
      "target": "AI2_Translated_to_Arabic",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Arabic Arithmetic Word Problem Solver uses AI2 Translated to Arabic for evaluation",
            "problem_addressed": "",
            "evidence": "The Arabic Arithmetic Word Problem Solver was evaluated on a dataset translated from AI2 to Arabic.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_128",
      "source": "Chen2014_NeuralParser",
      "target": "Raghunathan2010_MultiPassSieve",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "Neural Dependency Parser extends the Multi-Pass Sieve by using neural networks for dependency parsing",
            "problem_addressed": "",
            "evidence": "Almost all current dependency parsers classify based on millions of sparse indicator features. Not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_129",
      "source": "Roy2015_ARIS",
      "target": "Roy2018_DeclarativeMapping",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Connections",
            "detail": "ARIS uses verb categorization for arithmetic word problems, which is extended by Declarative Mapping to include declarative rules for broader problem solving",
            "problem_addressed": "",
            "evidence": "This paper presents a novel approach to learning to solve simple arithmetic word problems. Our system, ARIS, analyzes each of the sentences in the problem statement to identify the relevant variables and their values.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_130",
      "source": "Huang2016_LargeScaleDataset",
      "target": "Huang2017_FineGrainedExpressions",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Metrics",
            "detail": "The large-scale dataset used in Huang2016 is extended to include fine-grained expressions for solving math word problems",
            "problem_addressed": "",
            "evidence": "We build a large-scale dataset which is more than 9 times the size of previous ones, and contains many more problem types.",
            "confidence": 0.89
          }
        ]
      }
    },
    {
      "id": "edge_131",
      "source": "Wang2017_DeepNeuralSolver",
      "target": "Wang2017_TemplateBasedSolver",
      "label": "Replace",
      "relation_type": "Replace",
      "data": {
        "relations": [
          {
            "type": "Replace",
            "structure": "Architecture.Mechanism",
            "detail": "Deep Neural Solver replaces the template-based approach with a neural sequence-to-sequence model",
            "problem_addressed": "",
            "evidence": "In contrast to previous statistical learning approaches, we directly translate math word problems to equation templates using a recurrent neural network (RNN) model, without sophisticated feature engineering.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_132",
      "source": "Zhou2015_QuadraticProgramming",
      "target": "Roy2015_GeneralArithmetic",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Mechanisms",
            "detail": "Quadratic Programming optimizes the decision surface for solving algebra word problems, which is used in General Arithmetic Solver",
            "problem_addressed": "",
            "evidence": "To obtain a robust decision surface, we train a log-linear model to make the margin between the correct assignments and the false ones as large as possible.",
            "confidence": 0.87
          }
        ]
      }
    },
    {
      "id": "edge_133",
      "source": "Roy2015_GeneralArithmetic",
      "target": "Roy2018_DeclarativeMapping",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Connections",
            "detail": "General Arithmetic Solver is extended by Declarative Mapping to incorporate declarative rules for better semantic alignment",
            "problem_addressed": "",
            "evidence": "We develop declarative rules which govern the translation of natural language description of these concepts to math expressions.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_134",
      "source": "Seo2015_GEOS",
      "target": "Seo2015_GEOS",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Architecture.Components",
            "detail": "GEOS uses both text understanding and diagram interpretation components",
            "problem_addressed": "",
            "evidence": "This paper introduces GEOS, the first automated system to solve unaltered SAT geometry questions by combining text understanding and diagram interpretation.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_135",
      "source": "Wang2017_MathDQN",
      "target": "Huang2018_ReinforcementLearning",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanisms",
            "detail": "MathDQN extends the use of reinforcement learning for solving arithmetic word problems",
            "problem_addressed": "",
            "evidence": "We propose incorporating copy and alignment mechanism to the sequence-to-sequence model (namely CASS) to address these shortcomings.",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_136",
      "source": "Wang2017_SemanticallyAligned",
      "target": "Wang2017_TemplateBasedSolver",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Connections",
            "detail": "Semantically-Aligned Equation Generation optimizes the template-based solver by aligning symbolic and semantic worlds",
            "problem_addressed": "",
            "evidence": "Our model significantly outperforms state-of-the-art single model and the best non-retrieval-based model over about 10% accuracy.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_137",
      "source": "Kwiatkowski2013_SemanticParsers",
      "target": "Seo2015_GEOS",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Connections",
            "detail": "Semantic Parsers with On-the-fly Ontology Matching extends the capabilities of GEOS for geometry problem solving",
            "problem_addressed": "",
            "evidence": "In this paper, we introduce a new semantic parsing approach that learns to resolve such ontological mismatches.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_138",
      "source": "Roy2015_ExpressionTree",
      "target": "Koncel-Kedziorski2015_ALGES",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Connections",
            "detail": "ALGES extends ExpressionTree by adopting a more comprehensive search space and using Integer Linear Programming for syntactic validity and type consistency checks",
            "problem_addressed": "",
            "evidence": "ALGES does not discard irrelevant quantities but enumerates all syntactically valid trees, and applies Integer Linear Programming to enforce constraints such as syntactic validity and type consistency.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_139",
      "source": "Koncel-Kedziorski2015_ALGES",
      "target": "Huang2017_FGExpression",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Components",
            "detail": "FG-Expression improves upon ALGES by parsing equation templates into fine-grained units and using a max-margin objective for training",
            "problem_addressed": "",
            "evidence": "FG-Expression parses an equation template into fine-grained units, called template fragments, and uses a max-margin objective to train the log-linear model.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_140",
      "source": "Zhang2017_DeepNeuralSolver",
      "target": "Wang2018_MathDQN",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Methodology.Training_Strategy",
            "detail": "MathDQN optimizes Deep Neural Solver by incorporating reinforcement learning and deep Q-networks",
            "problem_addressed": "",
            "evidence": "MathDQN models the tree construction as a Markov Decision Process and leverages the strengths of deep Q-network (DQN) to improve performance on multi-step problems.",
            "confidence": 0.94
          }
        ]
      }
    },
    {
      "id": "edge_141",
      "source": "Seo2014_GALINGER",
      "target": "Seo2015_GEOS",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "GEOS extends G-ALINGER by adding text and diagram parsing capabilities",
            "problem_addressed": "",
            "evidence": "GEOS combines text and diagram parsing to solve geometry problems, while G-ALINGER focuses on geometry understanding.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_142",
      "source": "Zhang2017_DeepNeuralSolver",
      "target": "Math23K_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Deep Neural Solver uses Math23K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The Deep Neural Solver was evaluated on the Math23K dataset, which contains Chinese math word problems for elementary school students.",
            "confidence": 0.98
          }
        ]
      }
    },
    {
      "id": "edge_143",
      "source": "Roy2015_ExpressionTree",
      "target": "IL_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Expression Tree uses IL dataset for evaluation",
            "problem_addressed": "",
            "evidence": "Expression Tree was evaluated on the IL dataset, which contains single-step word problems with one operator.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_144",
      "source": "Roy2015_ExpressionTree",
      "target": "CC_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Expression Tree uses CC dataset for evaluation",
            "problem_addressed": "",
            "evidence": "Expression Tree was evaluated on the CC dataset, which contains multi-step math problems.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_145",
      "source": "Koncel-Kedziorski2015_ALGES",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "ALGES uses AI2 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "ALGES was evaluated on the AI2 dataset, which contains arithmetic word problems for third, fourth, and fifth graders.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_146",
      "source": "Koncel-Kedziorski2015_ALGES",
      "target": "IL_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "ALGES uses IL dataset for evaluation",
            "problem_addressed": "",
            "evidence": "ALGES was evaluated on the IL dataset, which contains single-step word problems with one operator.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_147",
      "source": "Koncel-Kedziorski2015_ALGES",
      "target": "CC_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "ALGES uses CC dataset for evaluation",
            "problem_addressed": "",
            "evidence": "ALGES was evaluated on the CC dataset, which contains multi-step math problems.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_148",
      "source": "Wang2018_MathDQN",
      "target": "IL_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "MathDQN uses IL dataset for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the IL dataset, which contains single-step word problems with one operator.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_149",
      "source": "Wang2018_MathDQN",
      "target": "CC_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "MathDQN uses CC dataset for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the CC dataset, which contains multi-step math problems.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_150",
      "source": "Wang2018_MathDQN",
      "target": "SingleEQ",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "MathDQN uses SingleEQ dataset for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the SingleEQ dataset, which contains both single-step and multi-step arithmetic problems.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_151",
      "source": "Wang2018_MathDQN",
      "target": "AllArith",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "MathDQN uses AllArith dataset for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the AllArith dataset, which contains arithmetic word problems.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_152",
      "source": "Wang2018_MathDQN",
      "target": "Dolphin-S",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "MathDQN uses Dolphin-S dataset for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the Dolphin-S dataset, which contains arithmetic word problems.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_153",
      "source": "Wang2018_MathDQN",
      "target": "MAWPS-S",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "MathDQN uses MAWPS-S dataset for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN was evaluated on the MAWPS-S dataset, which contains arithmetic word problems.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_154",
      "source": "Seo2014_GALINGER",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "G-ALINGER evaluated on Dolphin18K dataset",
            "problem_addressed": "",
            "evidence": "The dataset contains 18,460 math problems and 5,871 templates with one or multiple equations.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_155",
      "source": "Seo2014_GALINGER",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "G-ALINGER uses Accuracy metric for evaluation",
            "problem_addressed": "",
            "evidence": "G-ALINGER was evaluated using the Accuracy metric, which measures the proportion of correctly solved problems.",
            "confidence": 0.98
          }
        ]
      }
    },
    {
      "id": "edge_156",
      "source": "IL_2014",
      "target": "Dolphin18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Dolphin18K extends IL with a larger and more diverse dataset",
            "problem_addressed": "",
            "evidence": "Dolphin18K is so far the largest one, with 18,460 problems and 5,871 equation templates.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_157",
      "source": "CC_2014",
      "target": "Dolphin18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Dolphin18K extends CC with a larger and more diverse dataset",
            "problem_addressed": "",
            "evidence": "Dolphin18K is so far the largest one, with 18,460 problems and 5,871 equation templates.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_158",
      "source": "Math23K_2014",
      "target": "Dolphin18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset",
            "detail": "Dolphin18K extends Math23K by providing a larger and more diverse dataset",
            "problem_addressed": "",
            "evidence": "Dolphin18K contains 18,460 problems and 5,871 templates, providing a larger and more diverse dataset compared to Math23K.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_159",
      "source": "Accuracy_Classification",
      "target": "Accuracy_Arithmetic",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Metric",
            "detail": "Accuracy_Arithmetic extends Accuracy_Classification for arithmetic word problems",
            "problem_addressed": "",
            "evidence": "Accuracy_Arithmetic measures the proportion of correctly solved arithmetic word problems, extending the general Accuracy metric.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_160",
      "source": "Accuracy_Classification",
      "target": "Accuracy_EquationSet",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Metric",
            "detail": "Accuracy_EquationSet extends Accuracy_Classification for equation set problems",
            "problem_addressed": "",
            "evidence": "Accuracy_EquationSet measures the proportion of correctly solved equation set problems, extending the general Accuracy metric.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_161",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanism",
            "detail": "L3M is extended to CL3M by adding domain knowledge-based constraints.",
            "problem_addressed": "",
            "evidence": "CL3M augments L3M with knowledge-based constraints following (Roth and Yih, 2004; Denis and Baldridge, 2007).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_162",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanisms",
            "detail": "L3M extended to PL3M by introducing a probabilistic model for mention-entity links",
            "problem_addressed": "",
            "evidence": "We generalize L3M to PL3M, which considers multiple left-links and captures the notion of a mention-to-cluster link.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_163",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "label": "Improve, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanisms",
            "detail": "CL3M extended to CPL3M by incorporating probabilistic modeling",
            "problem_addressed": "",
            "evidence": "We extend CL3M to CPL3M by incorporating the probabilistic mechanisms of PL3M.",
            "confidence": 0.95
          },
          {
            "type": "Improve",
            "structure": "Architecture.Component",
            "detail": "Integrated probabilistic model into constrained latent left linking model",
            "problem_addressed": "",
            "evidence": "The CL3M integrates the probabilistic model of PL3M while maintaining domain knowledge-based constraints.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_164",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "ACE2004",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "L3M evaluated on ACE 2004 dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_165",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Ontonotes5_2012",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "L3M evaluated on Ontonotes-5.0 dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_166",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "ACE2004",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "CL3M evaluated on ACE 2004 dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_167",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "Ontonotes5_2012",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "CL3M evaluated on Ontonotes-5.0 dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_168",
      "source": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "target": "ACE2004",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "PL3M evaluated on ACE 2004 dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_169",
      "source": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "target": "Ontonotes5_2012",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "PL3M evaluated on Ontonotes-5.0 dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_170",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "MUC_Coreference",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "L3M evaluated using MUC metric",
            "problem_addressed": "",
            "evidence": "We compare the systems using three popular metrics for coreference — MUC, BCUB, and Entity-based CEAF.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_171",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "BCUB_Coreference",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "L3M evaluated using BCUB metric",
            "problem_addressed": "",
            "evidence": "We compare the systems using three popular metrics for coreference — MUC, BCUB, and Entity-based CEAF.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_172",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "CEAF_EntityBased",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "L3M evaluated using Entity-based CEAF metric",
            "problem_addressed": "",
            "evidence": "We compare the systems using three popular metrics for coreference — MUC, BCUB, and Entity-based CEAF.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_173",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "MUC_Coreference",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "CL3M evaluated using MUC metric",
            "problem_addressed": "",
            "evidence": "We compare the systems using three popular metrics for coreference — MUC, BCUB, and Entity-based CEAF.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_174",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "BCUB_Coreference",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "CL3M evaluated using BCUB metric",
            "problem_addressed": "",
            "evidence": "We compare the systems using three popular metrics for coreference — MUC, BCUB, and Entity-based CEAF.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_175",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "CEAF_EntityBased",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "CL3M evaluated using Entity-based CEAF metric",
            "problem_addressed": "",
            "evidence": "We compare the systems using three popular metrics for coreference — MUC, BCUB, and Entity-based CEAF.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_176",
      "source": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "target": "MUC_Coreference",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "PL3M evaluated using MUC metric",
            "problem_addressed": "",
            "evidence": "We compare the systems using three popular metrics for coreference — MUC, BCUB, and Entity-based CEAF.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_177",
      "source": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "target": "BCUB_Coreference",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "PL3M evaluated using BCUB metric",
            "problem_addressed": "",
            "evidence": "We compare the systems using three popular metrics for coreference — MUC, BCUB, and Entity-based CEAF.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_178",
      "source": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "target": "CEAF_EntityBased",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "PL3M evaluated using Entity-based CEAF metric",
            "problem_addressed": "",
            "evidence": "We compare the systems using three popular metrics for coreference — MUC, BCUB, and Entity-based CEAF.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_179",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "Chang2013_LatentLeftLinkingModel",
      "label": "Improve, Extend",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Components",
            "detail": "CL3M improves upon L3M by incorporating constraints",
            "problem_addressed": "",
            "evidence": "CL3M, with just five constraints, compares favorably with other, more complicated, state-of-the-art algorithms on a variety of evaluation metrics.",
            "confidence": 0.95
          },
          {
            "type": "Extend",
            "structure": "Architecture.Mechanism",
            "detail": "The Constrained Latent Left-Linking Model extends the Latent Left-Linking Model by adding constraint injection.",
            "problem_addressed": "",
            "evidence": "The CL3M extends the L3M by adding constraint injection.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_180",
      "source": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "target": "Chang2013_LatentLeftLinkingModel",
      "label": "Improve, Extend",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanisms",
            "detail": "PL3M improves upon L3M by considering multiple left-links",
            "problem_addressed": "",
            "evidence": "PL3M, when tuning the value of γ, is a strictly more general model than L3M.",
            "confidence": 0.95
          },
          {
            "type": "Extend",
            "structure": "Architecture.Mechanisms",
            "detail": "PL3M extends L3M with probabilistic modeling",
            "problem_addressed": "",
            "evidence": "We present a probabilistic generalization of L3M that can take into account entity-mention links by considering multiple possible coreference links.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_181",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "Raghunathan2010_MultiPassSieve",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Methodology.Training_Strategy",
            "detail": "CL3M improves upon Multi-Pass Sieve by using a principled learning approach",
            "problem_addressed": "",
            "evidence": "Unlike the unsupervised learning approach of Multi-Pass Sieve, CL3M uses a principled max-margin approach.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_182",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Bengtson2008_PairwiseCoreferenceModel",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Connections",
            "detail": "L3M extends Best-Left-Link approach with latent structural SVM",
            "problem_addressed": "",
            "evidence": "L3M admits efficient inference, linking each mention to a previously occurring mention to its left, much like the existing best-left-link inference models.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_183",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Finley2005_SupervisedClustering",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Methodology.Training_Strategy",
            "detail": "L3M improves upon supervised clustering by using a max-margin approach",
            "problem_addressed": "",
            "evidence": "L3M uses a max-margin approach to learn w, achieving better performance compared to supervised clustering.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_184",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "Roth2004_LinearProgrammingFormulation",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanisms",
            "detail": "CL3M extends linear programming formulation with domain-specific constraints",
            "problem_addressed": "",
            "evidence": "CL3M augments L3M with knowledge-based constraints following Roth and Yih (2004).",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_185",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Yu2009_StructuralSVM",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanisms",
            "detail": "L3M extends latent structural SVM with stochastic gradient descent",
            "problem_addressed": "",
            "evidence": "We present a novel latent structural SVM approach, optimized using a fast stochastic gradient-based technique.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_186",
      "source": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "target": "Yu2009_StructuralSVM",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanisms",
            "detail": "PL3M extends latent structural SVM with probabilistic modeling",
            "problem_addressed": "",
            "evidence": "We present a probabilistic generalization of L3M that can take into account entity-mention links by considering multiple possible coreference links.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_187",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Goldberg2010_EasyFirstNonDirectionalParser",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Mechanism",
            "detail": "Neural Network Parser optimizes parsing by using dense features instead of sparse indicator features",
            "problem_addressed": "",
            "evidence": "Almost all current dependency parsers classify based on millions of sparse indicator features. Not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly. In this work, we propose a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_188",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "English_Penn_Treebank_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "The neural network parser is evaluated on the English Penn Treebank dataset.",
            "problem_addressed": "",
            "evidence": "We conduct our experiments on the English Penn Treebank(PTB) and the Chinese Penn Treebank (CTB) datasets.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_189",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Chinese_Penn_Treebank_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "The neural network parser is evaluated on the Chinese Penn Treebank dataset.",
            "problem_addressed": "",
            "evidence": "We conduct our experiments on the English Penn Treebank(PTB) and the Chinese Penn Treebank (CTB) datasets.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_190",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "UAS_Parsing",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "The neural network parser uses the Unlabeled Attachment Score (UAS) as an evaluation metric.",
            "problem_addressed": "",
            "evidence": "On all datasets, we report unlabeled attachment scores(UAS) and labeled attachment scores (LAS) and punctuation is excluded in all evaluation metrics.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_191",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "LAS_Parsing",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "The neural network parser uses the Labeled Attachment Score (LAS) as an evaluation metric.",
            "problem_addressed": "",
            "evidence": "On all datasets, we report unlabeled attachment scores(UAS) and labeled attachment scores (LAS) and punctuation is excluded in all evaluation metrics.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_192",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "MaltParser",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm.Architecture",
            "detail": "The neural network parser outperforms MaltParser in terms of both accuracy and speed.",
            "problem_addressed": "",
            "evidence": "Our parser even surpasses MaltParser using liblinear, which is known to be highly optimized, while our parser achieves much better accuracy.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_193",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "MSTParser",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm.Architecture",
            "detail": "The neural network parser outperforms MSTParser in terms of speed.",
            "problem_addressed": "",
            "evidence": "Despite the fact that the graph-based MST-Parser achieves a similar result to ours on PTB (CoNLL dependencies), our parser is nearly 100 times faster.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_194",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Zhang2011_TransitionBasedParser",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Algorithm.Architecture",
            "detail": "The neural network parser optimizes the transition-based dependency parsing approach by using dense features.",
            "problem_addressed": "",
            "evidence": "In this work, we address all of these problems by using dense features in place of the sparse indicator features.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_195",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Collobert2011_DeepLearningParsing",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Architecture",
            "detail": "The neural network parser extends the use of dense representations for parsing.",
            "problem_addressed": "",
            "evidence": "This is inspired by the recent success of distributed word representations in many NLP tasks, e.g., POS tagging(Collobert et al., 2011).",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_196",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Henderson2004_NeuralNetworkParser",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Architecture",
            "detail": "The neural network parser extends the use of neural networks for dependency parsing.",
            "problem_addressed": "",
            "evidence": "(Henderson, 2004) was the first to attempt to use neural networks in a broad-coverage Penn Treebank parser, using a simple synchrony network to predict parse decisions in a constituency parser.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_197",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Koo2008_HigherOrderFeatures",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm.FeatureProcessing",
            "detail": "The neural network parser improves upon higher-order feature usage by learning compact dense vector representations.",
            "problem_addressed": "",
            "evidence": "While in aggregate both lexicalized features and higher-order interaction term features are very important in improving the performance of these systems, nevertheless, there is insufficient data to correctly weight most such features.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_198",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Huang2013_FeatureSelection",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Algorithm.FeatureProcessing",
            "detail": "The neural network parser optimizes feature selection by using dense representations.",
            "problem_addressed": "",
            "evidence": "The use of many feature templates cause a less studied problem: in modern dependency parsers, most of the runtime is consumed not by the core parsing algorithm but in the feature extraction step.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_199",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "deMarneffe2006_TypedDependencyExtractor",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Algorithm.Component",
            "detail": "The neural network parser uses typed dependency representations.",
            "problem_addressed": "",
            "evidence": "We adopt two different dependency representations: CoNLL Syntactic Dependencies(CD) and Stanford Basic Dependencies(SD).",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_200",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Mikolov2013_SkipGram",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Algorithm.Component",
            "detail": "The neural network parser uses pre-trained word embeddings from Skip-gram.",
            "problem_addressed": "",
            "evidence": "We use the pre-trained word embeddings from(Collobert et al., 2011) for English and our trained 50-dimensional word2vec embeddings(Mikolov et al., 2013) on Wikipedia and Gigaword corpus for Chinese.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_201",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Hinton2012_Dropout",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Algorithm.Methodology",
            "detail": "The neural network parser uses dropout for regularization.",
            "problem_addressed": "",
            "evidence": "We also apply a dropout (Hinton et al., 2012) with 0.5 rate.",
            "confidence": 0.94
          }
        ]
      }
    },
    {
      "id": "edge_202",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Duchi2011_AdaptiveSubgradient",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Algorithm.Methodology",
            "detail": "The neural network parser uses AdaGrad for optimization.",
            "problem_addressed": "",
            "evidence": "We use mini-batched AdaGrad(Duchi et al., 2011) for optimization.",
            "confidence": 0.94
          }
        ]
      }
    },
    {
      "id": "edge_203",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Koo2008_SimpleSemiSupervised",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm.TrainingStrategy",
            "detail": "The neural network parser improves upon semi-supervised learning methods.",
            "problem_addressed": "",
            "evidence": "Simple semi-supervised dependency parsing(Terry Koo et al., 2008) has been successful in improving parsing performance.",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_204",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Socher2013_CompositionalVectorGrammar",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Architecture",
            "detail": "The neural network parser extends the use of compositional vector grammars.",
            "problem_addressed": "",
            "evidence": "There have been a number of recent uses of deep learning for constituency parsing(Collobert, 2011; Socher et al., 2013).",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_205",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Nivre2004_ArcStandardSystem",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Algorithm.Component",
            "detail": "The neural network parser uses the arc-standard system for transition-based parsing.",
            "problem_addressed": "",
            "evidence": "In the arc-standard system, a configuration c=(s, b, A) consists of a stack s, a buffer b, and a set of dependency arcs A.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_206",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Henderson2007_SigmoidBeliefNetworks",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm.Architecture",
            "detail": "The neural network parser improves upon previous neural network architectures for parsing.",
            "problem_addressed": "",
            "evidence": "These are very different neural network architectures, and are much less scalable and in practice a restricted vocabulary was used to make the architecture practical.",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_207",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Stenetorp2013_RecursiveNeuralNetworks",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm.Architecture",
            "detail": "The neural network parser improves upon recursive neural networks for transition-based dependency parsing.",
            "problem_addressed": "",
            "evidence": "Most recently,(Stenetorp, 2013) attempted to build recursive neural networks for transition-based dependency parsing, however the empirical performance of his model is still unsatisfactory.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_208",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Collins2003_HeadDrivenModel",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm.Architecture",
            "detail": "The neural network parser improves upon head-driven statistical models.",
            "problem_addressed": "",
            "evidence": "Almost all current dependency parsers classify based on millions of sparse indicator features. Not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly.",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_209",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "Haghighi2009_SimpleCoreferenceResolution",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Constrained Latent Left Linking Model improves upon Simple Coreference Resolution by incorporating domain knowledge-based constraints.",
            "problem_addressed": "",
            "evidence": "Our constrained latent left linking model incorporates domain knowledge-based constraints, which are not present in the simple coreference resolution model (Haghighi and Klein, 2009).",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_210",
      "source": "Sleator1993_LinkParser",
      "target": "Chen2014_NeuralNetworkParser",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Connections",
            "detail": "Neural network parser improves upon Link Parser by using dense representations and neural network mechanisms.",
            "problem_addressed": "",
            "evidence": "Our parser uses dense representations and neural network mechanisms, improving scalability and efficiency over constraint-based parsing methods like Link Parser.",
            "confidence": 0.87
          }
        ]
      }
    },
    {
      "id": "edge_211",
      "source": "Chen2014_NeuralNetworkParser",
      "target": "Garg2011_TemporalRestrictedBoltzmanMachine",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Neural network parser improves upon temporal restricted Boltzmann machines by using dense representations and a novel cube activation function.",
            "problem_addressed": "",
            "evidence": "Our parser builds on the transition-based dependency parser approach using a Temporal Restricted Boltzman Machine (Garg and Henderson, 2011) but uses dense representations and a novel cube activation function.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_212",
      "source": "Raghunathan2010_MultiPassSieve",
      "target": "Haghighi2009_SimpleCoreferenceResolution",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Multi-pass sieve architecture improves upon the single-pass model by applying tiers of coreference models from highest to lowest precision.",
            "problem_addressed": "",
            "evidence": "This approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones. To overcome this problem, we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_213",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Lin2017_StructuredSelfAttention",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Structured Self-attentive Sentence Embedding extends to include multi-hop attention mechanism",
            "problem_addressed": "",
            "evidence": "We propose a self-attention mechanism for these sequential models to replace the max pooling or averaging step. Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_214",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Liang2016_TagBasedSolver",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Components",
            "detail": "Structured Self-attentive Sentence Embedding improves upon Tag-based Solver by using a matrix embedding",
            "problem_addressed": "",
            "evidence": "We propose a self-attention mechanism for these sequential models to replace the max pooling or averaging step. Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_215",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Hochreiter1997_LongShortTermMemory",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Structured Self-attentive Sentence Embedding extends the use of LSTM by adding a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_216",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Age_Dataset_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model is evaluated on the Age dataset.",
            "problem_addressed": "",
            "evidence": "We evaluate our model on 3 different datasets: the Age dataset, the Yelp dataset, and the Stanford Natural Language Inference (SNLI) Corpus.",
            "confidence": 0.98
          }
        ]
      }
    },
    {
      "id": "edge_217",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Yelp_Dataset_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model is evaluated on the Yelp dataset.",
            "problem_addressed": "",
            "evidence": "We evaluate our model on 3 different datasets: the Age dataset, the Yelp dataset, and the Stanford Natural Language Inference (SNLI) Corpus.",
            "confidence": 0.98
          }
        ]
      }
    },
    {
      "id": "edge_218",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "SNLI_Corpus_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model is evaluated on the SNLI Corpus.",
            "problem_addressed": "",
            "evidence": "We evaluate our model on 3 different datasets: the Age dataset, the Yelp dataset, and the Stanford Natural Language Inference (SNLI) Corpus.",
            "confidence": 0.98
          }
        ]
      }
    },
    {
      "id": "edge_219",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model uses classification accuracy as an evaluation metric.",
            "problem_addressed": "",
            "evidence": "Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks. We use classification accuracy as a measurement.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_220",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Chen2014_NeuralNetworkParser",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon Neural Network Parser by incorporating self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_221",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "DosSantos2016_AttentivePoolingNetworks",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding extends attentive pooling networks by using a matrix embedding and a penalization term.",
            "problem_addressed": "",
            "evidence": "We propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_222",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Bowman2015_LargeAnnotatedCorpus",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model uses the SNLI Corpus for textual entailment task.",
            "problem_addressed": "",
            "evidence": "We use the biggest dataset in textual entailment, the SNLI corpus (Bowman et al., 2015) for our evaluation on this task.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_223",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "DosSantos2014_DeepConvolutionalNeuralNetworks",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon deep convolutional neural networks by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_224",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Feng2015_ApplyingDeepLearning",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon applying deep learning to answer selection by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_225",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Palangi2016_DeepSentenceEmbedding",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon deep sentence embedding using LSTM by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_226",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Munkhdalai2016_NeuralSemanticEncoders",
      "label": "Improve, Use",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon neural semantic encoders by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          },
          {
            "type": "Use",
            "structure": "Dataset.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model uses the SNLI Corpus for textual entailment task.",
            "problem_addressed": "",
            "evidence": "We use the biggest dataset in textual entailment, the SNLI corpus (Bowman et al., 2015) for our evaluation on this task.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_227",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Bowman2016_FastUnifiedModel",
      "label": "Improve, Use",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon fast unified model for parsing and sentence understanding by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          },
          {
            "type": "Use",
            "structure": "Dataset.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model uses the SNLI Corpus for textual entailment task.",
            "problem_addressed": "",
            "evidence": "We use the biggest dataset in textual entailment, the SNLI corpus (Bowman et al., 2015) for our evaluation on this task.",
            "confidence": 0.97
          }
        ]
      }
    },
    {
      "id": "edge_228",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Munkhdalai2016_NeuralTreeIndexers",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon neural tree indexers by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_229",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Tan2016_ImprovedRepresentationLearning",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon improved representation learning for question answer matching by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_230",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "label": "Improve, Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model uses the same datasets as Constrained Latent Left Linking Model.",
            "problem_addressed": "",
            "evidence": "Both models use the ACE 2004 and Ontonotes-5.0 datasets.",
            "confidence": 0.9
          },
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon constrained latent left linking model by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_231",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Mikolov2013_SkipGram",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "The Structured Self-attentive Sentence Embedding model uses word embeddings initialized with Skip-gram.",
            "problem_addressed": "",
            "evidence": "We use 100-dimensional word2vec as initialization for word embeddings, and tune the embedding during training across all of our experiments.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_232",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Pennington2014_GloVe",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "The Structured Self-attentive Sentence Embedding model uses GloVe for initializing word embeddings.",
            "problem_addressed": "",
            "evidence": "We use 300-dimensional GloVe word embedding to initialize word embeddings.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_233",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Hill2016_LearningDistributedRepresentations",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon learning distributed representations of sentences by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_234",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Lee2016_SequentialShortTextClassification",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon sequential short-text classification by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_235",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "label": "Improve, Use",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon probabilistic latent left linking model by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          },
          {
            "type": "Use",
            "structure": "Dataset.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model uses the same datasets as Probabilistic Latent Left Linking Model.",
            "problem_addressed": "",
            "evidence": "Both models use the ACE 2004 and Ontonotes-5.0 datasets.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_236",
      "source": "Lin2017_StructuredSelfAttentiveSentenceEmbedding",
      "target": "Chang2013_LatentLeftLinkingModel",
      "label": "Improve, Use",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Structured Self-attentive Sentence Embedding improves upon latent left linking model by using a self-attention mechanism.",
            "problem_addressed": "",
            "evidence": "Different from previous approaches, the proposed self-attention mechanism allows extracting different aspects of the sentence into multiple vector representations.",
            "confidence": 0.92
          },
          {
            "type": "Use",
            "structure": "Dataset.Task",
            "detail": "The Structured Self-attentive Sentence Embedding model uses the same datasets as Latent Left Linking Model.",
            "problem_addressed": "",
            "evidence": "Both models use the ACE 2004 and Ontonotes-5.0 datasets.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_237",
      "source": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "target": "Hajishirzi2013_NECO",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Component",
            "detail": "Adds domain knowledge-based constraints and probabilistic model to the constrained latent left linking model",
            "problem_addressed": "",
            "evidence": "The Constrained Latent Left Linking Model (CL3M) extends the Latent Left Linking Model (L3M) by incorporating domain knowledge-based constraints and a probabilistic model, which improves coreference resolution performance.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_238",
      "source": "Liang2016_TagBasedSolver",
      "target": "Hosseini2014_ARIS",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Tag-based approach improves upon ARIS by handling more problem types and being less sensitive to irrelevant information.",
            "problem_addressed": "",
            "evidence": "Many rule-based approaches only handle addition and subtraction math operations, but we can solve much more problems types, such as Multiplication, Division, Comparison, Algebra, etc. Also, it can handle much more problem types other than addition and subtraction.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_239",
      "source": "Liang2016_TagBasedSolver",
      "target": "Kushman2014_KAZB",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Tag-based approach improves upon KAZB by incorporating understanding and reasoning, leading to better performance on complex problems.",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information, which can be used to identify the desired operand and filter out irrelevant quantities.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_240",
      "source": "Liang2016_TagBasedSolver",
      "target": "MA1_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Liang et al.'s solver evaluated on MA1 dataset",
            "problem_addressed": "",
            "evidence": "The experiments are performed on the datasets MA1, MA2 and IXL provided by Hosseini et al. (2014)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_241",
      "source": "Liang2016_TagBasedSolver",
      "target": "MA2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Liang et al.'s solver evaluated on MA2 dataset",
            "problem_addressed": "",
            "evidence": "The experiments are performed on the datasets MA1, MA2 and IXL provided by Hosseini et al. (2014)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_242",
      "source": "Liang2016_TagBasedSolver",
      "target": "IXL_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Liang et al.'s solver evaluated on IXL dataset",
            "problem_addressed": "",
            "evidence": "The experiments are performed on the datasets MA1, MA2 and IXL provided by Hosseini et al. (2014)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_243",
      "source": "Liang2016_TagBasedSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "Liang et al.'s solver evaluated using classification accuracy",
            "problem_addressed": "",
            "evidence": "The performance of our system is compared with ARIS and KAZB in overall performance.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_244",
      "source": "Liang2016_TagBasedSolver",
      "target": "Solution_Type_Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "Liang et al.'s solver evaluated using solution type accuracy",
            "problem_addressed": "",
            "evidence": "The performance of our system is compared with ARIS and KAZB in overall performance.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_245",
      "source": "Liang2016_TagBasedSolver",
      "target": "Stanford_CoreNLP",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Tool",
            "detail": "Liang et al.'s solver uses Stanford CoreNLP for language analysis",
            "problem_addressed": "",
            "evidence": "The Stanford CoreNLP suite is adopted as our LA, which enables a list of annotators to generate the necessary linguistic information.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_246",
      "source": "Liang2016_TagBasedSolver",
      "target": "Charniak2000_MaximumEntropyParser",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Liang et al.'s solver extends Maximum Entropy Parser for solution type classification",
            "problem_addressed": "",
            "evidence": "A SVM classifier with linear kernel functions is used, and it adopted various feature-sets.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses maximum entropy parser for linguistic analysis",
            "problem_addressed": "",
            "evidence": "The Stanford CoreNLP suite is adopted as our LA, which enables a list of annotators to generate the necessary linguistic information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_247",
      "source": "Liang2016_TagBasedSolver",
      "target": "Chang2013_ConstrainedLatentLeftLinkingModel",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses constrained latent left linking model for co-reference resolution",
            "problem_addressed": "",
            "evidence": "Dependency relation and co-reference resolution will provide such information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_248",
      "source": "Liang2016_TagBasedSolver",
      "target": "Chang2013_ProbabilisticLatentLeftLinkingModel",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses probabilistic latent left linking model for co-reference resolution",
            "problem_addressed": "",
            "evidence": "Dependency relation and co-reference resolution will provide such information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_249",
      "source": "Liang2016_TagBasedSolver",
      "target": "Chang2013_LatentLeftLinkingModel",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses latent left linking model for co-reference resolution",
            "problem_addressed": "",
            "evidence": "Dependency relation and co-reference resolution will provide such information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_250",
      "source": "Liang2016_TagBasedSolver",
      "target": "Hosseini2014_VerbCategorization",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends verb categorization for better problem understanding",
            "problem_addressed": "",
            "evidence": "The STC selects a math operation based on the global information across various input sentences.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_251",
      "source": "Liang2016_TagBasedSolver",
      "target": "Roy2015_QuantityExtraction",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends quantity extraction for better operand identification",
            "problem_addressed": "",
            "evidence": "The proposed tag provides the flexibility for annotating a given math quantity with associated syntactic and semantic information.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses quantity extraction for operand identification",
            "problem_addressed": "",
            "evidence": "The proposed tag provides the flexibility for annotating a given math quantity with associated syntactic and semantic information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_252",
      "source": "Liang2016_TagBasedSolver",
      "target": "Roy2015_QuantityEntailment",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends quantity entailment for better reasoning",
            "problem_addressed": "",
            "evidence": "It analyzes the text and transforms both body and question parts into their tag-based logic forms, and then performs inference on them.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses quantity entailment for reasoning",
            "problem_addressed": "",
            "evidence": "It analyzes the text and transforms both body and question parts into their tag-based logic forms, and then performs inference on them.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_253",
      "source": "Liang2016_TagBasedSolver",
      "target": "Roy2015_MathWordProblemSolver",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends the cascade of classifiers for better solution generation",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses sparse averaged perceptron for classification",
            "problem_addressed": "",
            "evidence": "A SVM classifier with linear kernel functions is used, and it adopted various feature-sets.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_254",
      "source": "Liang2016_TagBasedSolver",
      "target": "Roy2017_UNITDEP",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends unit dependency graph for better problem solving",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses unit dependency graph for better problem solving",
            "problem_addressed": "",
            "evidence": "The proposed tag provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_255",
      "source": "Liang2016_TagBasedSolver",
      "target": "Roy2015_LCA++",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends LCA++ for better problem solving",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses LCA++ for better problem solving",
            "problem_addressed": "",
            "evidence": "The proposed tag provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_256",
      "source": "Liang2016_TagBasedSolver",
      "target": "Roy2016_ExpressionTreeBasedSolver",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends expression tree-based solver for better problem solving",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses expression tree-based solver for better problem solving",
            "problem_addressed": "",
            "evidence": "The proposed tag provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_257",
      "source": "Liang2016_TagBasedSolver",
      "target": "Roy2018_KNOWLEDGE",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends KNOWLEDGE for better declarative rule selection",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses KNOWLEDGE for better declarative rule selection",
            "problem_addressed": "",
            "evidence": "The proposed tag provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_258",
      "source": "Liang2016_TagBasedSolver",
      "target": "Charniak1968_CARPS",
      "label": "Improve, Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends CARPS for better problem solving",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses CARPS for linguistic analysis",
            "problem_addressed": "",
            "evidence": "The Stanford CoreNLP suite is adopted as our LA, which enables a list of annotators to generate the necessary linguistic information.",
            "confidence": 0.85
          },
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Liang et al.'s solver improves upon CARPS by incorporating tag-based annotation",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_259",
      "source": "Liang2016_TagBasedSolver",
      "target": "Charniak1969_ComputerSolution",
      "label": "Improve, Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Methodology",
            "detail": "Liang et al.'s solver extends computer solution for better problem solving",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Component",
            "detail": "Liang et al.'s solver uses computer solution for linguistic analysis",
            "problem_addressed": "",
            "evidence": "The Stanford CoreNLP suite is adopted as our LA, which enables a list of annotators to generate the necessary linguistic information.",
            "confidence": 0.85
          },
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Liang et al.'s solver improves upon computer solution by incorporating tag-based annotation",
            "problem_addressed": "",
            "evidence": "The proposed tag-based approach provides the flexibility for annotating an extracted math quantity with its associated syntactic and semantic information.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_260",
      "source": "Roy2015_LCA++",
      "target": "Roy2015_QuantityExtraction",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "LCA++ extends QuantityExtraction with additional components",
            "problem_addressed": "",
            "evidence": "The architecture of LCA++ includes components like Irrelevance Classifier and LCA Operation Classifier.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Architecture.Component",
            "detail": "Used quantity extraction techniques",
            "problem_addressed": "",
            "evidence": "LCA++ uses the quantity extraction techniques of Roy et al.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_261",
      "source": "Roy2015_LCA++",
      "target": "Roy2015_QuantityEntailment",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Integrated quantity entailment techniques",
            "problem_addressed": "",
            "evidence": "LCA++ extends the quantity entailment techniques of Roy et al.",
            "confidence": 0.9
          },
          {
            "type": "Use",
            "structure": "Architecture.Component",
            "detail": "Used quantity entailment techniques",
            "problem_addressed": "",
            "evidence": "LCA++ uses the quantity entailment techniques of Roy et al.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_262",
      "source": "Roy2015_LCA++",
      "target": "Roy2015_MathWordProblemSolver",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Integrated math word problem solving techniques",
            "problem_addressed": "",
            "evidence": "LCA++ extends the math word problem solving techniques of Roy et al.",
            "confidence": 0.9
          },
          {
            "type": "Use",
            "structure": "Architecture.Component",
            "detail": "Used math word problem solving techniques",
            "problem_addressed": "",
            "evidence": "LCA++ uses the math word problem solving techniques of Roy et al.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_263",
      "source": "Roy2015_LCA++",
      "target": "Roy2017_UNITDEP",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Integrated unit dependency graph techniques",
            "problem_addressed": "",
            "evidence": "LCA++ extends the unit dependency graph techniques of Roy et al.",
            "confidence": 0.9
          },
          {
            "type": "Use",
            "structure": "Architecture.Component",
            "detail": "Used unit dependency graph techniques",
            "problem_addressed": "",
            "evidence": "LCA++ uses the unit dependency graph techniques of Roy et al.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_264",
      "source": "Roy2015_LCA++",
      "target": "Roy2015_LCA++",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Architecture.Component",
            "detail": "Used LCA operation prediction techniques",
            "problem_addressed": "",
            "evidence": "LCA++ uses LCA operation prediction techniques.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_265",
      "source": "Roy2015_LCA++",
      "target": "Roy2016_ExpressionTreeBasedSolver",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Integrated expression tree-based solving techniques",
            "problem_addressed": "",
            "evidence": "LCA++ extends the expression tree-based solving techniques of Roy et al.",
            "confidence": 0.9
          },
          {
            "type": "Use",
            "structure": "Architecture.Component",
            "detail": "Used expression tree-based solving techniques",
            "problem_addressed": "",
            "evidence": "LCA++ uses the expression tree-based solving techniques of Roy et al.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_266",
      "source": "Roy2015_LCA++",
      "target": "Roy2018_KNOWLEDGE",
      "label": "Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Component",
            "detail": "Integrated declarative knowledge mapping techniques",
            "problem_addressed": "",
            "evidence": "LCA++ extends the declarative knowledge mapping techniques of Roy et al.",
            "confidence": 0.9
          },
          {
            "type": "Use",
            "structure": "Architecture.Component",
            "detail": "Used declarative knowledge mapping techniques",
            "problem_addressed": "",
            "evidence": "LCA++ uses the declarative knowledge mapping techniques of Roy et al.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_267",
      "source": "Hosseini2014_ARIS",
      "target": "MA1_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "ARIS uses MA1 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include 395 problems and 1,483 sentences in total. MA1 covers simple MWPs on addition and subtraction for third, fourth, and fifth graders.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_268",
      "source": "Hosseini2014_ARIS",
      "target": "MA2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "ARIS uses MA2 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "Problems in MA2 include more irrelevant information compared to the other two datasets.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_269",
      "source": "Hosseini2014_ARIS",
      "target": "IXL_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "ARIS uses IXL dataset for evaluation",
            "problem_addressed": "",
            "evidence": "IXL includes more information gaps.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_270",
      "source": "Hosseini2014_ARIS",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "ARIS uses Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The performance of our system is compared with ARIS which is a rule-based system that changes the entity attribute according to the schema.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_271",
      "source": "Kushman2014_KAZB",
      "target": "LinearT2",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "KAZB uses LinearT2 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include LinearT2 and LinearT6.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_272",
      "source": "Kushman2014_KAZB",
      "target": "LinearT6",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "KAZB uses LinearT6 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include LinearT2 and LinearT6.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_273",
      "source": "Kushman2014_KAZB",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "KAZB uses Accuracy as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include Accuracy.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_274",
      "source": "Roy2015_QuantityExtraction",
      "target": "RTE_Datasets_2006",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "QuantityExtraction uses RTE datasets for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include RTE Datasets and Newswire Text.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_275",
      "source": "Roy2015_QuantityExtraction",
      "target": "Newswire_Text_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "QuantityExtraction uses Newswire Text dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include RTE Datasets and Newswire Text.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_276",
      "source": "Roy2015_QuantityExtraction",
      "target": "F1_Score_Quantitative_Reasoning",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "QuantityExtraction uses F1 Score as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include F1 Score, Precision, and Recall.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_277",
      "source": "Roy2015_QuantityExtraction",
      "target": "Precision_Quantitative_Reasoning",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "QuantityExtraction uses Precision as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include F1 Score, Precision, and Recall.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_278",
      "source": "Roy2015_QuantityExtraction",
      "target": "Recall_Quantitative_Reasoning",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "QuantityExtraction uses Recall as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include F1 Score, Precision, and Recall.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_279",
      "source": "Roy2015_QuantityEntailment",
      "target": "RTE_Datasets_2006",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "QuantityEntailment uses RTE datasets for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include RTE Datasets and Newswire Text.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_280",
      "source": "Roy2015_QuantityEntailment",
      "target": "Newswire_Text_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "QuantityEntailment uses Newswire Text dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include RTE Datasets and Newswire Text.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_281",
      "source": "Roy2015_QuantityEntailment",
      "target": "F1_Score_Quantitative_Reasoning",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "QuantityEntailment uses F1 Score as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include F1 Score, Precision, and Recall.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_282",
      "source": "Roy2015_QuantityEntailment",
      "target": "Precision_Quantitative_Reasoning",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "QuantityEntailment uses Precision as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include F1 Score, Precision, and Recall.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_283",
      "source": "Roy2015_QuantityEntailment",
      "target": "Recall_Quantitative_Reasoning",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "QuantityEntailment uses Recall as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include F1 Score, Precision, and Recall.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_284",
      "source": "Roy2015_MathWordProblemSolver",
      "target": "Elementary_Math_Word_Problems_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "MathWordProblemSolver uses Elementary Math Word Problems dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include Elementary Math Word Problems.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_285",
      "source": "Roy2015_MathWordProblemSolver",
      "target": "Accuracy_MathProblemSolving",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "MathWordProblemSolver uses Accuracy as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include Accuracy.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_286",
      "source": "Roy2017_UNITDEP",
      "target": "AllArith_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "UNITDEP uses AllArith dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, and AllArithTmpl.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_287",
      "source": "Roy2017_UNITDEP",
      "target": "AllArithLex_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "UNITDEP uses AllArithLex dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, and AllArithTmpl.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_288",
      "source": "Roy2017_UNITDEP",
      "target": "AllArithTmpl_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "UNITDEP uses AllArithTmpl dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, and AllArithTmpl.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_289",
      "source": "Roy2017_UNITDEP",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "UNITDEP uses Accuracy as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include Accuracy.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_290",
      "source": "Roy2015_LCA++",
      "target": "AllArith_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "LCA++ uses AllArith dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, and AllArithTmpl.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_291",
      "source": "Roy2015_LCA++",
      "target": "AllArithLex_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "LCA++ uses AllArithLex dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, and AllArithTmpl.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_292",
      "source": "Roy2015_LCA++",
      "target": "AllArithTmpl_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "LCA++ uses AllArithTmpl dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, and AllArithTmpl.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_293",
      "source": "Roy2015_LCA++",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "LCA++ uses Accuracy as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include Accuracy.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_294",
      "source": "Roy2016_ExpressionTreeBasedSolver",
      "target": "AI2_Dataset_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "ExpressionTreeBasedSolver uses AI2 Dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AI2 Dataset, IL Dataset, and Commoncore Dataset.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_295",
      "source": "Roy2016_ExpressionTreeBasedSolver",
      "target": "IL_Dataset_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "ExpressionTreeBasedSolver uses IL Dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AI2 Dataset, IL Dataset, and Commoncore Dataset.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_296",
      "source": "Roy2016_ExpressionTreeBasedSolver",
      "target": "Commoncore_Dataset_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "ExpressionTreeBasedSolver uses Commoncore Dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AI2 Dataset, IL Dataset, and Commoncore Dataset.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_297",
      "source": "Roy2016_ExpressionTreeBasedSolver",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "ExpressionTreeBasedSolver uses Accuracy as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include Accuracy.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_298",
      "source": "Roy2018_KNOWLEDGE",
      "target": "AllArith_2018",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "KNOWLEDGE uses AllArith dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, AllArithTmpl, Perturb, and Aggregate.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_299",
      "source": "Roy2018_KNOWLEDGE",
      "target": "AllArithLex_2018",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "KNOWLEDGE uses AllArithLex dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, AllArithTmpl, Perturb, and Aggregate.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_300",
      "source": "Roy2018_KNOWLEDGE",
      "target": "AllArithTmpl_2018",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "KNOWLEDGE uses AllArithTmpl dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, AllArithTmpl, Perturb, and Aggregate.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_301",
      "source": "Roy2018_KNOWLEDGE",
      "target": "Perturb_2018",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "KNOWLEDGE uses Perturb dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, AllArithTmpl, Perturb, and Aggregate.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_302",
      "source": "Roy2018_KNOWLEDGE",
      "target": "Aggregate_2018",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Datasets",
            "detail": "KNOWLEDGE uses Aggregate dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The datasets include AllArith, AllArithLex, AllArithTmpl, Perturb, and Aggregate.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_303",
      "source": "Roy2018_KNOWLEDGE",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics",
            "detail": "KNOWLEDGE uses Accuracy as a metric",
            "problem_addressed": "",
            "evidence": "The metrics include Accuracy.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_304",
      "source": "Roy2018_KNOWLEDGE",
      "target": "Roy2015_QuantityExtraction",
      "label": "Improve, Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "KNOWLEDGE extends QuantityExtraction by incorporating declarative rules",
            "problem_addressed": "",
            "evidence": "The architecture components include Concept Selection and Declarative Rule Selection.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "KNOWLEDGE uses QuantityExtraction for feature processing",
            "problem_addressed": "",
            "evidence": "Feature processing includes Dependency Parsing, Coreference Resolution, Verb Classification, and Rate Component Detection.",
            "confidence": 0.85
          },
          {
            "type": "Improve",
            "structure": "Architecture.Mechanisms",
            "detail": "KNOWLEDGE improves QuantityExtraction by adding declarative rule selection",
            "problem_addressed": "",
            "evidence": "The mechanisms include Transfer, Dimensional Analysis, Part-Whole Relation, and Explicit Math.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_305",
      "source": "Roy2018_KNOWLEDGE",
      "target": "Roy2015_QuantityEntailment",
      "label": "Improve, Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "KNOWLEDGE extends QuantityEntailment by incorporating declarative rules",
            "problem_addressed": "",
            "evidence": "The architecture components include Concept Selection and Declarative Rule Selection.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "KNOWLEDGE uses QuantityEntailment for feature processing",
            "problem_addressed": "",
            "evidence": "Feature processing includes Dependency Parsing, Coreference Resolution, Verb Classification, and Rate Component Detection.",
            "confidence": 0.85
          },
          {
            "type": "Improve",
            "structure": "Architecture.Mechanisms",
            "detail": "KNOWLEDGE improves QuantityEntailment by adding declarative rule selection",
            "problem_addressed": "",
            "evidence": "The mechanisms include Transfer, Dimensional Analysis, Part-Whole Relation, and Explicit Math.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_306",
      "source": "Roy2018_KNOWLEDGE",
      "target": "Roy2015_MathWordProblemSolver",
      "label": "Improve, Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "KNOWLEDGE extends MathWordProblemSolver by incorporating declarative rules",
            "problem_addressed": "",
            "evidence": "The architecture components include Concept Selection and Declarative Rule Selection.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "KNOWLEDGE uses MathWordProblemSolver for feature processing",
            "problem_addressed": "",
            "evidence": "Feature processing includes Dependency Parsing, Coreference Resolution, Verb Classification, and Rate Component Detection.",
            "confidence": 0.85
          },
          {
            "type": "Improve",
            "structure": "Architecture.Mechanisms",
            "detail": "KNOWLEDGE improves MathWordProblemSolver by adding declarative rule selection",
            "problem_addressed": "",
            "evidence": "The mechanisms include Transfer, Dimensional Analysis, Part-Whole Relation, and Explicit Math.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_307",
      "source": "Roy2018_KNOWLEDGE",
      "target": "Roy2017_UNITDEP",
      "label": "Improve, Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "KNOWLEDGE extends UNITDEP by incorporating declarative rules",
            "problem_addressed": "",
            "evidence": "The architecture components include Concept Selection and Declarative Rule Selection.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "KNOWLEDGE uses UNITDEP for feature processing",
            "problem_addressed": "",
            "evidence": "Feature processing includes Dependency Parsing, Coreference Resolution, Verb Classification, and Rate Component Detection.",
            "confidence": 0.85
          },
          {
            "type": "Improve",
            "structure": "Architecture.Mechanisms",
            "detail": "KNOWLEDGE improves UNITDEP by adding declarative rule selection",
            "problem_addressed": "",
            "evidence": "The mechanisms include Transfer, Dimensional Analysis, Part-Whole Relation, and Explicit Math.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_308",
      "source": "Roy2018_KNOWLEDGE",
      "target": "Roy2015_LCA++",
      "label": "Improve, Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "KNOWLEDGE extends LCA++ by incorporating declarative rules",
            "problem_addressed": "",
            "evidence": "The architecture components include Concept Selection and Declarative Rule Selection.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "KNOWLEDGE uses LCA++ for feature processing",
            "problem_addressed": "",
            "evidence": "Feature processing includes Dependency Parsing, Coreference Resolution, Verb Classification, and Rate Component Detection.",
            "confidence": 0.85
          },
          {
            "type": "Improve",
            "structure": "Architecture.Mechanisms",
            "detail": "KNOWLEDGE improves LCA++ by adding declarative rule selection",
            "problem_addressed": "",
            "evidence": "The mechanisms include Transfer, Dimensional Analysis, Part-Whole Relation, and Explicit Math.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_309",
      "source": "Roy2018_KNOWLEDGE",
      "target": "Roy2016_ExpressionTreeBasedSolver",
      "label": "Improve, Use, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "KNOWLEDGE extends ExpressionTreeBasedSolver by incorporating declarative rules",
            "problem_addressed": "",
            "evidence": "The architecture components include Concept Selection and Declarative Rule Selection.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "KNOWLEDGE uses ExpressionTreeBasedSolver for feature processing",
            "problem_addressed": "",
            "evidence": "Feature processing includes Dependency Parsing, Coreference Resolution, Verb Classification, and Rate Component Detection.",
            "confidence": 0.85
          },
          {
            "type": "Improve",
            "structure": "Architecture.Mechanisms",
            "detail": "KNOWLEDGE improves ExpressionTreeBasedSolver by adding declarative rule selection",
            "problem_addressed": "",
            "evidence": "The mechanisms include Transfer, Dimensional Analysis, Part-Whole Relation, and Explicit Math.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_310",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Chen2014_NeuralNetworkParser",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "The neural network parser improves upon the easy-first non-directional dependency parsing algorithm by incorporating neural embeddings and transition-based parsing.",
            "problem_addressed": "",
            "evidence": "Our parser uses neural embeddings and a transition-based approach, which significantly outperforms traditional parsing algorithms such as the easy-first non-directional parser (Goldberg and Elhadad, 2010).",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_311",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "WSJ_Treebank_2010",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "The easy-first non-directional dependency parsing algorithm was evaluated on the WSJ Treebank.",
            "problem_addressed": "",
            "evidence": "We evaluate the parser using the WSJ Treebank. The trees were converted to dependency structures with the Penn2Malt conversion program.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_312",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "CoNLL_2007_English_dataset_2010",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "The easy-first non-directional dependency parsing algorithm was evaluated on the CoNLL 2007 English dataset.",
            "problem_addressed": "",
            "evidence": "We evaluated the parsers also on the English dataset from the CoNLL 2007 shared task.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_313",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "The easy-first non-directional dependency parsing algorithm uses accuracy as an evaluation metric.",
            "problem_addressed": "",
            "evidence": "We evaluate the parsers using three common measures: (unlabeled) Accuracy.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_314",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Root_Prediction",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "The easy-first non-directional dependency parsing algorithm uses root prediction as an evaluation metric.",
            "problem_addressed": "",
            "evidence": "Root: The percentage of sentences in which the ROOT attachment is correct.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_315",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Complete_Correct_Parse",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "The easy-first non-directional dependency parsing algorithm uses complete correct parse as an evaluation metric.",
            "problem_addressed": "",
            "evidence": "Complete: the percentage of sentences in which all tokens were assigned their correct parent.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_316",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "MALT",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm improves upon the MALT parser by addressing locality issues.",
            "problem_addressed": "",
            "evidence": "While all of their decisions are very local, and the strict left-to-right order implies that, while the feature set can use rich structural information from the left of the current attachment point, it is also very restricted in information to the right of the attachment point.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_317",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "MST",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm improves upon the MST parser by reducing computational complexity.",
            "problem_addressed": "",
            "evidence": "In terms of feature extraction and score calculation operations, our algorithm has the same cost as traditional shift-reduce(MALT) parsers, and is an order of magnitude more efficient than graph-based (MST) parsers.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_318",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Shen2007_BidirectionalIncrementalConstruction",
      "label": "Improve, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm extends the bidirectional incremental construction approach.",
            "problem_addressed": "",
            "evidence": "We build on top of that work and present a concrete and efficient greedy non-directional dependency parsing algorithm.",
            "confidence": 0.85
          },
          {
            "type": "Improve",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm improves upon the bidirectional incremental construction approach by optimizing the order of parsing actions.",
            "problem_addressed": "",
            "evidence": "The parser learns both the attachment preferences and the order in which they should be performed.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_319",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Nivre2004_ArcStandardSystem",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm improves upon the Arc-Standard system by allowing more flexible parsing order.",
            "problem_addressed": "",
            "evidence": "In contrast, our algorithm builds a dependency tree by iteratively selecting the best pair of neighbors to connect at each parsing step.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_320",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Huang2009_BilinguallyConstrainedParsing",
      "label": "Improve, Use, Extend",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm improves upon bilingually constrained parsing by incorporating richer structural features.",
            "problem_addressed": "",
            "evidence": "We extended that feature set to include the structure on both sides of the proposed attachment point.",
            "confidence": 0.85
          },
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "The easy-first non-directional dependency parsing algorithm uses feature templates similar to those in bilingually constrained parsing.",
            "problem_addressed": "",
            "evidence": "We extended that feature set to include the structure on both sides of the proposed attachment point.",
            "confidence": 0.9
          },
          {
            "type": "Extend",
            "structure": "Feature_Processing",
            "detail": "The easy-first non-directional dependency parsing algorithm extends bilingually constrained parsing by incorporating richer structural features.",
            "problem_addressed": "",
            "evidence": "We extended that feature set to include the structure on both sides of the proposed attachment point.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_321",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Zhang2008_BeamSearchParser",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm improves upon beam search parsers by reducing computational complexity.",
            "problem_addressed": "",
            "evidence": "Beam-search decoding for left-to-right parsers(Zhang and Clark, 2008) is also linear, but has an additional linear dependence on the beam-size. The reported results in(Zhang and Clark, 2008) use a beam size of 64, compared to our constant of k= 6.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_322",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Collins2002_DiscriminativeTraining",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Methodology",
            "detail": "The easy-first non-directional dependency parsing algorithm uses a structured perceptron for training.",
            "problem_addressed": "",
            "evidence": "We use a linear model score(x)=w~ · φ(x), where φ(x) is a feature representation andw~ is a weight vector. We write φact(i) to denote the feature representation extracted for action act at location i. The model is trained using a variant of the structured perceptron(Collins, 2002).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_323",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Nivre2006_MaltParser",
      "label": "Compare, Improve",
      "relation_type": "Compare",
      "data": {
        "relations": [
          {
            "type": "Compare",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm is compared to the MALT parser.",
            "problem_addressed": "",
            "evidence": "We evaluate our parser against the transition-based MALT parser and the graph-based MST parser.",
            "confidence": 0.9
          },
          {
            "type": "Improve",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm improves upon the MALT parser by addressing locality issues.",
            "problem_addressed": "",
            "evidence": "While all of their decisions are very local, and the strict left-to-right order implies that, while the feature set can use rich structural information from the left of the current attachment point, it is also very restricted in information to the right of the attachment point.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_324",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "McDonald2005_MSTParser",
      "label": "Compare, Improve",
      "relation_type": "Compare",
      "data": {
        "relations": [
          {
            "type": "Compare",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm is compared to the MST parser.",
            "problem_addressed": "",
            "evidence": "We evaluate our parser against the transition-based MALT parser and the graph-based MST parser.",
            "confidence": 0.9
          },
          {
            "type": "Improve",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm improves upon the MST parser by reducing computational complexity.",
            "problem_addressed": "",
            "evidence": "In terms of feature extraction and score calculation operations, our algorithm has the same cost as traditional shift-reduce(MALT) parsers, and is an order of magnitude more efficient than graph-based (MST) parsers.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_325",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "deMarneffe2006_TypedDependencyExtractor",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "The easy-first non-directional dependency parsing algorithm uses typed dependency extraction for feature processing.",
            "problem_addressed": "",
            "evidence": "We extended that feature set to include the structure on both sides of the proposed attachment point.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_326",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Sagae2006a_BestFirstProbabilisticParser",
      "label": "Improve, Compare",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm improves upon the best-first probabilistic parser by incorporating richer structural features.",
            "problem_addressed": "",
            "evidence": "Our non-directional easy-first parser significantly outperforms the left-to-right greedy MALT parser in terms of accuracy and root prediction, and significantly outperforms both parsers in terms of exact match.",
            "confidence": 0.85
          },
          {
            "type": "Compare",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm is compared to the best-first probabilistic parser.",
            "problem_addressed": "",
            "evidence": "While all models suffer from the move to the smaller dataset and the more challenging annotation scheme, the overall story remains the same: the non-directional parser is better than MALT but not as good as MST in terms of parent-accuracy and root prediction, and is better than both MALT and MST in terms of producing complete correct parses.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_327",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Sagae2006b_ParserCombination",
      "label": "Compare, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm extends the idea of parser combination by producing different structures.",
            "problem_addressed": "",
            "evidence": "The parses produced by the non-directional parser are different than the parses produced by the graph-based and left-to-right parsers.",
            "confidence": 0.85
          },
          {
            "type": "Compare",
            "structure": "Algorithm",
            "detail": "The easy-first non-directional dependency parsing algorithm is compared to parser combination methods.",
            "problem_addressed": "",
            "evidence": "A non-oracle blending of MALT+MST+NONDIR using Sagae and Lavie’s(2006) simplest combination method assigning each component the same weight, yield an accuracy of 90.8 on the CoNLL 2007 English dataset, making it the highest scoring system among the participants.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_328",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Nivre2007_SharedTask",
      "label": "Evaluate",
      "relation_type": "Evaluate",
      "data": {
        "relations": [
          {
            "type": "Evaluate",
            "structure": "Dataset",
            "detail": "The easy-first non-directional dependency parsing algorithm was evaluated in the CoNLL 2007 shared task.",
            "problem_addressed": "",
            "evidence": "We evaluated the parsers also on the English dataset from the CoNLL 2007 shared task.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_329",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Yamada2003_HeadFindingRules",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "The easy-first non-directional dependency parsing algorithm uses head-finding rules for feature processing.",
            "problem_addressed": "",
            "evidence": "The trees were converted to dependency structures with the Penn2Malt conversion program, using the head-finding rules from(Yamada and Matsumoto, 2003).",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_330",
      "source": "Goldberg2010_EasyFirstNonDirectionalParser",
      "target": "Carreras2007_ProjectivizationProcedure",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "The easy-first non-directional dependency parsing algorithm uses projectivization procedures for handling non-projective structures.",
            "problem_addressed": "",
            "evidence": "For the non-directional parser, we projectivize the training set prior to training using the procedure described in(Carreras, 2007).",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_331",
      "source": "Huang2017_FineGrainedInference",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Fine-Grained Inference algorithm uses the Dolphin18K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The Fine-Grained Inference algorithm is evaluated on the Dolphin18K dataset, which contains 18,460 math problems and 5,871 templates with one or multiple equations.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_332",
      "source": "Chang2013_L3M",
      "target": "ACE",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "L3M model evaluated on ACE dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_333",
      "source": "Chang2013_L3M",
      "target": "Ontonotes",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "L3M model evaluated on Ontonotes dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_334",
      "source": "Chang2013_L3M",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "L3M model evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_335",
      "source": "Chang2013_L3M",
      "target": "F1 Score",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "L3M model evaluated using F1 Score metric",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_336",
      "source": "Chang2013_L3M",
      "target": "Soon2001_PairwiseModel",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Algorithm.Improvement",
            "detail": "L3M model optimizes the pairwise mention model",
            "problem_addressed": "",
            "evidence": "Most machine learning approaches to coreference resolution learn a scoring function to estimate the compatibility between two mentions or two sets of previously clustered mentions. Then, a decoding algorithm is designed to aggregate these scores and find an optimal clustering assignment.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_337",
      "source": "Chang2013_L3M",
      "target": "Ng2002_PairwiseModel",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Algorithm.Improvement",
            "detail": "L3M model optimizes the pairwise mention model",
            "problem_addressed": "",
            "evidence": "Most machine learning approaches to coreference resolution learn a scoring function to estimate the compatibility between two mentions or two sets of previously clustered mentions. Then, a decoding algorithm is designed to aggregate these scores and find an optimal clustering assignment.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_338",
      "source": "Chang2013_L3M",
      "target": "Bengtson2008_FeatureSelection",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Feature",
            "detail": "L3M model extends feature selection with knowledge-based constraints",
            "problem_addressed": "",
            "evidence": "We show that L3M admits efficient inference and can be augmented with knowledge-based constraints.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_339",
      "source": "Chang2013_L3M",
      "target": "Roth2010_MultiPassSieve",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Architecture",
            "detail": "L3M model extends the multi-pass sieve architecture",
            "problem_addressed": "",
            "evidence": "We show that L3M admits efficient inference and can be augmented with knowledge-based constraints.",
            "confidence": 0.8
          }
        ]
      }
    },
    {
      "id": "edge_340",
      "source": "Roth2010_MultiPassSieve",
      "target": "ACE",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "Multi-pass sieve model evaluated on ACE dataset",
            "problem_addressed": "",
            "evidence": "In spite of its simplicity, our approach outperforms many state-of-the-art supervised",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_341",
      "source": "Roth2010_MultiPassSieve",
      "target": "Ontonotes",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "Multi-pass sieve model evaluated on Ontonotes dataset",
            "problem_addressed": "",
            "evidence": "In spite of its simplicity, our approach outperforms many state-of-the-art supervised",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_342",
      "source": "Roth2010_MultiPassSieve",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "Multi-pass sieve model evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "In spite of its simplicity, our approach outperforms many state-of-the-art supervised",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_343",
      "source": "Roth2010_MultiPassSieve",
      "target": "F1 Score",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "Multi-pass sieve model evaluated using F1 Score metric",
            "problem_addressed": "",
            "evidence": "In spite of its simplicity, our approach outperforms many state-of-the-art supervised",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_344",
      "source": "Roth2010_MultiPassSieve",
      "target": "Soon2001_PairwiseModel",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Algorithm.Improvement",
            "detail": "Multi-pass sieve model optimizes the pairwise mention model",
            "problem_addressed": "",
            "evidence": "This approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_345",
      "source": "Roth2010_MultiPassSieve",
      "target": "Ng2002_PairwiseModel",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Algorithm.Improvement",
            "detail": "Multi-pass sieve model optimizes the pairwise mention model",
            "problem_addressed": "",
            "evidence": "This approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_346",
      "source": "Roth2010_MultiPassSieve",
      "target": "Bengtson2008_FeatureSelection",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Feature",
            "detail": "Multi-pass sieve model extends feature selection with modular architecture",
            "problem_addressed": "",
            "evidence": "The framework is highly modular: new coreference modules can be plugged in without any change to the other modules.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_347",
      "source": "Roy2015_UnitDependencyGraph",
      "target": "Roy2015_ExpressionTree",
      "label": "Optimize, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Architecture",
            "detail": "Unit Dependency Graph extends the expression tree approach",
            "problem_addressed": "",
            "evidence": "Unit Dependency Graphs(UDGs) were proposed to better capture and reason about units.",
            "confidence": 0.9
          },
          {
            "type": "Optimize",
            "structure": "Algorithm.Improvement",
            "detail": "Unit Dependency Graph optimizes the expression tree approach",
            "problem_addressed": "",
            "evidence": "Unit Dependency Graphs(UDGs) were proposed to better capture and reason about units.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_348",
      "source": "Roy2015_UnitDependencyGraph",
      "target": "Math23K",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "Unit Dependency Graph evaluated on Math23K dataset",
            "problem_addressed": "",
            "evidence": "Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_349",
      "source": "Roy2015_UnitDependencyGraph",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "Unit Dependency Graph evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_350",
      "source": "Roy2015_UnitDependencyGraph",
      "target": "F1 Score",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "Unit Dependency Graph evaluated using F1 Score metric",
            "problem_addressed": "",
            "evidence": "Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_351",
      "source": "Roy2015_UnitDependencyGraph",
      "target": "Koncel2015_ExpressionTree",
      "label": "Optimize, Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Architecture",
            "detail": "Unit Dependency Graph extends the expression tree approach",
            "problem_addressed": "",
            "evidence": "Unit Dependency Graphs(UDGs) were proposed to better capture and reason about units.",
            "confidence": 0.9
          },
          {
            "type": "Optimize",
            "structure": "Algorithm.Improvement",
            "detail": "Unit Dependency Graph optimizes the expression tree approach",
            "problem_addressed": "",
            "evidence": "Unit Dependency Graphs(UDGs) were proposed to better capture and reason about units.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_352",
      "source": "ALGES2015_EquationTree",
      "target": "Wang2018_TranslatingMathWordProblem",
      "label": "Replace",
      "relation_type": "Replace",
      "data": {
        "relations": [
          {
            "type": "Replace",
            "structure": "Architecture.Component",
            "detail": "Equation Tree replaced by Seq2Seq model",
            "problem_addressed": "",
            "evidence": "ALGES adopts a more brutal-force manner to exploit all the possible equation trees... Consequently, its computation cost is dozens of times higher than that in [30], according to an efficiency evaluation in [17].",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_353",
      "source": "UnitDep2017_UnitDependencyGraph",
      "target": "Wang2018_TranslatingMathWordProblem",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Feature_Processing",
            "detail": "Unit Dependency Graph features optimized for Seq2Seq model",
            "problem_addressed": "",
            "evidence": "UnitDep can be viewed as an extension work of [30] by the same authors... Finally, the candidate graph G with the highest likelihood and rate-consistent with T is used to calculate the total score of T.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_354",
      "source": "Wang2018_TranslatingMathWordProblem",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Translating Math Word Problem to Expression Tree evaluated on AI2 dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_355",
      "source": "Wang2018_TranslatingMathWordProblem",
      "target": "IL_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Translating Math Word Problem to Expression Tree evaluated on IL dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_356",
      "source": "Wang2018_TranslatingMathWordProblem",
      "target": "CC_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Translating Math Word Problem to Expression Tree evaluated on CC dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_357",
      "source": "Huang2017_FineGrainedExpressions",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Fine-Grained Expressions uses Dolphin18K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "Fine-Grained Expressions is evaluated on Dolphin18K, a large-scale dataset for math word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_358",
      "source": "Seo2014_DiagramUnderstanding",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Diagram Understanding evaluated on AI2 dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_359",
      "source": "Seo2014_DiagramUnderstanding",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Diagram Understanding evaluated on Dolphin18K dataset",
            "problem_addressed": "",
            "evidence": "The dataset contains 18,460 math problems and 5,871 templates with one or multiple equations.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_360",
      "source": "Seo2015_GEOS",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "GEOS evaluated on AI2 dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_361",
      "source": "Seo2014_GALINGER",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "G-ALINGER evaluated on AI2 dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_362",
      "source": "Alvin2017_GeoShader",
      "target": "AI2_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "GeoShader evaluated on AI2 dataset",
            "problem_addressed": "",
            "evidence": "The accuracy of arithmetic word problems is evaluated on the datasets that are manually harvested and annotated from online websites.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_363",
      "source": "Alvin2017_GeoShader",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Dolphin18K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_364",
      "source": "Koncel-Kedziorski2015_ParsingAlgebraicWordProblems",
      "target": "ALG514_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Parsing Algebraic Word Problems evaluated on ALG514 dataset",
            "problem_addressed": "",
            "evidence": "The dataset is crawled from Algebra.com, a crowd-sourced tutoring website.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_365",
      "source": "Upadhyay2016_LearningFromExplicitImplicitSupervision",
      "target": "DRAW1K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Learning from Explicit and Implicit Supervision evaluated on DRAW1K dataset",
            "problem_addressed": "",
            "evidence": "The dataset contains 1,000 linear equation problems crawled and filtered from algebra.com.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_366",
      "source": "Sachan2017_FromTextbooksToKnowledge",
      "target": "Geometry_Textbooks",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "From Textbooks to Knowledge evaluated on Geometry Textbooks",
            "problem_addressed": "",
            "evidence": "The dataset contains geometry problems from textbooks.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_367",
      "source": "Yu2015_SyntaxSemanticsModel",
      "target": "Chinese_Arithmetic_Problems",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Syntax-Semantics Model evaluated on Chinese Arithmetic Problems",
            "problem_addressed": "",
            "evidence": "The dataset contains Chinese arithmetic word problems.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_368",
      "source": "Siya2017_ArabicArithmeticWordProblemsSolver",
      "target": "Arabic_Arithmetic_Problems",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Arabic Arithmetic Word Problems Solver evaluated on Arabic Arithmetic Problems",
            "problem_addressed": "",
            "evidence": "The dataset contains Arabic arithmetic word problems.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_369",
      "source": "Huang2017_NeuralMathWordProblemSolver",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset",
            "detail": "Neural Math Word Problem Solver evaluated on Dolphin18K dataset",
            "problem_addressed": "",
            "evidence": "The dataset contains 18,460 math problems and 5,871 templates with one or multiple equations.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_370",
      "source": "Seo2015_GEOS",
      "target": "Accuracy_Arithmetic",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "GEOS evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Proportion of correctly solved arithmetic word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_371",
      "source": "Seo2014_GALINGER",
      "target": "Accuracy_Arithmetic",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "G-ALINGER evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Proportion of correctly solved arithmetic word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_372",
      "source": "Alvin2017_GeoShader",
      "target": "Accuracy_Arithmetic",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "GeoShader evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Proportion of correctly solved arithmetic word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_373",
      "source": "Huang2017_FineGrainedExpressions",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Fine-Grained Expressions uses Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The accuracy of Fine-Grained Expressions is reported on Dolphin18K.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_374",
      "source": "Koncel-Kedziorski2015_ParsingAlgebraicWordProblems",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "Parsing Algebraic Word Problems evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Classification accuracy is a common metric for evaluating the performance of algorithms.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_375",
      "source": "Upadhyay2016_LearningFromExplicitImplicitSupervision",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "Learning from Explicit and Implicit Supervision evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Classification accuracy is a common metric for evaluating the performance of algorithms.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_376",
      "source": "Sachan2017_FromTextbooksToKnowledge",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "From Textbooks to Knowledge evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Classification accuracy is a common metric for evaluating the performance of algorithms.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_377",
      "source": "Yu2015_SyntaxSemanticsModel",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "Syntax-Semantics Model evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Classification accuracy is a common metric for evaluating the performance of algorithms.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_378",
      "source": "Siya2017_ArabicArithmeticWordProblemsSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric",
            "detail": "Arabic Arithmetic Word Problems Solver evaluated using Accuracy metric",
            "problem_addressed": "",
            "evidence": "Classification accuracy is a common metric for evaluating the performance of algorithms.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_379",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "ACE_2004",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "L3M algorithm is evaluated on the ACE 2004 dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE 2004(NIST, 2004).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_380",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Ontonotes-5.0_2012",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "L3M algorithm is evaluated on the Ontonotes-5.0 dataset",
            "problem_addressed": "",
            "evidence": "Experiments on Ontonotes-5.0(Pradhan et al., 2012).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_381",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "MUC",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "L3M algorithm performance measured by MUC metric",
            "problem_addressed": "",
            "evidence": "CL3M achieves the best result reported on Ontonotes-5.0 development set and essentially ties with(Fernandes et al., 2012) on the test set.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_382",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "BCUB",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "L3M algorithm performance measured by BCUB metric",
            "problem_addressed": "",
            "evidence": "CL3M is also the best algorithm on ACE and when evaluated on the gold mentions of Ontonotes.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_383",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "CEAF",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "L3M algorithm performance measured by CEAF metric",
            "problem_addressed": "",
            "evidence": "CL3M is also the best algorithm on ACE and when evaluated on the gold mentions of Ontonotes.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_384",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "High-ConfidenceCorpus_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Training",
            "detail": "L3M algorithm trained on high-confidence corpus",
            "problem_addressed": "",
            "evidence": "For learning with L3M, we do stochastic gradient descent with 5 passes over the data.",
            "confidence": 0.85
          }
        ]
      }
    },
    {
      "id": "edge_385",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "PennTreeBank_1993",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Training",
            "detail": "L3M algorithm potentially uses Penn Tree Bank for training",
            "problem_addressed": "",
            "evidence": "For learning with L3M, we do stochastic gradient descent with 5 passes over the data.",
            "confidence": 0.7
          }
        ]
      }
    },
    {
      "id": "edge_386",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "BLEU_Score_Translation",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "L3M algorithm indirectly uses BLEU score for evaluation",
            "problem_addressed": "",
            "evidence": "The BLEU score is used in related tasks such as translation.",
            "confidence": 0.6
          }
        ]
      }
    },
    {
      "id": "edge_387",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Perplexity_LanguageModeling",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "L3M algorithm indirectly uses perplexity for evaluation",
            "problem_addressed": "",
            "evidence": "Perplexity is used in related tasks such as language modeling.",
            "confidence": 0.6
          }
        ]
      }
    },
    {
      "id": "edge_388",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "F1_Score_Parsing",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Evaluation",
            "detail": "L3M algorithm indirectly uses F1 score for evaluation",
            "problem_addressed": "",
            "evidence": "F1 score is used in related tasks such as parsing.",
            "confidence": 0.6
          }
        ]
      }
    },
    {
      "id": "edge_389",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "WMT15_EnglishGerman_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Training",
            "detail": "L3M algorithm potentially uses WMT'15 English-German dataset for training",
            "problem_addressed": "",
            "evidence": "For learning with L3M, we do stochastic gradient descent with 5 passes over the data.",
            "confidence": 0.6
          }
        ]
      }
    },
    {
      "id": "edge_390",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "ImageCaptioning_2015",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Training",
            "detail": "L3M algorithm potentially uses Image Captioning dataset for training",
            "problem_addressed": "",
            "evidence": "For learning with L3M, we do stochastic gradient descent with 5 passes over the data.",
            "confidence": 0.6
          }
        ]
      }
    },
    {
      "id": "edge_391",
      "source": "Zhang2019_DeepNeuralSolver",
      "target": "Wang2018_TranslatingMathWordProblem",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Connections",
            "detail": "Optimized connections with Seq2Seq Model and Expression Tree",
            "problem_addressed": "",
            "evidence": "Seq2SeqET extended the idea of DNS by using expression tree as the output sequence. In other words, it applied seq2seq model to convert the problem text into an expression tree, which can be viewed as a template.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_392",
      "source": "Wang2018_TranslatingMathWordProblem",
      "target": "Math23K_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Math23K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "We implemented our own version of DNS and evaluated its performance on the large dataset.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_393",
      "source": "Wang2018_MathDQN",
      "target": "Roy2015_ExpressionTree",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Mechanism",
            "detail": "Optimized Expression Tree construction with Deep Q-Network and Reinforcement Learning",
            "problem_addressed": "",
            "evidence": "MathDQN models the tree construction as Markov Decision Process and leverages the strengths of deep Q-network (DQN).",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_394",
      "source": "Chiang2018_SemanticallyAlignedEquationGeneration",
      "target": "Roy2015_ExpressionTree",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanism",
            "detail": "Extended Expression Tree with LSTM Network and Self-Attention",
            "problem_addressed": "",
            "evidence": "It applies seq2seq model to infer the unknown variables in the expression tree in a recursive manner.",
            "confidence": 0.87
          }
        ]
      }
    },
    {
      "id": "edge_395",
      "source": "Huang2017_FGExpression",
      "target": "Kushman2014_TemplateBasedSolver",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Improved Template-Based Solver with Fine-grained Units and Template Fragment Mapping",
            "problem_addressed": "",
            "evidence": "FG-Expression parses an equation template into fine-grained units, called template fragment.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_396",
      "source": "CASS2018_ReinforcementLearning",
      "target": "Wang2017_DeepNeuralSolver",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Connections",
            "detail": "Optimized connections with Copy Mechanism and Alignment Mechanism",
            "problem_addressed": "",
            "evidence": "CASS adjusts the output sequence generation process by incorporating the copy and alignment mechanism.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_397",
      "source": "CASS2018_ReinforcementLearning",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Dolphin18K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "CASS further improved the accuracy on Dolphin18K to 29%",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_398",
      "source": "CASS2018_ReinforcementLearning",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Used Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_399",
      "source": "Seo2014_GEOREP",
      "target": "Seo2014_GEOS",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanism",
            "detail": "Extended GEOREP with text-diagram alignment and logical expression generation",
            "problem_addressed": "",
            "evidence": "GEOS can be considered as the first work to tackle a complete geometric word problem.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_400",
      "source": "Seo2014_GEOS",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Dolphin18K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "GEOS was evaluated on Dolphin18K.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_401",
      "source": "Seo2014_GEOS",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Used Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_402",
      "source": "Sachan2017_TextbookAxiomaticKnowledge",
      "target": "Seo2014_GEOS",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Architecture.Mechanism",
            "detail": "Improved GEOS with axiomatic knowledge extraction and reasoning engine",
            "problem_addressed": "",
            "evidence": "It harvests an axiomatic knowledge from 20 publicly available math textbooks and builds a more powerful reasoning engine.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_403",
      "source": "Sachan2017_TextbookAxiomaticKnowledge",
      "target": "Dolphin18K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Used Dolphin18K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_404",
      "source": "Sachan2017_TextbookAxiomaticKnowledge",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Used Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_405",
      "source": "Alvin2017_GeoShader",
      "target": "Seo2014_GEOS",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Mechanism",
            "detail": "Extended GEOS with Hypergraph Analysis for Shaded Area Geometry Problems",
            "problem_addressed": "",
            "evidence": "GeoShader presents an interesting reasoning technique based on analysis hypergraph.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_406",
      "source": "Alvin2017_GeoShader",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Used Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The performances of the equation set solvers on the existing datasets are reported in Table 4.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_407",
      "source": "Roy2015_ExpressionTree",
      "target": "Roy2015_QuantityPairFeatures",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "Used Quantity-pair Features for better feature extraction",
            "problem_addressed": "",
            "evidence": "The relationship between two quantities is helpful to determine their associated operator.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_408",
      "source": "Roy2015_ExpressionTree",
      "target": "Roy2015_ContextFeatures",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "Used Context-related Features for better feature extraction",
            "problem_addressed": "",
            "evidence": "The information embedded in the text window centered at a particular quantity can also provide important clues for solving math word problems.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_409",
      "source": "Roy2015_ExpressionTree",
      "target": "Roy2015_QuestionFeatures",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "Used Question-related Features for better feature extraction",
            "problem_addressed": "",
            "evidence": "Distinguishing features can also be derived from questions.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_410",
      "source": "Roy2015_ExpressionTree",
      "target": "Roy2015_VerbFeatures",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "Used Verb-related Features for better feature extraction",
            "problem_addressed": "",
            "evidence": "Verbs are important indicators for correct operator determination.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_411",
      "source": "Roy2015_ExpressionTree",
      "target": "Roy2015_GlobalFeatures",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Feature_Processing",
            "detail": "Used Global Features for better feature extraction",
            "problem_addressed": "",
            "evidence": "There are certain types of global features in the document-level proposed by existing solvers.",
            "confidence": 0.9
          }
        ]
      }
    },
    {
      "id": "edge_412",
      "source": "Chang2013_L3M",
      "target": "ACE_2013",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "L3M algorithm evaluated on ACE dataset",
            "problem_addressed": "",
            "evidence": "Experiments on ACE 2004 ... (Chang et al., 2013)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_413",
      "source": "Chang2013_L3M",
      "target": "Ontonotes_2013",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "L3M algorithm evaluated on Ontonotes dataset",
            "problem_addressed": "",
            "evidence": "Experiments on Ontonotes-5.0 ... (Chang et al., 2013)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_414",
      "source": "Chang2013_L3M",
      "target": "CL3M_2013",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Architecture",
            "detail": "CL3M extends L3M with constraints",
            "problem_addressed": "",
            "evidence": "We show that L3M admits efficient inference and can be augmented with knowledge-based constraints; we also present a fast stochastic gradient based learning. (Chang et al., 2013)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_415",
      "source": "CL3M_2013",
      "target": "ACE_2013",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "CL3M algorithm evaluated on ACE dataset",
            "problem_addressed": "",
            "evidence": "CL3M is also the best algorithm on ACE ... (Chang et al., 2013)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_416",
      "source": "CL3M_2013",
      "target": "Ontonotes_2013",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Evaluation",
            "detail": "CL3M algorithm evaluated on Ontonotes dataset",
            "problem_addressed": "",
            "evidence": "CL3M achieves the best result reported on Ontonotes-5.0 ... (Chang et al., 2013)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_417",
      "source": "Chang2013_L3M",
      "target": "Fernandes2012",
      "label": "Compare",
      "relation_type": "Compare",
      "data": {
        "relations": [
          {
            "type": "Compare",
            "structure": "Algorithm.Performance",
            "detail": "L3M compared with Fernandes et al. (2012)",
            "problem_addressed": "",
            "evidence": "CL3M essentially ties with (Fernandes et al., 2012) on the test set. (Chang et al., 2013)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_418",
      "source": "Chang2013_L3M",
      "target": "Soon2001",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Methodology",
            "detail": "L3M extends pairwise mention model",
            "problem_addressed": "",
            "evidence": "The most popular of these frameworks is the pairwise mention model (Soon et al., 2001; Ng and Cardie, 2002). In this paper, we describe the Latent Left Linking model (L3M) ... (Chang et al., 2013)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_419",
      "source": "Chang2013_L3M",
      "target": "Ng2002",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Methodology",
            "detail": "L3M extends pairwise mention model",
            "problem_addressed": "",
            "evidence": "The most popular of these frameworks is the pairwise mention model (Soon et al., 2001; Ng and Cardie, 2002). In this paper, we describe the Latent Left Linking model (L3M) ... (Chang et al., 2013)",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_420",
      "source": "Roy2015_ExpressionTree",
      "target": "ALGES_2015",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Connections",
            "detail": "ALGES extends Expression Tree by using Integer Linear Programming for more exhaustive tree enumeration",
            "problem_addressed": "",
            "evidence": "ALGES does not discard irrelevant quantities but enumerates all syntactically valid trees, using Integer Linear Programming to enforce constraints.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_421",
      "source": "Roy2015_ExpressionTree",
      "target": "MathDQN_2018",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Methodology.Training_Strategy",
            "detail": "MathDQN optimizes Expression Tree by using reinforcement learning for operator selection",
            "problem_addressed": "",
            "evidence": "MathDQN iteratively picks the best operator for two selected quantities using a deep Q-network, improving the tree construction process.",
            "confidence": 0.88
          }
        ]
      }
    },
    {
      "id": "edge_422",
      "source": "MathDQN_2018",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MathDQN uses Math23K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "MathDQN is evaluated on Math23K, a large-scale dataset containing Chinese math word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_423",
      "source": "MathDQN_2018",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "MathDQN uses Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The accuracy of MathDQN is reported on various datasets.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_424",
      "source": "Kushman2014_EquationSetSolver",
      "target": "ALG514_2014",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Equation Set Solver uses ALG514 dataset for evaluation",
            "problem_addressed": "",
            "evidence": "Equation Set Solver is evaluated on ALG514, a crowdsourced tutoring website dataset for algebra problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_425",
      "source": "Kushman2014_EquationSetSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Equation Set Solver uses Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The accuracy of Equation Set Solver is reported on ALG514.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_426",
      "source": "Sachan2017_TextbookAxiomaticKnowledge",
      "target": "Seo2015_GEOS",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Methodology.Training_Strategy",
            "detail": "Textbook Axiomatic Knowledge improves GEOS by leveraging structured axiomatic knowledge for logical inference",
            "problem_addressed": "",
            "evidence": "Textbook Axiomatic Knowledge builds a more powerful reasoning engine that leverages structured axiomatic knowledge for logical inference.",
            "confidence": 0.91
          }
        ]
      }
    },
    {
      "id": "edge_427",
      "source": "Alvin2017_GeoShader",
      "target": "Seo2015_GEOS",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "GeoShader extends GEOS by introducing an analysis hypergraph for solving shaded area geometry problems",
            "problem_addressed": "",
            "evidence": "GeoShader introduces an analysis hypergraph to solve geometry problems with shaded areas, enhancing the capabilities of GEOS.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_428",
      "source": "T_RNN2019_TemplateBasedSolver",
      "target": "Math23K_2017",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "Template-Based Solver with Recursive Neural Networks uses Math23K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "T-RNN is evaluated on Math23K, a large-scale dataset containing Chinese math word problems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_429",
      "source": "T_RNN2019_TemplateBasedSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Template-Based Solver with Recursive Neural Networks uses Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The accuracy of T-RNN is reported on Math23K.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_430",
      "source": "DNS2017_DeepNeuralSolver",
      "target": "Accuracy_Classification",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metrics.Use",
            "detail": "Deep Neural Solver uses Accuracy as a classification metric",
            "problem_addressed": "",
            "evidence": "The accuracy of DNS is reported on Math23K.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_431",
      "source": "DNS2014_DeepLearningModel",
      "target": "DNS2017_DeepNeuralSolver",
      "label": "Optimize",
      "relation_type": "Optimize",
      "data": {
        "relations": [
          {
            "type": "Optimize",
            "structure": "Architecture.Components",
            "detail": "DNS2017 optimizes DNS2014 by adding LSTM binary classification and similarity-based methods",
            "problem_addressed": "",
            "evidence": "DNS2017 builds a LSTM-based binary classification model to determine quantity relevance and integrates a similarity-based method for better performance.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_432",
      "source": "Dolphin18K_2016",
      "target": "Math23K_2017",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Size",
            "detail": "Math23K extends Dolphin18K by including more complex Chinese math word problems",
            "problem_addressed": "",
            "evidence": "Math23K contains 23,162 Chinese math word problems, expanding the scope and complexity beyond Dolphin18K.",
            "confidence": 0.94
          }
        ]
      }
    },
    {
      "id": "edge_433",
      "source": "Dolphin18K_2016",
      "target": "Dolphin-S_2017",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Dataset.Subset",
            "detail": "Dolphin-S is a subset of Dolphin18K with single and multiple operators",
            "problem_addressed": "",
            "evidence": "Dolphin-S is extracted from Dolphin18K, focusing on problems with single and multiple operators.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_434",
      "source": "Kushman2014_EquationSetSolver",
      "target": "EnhancedTemplateBasedSolver_2015",
      "label": "Improve",
      "relation_type": "Improve",
      "data": {
        "relations": [
          {
            "type": "Improve",
            "structure": "Methodology.Training_Strategy",
            "detail": "Enhanced Template-Based Solver improves Equation Set Solver by using max-margin objective and constraint generation algorithm",
            "problem_addressed": "",
            "evidence": "Enhanced Template-Based Solver uses max-margin objective and constraint generation algorithm to improve the training process.",
            "confidence": 0.92
          }
        ]
      }
    },
    {
      "id": "edge_435",
      "source": "Upadhyay2016_MixedSP",
      "target": "DRAW1K_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Use",
            "detail": "MixedSP uses DRAW1K dataset for evaluation",
            "problem_addressed": "",
            "evidence": "MixedSP is evaluated on DRAW1K, a dataset for arithmetic word problems with diverse vocabularies and equation systems.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_436",
      "source": "DNS2017_DeepNeuralSolver",
      "target": "DNS2014_DeepLearningModel",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Architecture.Components",
            "detail": "DNS2017 extends DNS2014 by adding LSTM binary classification and similarity-based methods",
            "problem_addressed": "",
            "evidence": "DNS2017 builds a LSTM-based binary classification model to determine quantity relevance and integrates a similarity-based method for better performance.",
            "confidence": 0.93
          }
        ]
      }
    },
    {
      "id": "edge_437",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Ontonotes-5.0_2013",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Application",
            "detail": "L3M algorithm is evaluated on the Ontonotes-5.0 dataset",
            "problem_addressed": "",
            "evidence": "Experiments on Ontonotes-5.0 (Pradhan et al., 2012) and ACE 2004 (NIST, 2004).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_438",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "ACE",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Application",
            "detail": "L3M algorithm is evaluated on the ACE dataset",
            "problem_addressed": "",
            "evidence": "Experiments on Ontonotes-5.0 (Pradhan et al., 2012) and ACE 2004 (NIST, 2004).",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_439",
      "source": "Wang2016_KnowledgePoweredWordEmbedding",
      "target": "VerbalIQTestQuestions_2016",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Application",
            "detail": "Knowledge-Powered Word Embedding algorithm is evaluated on Verbal IQ Test Questions dataset",
            "problem_addressed": "",
            "evidence": "Experimental results have shown that the proposed framework can not only outperform existing methods for solving verbal comprehension questions.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_440",
      "source": "Wang2016_KnowledgePoweredWordEmbedding",
      "target": "Accuracy_VerbalComprehension",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Application",
            "detail": "Knowledge-Powered Word Embedding algorithm uses Accuracy as an evaluation metric",
            "problem_addressed": "",
            "evidence": "Experimental results have shown that the proposed framework can not only outperform existing methods for solving verbal comprehension questions.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_441",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Application",
            "detail": "L3M algorithm uses Accuracy as an evaluation metric",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_442",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "F1 Score",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Application",
            "detail": "L3M algorithm uses F1 Score as an evaluation metric",
            "problem_addressed": "",
            "evidence": "Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_443",
      "source": "Chang2013_LatentLeftLinkingModel",
      "target": "CL3M",
      "label": "Extend",
      "relation_type": "Extend",
      "data": {
        "relations": [
          {
            "type": "Extend",
            "structure": "Algorithm.Variant",
            "detail": "CL3M is an extension of L3M with knowledge-based constraints",
            "problem_addressed": "",
            "evidence": "We show that L3M admits efficient inference and can be augmented with knowledge-based constraints; we also present a fast stochastic gradient based learning.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_444",
      "source": "CL3M",
      "target": "Ontonotes-5.0_2013",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Application",
            "detail": "CL3M algorithm is evaluated on the Ontonotes-5.0 dataset",
            "problem_addressed": "",
            "evidence": "CL3M achieves the best result reported on Ontonotes-5.0 development set and essentially ties with (Fernandes et al., 2012) on the test set.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_445",
      "source": "CL3M",
      "target": "ACE",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Dataset.Application",
            "detail": "CL3M algorithm is evaluated on the ACE dataset",
            "problem_addressed": "",
            "evidence": "CL3M is also the best algorithm on ACE and when evaluated on the gold mentions of Ontonotes.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_446",
      "source": "CL3M",
      "target": "Accuracy",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Application",
            "detail": "CL3M algorithm uses Accuracy as an evaluation metric",
            "problem_addressed": "",
            "evidence": "CL3M achieves the best result reported on Ontonotes-5.0 development set and essentially ties with (Fernandes et al., 2012) on the test set.",
            "confidence": 0.95
          }
        ]
      }
    },
    {
      "id": "edge_447",
      "source": "CL3M",
      "target": "F1 Score",
      "label": "Use",
      "relation_type": "Use",
      "data": {
        "relations": [
          {
            "type": "Use",
            "structure": "Metric.Application",
            "detail": "CL3M algorithm uses F1 Score as an evaluation metric",
            "problem_addressed": "",
            "evidence": "CL3M achieves the best result reported on Ontonotes-5.0 development set and essentially ties with (Fernandes et al., 2012) on the test set.",
            "confidence": 0.95
          }
        ]
      }
    }
  ],
  "task_id": null
}