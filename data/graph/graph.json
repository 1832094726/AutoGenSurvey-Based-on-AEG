{
  "nodes": [
    {
      "id": "HUANG2017_FINEGRAINEDEXPRESSIONS",
      "label": "Fine-grained Expressions",
      "type": "Algorithm",
      "year": 2017,
      "task": "Math Word Problem Solving",
      "node_type": "Algorithm"
    },
    {
      "id": "WANG2018_MATHDQN",
      "label": "MathDQN",
      "type": "Algorithm",
      "year": 2018,
      "task": "Math Word Problem Solving",
      "node_type": "Algorithm"
    },
    {
      "id": "WANG2017_DEEPNEURALSOLVER",
      "label": "Deep Neural Solver",
      "type": "Algorithm",
      "year": 2017,
      "task": "Math Word Problem Solving",
      "node_type": "Algorithm"
    },
    {
      "id": "ROY2015_EXPRESSIONTREE",
      "label": "Expression Tree",
      "type": "Algorithm",
      "year": 2015,
      "task": "Arithmetic Word Problem Solving",
      "node_type": "Algorithm"
    },
    {
      "id": "ALGES2015_EQUATIONTREE",
      "label": "ALGES",
      "type": "Algorithm",
      "year": 2015,
      "task": "Algebraic Word Problem Solving",
      "node_type": "Algorithm"
    },
    {
      "id": "WANG2018_SEQ2SEQET",
      "label": "Seq2SeqET",
      "type": "Algorithm",
      "year": 2018,
      "task": "Arithmetic Word Problem Solving",
      "node_type": "Algorithm"
    },
    {
      "id": "CHIANG2018_STACKDECODER",
      "label": "StackDecoder",
      "type": "Algorithm",
      "year": 2018,
      "task": "Arithmetic Word Problem Solving",
      "node_type": "Algorithm"
    },
    {
      "id": "WANG2019_T_RNN",
      "label": "T-RNN",
      "type": "Algorithm",
      "year": 2019,
      "task": "Arithmetic Word Problem Solving",
      "node_type": "Algorithm"
    },
    {
      "id": "DOLPHIN18K_2016",
      "label": "DOLPHIN18K_2016",
      "type": "Unknown",
      "node_type": "Unknown"
    },
    {
      "id": "ACCURACY_CLASSIFICATION",
      "label": "ACCURACY_CLASSIFICATION",
      "type": "Unknown",
      "node_type": "Unknown"
    },
    {
      "id": "AI2_2014",
      "label": "AI2_2014",
      "type": "Unknown",
      "node_type": "Unknown"
    },
    {
      "id": "ALG514_2014",
      "label": "ALG514_2014",
      "type": "Unknown",
      "node_type": "Unknown"
    }
  ],
  "edges": [
    {
      "source": "HUANG2017_FINEGRAINEDEXPRESSIONS",
      "target": "WANG2018_MATHDQN",
      "label": "Improve",
      "relation_type": "Improve",
      "structure": "MathDQN改进了Fine-grained Expressions的表达方式",
      "detail": "MathDQN通过引入深度强化学习框架，改进了Fine-grained Expressions的表达方式，提高了模型的准确性和泛化能力。",
      "evidence": "MathDQN models the tree construction as a Markov Decision Process and leverages the strengths of deep Q-network (DQN).",
      "confidence": 0.85
    },
    {
      "source": "WANG2017_DEEPNEURALSOLVER",
      "target": "WANG2018_SEQ2SEQET",
      "label": "Extend",
      "relation_type": "Extend",
      "structure": "Seq2SeqET扩展了Deep Neural Solver的表达树输出",
      "detail": "Seq2SeqET扩展了Deep Neural Solver的思想，使用表达树作为输出序列，进一步提高了模型的表现。",
      "evidence": "Seq2SeqET extended the idea of DNS by using expression tree as the output sequence. In other words, it applied seq2seq model to convert the problem text into an expression tree, which can be viewed as a template.",
      "confidence": 0.85
    },
    {
      "source": "WANG2017_DEEPNEURALSOLVER",
      "target": "WANG2018_MATHDQN",
      "label": "Improve",
      "relation_type": "Improve",
      "structure": "MathDQN改进了Deep Neural Solver的训练策略",
      "detail": "MathDQN使用深度强化学习来改进Deep Neural Solver的训练策略，提高了模型的泛化能力和鲁棒性。",
      "evidence": "MathDQN iteratively picks the best operator for two selected quantities. This procedure can be viewed as beam search with k=1 when exploiting candidate expression trees. Its deep Q-network acts as the operator classifier and guides the model to select the most promising operator for tree construction.",
      "confidence": 0.9
    },
    {
      "source": "WANG2017_DEEPNEURALSOLVER",
      "target": "WANG2019_T_RNN",
      "label": "Extend",
      "relation_type": "Extend",
      "structure": "T-RNN扩展了Deep Neural Solver的编码网络",
      "detail": "T-RNN通过引入双向LSTM和自注意力机制，扩展了Deep Neural Solver的编码网络，进一步提升了模型的性能。",
      "evidence": "First, an effective embedding network with Bi-LSTM and self attention is used to vectorize the quantities.",
      "confidence": 0.85
    },
    {
      "source": "WANG2017_DEEPNEURALSOLVER",
      "target": "CHIANG2018_STACKDECODER",
      "label": "Extend",
      "relation_type": "Extend",
      "structure": "StackDecoder扩展了Deep Neural Solver的解码器",
      "detail": "StackDecoder通过引入堆栈机制，扩展了Deep Neural Solver的解码器，增强了模型的语义理解能力。",
      "evidence": "Its encoder extracts semantic meanings of quantities in the question text and the decoder is equipped with a stack to facilitate tracking the semantic meanings of operands.",
      "confidence": 0.8
    },
    {
      "source": "ROY2015_EXPRESSIONTREE",
      "target": "WANG2018_MATHDQN",
      "label": "Improve",
      "relation_type": "Improve",
      "structure": "MathDQN改进了ExpressionTree的表达树构建方法",
      "detail": "MathDQN使用深度强化学习和马尔可夫决策过程来迭代选择最佳操作符，从而改进了ExpressionTree的表达树构建方法。",
      "evidence": "MathDQN models the tree construction as a Markov Decision Process and leverages the strengths of deep Q-network (DQN). By using a two-layer feed-forward neural network as the deep Q-network to approximate the Q-value function, the framework learns model parameters from the reward feedback of the environment. Consequently, the RL framework demonstrates higher generality and robustness than the other tree-based methods when handling complicated scenarios.",
      "confidence": 0.9
    },
    {
      "source": "ROY2015_EXPRESSIONTREE",
      "target": "ALGES2015_EQUATIONTREE",
      "label": "Extend",
      "relation_type": "Extend",
      "structure": "ALGES扩展了ExpressionTree的树结构",
      "detail": "ALGES通过引入整数线性规划（ILP）来扩展ExpressionTree的树结构，从而更好地处理多步问题。",
      "evidence": "ALGES exploits the whole search space to enumerate all the possible trees, whereas ExpressionTree and ALGES use beam search for efficiency concern.",
      "confidence": 0.8
    },
    {
      "source": "WANG2018_SEQ2SEQET",
      "target": "WANG2019_T_RNN",
      "label": "Improve",
      "relation_type": "Improve",
      "structure": "T-RNN改进了Seq2SeqET的编码和模板表示",
      "detail": "T-RNN通过引入双向LSTM和自注意力机制，改进了Seq2SeqET的编码和模板表示，进一步提升了模型的性能。",
      "evidence": "T-RNN can be viewed as an improvement of Seq2SeqET, in terms of quantity encoding, template representation and tree construction.",
      "confidence": 0.9
    },
    {
      "source": "ACCURACY_CLASSIFICATION",
      "target": "ACCURACY_CLASSIFICATION",
      "label": "Use",
      "relation_type": "Use",
      "structure": "多个算法使用了相同的评估指标",
      "detail": "多个算法如Fine-grained Expressions、MathDQN、Deep Neural Solver等都使用了分类准确率作为评估指标。",
      "evidence": "The metrics used in these algorithms include Accuracy_Classification.",
      "confidence": 0.95
    },
    {
      "source": "AI2_2014",
      "target": "DOLPHIN18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "structure": "Dolphin18K扩展了AI2的数据规模和多样性",
      "detail": "Dolphin18K包含了更多的数学问题，数据量更大，问题类型更加多样化，扩展了AI2的数据规模和多样性。",
      "evidence": "The harvested dataset is so far the largest one, with 18,460 problems and 5,871 equation templates. Since the dataset is collected from online forum, there could exist errors in the annotations and answers.",
      "confidence": 0.9
    },
    {
      "source": "ALG514_2014",
      "target": "DOLPHIN18K_2016",
      "label": "Extend",
      "relation_type": "Extend",
      "structure": "Dolphin18K扩展了ALG514的数据规模和多样性",
      "detail": "Dolphin18K包含了更多的数学问题，数据量更大，问题类型更加多样化，扩展了ALG514的数据规模和多样性。",
      "evidence": "The harvested dataset is so far the largest one, with 18,460 problems and 5,871 equation templates.",
      "confidence": 0.9
    }
  ]
}